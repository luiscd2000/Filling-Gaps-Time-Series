{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6197585c",
   "metadata": {},
   "source": [
    "# INITIAL WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a9bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "85862edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as skm\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9ec424ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "betb011_22 = pd.read_excel(\"BE_7_42647_2022_timeseries.xlsx\")\n",
    "betb011_23 = pd.read_excel(\"BE_7_42647_2023_timeseries.xlsx\")\n",
    "\n",
    "betr012_22 = pd.read_excel(\"BE_7_42119_2022_timeseries.xlsx\")\n",
    "betr012_23 = pd.read_excel(\"BE_7_42119_2023_timeseries.xlsx\")\n",
    "\n",
    "betb004_22 = pd.read_excel(\"BE_7_42253_2022_timeseries.xlsx\")\n",
    "betb004_23 = pd.read_excel(\"BE_7_42253_2023_timeseries.xlsx\")\n",
    "\n",
    "betr001_22 = pd.read_excel(\"BE_7_41247_2022_timeseries.xlsx\")\n",
    "betr001_23 = pd.read_excel(\"BE_7_41247_2023_timeseries.xlsx\")\n",
    "\n",
    "betmeu1_22 = pd.read_excel(\"BE_7_61521_2022_timeseries.xlsx\")\n",
    "betmeu1_23 = pd.read_excel(\"BE_7_61521_2023_timeseries.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "76d77cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "betb011 = pd.concat([betb011_22,betb011_23])\n",
    "betr012 = pd.concat([betr012_22,betr012_23])\n",
    "betb004 = pd.concat([betb004_22,betb004_23])\n",
    "betr001 = pd.concat([betr001_22,betr001_23])\n",
    "betmeu1 = pd.concat([betmeu1_22,betmeu1_23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "818dc6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_remove = ['AirQualityStation','Countrycode','Namespace','AirQualityNetwork','SamplingProcess','SamplingPoint','Sample','AirPollutantCode','AveragingTime','UnitOfMeasurement','Validity','Verification']\n",
    "betb011 = betb011.drop(columns=columns_remove)\n",
    "betr012 = betr012.drop(columns=columns_remove)\n",
    "betb004 = betb004.drop(columns=columns_remove)\n",
    "betr001 = betr001.drop(columns=columns_remove)\n",
    "betmeu1 = betmeu1.drop(columns=columns_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf7400d",
   "metadata": {},
   "source": [
    "This is done to have a copy of the original data to perform other interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "35a351b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "betb011_ori = betb011.copy()\n",
    "betr012_ori = betr012.copy()\n",
    "betb004_ori = betb004.copy()\n",
    "betr001_ori = betr001.copy()\n",
    "betmeu1_ori = betmeu1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "84c6291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "betb011_ori2 = betb011.copy()\n",
    "betb011_nn = betb011.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c0d44771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_35856\\2765411853.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n"
     ]
    }
   ],
   "source": [
    "# List of datasets\n",
    "datasets = [betb011_ori, betr012_ori, betb004_ori, betr001_ori, betmeu1_ori]\n",
    "\n",
    "# Apply the transformation to each dataset\n",
    "for data in datasets:\n",
    "    data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')\n",
    "    data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'].str.replace(r' [+-]\\d{2}:\\d{2}', ''), format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7dc7744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformations to each dataset\n",
    "for data in datasets:\n",
    "    data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'])\n",
    "    data = data.sort_values(by='DatetimeBegin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a3793",
   "metadata": {},
   "source": [
    "# Now we preprocess. Remove variables we dont need and make new variables such as weekend or not and add days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "21b96409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concentration</th>\n",
       "      <th>DatetimeBegin</th>\n",
       "      <th>DatetimeEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.5</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>2022-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2022-01-01 05:00:00</td>\n",
       "      <td>2022-01-01 06:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Concentration       DatetimeBegin         DatetimeEnd\n",
       "0           34.0 2022-01-01 01:00:00 2022-01-01 02:00:00\n",
       "1           36.5 2022-01-01 02:00:00 2022-01-01 03:00:00\n",
       "2           37.0 2022-01-01 03:00:00 2022-01-01 04:00:00\n",
       "3           35.0 2022-01-01 04:00:00 2022-01-01 05:00:00\n",
       "4           33.0 2022-01-01 05:00:00 2022-01-01 06:00:00"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove = ['AirQualityStationEoICode', 'AirPollutant']\n",
    "data = data.drop(columns=columns_to_remove)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3f5a0ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Concentration       DatetimeBegin         DatetimeEnd  Year  Month  Day  \\\n",
      "0           34.0 2022-01-01 01:00:00 2022-01-01 02:00:00  2022      1    1   \n",
      "1           36.5 2022-01-01 02:00:00 2022-01-01 03:00:00  2022      1    1   \n",
      "2           37.0 2022-01-01 03:00:00 2022-01-01 04:00:00  2022      1    1   \n",
      "3           35.0 2022-01-01 04:00:00 2022-01-01 05:00:00  2022      1    1   \n",
      "4           33.0 2022-01-01 05:00:00 2022-01-01 06:00:00  2022      1    1   \n",
      "\n",
      "       Time  \n",
      "0  01:00:00  \n",
      "1  02:00:00  \n",
      "2  03:00:00  \n",
      "3  04:00:00  \n",
      "4  05:00:00  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'DatetimeBegin' and 'DatetimeEnd' columns to datetime objects\n",
    "data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'])\n",
    "data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'])\n",
    "\n",
    "# Extract year, month, day, and time into separate columns\n",
    "data['Year'] = data['DatetimeBegin'].dt.year\n",
    "data['Month'] = data['DatetimeBegin'].dt.month\n",
    "data['Day'] = data['DatetimeBegin'].dt.day\n",
    "data['Time'] = data['DatetimeBegin'].dt.time\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8f47e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'DatetimeBegin' and 'DatetimeEnd' columns to datetime objects\n",
    "data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'])\n",
    "data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'])\n",
    "\n",
    "# Extract day of the week\n",
    "data['DayOfWeek'] = (data['DatetimeBegin'].dt.weekday + 1) % 7\n",
    "\n",
    "# Create a new column indicating whether the day is a weekend or not\n",
    "data['Weekend'] = (data['DatetimeBegin'].dt.dayofweek // 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e2e613fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concentration</th>\n",
       "      <th>DatetimeBegin</th>\n",
       "      <th>DatetimeEnd</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.5</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>2022-01-01 05:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2022-01-01 05:00:00</td>\n",
       "      <td>2022-01-01 06:00:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Concentration       DatetimeBegin         DatetimeEnd  Year  Month  Day  \\\n",
       "0           34.0 2022-01-01 01:00:00 2022-01-01 02:00:00  2022      1    1   \n",
       "1           36.5 2022-01-01 02:00:00 2022-01-01 03:00:00  2022      1    1   \n",
       "2           37.0 2022-01-01 03:00:00 2022-01-01 04:00:00  2022      1    1   \n",
       "3           35.0 2022-01-01 04:00:00 2022-01-01 05:00:00  2022      1    1   \n",
       "4           33.0 2022-01-01 05:00:00 2022-01-01 06:00:00  2022      1    1   \n",
       "\n",
       "       Time  DayOfWeek  Weekend  \n",
       "0  01:00:00          6        1  \n",
       "1  02:00:00          6        1  \n",
       "2  03:00:00          6        1  \n",
       "3  04:00:00          6        1  \n",
       "4  05:00:00          6        1  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba13fe7",
   "metadata": {},
   "source": [
    "##### Now we make the data daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b5573a36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month  Day  Concentration  DayOfWeek  Weekend\n",
      "0  2022      1    1      34.826087          6        1\n",
      "1  2022      1    2      44.717391          0        1\n",
      "2  2022      1    3      58.812500          1        0\n",
      "3  2022      1    4      52.604167          2        0\n",
      "4  2022      1    5      35.173913          3        0\n"
     ]
    }
   ],
   "source": [
    "# Convert 'DatetimeBegin' and 'DatetimeEnd' columns to datetime objects\n",
    "data['DatetimeBegin'] = pd.to_datetime(data['DatetimeBegin'])\n",
    "data['DatetimeEnd'] = pd.to_datetime(data['DatetimeEnd'])\n",
    "\n",
    "# Remove the 'Time' column\n",
    "data.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# Group by 'Year', 'Month', and 'Day', and calculate the daily average concentration\n",
    "data = data.groupby(['Year', 'Month', 'Day']).agg({'Concentration': 'mean', 'DayOfWeek': 'first', 'Weekend': 'first'}).reset_index()\n",
    "\n",
    "# Display the daily dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a05380e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 648 entries, 0 to 647\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Year           648 non-null    int64  \n",
      " 1   Month          648 non-null    int64  \n",
      " 2   Day            648 non-null    int64  \n",
      " 3   Concentration  627 non-null    float64\n",
      " 4   DayOfWeek      648 non-null    int64  \n",
      " 5   Weekend        648 non-null    int32  \n",
      "dtypes: float64(1), int32(1), int64(4)\n",
      "memory usage: 28.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c760f5",
   "metadata": {},
   "source": [
    "### Now we make a new variable based on the optimal SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e8af6d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month  Day  Concentration  DayOfWeek  Weekend       Date\n",
      "0  2022      1    1      34.826087          6        1 2022-01-01\n",
      "1  2022      1    2      44.717391          0        1 2022-01-02\n",
      "2  2022      1    3      58.812500          1        0 2022-01-03\n",
      "3  2022      1    4      52.604167          2        0 2022-01-04\n",
      "4  2022      1    5      35.173913          3        0 2022-01-05\n"
     ]
    }
   ],
   "source": [
    "data['Date'] = pd.to_datetime(data[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9e454ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.826087</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44.717391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>58.812500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>52.604167</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>35.173913</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year  Month  Day  Concentration  DayOfWeek  Weekend\n",
       "Date                                                           \n",
       "2022-01-01  2022      1    1      34.826087          6        1\n",
       "2022-01-02  2022      1    2      44.717391          0        1\n",
       "2022-01-03  2022      1    3      58.812500          1        0\n",
       "2022-01-04  2022      1    4      52.604167          2        0\n",
       "2022-01-05  2022      1    5      35.173913          3        0"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set 'Date' as the index\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "996786f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ff1a1453d0>]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(data.Concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9c279b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concentration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>34.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>44.717391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>58.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>52.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>35.173913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Concentration\n",
       "Date                     \n",
       "2022-01-01      34.826087\n",
       "2022-01-02      44.717391\n",
       "2022-01-03      58.812500\n",
       "2022-01-04      52.604167\n",
       "2022-01-05      35.173913"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "data_a = data[['Concentration']].copy()\n",
    "\n",
    "# Reset the index to keep it as a regular column\n",
    "data_a.reset_index(inplace=True)\n",
    "data_a.set_index('Date', inplace=True)\n",
    "\n",
    "data_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "34d813b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the 'Concentration' column as a NumPy array\n",
    "data_b = data['Concentration'].to_numpy()\n",
    "\n",
    "# Plot the time series data\n",
    "plt.plot(data_b)\n",
    "plt.title('Time Series Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Concentration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7ee48b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_a.dropna(subset=['Concentration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "db6359a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Concentration\n",
      "Date                     \n",
      "2022-01-01      34.826087\n",
      "2022-01-02      44.717391\n",
      "2022-01-03      58.812500\n",
      "2022-01-04      52.604167\n",
      "2022-01-05      35.173913\n",
      "2022-01-06      31.729167\n",
      "2022-01-07      44.562500\n",
      "2022-01-08      47.739130\n",
      "2022-01-09      44.416667\n",
      "2022-01-10       9.041667\n",
      "2022-01-11      15.739130\n",
      "2022-01-12       5.270833\n",
      "2022-01-13       2.687500\n",
      "2022-01-14       4.282609\n",
      "2022-01-15       7.937500\n",
      "2022-01-16      11.770833\n",
      "2022-01-17      14.021739\n",
      "2022-01-18      12.645833\n",
      "2022-01-19      15.250000\n",
      "2022-01-20      54.695652\n",
      "2022-01-21      32.541667\n",
      "2022-01-22      32.145833\n",
      "2022-01-23      34.391304\n",
      "2022-01-24      28.125000\n",
      "2022-01-25       4.687500\n",
      "2022-01-26      12.500000\n",
      "2022-01-27      26.729167\n",
      "2022-01-28      12.687500\n",
      "2022-01-29      45.043478\n",
      "2022-01-30      45.083333\n",
      "2022-01-31      67.520833\n",
      "2022-02-01      42.586957\n",
      "2022-02-02      41.270833\n",
      "2022-02-03      40.520833\n",
      "2022-02-04      49.891304\n",
      "2022-02-05      49.687500\n",
      "2022-02-06      63.229167\n",
      "2022-02-07      52.916667\n",
      "2022-02-08      52.217391\n",
      "2022-02-09      43.166667\n",
      "2022-02-10      30.041667\n",
      "2022-02-11      33.760870\n",
      "2022-02-12      38.729167\n",
      "2022-02-13      59.812500\n",
      "2022-02-14      60.739130\n",
      "2022-02-15      48.937500\n",
      "2022-02-16      55.770833\n",
      "2022-02-17      70.369565\n",
      "2022-02-18      63.083333\n",
      "2022-02-19      65.083333\n",
      "2022-02-20      65.847826\n",
      "2022-02-21      68.437500\n",
      "2022-02-22      39.958333\n",
      "2022-02-23      43.782609\n",
      "2022-02-24      55.770833\n",
      "2022-02-25      50.791667\n",
      "2022-02-26      33.543478\n",
      "2022-02-27      48.104167\n",
      "2022-02-28      40.187500\n",
      "2022-03-01      19.369565\n",
      "2022-03-02      19.270833\n",
      "2022-03-03      24.062500\n",
      "2022-03-04      31.434783\n",
      "2022-03-05      24.687500\n",
      "2022-03-06      41.326087\n",
      "2022-03-07      47.708333\n",
      "2022-03-08      43.729167\n",
      "2022-03-09      48.847826\n",
      "2022-03-10      63.770833\n",
      "2022-03-11      64.979167\n",
      "2022-03-12      74.086957\n",
      "2022-03-13      81.645833\n",
      "2022-03-14      51.333333\n",
      "2022-03-15      34.125000\n",
      "2022-03-16      24.260870\n",
      "2022-03-17      48.052632\n",
      "2022-03-18      39.725000\n",
      "2022-03-19      63.695652\n",
      "2022-03-20      56.166667\n",
      "2022-03-21      41.108696\n",
      "2022-03-22      50.250000\n",
      "2022-03-23      52.979167\n",
      "2022-03-24      50.978261\n",
      "2022-03-25      61.416667\n",
      "2022-03-26      69.583333\n",
      "2022-03-27      35.736842\n",
      "2022-03-30      45.000000\n",
      "2022-03-31      49.477273\n",
      "2022-04-01      54.979167\n",
      "2022-04-02      69.130435\n",
      "2022-04-03      57.562500\n",
      "2022-04-04      48.565217\n",
      "2022-04-05      37.272727\n",
      "2022-04-06      53.416667\n",
      "2022-04-07      65.395833\n",
      "2022-04-08      49.413043\n",
      "2022-04-09      57.916667\n",
      "2022-04-10      55.250000\n",
      "2022-04-11      62.479167\n",
      "2022-04-12      56.347826\n",
      "2022-04-13      19.520833\n",
      "2022-04-14      33.270833\n",
      "2022-04-15      38.456522\n",
      "2022-04-16      54.520833\n",
      "2022-04-17      58.875000\n",
      "2022-04-18      63.130435\n",
      "2022-04-19      56.645833\n",
      "2022-04-20      63.604167\n",
      "2022-04-21      64.586957\n",
      "2022-04-22      52.395833\n",
      "2022-04-23      68.041667\n",
      "2022-04-24      78.304348\n",
      "2022-04-25      45.791667\n",
      "2022-04-26      58.958333\n",
      "2022-04-27      67.130435\n",
      "2022-04-28      66.541667\n",
      "2022-04-29      44.250000\n",
      "2022-04-30      66.130435\n",
      "2022-05-01      58.854167\n",
      "2022-05-02      60.479167\n",
      "2022-05-03      60.043478\n",
      "2022-05-04      52.145833\n",
      "2022-05-05      36.937500\n",
      "2022-05-06      46.934783\n",
      "2022-05-07      45.083333\n",
      "2022-05-08      61.729167\n",
      "2022-05-09      64.978261\n",
      "2022-05-10      60.104167\n",
      "2022-05-11      66.333333\n",
      "2022-05-12      56.782609\n",
      "2022-05-13      60.833333\n",
      "2022-05-14      73.625000\n",
      "2022-05-15      82.608696\n",
      "2022-05-16      61.666667\n",
      "2022-05-17      58.750000\n",
      "2022-05-18      75.956522\n",
      "2022-05-19      58.666667\n",
      "2022-05-20      48.386364\n",
      "2022-05-21      67.065217\n",
      "2022-05-22      73.791667\n",
      "2022-05-23      50.043478\n",
      "2022-05-24      55.434783\n",
      "2022-05-25      55.791667\n",
      "2022-05-26      56.812500\n",
      "2022-05-27      62.521739\n",
      "2022-05-28      60.000000\n",
      "2022-05-29      57.166667\n",
      "2022-05-30      52.239130\n",
      "2022-05-31      52.666667\n",
      "2022-06-01      59.812500\n",
      "2022-06-02      75.041667\n",
      "2022-06-03      87.391304\n",
      "2022-06-04      90.062500\n",
      "2022-06-05      47.645833\n",
      "2022-06-06      57.782609\n",
      "2022-06-07      41.291667\n",
      "2022-06-08      31.812500\n",
      "2022-06-09      48.391304\n",
      "2022-06-10      47.062500\n",
      "2022-06-11      54.604167\n",
      "2022-06-12      62.369565\n",
      "2022-06-13      62.166667\n",
      "2022-06-14      73.062500\n",
      "2022-06-15      95.521739\n",
      "2022-06-16      90.090909\n",
      "2022-06-17      93.282609\n",
      "2022-06-18     104.804348\n",
      "2022-06-19      59.229167\n",
      "2022-06-20      60.229167\n",
      "2022-06-21      50.500000\n",
      "2022-06-22      78.791667\n",
      "2022-06-23      74.020833\n",
      "2022-06-24      55.586957\n",
      "2022-06-25      44.187500\n",
      "2022-06-26      45.208333\n",
      "2022-06-27      31.934783\n",
      "2022-06-28      56.291667\n",
      "2022-06-29      68.229167\n",
      "2022-06-30      37.152174\n",
      "2022-07-01      42.208333\n",
      "2022-07-02      58.312500\n",
      "2022-07-03      55.021739\n",
      "2022-07-04      52.708333\n",
      "2022-07-05      56.041667\n",
      "2022-07-06      61.717391\n",
      "2022-07-07      47.250000\n",
      "2022-07-08      58.666667\n",
      "2022-07-09      60.739130\n",
      "2022-07-10      50.541667\n",
      "2022-07-11      51.770833\n",
      "2022-07-12      57.021739\n",
      "2022-07-13      76.895833\n",
      "2022-07-14      56.895833\n",
      "2022-07-15      54.347826\n",
      "2022-07-16      61.000000\n",
      "2022-07-17      68.875000\n",
      "2022-07-18      95.568182\n",
      "2022-07-19     110.125000\n",
      "2022-07-20      80.583333\n",
      "2022-07-21      49.652174\n",
      "2022-07-22      50.208333\n",
      "2022-07-23      68.916667\n",
      "2022-07-24      79.152174\n",
      "2022-07-25      56.437500\n",
      "2022-07-26      51.562500\n",
      "2022-07-27      56.934783\n",
      "2022-07-28      70.125000\n",
      "2022-07-29      86.812500\n",
      "2022-07-30      76.065217\n",
      "2022-07-31      47.229167\n",
      "2022-08-01      57.625000\n",
      "2022-08-02      55.478261\n",
      "2022-08-03      48.000000\n",
      "2022-08-04      40.666667\n",
      "2022-08-05      56.295455\n",
      "2022-08-06      55.458333\n",
      "2022-08-07      73.270833\n",
      "2022-08-08      70.416667\n",
      "2022-08-09      70.043478\n",
      "2022-08-10      91.166667\n",
      "2022-08-11     103.520833\n",
      "2022-08-12     106.217391\n",
      "2022-08-13      97.291667\n",
      "2022-08-14     100.708333\n",
      "2022-08-15      92.217391\n",
      "2022-08-16     102.583333\n",
      "2022-08-17      70.416667\n",
      "2022-08-18      80.565217\n",
      "2022-08-19      39.937500\n",
      "2022-08-20      50.145833\n",
      "2022-08-21      47.700000\n",
      "2022-08-22      97.545455\n",
      "2022-08-23      53.000000\n",
      "2022-08-24      74.604167\n",
      "2022-08-25      89.791667\n",
      "2022-08-26      64.608696\n",
      "2022-08-27      58.604167\n",
      "2022-08-28      69.062500\n",
      "2022-08-29      64.413043\n",
      "2022-08-30      66.354167\n",
      "2022-08-31      72.020833\n",
      "2022-09-01      74.304348\n",
      "2022-09-02      69.041667\n",
      "2022-09-03      71.020833\n",
      "2022-09-04      64.104167\n",
      "2022-09-05      75.847826\n",
      "2022-09-06      59.227273\n",
      "2022-09-07      57.416667\n",
      "2022-09-08      47.391304\n",
      "2022-09-09      48.395833\n",
      "2022-09-10      47.541667\n",
      "2022-09-11      49.500000\n",
      "2022-09-12      45.875000\n",
      "2022-09-13      34.354167\n",
      "2022-09-14      25.217391\n",
      "2022-09-15      33.062500\n",
      "2022-09-16      43.166667\n",
      "2022-09-17      35.173913\n",
      "2022-09-18      37.645833\n",
      "2022-09-19      36.166667\n",
      "2022-09-20      33.521739\n",
      "2022-09-21      27.375000\n",
      "2022-09-22      32.770833\n",
      "2022-09-23      32.847826\n",
      "2022-09-24      45.291667\n",
      "2022-09-25      39.604167\n",
      "2022-09-26      36.586957\n",
      "2022-09-27      36.333333\n",
      "2022-09-28      29.604167\n",
      "2022-09-29      22.782609\n",
      "2022-09-30      31.312500\n",
      "2022-10-01      47.291667\n",
      "2022-10-02      38.434783\n",
      "2022-10-03      18.437500\n",
      "2022-10-04      30.250000\n",
      "2022-10-05      47.214286\n",
      "2022-10-06      40.458333\n",
      "2022-10-07      33.375000\n",
      "2022-10-08      41.380952\n",
      "2022-10-09       7.000000\n",
      "2022-10-10      41.500000\n",
      "2022-10-11       5.833333\n",
      "2022-10-12      18.477273\n",
      "2022-10-13      21.708333\n",
      "2022-10-14      23.391304\n",
      "2022-10-15      37.166667\n",
      "2022-10-16      37.729167\n",
      "2022-10-17      21.500000\n",
      "2022-10-18      26.729167\n",
      "2022-10-19      22.937500\n",
      "2022-10-20      20.608696\n",
      "2022-10-21      41.208333\n",
      "2022-10-22      38.687500\n",
      "2022-10-23      37.333333\n",
      "2022-10-24      51.714286\n",
      "2022-10-25      41.000000\n",
      "2022-11-07      52.400000\n",
      "2022-11-08      47.750000\n",
      "2022-11-09      46.479167\n",
      "2022-11-10      33.142857\n",
      "2022-11-11      29.125000\n",
      "2022-11-12       8.062500\n",
      "2022-11-13       6.750000\n",
      "2022-11-14       5.586957\n",
      "2022-11-15      34.541667\n",
      "2022-11-16      38.416667\n",
      "2022-11-17      53.521739\n",
      "2022-11-18      29.895833\n",
      "2022-11-19       6.229167\n",
      "2022-11-20       4.000000\n",
      "2022-11-21      36.692308\n",
      "2022-11-22      44.770833\n",
      "2022-11-23      36.888889\n",
      "2022-11-24      45.026316\n",
      "2022-11-25      28.333333\n",
      "2022-11-26      21.543478\n",
      "2022-11-27      32.312500\n",
      "2022-11-28      16.937500\n",
      "2022-11-29       6.600000\n",
      "2022-12-01       8.807692\n",
      "2022-12-02      12.500000\n",
      "2022-12-03      10.375000\n",
      "2022-12-04       6.833333\n",
      "2022-12-05       2.326087\n",
      "2022-12-06       9.479167\n",
      "2022-12-07      16.775000\n",
      "2022-12-08      16.891304\n",
      "2022-12-09      10.875000\n",
      "2022-12-10      19.104167\n",
      "2022-12-11      29.260870\n",
      "2022-12-12      12.604167\n",
      "2022-12-13       3.750000\n",
      "2022-12-14       3.673913\n",
      "2022-12-15       2.000000\n",
      "2022-12-16       5.437500\n",
      "2022-12-17       3.130435\n",
      "2022-12-18      13.458333\n",
      "2022-12-19      32.666667\n",
      "2022-12-20      32.608696\n",
      "2022-12-21      28.166667\n",
      "2022-12-22      31.041667\n",
      "2022-12-23      42.304348\n",
      "2022-12-24      44.333333\n",
      "2022-12-25      29.937500\n",
      "2022-12-26      46.521739\n",
      "2022-12-27      42.270833\n",
      "2022-12-28      50.041667\n",
      "2022-12-29      55.108696\n",
      "2022-12-30      43.977273\n",
      "2023-01-01      49.545455\n",
      "2023-01-02      48.083333\n",
      "2023-01-03      41.729167\n",
      "2023-01-04      54.727273\n",
      "2023-01-05      46.520833\n",
      "2023-01-06      43.583333\n",
      "2023-01-07      51.369565\n",
      "2023-01-08      65.145833\n",
      "2023-01-09      54.312500\n",
      "2023-01-10      41.652174\n",
      "2023-01-11      53.375000\n",
      "2023-01-12      54.395833\n",
      "2023-01-13      60.625000\n",
      "2023-01-14      55.369565\n",
      "2023-01-15      64.354167\n",
      "2023-01-16      55.687500\n",
      "2023-01-17      22.717391\n",
      "2023-01-18      15.020833\n",
      "2023-01-19      21.958333\n",
      "2023-01-20      24.847826\n",
      "2023-01-21      18.562500\n",
      "2023-01-22      30.645833\n",
      "2023-01-23      13.652174\n",
      "2023-01-24      22.395833\n",
      "2023-01-25      11.770833\n",
      "2023-01-26      25.695652\n",
      "2023-01-27      43.395833\n",
      "2023-01-28      40.916667\n",
      "2023-01-29      20.195652\n",
      "2023-01-30      44.125000\n",
      "2023-01-31      25.666667\n",
      "2023-02-01      50.022727\n",
      "2023-02-02      51.625000\n",
      "2023-02-03      52.354167\n",
      "2023-02-04      26.239130\n",
      "2023-02-05      53.416667\n",
      "2023-02-06      23.270833\n",
      "2023-02-07      11.173913\n",
      "2023-02-08      14.166667\n",
      "2023-02-09      16.833333\n",
      "2023-02-10      15.260870\n",
      "2023-02-11      28.145833\n",
      "2023-02-12      36.770833\n",
      "2023-02-13      12.782609\n",
      "2023-02-14       9.895833\n",
      "2023-02-15      14.520833\n",
      "2023-02-16      27.478261\n",
      "2023-02-17      52.979167\n",
      "2023-02-18      60.645833\n",
      "2023-02-19      49.869565\n",
      "2023-02-20      49.250000\n",
      "2023-02-24      56.125000\n",
      "2023-02-25      44.781250\n",
      "2023-02-27      48.312500\n",
      "2023-02-28      35.977273\n",
      "2023-03-01      38.590909\n",
      "2023-03-02      31.130435\n",
      "2023-03-03      39.522727\n",
      "2023-03-04      66.437500\n",
      "2023-03-05      53.687500\n",
      "2023-03-06      46.666667\n",
      "2023-03-07      51.062500\n",
      "2023-03-08      32.979167\n",
      "2023-03-09      26.217391\n",
      "2023-03-10      54.729167\n",
      "2023-03-11      46.062500\n",
      "2023-03-12      60.565217\n",
      "2023-03-13      48.166667\n",
      "2023-03-14      60.333333\n",
      "2023-03-15      52.456522\n",
      "2023-03-16      63.666667\n",
      "2023-03-17      54.812500\n",
      "2023-03-18      60.416667\n",
      "2023-03-19      52.673913\n",
      "2023-03-20      48.145833\n",
      "2023-03-21      48.071429\n",
      "2023-03-22      58.857143\n",
      "2023-03-23      70.375000\n",
      "2023-03-24      68.750000\n",
      "2023-03-25      73.750000\n",
      "2023-03-26      64.458333\n",
      "2023-03-27      69.739130\n",
      "2023-03-28      50.500000\n",
      "2023-03-29      46.125000\n",
      "2023-03-30      68.204545\n",
      "2023-03-31      65.458333\n",
      "2023-04-01      46.270833\n",
      "2023-04-02      51.304348\n",
      "2023-04-03      47.812500\n",
      "2023-04-04      55.750000\n",
      "2023-04-05      48.812500\n",
      "2023-04-06      49.347826\n",
      "2023-04-07      63.020833\n",
      "2023-04-08      59.833333\n",
      "2023-04-09      51.869565\n",
      "2023-04-10      65.229167\n",
      "2023-04-11      71.979167\n",
      "2023-04-12      73.086957\n",
      "2023-04-13      72.500000\n",
      "2023-04-14      55.229167\n",
      "2023-04-15      63.826087\n",
      "2023-04-16      54.916667\n",
      "2023-04-17      62.583333\n",
      "2023-04-18      53.152174\n",
      "2023-04-19      66.416667\n",
      "2023-04-20      71.625000\n",
      "2023-04-21      60.173913\n",
      "2023-04-22      24.458333\n",
      "2023-04-23      63.437500\n",
      "2023-04-24      76.750000\n",
      "2023-04-25      74.500000\n",
      "2023-04-26      58.250000\n",
      "2023-04-27      68.108696\n",
      "2023-04-28      37.625000\n",
      "2023-04-29      71.895833\n",
      "2023-04-30      71.739130\n",
      "2023-05-01      61.458333\n",
      "2023-05-02      63.541667\n",
      "2023-05-03      67.108696\n",
      "2023-05-04      67.750000\n",
      "2023-05-05      60.125000\n",
      "2023-05-06      53.891304\n",
      "2023-05-07      38.687500\n",
      "2023-05-08      33.145833\n",
      "2023-05-09      33.108696\n",
      "2023-05-10      42.250000\n",
      "2023-05-11      50.704545\n",
      "2023-05-12      41.478261\n",
      "2023-05-13      76.958333\n",
      "2023-05-14      70.000000\n",
      "2023-05-15      55.977273\n",
      "2023-05-16      62.312500\n",
      "2023-05-17      60.583333\n",
      "2023-05-18      69.729167\n",
      "2023-05-19      74.304348\n",
      "2023-05-20      78.104167\n",
      "2023-05-21      68.479167\n",
      "2023-05-22      58.978261\n",
      "2023-05-23      71.395833\n",
      "2023-05-24      59.522727\n",
      "2023-05-25      69.391304\n",
      "2023-05-26      76.770833\n",
      "2023-05-27      84.437500\n",
      "2023-05-28      83.326087\n",
      "2023-05-29      75.458333\n",
      "2023-05-30      74.479167\n",
      "2023-05-31      73.956522\n",
      "2023-06-01      68.916667\n",
      "2023-06-02      81.270833\n",
      "2023-06-03      80.260870\n",
      "2023-06-04      84.520833\n",
      "2023-06-05      76.312500\n",
      "2023-06-06      83.130435\n",
      "2023-06-07      78.729167\n",
      "2023-06-08      88.041667\n",
      "2023-06-09     101.357143\n",
      "2023-06-10     109.625000\n",
      "2023-06-11      98.416667\n",
      "2023-06-12     100.913043\n",
      "2023-06-13     111.854167\n",
      "2023-06-14     107.541667\n",
      "2023-06-15      93.956522\n",
      "2023-06-16     109.645833\n",
      "2023-06-17     108.187500\n",
      "2023-06-18      98.869565\n",
      "2023-06-19      74.261905\n",
      "2023-06-20      68.369565\n",
      "2023-06-21      63.340909\n",
      "2023-06-22      51.473684\n",
      "2023-06-23      67.847826\n",
      "2023-06-24      70.978261\n",
      "2023-06-25      96.645833\n",
      "2023-06-26      72.604167\n",
      "2023-06-27      62.913043\n",
      "2023-06-28      52.770833\n",
      "2023-06-29      51.604167\n",
      "2023-06-30      60.086957\n",
      "2023-07-01      41.083333\n",
      "2023-07-02      71.500000\n",
      "2023-07-03      63.673913\n",
      "2023-07-04      58.956522\n",
      "2023-07-05      59.312500\n",
      "2023-07-06      63.608696\n",
      "2023-07-07      76.416667\n",
      "2023-07-08      80.104167\n",
      "2023-07-09      68.586957\n",
      "2023-07-10      67.562500\n",
      "2023-07-11      58.375000\n",
      "2023-07-12      58.391304\n",
      "2023-07-13      59.958333\n",
      "2023-07-14      72.041667\n",
      "2023-07-15      54.130435\n",
      "2023-07-16      52.312500\n",
      "2023-07-17      55.000000\n",
      "2023-07-18      62.065217\n",
      "2023-07-19      52.250000\n",
      "2023-07-20      44.833333\n",
      "2023-07-21      48.347826\n",
      "2023-07-22      58.229167\n",
      "2023-07-23      46.645833\n",
      "2023-07-24      44.173913\n",
      "2023-07-25      51.312500\n",
      "2023-07-26      60.437500\n",
      "2023-07-27      34.608696\n",
      "2023-07-28      33.375000\n",
      "2023-07-29      45.187500\n",
      "2023-07-30      52.978261\n",
      "2023-07-31      38.520833\n",
      "2023-08-01      51.312500\n",
      "2023-08-02      49.260870\n",
      "2023-08-03      48.875000\n",
      "2023-08-04      45.562500\n",
      "2023-08-05      45.062500\n",
      "2023-08-06      56.043478\n",
      "2023-08-07      54.375000\n",
      "2023-08-08      44.229167\n",
      "2023-08-09      53.804348\n",
      "2023-08-10      60.666667\n",
      "2023-08-11      61.812500\n",
      "2023-08-12      51.130435\n",
      "2023-08-13      55.145833\n",
      "2023-08-14      59.729167\n",
      "2023-08-15      60.043478\n",
      "2023-08-16      63.437500\n",
      "2023-08-17      48.645833\n",
      "2023-08-18      52.673913\n",
      "2023-08-19      58.604167\n",
      "2023-08-20      54.083333\n",
      "2023-08-21      54.717391\n",
      "2023-08-22      48.541667\n",
      "2023-08-23      58.083333\n",
      "2023-08-24      47.108696\n",
      "2023-08-25      37.687500\n",
      "2023-08-26      52.541667\n",
      "2023-08-27      52.000000\n",
      "2023-08-28      48.333333\n",
      "2023-08-29      43.583333\n",
      "2023-08-30      48.065217\n",
      "2023-08-31      48.270833\n",
      "2023-09-01      32.437500\n",
      "2023-09-02      34.434783\n",
      "2023-09-03      53.458333\n",
      "2023-09-04      58.354167\n",
      "2023-09-05      59.456522\n",
      "2023-09-06      68.208333\n",
      "2023-09-07      70.500000\n",
      "2023-09-08      75.565217\n",
      "2023-09-09      79.020833\n",
      "2023-09-10      82.229167\n",
      "2023-09-11      72.022727\n",
      "2023-09-12      47.312500\n",
      "2023-09-13      49.062500\n",
      "2023-09-14      42.913043\n",
      "2023-09-15      48.291667\n",
      "2023-09-16      51.270833\n",
      "2023-09-17      41.479167\n",
      "2023-09-18      53.652174\n",
      "2023-09-19      46.433333\n",
      "2023-09-20      65.136364\n",
      "2023-09-21      44.895833\n",
      "2023-09-22      44.375000\n",
      "2023-09-23      35.500000\n",
      "2023-09-24      46.791667\n",
      "2023-09-25      49.270833\n",
      "2023-09-26      34.260870\n",
      "2023-09-27      44.375000\n",
      "2023-09-28      49.604167\n",
      "2023-09-29      36.630435\n",
      "2023-09-30      37.437500\n",
      "2023-10-01      55.395833\n",
      "2023-10-02      55.630435\n",
      "2023-10-03      63.270833\n",
      "2023-10-04      43.541667\n",
      "2023-10-05      40.086957\n",
      "2023-10-06      49.565217\n",
      "2023-10-07      58.916667\n",
      "2023-10-08      43.130435\n",
      "2023-10-09      29.065217\n"
     ]
    }
   ],
   "source": [
    "print(data_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "42650cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -4.183112718587053\n",
      "p-value: 0.0007036380147547563\n",
      "Critical Values: {'1%': -3.440924132966757, '5%': -2.866205413627313, '10%': -2.5692545786625383}\n",
      "The time series is likely stationary.\n"
     ]
    }
   ],
   "source": [
    "# Perform Augmented Dickey-Fuller test\n",
    "result = adfuller(data_a)\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "print('Critical Values:', result[4])\n",
    "\n",
    "# Interpret the results\n",
    "if result[1] <= 0.05:\n",
    "    print('The time series is likely stationary.')\n",
    "else:\n",
    "    print('The time series is likely non-stationary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0251bd",
   "metadata": {},
   "source": [
    "###### We have stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b13ecf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acf_plot = plot_acf(data_a.Concentration, lags=100)\n",
    "plt.axhline(y=0, color='black', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "88b85e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\graphics\\tsaplots.py:348: FutureWarning: The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pacf_plot = plot_pacf(data_a.Concentration, lags=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d1808e3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Order: (6, 0, 5)\n",
      "Best Model AIC: 4905.66\n",
      "Best Model BIC: 4963.39\n",
      "Best Model MSE: 140.51\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  627\n",
      "Model:                 ARIMA(6, 0, 5)   Log Likelihood               -2439.828\n",
      "Date:                Sat, 24 Feb 2024   AIC                           4905.655\n",
      "Time:                        14:39:55   BIC                           4963.388\n",
      "Sample:                             0   HQIC                          4928.085\n",
      "                                - 627                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         50.9434      7.089      7.187      0.000      37.050      64.837\n",
      "ar.L1          0.1083      0.068      1.581      0.114      -0.026       0.242\n",
      "ar.L2          0.0895      0.065      1.383      0.167      -0.037       0.216\n",
      "ar.L3          0.2943      0.051      5.809      0.000       0.195       0.394\n",
      "ar.L4          0.4159      0.046      8.953      0.000       0.325       0.507\n",
      "ar.L5          0.5264      0.064      8.211      0.000       0.401       0.652\n",
      "ar.L6         -0.4748      0.060     -7.949      0.000      -0.592      -0.358\n",
      "ma.L1          0.5576      0.052     10.638      0.000       0.455       0.660\n",
      "ma.L2          0.3416      0.059      5.837      0.000       0.227       0.456\n",
      "ma.L3         -0.0444      0.065     -0.679      0.497      -0.173       0.084\n",
      "ma.L4         -0.3777      0.061     -6.213      0.000      -0.497      -0.259\n",
      "ma.L5         -0.8454      0.047    -18.141      0.000      -0.937      -0.754\n",
      "sigma2       139.4167      7.870     17.715      0.000     123.992     154.841\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.04   Jarque-Bera (JB):                 6.07\n",
      "Prob(Q):                              0.85   Prob(JB):                         0.05\n",
      "Heteroskedasticity (H):               0.66   Skew:                            -0.17\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         3.34\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "data_a = data['Concentration'].to_numpy()\n",
    "\n",
    "# Define the range of AR and MA values to check\n",
    "ar_range = range(10)\n",
    "ma_range = range(10)\n",
    "\n",
    "# Initialize variables for tracking the best model\n",
    "best_aic = float('inf')\n",
    "best_order = None\n",
    "best_results = None\n",
    "\n",
    "# Iterate through AR and MA values\n",
    "for p in ar_range:\n",
    "    for q in ma_range:\n",
    "        order = (p, 0, q)  # ARIMA order (p, d, q), here d=0 for ARMA\n",
    "        model = sm.tsa.ARIMA(data_a, order=order)\n",
    "        results = model.fit()\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE)\n",
    "        fitted_values = results.fittedvalues\n",
    "        mse = mean_squared_error(data_a, fitted_values)\n",
    "\n",
    "        # Check if the current model has a lower AIC than the best so far\n",
    "        if results.aic < best_aic:\n",
    "            best_aic = results.aic\n",
    "            best_order = order\n",
    "            best_results = results\n",
    "\n",
    "            # Update the best MSE as well\n",
    "            best_mse = mse\n",
    "\n",
    "# Display the best model's information including AIC, BIC, MSE, and summary\n",
    "print(f'Best Model Order: {best_order}')\n",
    "print(f'Best Model AIC: {best_aic:.2f}')\n",
    "print(f'Best Model BIC: {best_results.bic:.2f}')\n",
    "print(f'Best Model MSE: {best_mse:.2f}')\n",
    "print(best_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9341d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARMA(6, 0, 5) model\n",
    "order_arma = (6, 0, 5)  # ARIMA order (p, d, q), here d=0 for ARMA\n",
    "model_arma = sm.tsa.ARIMA(data_a['Concentration'], order=order_arma)\n",
    "results_arma = model_arma.fit()\n",
    "\n",
    "# Extract the predicted (fitted) values\n",
    "fitted_values = pd.DataFrame({\n",
    "    'FittedValues': results_arma.fittedvalues\n",
    "})\n",
    "\n",
    "# Combine the original data_a DataFrame with the fitted values\n",
    "data['FittedValues'] = fitted_values['FittedValues']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "d039a1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot original data and predicted values\n",
    "plt.plot(data_a, label='Original Data')\n",
    "plt.plot(results_arma.fittedvalues, label='ARMA(6,0,5) Predictions', linestyle='--')\n",
    "plt.title('ARMA(6,0,5) Model Fit')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Concentration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "983100d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAHFCAYAAAAdTZjVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAADRR0lEQVR4nOydd5gURfrHvz0zm1mWzJKTGFFRUJIKGMCs55kVwVPvzOep5+npKeeJmPWnnplDz+yZT09EDJhAAUFREANZWJC4S9g0078/ZnumqrqqOkxP2n0/z7PPzvR0V1d3V1e99aYyTNM0QRAEQRAE0UIIZbsCBEEQBEEQmYSEH4IgCIIgWhQk/BAEQRAE0aIg4YcgCIIgiBYFCT8EQRAEQbQoSPghCIIgCKJFQcIPQRAEQRAtChJ+CIIgCIJoUZDwQxAEQRBEi4KEH4JIA08++SQMw0j8RSIRdOnSBaeffjp+/PHHtJ134sSJMAzD1b69e/fGhAkT0lYXr/UJkhtuuAE9e/ZEJBJBmzZtXB1z5ZVXwjAMHHvssdLfly9fzj3TUCiEtm3b4rDDDsP06dOV5f7ud7/DkUceyW277777cNJJJ6FPnz4wDAOjRo2SHvu3v/0N+++/P2KxmKtrGDVqFAzDQN++fSFL3v/xxx8n6v/kk0+6KtMNVntfvny552Oz1UaIlg0JPwSRRqZOnYpZs2ZhxowZuPTSS/Hmm2/ioIMOwubNm9NyvvPPPx+zZs1KS9n5whtvvIFJkybhnHPOwcyZMzFjxgzHYxoaGvDMM88AAKZNm4ZffvlFue9ll12GWbNm4ZNPPsFdd92FH3/8EUcffTQ+/vhj277z58/HU089hVtuuYXb/sgjj2DFihU49NBD0bFjR+W5rr76aixbtgxPPfWU4zVYlJeXY9myZfjggw9sv/3rX/9C69atXZdFEM0VEn4IIo0MGDAAQ4cOxahRo3D99dfj2muvxfr16/H666+n5Xzdu3fH0KFD01J2vvDtt98CAC6//HKMGDECgwcPdjzmjTfewK+//opjjjkG0WhUK2z07NkTQ4cOxYgRI3DeeefhmWeeQTQaxZQpU2z73nbbbTjwwANtdVi0aBHmzZuHKVOmoFOnTspzVVRU4Oyzz8Ztt90m1eTo6vevf/2L215TU4P//Oc/OO2001yVQxDNGRJ+CCKDWIPgunXruO1z587F8ccfj3bt2qG4uBj77bcfXnrpJW6fHTt24Oqrr0afPn1QXFyMdu3aYfDgwXj++ecT+8hMCA0NDbjmmmtQWVmJ0tJSHHTQQfjyyy9tdVOZH2QmjRdffBFjxoxBly5dUFJSgj322APXXnsttm/f7ngPPvjgA4waNQrt27dHSUkJevbsid/+9rfYsWOH9rhYLIY77rgDu+++O4qKitCpUyecc845WL16dWKf3r1744YbbgAAdO7cGYZhYOLEiY51mjJlCgoLCzF16lT06NEDU6dOdS1sqJ7punXr8Nprr2HcuHG2Y0Ih913vuHHj8MMPP+DDDz90fczvfvc7vPrqq9iyZUti2wsvvAAAOP3006XHfPrppzjssMNQXl6O0tJSDB8+HG+//bZtv9mzZ2PEiBEoLi5G165dcd1116GhoUFa5osvvohhw4ahrKwMrVq1wtixYzF//nzX10EQ6YKEH4LIIMuWLQMA7LrrroltH374IUaMGIEtW7bgkUcewRtvvIGBAwfitNNO4/wyrrzySjz88MO4/PLLMW3aNDz99NM45ZRTsHHjRu05L7jgAtx1110455xz8MYbb+C3v/0tTjrppJRMb5apZ8qUKZg2bRquuOIKvPTSSzjuuOO0xy1fvhzHHHMMCgsL8a9//QvTpk3DbbfdhrKyMtTX12uPveiii/CXv/wFRxxxBN5880384x//wLRp0zB8+HBs2LABAPDaa6/hvPPOAxA3X82aNQvnn3++ttzVq1dj+vTpOOGEE9CxY0eMHz8eP/30k9SMJUP2TAFg+vTpaGhowOjRo12Vo2LQoEFo1aqVVBBRcfrppyMcDnOC8ZQpU3DyySdLzV4zZ87EoYceiq1bt2LKlCl4/vnnUV5ejuOOOw4vvvhiYr9FixbhsMMOw5YtW/Dkk0/ikUcewfz5821mPQC49dZbccYZZ2DPPffESy+9hKeffho1NTU4+OCDsWjRIo93gSACxiQIInCmTp1qAjBnz55tNjQ0mDU1Nea0adPMyspK85BDDjEbGhoS++6+++7mfvvtx20zTdM89thjzS5dupjRaNQ0TdMcMGCAeeKJJ2rPe9NNN5nsa7148WITgPmnP/2J2+/ZZ581AZjjx49XHitey7Jly6TnjMViZkNDgzlz5kwTgPn1118ry3z55ZdNAOaCBQu01yFiXcfFF1/Mbf/iiy9MAOZf//pX2zl//fVXV2XffPPNJgBz2rRppmma5tKlS03DMMxx48Zx+y1btswEYN5+++1mQ0ODWVtbay5YsMAcNmyY2aVLF9v9ueiii8ySkhIzFotpz7/XXnuZI0eO1O4zYsQIc8iQIY7XMnLkSHOvvfYyTdM0x48fbw4ePNg0TdP87rvvTADmRx99ZM6ZM8cEYE6dOjVx3NChQ81OnTqZNTU1iW2NjY3mgAEDzO7duyeu4bTTTjNLSkrMqqoqbr/dd9+dayMrV640I5GIedlll3H1q6mpMSsrK81TTz01sU3V7gginZDmhyDSyNChQ1FQUIDy8nIceeSRaNu2Ld544w1EIhEAwE8//YTvv/8eZ511FgCgsbEx8Xf00Udj7dq1WLJkCQDgwAMPxDvvvINrr70WH330EXbu3Ol4fstUYpVvceqppybq4IelS5fizDPPRGVlJcLhMAoKCjBy5EgAwOLFi5XHDRw4EIWFhfj973+Pp556CkuXLnV1Pus6xOi0Aw88EHvssQfef/99X9dhmmbC1HXEEUcAAPr06YNRo0bhlVdeQXV1te2Yv/zlLygoKEBxcTEGDhyIb7/9Fv/973/Ru3dvbr81a9agY8eOgUQyderUSeuELeN3v/sd5s6di4ULF2LKlCno168fDjnkENt+27dvxxdffIGTTz4ZrVq1SmwPh8MYN24cVq9enWiDH374IQ477DB07tyZ20/0I3r33XfR2NiIc845h2vTxcXFGDlyJD766CNP10IQQUPCD0GkkX//+9+YM2cOPvjgA/zhD3/A4sWLccYZZyR+t/xErr76ahQUFHB/F198MQAkTDr3338//vKXv+D111/H6NGj0a5dO5x44ona0HnLJFZZWcltj0QiaN++va9r2rZtGw4++GB88cUXuOWWW/DRRx9hzpw5ePXVVwFAK5T169cPM2bMQKdOnXDJJZegX79+6NevH/7v//5Pe07rOrp06WL7rWvXro6mPxUffPABli1bhlNOOQXV1dXYsmULtmzZglNPPRU7duzgzEYWf/zjHzFnzhx8+umnuOuuu9DQ0IATTjjBVoedO3eiuLjYV71EiouLXQm7LIcccgj69++PRx99FE8//TR+97vfSQWxzZs3wzRN5b0Fkvd/48aNtrYE2NuX1a4POOAAW7t+8cUXE22aILKF/6kfQRCO7LHHHgmH2NGjRyMajeKJJ57Ayy+/jJNPPhkdOnQAAFx33XU46aSTpGXstttuAICysjL8/e9/x9///nesW7cuoQU67rjj8P3330uPtQScqqoqdOvWLbG9sbHRNlhbA3VdXR2KiooS28WB6oMPPsCaNWvw0UcfJbQ9ADjnWh0HH3wwDj74YESjUcydOxcPPPAArrjiCnTu3FnpjGtdx9q1a9G9e3futzVr1iTuo1esCK177rkH99xzj/T3P/zhD9y27t27J57piBEjUFlZibPPPhs33XQTHnzwwcR+HTp0wFdffeWrXiKbNm3ydY3nnnsubrjhBhiGgfHjx0v3adu2LUKhENauXWv7bc2aNQCQOHf79u1RVVVl20/cZu3/8ssvo1evXp7rTRDphjQ/BJFB7rjjDrRt2xY33ngjYrEYdtttN/Tv3x9ff/01Bg8eLP0rLy+3ldO5c2dMmDABZ5xxBpYsWaKMlLKS5z377LPc9pdeegmNjY3cNsts880333Db//vf/3LfLe0BKyABwKOPPqq/eIFwOIwhQ4bgn//8JwBoBYVDDz0UABK5eCzmzJmDxYsX47DDDvN0biCu8XjttdcwYsQIfPjhh7a/s846C3PmzEmEzqs466yzMGrUKDz++ONYsWJFYvvuu++OjRs3YuvWrZ7rJrJ06VLsueeeno8bP348jjvuOPz5z3/mhF+WsrIyDBkyBK+++iqnXYrFYnjmmWfQvXv3hDP36NGj8f7773ORbdFolHOKBoCxY8ciEong559/VrZrgsgmpPkhiAzStm1bXHfddbjmmmvw3HPP4eyzz8ajjz6Ko446CmPHjsWECRPQrVs3bNq0CYsXL8ZXX32F//znPwCAIUOG4Nhjj8U+++yDtm3bYvHixXj66acxbNgwlJaWSs+3xx574Oyzz8Z9992HgoICHH744fj2229x11132aJ+jj76aLRr1w7nnXcebr75ZkQiETz55JNYtWoVt9/w4cPRtm1bXHjhhbjppptQUFCAZ599Fl9//bXj9T/yyCP44IMPcMwxx6Bnz56ora1N5KM5/PDDlcfttttu+P3vf48HHngAoVAIRx11FJYvX46//e1v6NGjB/70pz85nlvk2WefRW1tLS6//HJphuX27dvj2WefxZQpU3Dvvfdqy7r99tsxZMgQ/OMf/8ATTzwBIC54mqaJL774AmPGjOH2nzt3biJ1QHV1NUzTxMsvvwwgbipitSUbN27Ejz/+iMsuu8zzNXbt2tVVTqnJkyfjiCOOwOjRo3H11VejsLAQDz30EL799ls8//zzCYH3hhtuwJtvvolDDz0UN954I0pLS/HPf/7TluKgd+/euPnmm3H99ddj6dKlCX+3devW4csvv0xoMQkia2TX35ogmidWhNScOXNsv+3cudPs2bOn2b9/f7OxsdE0TdP8+uuvzVNPPdXs1KmTWVBQYFZWVpqHHnqo+cgjjySOu/baa83Bgwebbdu2NYuKisy+ffuaf/rTn8wNGzYk9pFFztTV1ZlXXXWV2alTJ7O4uNgcOnSoOWvWLLNXr15ctJdpmuaXX35pDh8+3CwrKzO7detm3nTTTeYTTzxhi/b6/PPPzWHDhpmlpaVmx44dzfPPP9/86quvbFFEYn1mzZpl/uY3vzF79eplFhUVme3btzdHjhxpvvnmm473NBqNmrfffru56667mgUFBWaHDh3Ms88+21y1ahW3n9tor4EDB5qdOnUy6+rqlPsMHTrU7NChg1lXV5eI9rrzzjul+55yyilmJBIxf/rpp0R9e/fubYtQM814JBYA6R97/0zTNKdMmWIWFBRwEVYq2GgvFbJoL9M0zU8++cQ89NBDzbKyMrOkpMQcOnSo+d///td2/GeffWYOHTrULCoqMisrK80///nP5mOPPSaNCHz99dfN0aNHm61btzaLiorMXr16mSeffLI5Y8aMxD4U7UVkA8M0XWbyIgiCIDxx9913Y9KkSfjll19QUlLiq4yDDz4YPXv2tJkuCYLwD/n8EARBpIlLLrkEFRUVCb8mr3z88ceYM2cO/vGPfwRcM4Jo2ZDwQxAEkSaKi4vx9NNP25zD3bJx40b8+9//Rt++fQOuGUG0bMjsRRAEQRBEi4I0PwRBEARBtChI+CEIgiAIokVBwg9BEARBEC0KSnIoEIvFsGbNGpSXlweyICFBEARBEOnHNE3U1NSga9euCIX0uh0SfgTWrFmDHj16ZLsaBEEQBEH4YNWqVbY1AEVI+BGw1lFatWqVLf0/QRAEQRC5SXV1NXr06CFdD1GEhB8By9TVunVrEn4IgiAIIs9w47JCDs8EQRAEQbQoSPghCIIgCKJFQcIPQRAEQRAtChJ+CIIgCIJoUZDwQxAEQRBEi4KEH4IgCIIgWhQk/BAEQRAE0aIg4YcgCIIgiBYFCT8EQRAEQbQo8lb4mTx5MgzDwBVXXJHYZpomJk6ciK5du6KkpASjRo3Cd999l71KEgRBEASRc+Sl8DNnzhw89thj2Geffbjtd9xxB+655x48+OCDmDNnDiorK3HEEUegpqYmSzUlCIIgCCLXyDvhZ9u2bTjrrLPw+OOPo23btontpmnivvvuw/XXX4+TTjoJAwYMwFNPPYUdO3bgueeey2KNCYIgCILIJfJO+LnkkktwzDHH4PDDD+e2L1u2DFVVVRgzZkxiW1FREUaOHInPP/9cWV5dXR2qq6u5P4JoztQ2RGGaZrarQRAEkTXySvh54YUXMG/ePEyePNn2W1VVFQCgc+fO3PbOnTsnfpMxefJkVFRUJP569OgRbKUJIof4taYOu/9tGs6e8kW2q0IQBJE18kb4WbVqFf74xz/i2WefRXFxsXI/cSl70zS1y9tfd9112Lp1a+Jv1apVgdWZIHKNt79ZAwD47KeNWa4JQRBE9ohkuwJumTdvHtavX49BgwYltkWjUXz88cd48MEHsWTJEgBxDVCXLl0S+6xfv96mDWIpKipCUVFR+ipOEARBEEROkTean8MOOwwLFy7EggULEn+DBw/GWWedhQULFqBv376orKzEe++9lzimvr4eM2fOxPDhw7NYc4LIHcjThyAIIo80P+Xl5RgwYAC3raysDO3bt09sv+KKK3Drrbeif//+6N+/P2699VaUlpbizDPPzEaVCYIgCILIQfJG+HHDNddcg507d+Liiy/G5s2bMWTIEEyfPh3l5eXZrhpBEARBEDlCXgs/H330EffdMAxMnDgREydOzEp9CCLXoQh3giCIPPL5IQiCIAiCCAISfgiCIAiCaFGQ8EMQBEEQRIuChB+CIAiCIFoUJPwQRAuC/J0JgiBI+CEIgiAIooVBwg9BEARBEC0KEn4IgiAIgmhRkPBDEARBEESLgoQfgmhBmJTimSAIgoQfgiAIgiBaFiT8EARBEATRoiDhhyAIgiCIFgUJPzlMLGZi6a/byE+DIAiCIAKEhJ8c5ua3FuHQu2fioY9+znZVCIIgCKLZQMJPDvPk58sBAHe+uyS7FSEIgiCIZgQJPwTRgiALKkEQBAk/BEEQBEG0MEj4yQMMI9s1IAiCIIjmAwk/BEEQBEG0KEj4IYgc4teaOrw8bzVqG6LZrgpBEESzJZLtChAEkeTUR2dh2YbtWLh6C/5+woDAyzdBHs8EQRCk+ckDyOWn5bBsw3YAwLTvqrJcE4IgiOYLCT8EkYPESEFDEASRNkj4IYgcJJYm6Yfy/BAEQZDwQxA5SYykFIIgiLRBwg9B5CDpMntRziiCIAgSfggiJ0mX5ocUSgRBECT8EEROQkIKQRBE+iDhhyBykLRpftJSKkEQRH5Bwg9B5CDk8EwQBJE+8kb4efjhh7HPPvugdevWaN26NYYNG4Z33nkn8btpmpg4cSK6du2KkpISjBo1Ct99910WaxwcBnmptjhisWzXgCAIovmSN8JP9+7dcdttt2Hu3LmYO3cuDj30UJxwwgkJAeeOO+7APffcgwcffBBz5sxBZWUljjjiCNTU1GS55qlDok/LgzQ/BEEQ6SNvhJ/jjjsORx99NHbddVfsuuuumDRpElq1aoXZs2fDNE3cd999uP7663HSSSdhwIABeOqpp7Bjxw4899xz2a46QXiGhB+CIIj0kTfCD0s0GsULL7yA7du3Y9iwYVi2bBmqqqowZsyYxD5FRUUYOXIkPv/88yzWlCD8kS7Rh2QqgiCIPFvVfeHChRg2bBhqa2vRqlUrvPbaa9hzzz0TAk7nzp25/Tt37owVK1Zoy6yrq0NdXV3ie3V1dfAVJwiPkJBCEASRPvJK87PbbrthwYIFmD17Ni666CKMHz8eixYtSvwuOgabpunoLDx58mRUVFQk/nr06JGWuhMEQRAEkRvklfBTWFiIXXbZBYMHD8bkyZOx77774v/+7/9QWVkJAKiqquL2X79+vU0bJHLddddh69atib9Vq1alrf4EQRAEQWSfvBJ+REzTRF1dHfr06YPKykq89957id/q6+sxc+ZMDB8+XFtGUVFRInze+iMIgiAIovmSNz4/f/3rX3HUUUehR48eqKmpwQsvvICPPvoI06ZNg2EYuOKKK3Drrbeif//+6N+/P2699VaUlpbizDPPzHbVCSJnMCnHM0EQRP4IP+vWrcO4ceOwdu1aVFRUYJ999sG0adNwxBFHAACuueYa7Ny5ExdffDE2b96MIUOGYPr06SgvL89yzVOHchwSBEEAtQ1RFBeEtfvc894P+HFdDf555v4IhajzJOTkjfAzZcoU7e+GYWDixImYOHFiZipEEARBZIxJby/C458swysXDcegXm2V+93//o8AgM9/3oiD+nfIVPWIPCOvfX5aKg3RGB54/0fMX7k521Uh8gwKoSfylcc/WQYAuGPa9672r2uMprM6RJ5Dwk8e8vSsFbj7vR/wm4cogSNBEC0Lkt+JICDhJw/5cX3+r1dGEAThC5J+iAAg4ScPMGhpU8IlpmlixcbtMMm+RTRT3EYs0itA6CDhJy8hYYiQM/md7zHyzo/w2MdLs10VgkgLJNQQQUDCTx5Coe+ECkvomfyOO6dQgsg3YiT9EAFAwk8eQrIPEQRkGiMIoqVCwk8+IEg7pPkh/EICD5HvuG3B1NIJHST85CHkAE0EAclBRD5C7ZYIAhJ+CKIFYTBqQxpDiHyE2i0RBCT85CFk9iL8QmavlkltQ7TZPPvmch1EdiHhJw8h2YdQ4WUdRxpEWgarNu3A7n+bhkufn5/tqhBEzkDCTx5ikOqHUFAU0a94TfJOy+PZL1YCAN7+Zm2WaxIMujbMCvQk3BM6SPghiGZEUYH7VzrbQ8Mlz32FcVO+oEEqzXjRBuYDugzP1JQIt0SyXQHCO6T4ab4YRmodeGHYg/CTxYGiIRpLaCKWbdiOvh1bZa8yzZxIM5N+tJqfzFWDyHNI80MQOUQ4Rcm2MJJ/rzQNWOkllKfCzxOfLMUlz36FxmiM2x7TNBjK/ky4Jf96yhaI2HVRnp/mCyv7+DEHFXkQftwuEEnkNyEPAnVdYxSrN+9IY23cc8vbi/H2wrV497t13Hbde8H+RK2b0EHCTx4g9l3s9/OfmmubGRH5C+vMHtVNcRUUOjk8ey6RyHfCHjQ/Jzz4GQ66/UPMX7k5jTXyRk1tg+t9SaAn3ELCTx7CdmUzFq/DjMXrlPsS+QVr9mr0Jfzkh88PWScyhxfNz/dVNQCANxasSVd1POPlPaB2RbiFhJ88ROzL6hpJ89NcYCfpfvwXWLNXQw5rBLM1Q69vjGFJVU2LijDz4/LjRWBKN6IGtAU9OiKNkPCTh1Cen+ZLKEXNDyv81DZEA6lTOsjWAHbuk19i7H0f47X5v2SnAlnAi9nLIpe6GPE90E0KYlyen7RViWgGkPCTh9gcoHOppyJSgn2U0aj33rsgzAo/es1PSxwcPvtpIwDg37NWZLkmmSOXtDh+iImaH82+LbFNE/4g4acZkN9dG/HwRz/jjQVxTYSRouaHNefIND80OMRpqWYvt070udSnNMTcm2/di0lES4eSHOYjmugvIr9YtKYat0/7HgBwwsBunNreT7QXe0Rdo97slc3ImGzLHi1pWGTNXo2xGMIhfUQgkFt9iqgB1Ye6t6QnS6QCaX7yEDHPD+X9yT4bttXh8583eO58N26v476zhzd6mPFasPISmb3U5Pu1V22txWXPz8e8FZvwzsK1GHPvTCxpitQSYZMcNro0peaSKT1qisKPet88f6xEBiHNTx5gE3ZI85NzHHT7B6htiOHxcwbjiD07uz5O7MjNVDU/zPGyaK9cyYOS7XrkeybgP7/8NT75cQP++3UyJP3S577Ce1eOtO3LOdG7FX6a/pumidWbd6JHu9KU6psKtmgvzb5m7gY4EjkGaX7yEHvGZyLbWFqWD5esT6kctp/3Iftwg3qDw0CXzeE/27JHts+fKis22rMw76iXmzn53FEupYOmQ2584zscfMeHeOrz5V6rGBii75vW7MW06nx/xkR6IeEnDyHNT3aJxkys2hTMEgBi/8yH6vrR/CQ/yzJ/s1rEbPpHsGfORvPN93HRyzvPCgRuneitdvL07HhU3B1NfmnZwIsGlAQewi0k/DQDcsk+3xK4/IX5OPiOD/Hm1/YsuF47X1EASXVtIlZ4qs9hsxdLNmqU746xXsLXWdnBbeLLXOpSPJm90lsVohlBwk8eYnd4JjLJ29+sBQA88tHPKZdl8/lJUW0f4zQ/uWz2yu4wleeyjzfND3OtfvzIso19VffcjPb69peteG8RLTWUL5Dwk4fk0qysJeMnc66IqInhxyYfHbnDLD9XBv1sVyMXNWBe8Kb5ce8Hliyf/57Nu2X3+VHvy+4aRJ29CFPHPvApLvj3XGXUHZFbkPCTB9h8fGy/qzvCusYo1m7dGXyl8gjTNPHEJ0sxe+nGQMsNBSH8CH0rO1Cl7PDsUECuLGyaFZ+f/JZ9PK3XxQ7gbh2eRe1yNu+XqOnRh7qz709qlY7GTJzwz89w7tQvPR23bMP2lM5LZIa8EX4mT56MAw44AOXl5ejUqRNOPPFELFmyhNvHNE1MnDgRXbt2RUlJCUaNGoXvvvsuSzVOI4Z7s9dR//cJhk3+AN9XVae3TjnM+4vX45a3F+P0x2YHWm5YeuO9dbj2UHf1b27ghB+nBW9zRADIRjXyPdTdr8+P21D3XMJTnVN8f1iWbdiOb1ZvxYdLfnVMGMpCmvn8IG+En5kzZ+KSSy7B7Nmz8d5776GxsRFjxozB9u1JKfuOO+7APffcgwcffBBz5sxBZWUljjjiCNTUNC81pPhuhTRPcemv8fvzvyY/lZbI8o3pmYlFJDc+lQ7X5vzsQyxgj/CTJDFjZDvUPbunTxkvQQ4xTvPjz+yVTeyruutC3ZOkKuAWFyTf7+qdja6Py6FbR2jImySH06ZN475PnToVnTp1wrx583DIIYfANE3cd999uP7663HSSScBAJ566il07twZzz33HP7whz9ko9qB4PQyucnwnO+dfS6iEzrdwj4XeyfvvTw+ssfJ4Tmboe7Jc2dlsMjzF8KLcMJrftzm+RHMXlm8YTafH82+QWr02KKqaxvQsbwosLKJ7JM3mh+RrVu3AgDatWsHAFi2bBmqqqowZsyYxD5FRUUYOXIkPv/8c2U5dXV1qK6u5v5yHT9q1TzX8uckQWh+dD4+fp6Zc4bn3IPMXt7xFu3l3eHZXoavwwLB0/IWzG+pPmP2+OqdDa6Po9Qj+UFeCj+maeLKK6/EQQcdhAEDBgAAqqqqAACdO/NLC3Tu3Dnxm4zJkyejoqIi8dejR4/0VTwgbJqeZv6ubatrxMZtdc47ZhjDAFZu3JFSeK2us/Yz2+ZMHE6anxxxeM7K+bN7+pTxsp6fn8Vyc6lLsS1sqnl67C+ptjH2Xm31IvykdloiQ+Sl8HPppZfim2++wfPPP2/7TZS6TdPUSuLXXXcdtm7dmvhbtWpV4PUNGvFy3Dg/5nNo74Cb3sWgW2agptZ9B5QJPvlxAw6580M88cmyFEpRD0z+ND/Jz7Ikh/IzZx723BTt5R2/Zq8Gt9FeOTSCewl1ZyciqT5jTvNT68HnJ4fuHaEm74Sfyy67DG+++SY+/PBDdO/ePbG9srISAGxanvXr19u0QSxFRUVo3bo195fr+FnbK187e7Yz+/nX3AwhvS2F1P9azU+KPj9SzU+ONIRsJznMf7OXT4dn1wubij4/2SMqCGy6ugRp9mLnDt7MXimdlsgQeSP8mKaJSy+9FK+++io++OAD9OnTh/u9T58+qKysxHvvvZfYVl9fj5kzZ2L48OGZrm5aEV8uN694OjqvWMzEWU/MxpUvLkhD6XFYbUiBPLY86xRFkq+RVw0bF50SE3/zEe3l4POj2relke+X7i3PT/KzKEiosA3gWbxf3jQ/zOeUz5u8V9U5pnUmUidvhJ9LLrkEzzzzDJ577jmUl5ejqqoKVVVV2LkznsDPMAxcccUVuPXWW/Haa6/h22+/xYQJE1BaWoozzzwzy7UPFnHW52aGk47OfnFVNT77aSNenf9L8IU3wZpuWCEjl+CEH4/3mRuYAtD8sMe4NXFkg0yNpTW1DYEtQptLeMrzE2MFYo2/DNN4cmmaYfdT0vn8sGavFB2eOc2P3uzF37tcunuEirwJdX/44YcBAKNGjeK2T506FRMmTAAAXHPNNdi5cycuvvhibN68GUOGDMH06dNRXl6e4dpmGBfveDp8fjIxttYzifpk0VWZRhYqXBQJA/A3MzR1Pj8+yuOTHDqFumePIGfoOoZN/gDb6hrx4dWj0KdDGXP+/Fb9+E5yqHlp2f1yyXTjW/OTqsMzU4CTwzN3rhy6d4SavBF+3HRWhmFg4sSJmDhxYvorlEGc7PvZcmZmq+XkWO4XVvMTxFpaqSJzIi4qYM1e3tD7/NhLW19Ti531UfRqX2b7TSxDNtAFGQ0TFOmsx7a6+Iz905828MJP+k6ZEby8am59fljh2xY4ksU7FvMwKeDMyAFGezn5/MQUWrMZi9YhZpoYs1dlapUhAidvhB8iic3nJ1tOP0Id0jFbZDU/uTBY10uWjCgM+9dIsZckan5knfeBk94HAHz1tyPQrqxQW15uL2ya2YqIA2j+Ozy735e9Ul2GZ/1q6e7PFzRind2u6p5qG2PP47S8hey27qyP4vx/zwUAfPv3sWhVRMNtLpF9OwLhiM330JR/X75hO56etVz6oqa77xL9VYKCE35yYL4uE35YzY9X2M7aybeB3XeFYskOzudHMsvnfCKyeT9N5Ze0IA6YqWoFso0Xsxe3sKnGCZ5bbDb7StYEbnMTAfxzDVLz41QWp/lpunm1Dcl+eEe9+1B5IjOQKNoMsF68UXd9BADYvKMBlx/Wn9sn3T4O6ZpJs2amXJisy8xexZFwIGXrFjkFgNoG1vlbfk7O58ftUgZZINPmtyByKOUS3nx+3Dk886ab3JF+vPj8cC3L40Nes2UndjZE0a9jKwC8tpBtP1Vba1FRUoCSwuQ7yAmO1n/2FuZ5e2uOkOYnD7EvgMnz5bJNkmOCrwfv8xN8+QDvtJsL/YfU7JWuaC9hX3b2KNM2NURjXHky/w7299/883Nc9vx8T/XNV+zPJRdak3+8+fwkP+u0KDrtbTbvli3Pj0vznFfNz/DbPsBhd8/E5u31AHihyxIMV23agaGT38dBt3/AHctrfpr+MwJkfre25gkJP3mIk4ZA1jEG8fKZpsnNhtiXO32aH72tPdNIHZ5TCMHXLT0g3tKdjBpdfMT//PAn9L/+HaxkwrpldWWL/GXLTvz36zWe6xwEmYr2smhuZi+/SQ516Q9M5icxtiCb0XFeFjblNYr+6ryi6R1ihUHr48wffgUAbGwSkCykWrMMTA4J/5Dwk4fIPDlYZB1jEC/fOf/6Ekf93ydS7Ue6BpM6zuE5+z2I1OeHMUF5TnLIzVTVPj5A3IEyuS9fzp3vLrGVLfPvyIFbCEDMx5L+89lzKOXIjfCJ3ySHumgvmfYiF/BiskxF8yMiM3upIk5l5+I046T7yTlI+MlDnDQ/6YgIN00Tn/y4AUvW1WDeis0AwK21lS7ND+uj4PUM9Y0xxygNrwTt8MzilOeH1fy4GbydHJ6zSaZlDy/h0m6pb4zhmPs/wdX/+TqA0rzhN8mhLtorXUELqeLN4dlff8GvCWbazmuVqxJ+TIngGGTOISJ4SPjJQ8QBTOwb0jFpY8+xYVsdXp63Gqc9NjtZpzT51voNdTdNE0fe9zEOnPS+4wKffutjkYrZi70ksZNvjJoY/68vMfmdxQCAHRrNjwypw3MOdsKZEMjE+yUKQ3749Kdf8d2aarw8b3XKZXnF78KmuuUtOMFBnGC5P13g2DU/7nx+vGj3ZGZY2f0IK4ROLkGkWBCRk5Dwkw845PURBw+p2Qsmvlq5OaG18UJDNIbXmSUsNm6rwzUv87PdtPn8cMKG+3M0xkws3bAdW3c24Kf124KrjzLDcxOeHZ7ts0uLz3/egJk//IpHZy4FIJq9nE+km+VnG943I/3nCyJ7tkh2Vw/x5/OjaxKZ9sNyizefH3/mVNn7xL7qUQfNj+x4Pq0EkWtQqHseIr5IbsxetQ1RnPTQ5wCAxTcfyYVpOjHl02W47Z3kyuUbttXb9kmf2cuf5ocd7Gpqg8ux4RTt5RX2ksSBSTRDsGYvN/dbmuTQU+3SR6Z9bmzny5Ub4RNvPj9qAZtFZuZJluH+fEGgy3/l3ufHi7nMXgabId0qS2VtlJnb/GqhiMxAmp98xCEkWjYrrGYEAK8Jt95fvI77vnF7nWRxVfXxtQ1R3PLWImkIvhN8kkP3eElN76k+TiuleyxP18mzKnbTNDmzl5u+VOrzk4OdcCaqJLbPdJ1yW10jTnt0FqZ+tixNZ4jjd20v3b3Wmb10RGMmvv1lK9d+P/7hV5zx2GxlMk4neCdt/p1zK9R4ecZ8maZtW8wEflhXwwVgsKZTmdCVae0m4Q0SfvIQu+ZHNHvZt7MvqpeOU8avNXbNj25Qffijn/HEp8tw6qOzPJ+rzq/mh9m52qPmZ3tdIya9vUhqIpRpflIhJuk0LSLM9L4xZmInI7T61vzkSCfMm1jSXylRixa0ptJq/099vhxfLNuEv/93UaDli3hZ41eXToHF7y25fdr3OPaBT3Hr/xYntp3zry8xa+lG/OnFBf4KZfBiveUFFp8+P02f2dfn61VbMObej3HNy98ktsnyALHH5+JEg0hCwk8e4jbaS5XczGvHL2Z7/XVbnW0fXQeVis+NX2Ejymg9vGp+Lnt+Ph7/ZBn+8PRc229OiQO9dni6gSnECD/1jTHB7OVctjTUXbJfS+ikbdFeAVwyO4ewit9e5yxoR2MmLn9+vm/t0IqN2zFj8XrX++sEbH4/+WTJicc+jvukTfnUfj3ra+x9hRvYs4sL9Gp9flxquezns+/sdA94sxhbFv/fa12IzEDCTx4ivqg2h+cmYYVf4ZsZZFN8E6OxmM2w5taXwCucz48HDQGn+fEg/JimiQ++jw8sMt8m2b1LRXPBDUwas1dDNCZEe7nR/OgFNd22dLGxSXDOdBiwzYclYG2T1cbdaFXf/a4Kb369xrd2aOSdH3maFJgSrYQM9j0N6u74fbbaNe80ZfICh/uTy4QXp36SS8MhCZX3639EZAYSfvIQJ82PkdD8JH9ghQjPwoiLVeTdzii94jfUnRUkapjZuFOHyGZI3q9nG9vvsnuXSr/GdfIK8yVg1/y4y/MTc7VvpjrmZ79YgUG3zMB9M36w/bZ26078461FWLlxh+TI1LGFugd8ydGYiQ0SjaiMLTuC80Fzg1uzl5Nv0ONNGh4v+NUq8pof9yZLt4KeiMxs5dRPNipM8gnNj8QJmsgdSPjJA2yruovfbWYvw7adddRLRRNjlStOcPWOlP7P5Vf4UYV5O5Xx3ZrqxGfZgqVOgoLXS1Utnhj/nvxcH41pMzxLyzZNLFpTjf3/8R6e+nx5U/1kmqvMcP1r3wIA7pvxoy0k+YJ/z8WUT5fhjMdnqw5PCS/aAz989tMGDL5lBh788CcXdUlPjLxK6eRWA+EUFTaJ8elxSxC32UugHvubl35HlqfM6V1X+/yYkrqYqNpai3umL8G66lr3FSPSBgk/GeSHdTU45v5PMGPROuedNTh2Bg6an1T7Xlmn4LZT9Ypvs5dK+HE4bhEj/MjOJ9f8+L8+1jIlFsNqguobBbOXi559w7Z6HH3/J9i8owE3vfmd9ByqbelGPOe3v8Tv+y9bdqbpfMGbvVhh4+GZP7s+LtXJh1d4nx/1ftE0aCr8m710v7nU/Hi4CpnwolsKBBCFH7YO/H+rzPOemoP7P/gJ5z01x3W9iPRBwk8GufjZr/Ddmmqc/2+7I60OMazcnuFZMJcktie3sRqUdKSxd9upeqXOp+ZHNcA4zeYWr2WEH8muTgOX10vV+TawAk5D1PTs8Oy6DllQypvc5/Sf3762V7Dle4mfZAfNtVt3Jvyg0oXMH0UGNykK6Ab5fba+j3Mp6InI8vQ4an7YCaUs2ou5hpiZ1Cpbgj6RXUj4ySCbt9sdaH1hs3vxXy2zV1A+Pzazm2mPAEuXw7PfpSlUApdTn17NrFcm21WeydU/nD+GULao+YkqHCy9IDsu276YmTj/M7NXclqlIE7ppEH9bs1W6Xb2fRg2+QMMumVGALVR497nR67JSIWgnq1b/xnuN58Oz9Z9cOq3lA7PktPns8NzNGYGshxMrkHCTwYJarkBu+wjaH6sPD9M58y+qCn7/Mj8RrSqaP/naghY8xONmdq6yiKk+OPt22TOjm7RRXux3+ujUU4Y8vsIc6ULy0Z4/emPJfNMBTEYsc9D5m9zzP2fSgUgWT/g5n588uOveO6Lld4qCfdmL177Eczz8d1OhePcJmr0+y7KHKWdNNbKUHeZz09Wl0Lxz9OzV2Cfie/iD8/My3ZVAoeEnwwSlPRs818Qik2avXjNgYVnzY/MuVnY5rZTBeK5UNxmfq0P2OfnsLs/woSpaps7l1NEUoTTGj5e0c222Wuob+RnX0HOJLPi86P4nE5WbWI0PwGc1M37/NGSX10d5+adHDflS/z1tYXuKseez63Zy4WQ9O9Zyz32Y8E8XekivRL8JjmU5URzzPMTlZ/LOsyv/1Eu8bfXv8X2+ije8+GnGouZWLy2OuM+bm4h4SeDBOVr4+TwLDN71Svs037w6vAsNv5D7/4II+/8CN9XOdu+3XZ6Tue0WLO1FjN/sA9IFmyH5tbhWa4NMrF2q7PzLnvbtGavaEzQ/Pg1e0m2ZbljTpcWKN3aJU7zo/D62SZJeijrB9Lhh2fh1vziZnmLG9/4Dv/9Zo2vc3tBPM6t1px3MnZ/Ppn52anrUQeRmCnVpblwz3s/4Kj/+wR//+932a6KFBJ+MkhQErBYiq1Dk2R4rmOcZb37/IgO13Z0al2xeuuq4w6eMyWzYhEu8ZrLak/7di0++XGDdh/VwNjocD4nk4X1+a7pSzBs8gd4etZybT3Y6xNDoDmH58aYr3thq6vUZOmvrFTIxDnTfQ7uPVJ4PMsyPssF6PRVlh/Y1fu51VQsWuveYTeoq4o6mKOT51NrUnXItGNOAqkqa77ssJhpKleEz1fqGqM48/HZ+L8ZP0p/t9I+/HvWikxWyzUk/GSQoEwVNs2P8D2Z5yf5Q22Q0V6mva/Xan4Uv5UWRRxPJcu8quOXLTtx4TNf4fZp32v3U80kucRlTf9rahuwbEPcTCdThcsu758fxkOf//aGftbDLynA/yZqfvyq9Fnkmp9sYEo+pesM6YEd/FTDGqv5+WFdDeav3Cxte5kSfvQa2uRnt341Xs7tBVH4anDrNMP1F+7PzWlgY9Z//Tl5h2d7FXiNG79WXz7gpDl9+5u1+PznjbhXkrQ0H3AefYjACCyCwra8BT8oO4a6p+zwLNmmKVLlc1BaYE8iaC9XfqyK9S4TiDVEYygI22V/WQTHsMkfYFtdI6b/6RBHk4XXO8v5GohmL85hPSbMND2eqAmp1i7NKpJYzOTWKQMyYxJIu9nLxUNgNT9j7v0YAHDS/t18leUXmTOufD9375qX+xqU2cvt/WH3kp07GjPREI2hWOh7ZAKik9mLd3i2C0K8FspEQTjEpe7IdZxMjbUN+XMtMkjzk0G8dHCeoqdMUxp5ohrUUu1oY6Zpc4LW+xIkP7Mvf1mRs/DjVfPj9soaGlVmL7vmx5q9f/zDr1LNTyrCA5dV15bhOVmXusYYpxkKVPOTRhlh7dadGHTLe5j8jvfswKmSbj9LTvOjNHtFbdtWbbIv4eH0TqYSLMG3Mc05XPj8xPfzd+5U8OPwLDv32Ps+xt4T38WOet4cKYu6dM7zI9eoWZ95Ad9EJJxfmp9axlUi37RWbiDhJ0dhXxx7tJVd88N2njKHZxavHambpSysc23d0WBbn4lbZ6s22emIsy8ZbjtkL/sA6vxBjQpVtoVskEplYNLl+WGLbRAcngPVaqRRSPjnhz9h844GPDqTXxfK3oJ5ahuiuHv6EixYtcX3udPtyO3GfGwJzuzzkpq9nAbalNqYu/PwwrWuPA+TONd76o9zrfkRTE0iP63fhoaoiW9W8ykI+KU93J2Tc3iWTNLYo+Nmr/wablnNjsxfKduBEqmSX0+jBaFrVuJvsZgpnYWq+qhUfX5kjd46/ci7PsQhd37ICUBsZylzANXB9z/B6X5UM8kGic9P4rspv3dcHZs+u1jc23as2NdyeX4aRZ8fd+XbsR+Yzk5MVU8ns9fjHy/FAx/8hBP/+Znrc4nPNN0Oz7ypWR/t5WSydBpoU9HWug91Z/bTtAlP99VntcV6OuXfkp3Oi9+STEB0XNg0Jr+vyVXd+YlUQZ5pfuoamYWUJb/naAS7a0j4yVHYF0eWYZn7DnFQ1mt+vM4iZZofWwRY07msFas/XLI+8Rt7OtYB1JUo40Hz8/Ov27B5u7sVs1XCD9fhyQQdl2avskJ37nS8wzNfjpjhOYg8P5k2e6kGW25hU8nvP6zf5uk8n/64AXvd9C6XBDDdwg8fqSc/2Q5L+NE8Z93xFo0pZMnzleQwIM2Pf4dnHrfX77Q4q8Wt/1uMMffOlGrmXJu9HARaXvOTj2YvNsFsnks6Ekj4yVF0nZTN4dnkO9SQJNSdKztVh2fJ4WKR62uSjsfs+Tjhx8UL5bbzXLZhOw67e6brddOUmh92Nif8ZsKUan74SI/4l5JCZ5MewN8bUShlB0TR7OXb4dmhkw4avxoLr8PEh0vWo74xhrnLNyW2ie9J0G4L7POqU7Qnq72zY7efUPdUND+69eNY3GqI/j1rBV6au8rduRXbf1hXg69WbnZVBuC8yKjT+UQW/rIVP6zbhjcW/AJAFBDjX5wmiY5rewllFuSI2cutIMNqfqS3wqGcXHcTyo2nQdjwonY2IX9Rg3J4FveXvTziPuurk4s1soP2tlpW+HE+t0PC5QRzlm3S/GqnXuXw7OBYKftZrvlxKfxwiiZT+I3X/PChyH5n1DLhLX3ij1+zF9txvjJvtXKdLIvlTakIOOFVKFcW3ZcK3Np5iiie7fXxAcQpQaUXE4tXxEFYhdt3DQCuefmbpmP0e6pON+bej3HSQ5+jaqs8OlM8zn2SQ2/aUUOiJU89w7P1mW+LuaD5eeijn3DApBmuMuyzmh8/GryQW9t/liDhJ0fR2qtt+/JLH5jMdhleG7I46zLh7IS9viYp/HA+P0yUhVRVrBEAdNX22rHIND+xmCkII/bjnEwW1jElPsxe4gDILW8RFZ5xnmh+VG2NF37s+xhMA7vqP1/jmPs/1Z5nWVNnrpqNA0BhwMIP24ScFuBVJcST/S7DreZDhh9zltv2JV53XWMUP/+aNFk6+ZNZ+bNsCIc55dxJHKZ5f2XtrCgSbxOya3d0eGYjQyXnFYXOXHB4vmPaEmzYVo9JbztHX7KJcU3Tfv+cmggJPwHy8ccf47jjjkPXrl1hGAZef/117nfTNDFx4kR07doVJSUlGDVqFL77LjdTa6eC/aWGNBJI1R97XTFCnHW5MXv9ygg/7P5stJc4CLy/eB0OmDSDW37CaZC0iHgc2GTCj5hITbq8hcwPSFKtUo3mZ8aidRhz70x8t2Yrn1xNKJtf2yug5S1k29Io/fgt20u/GY2ZifBxLk+TsF/QM292QK53yN/CCq5Ss5ejf4nzS6u6Z26THMpMP06I79Epj8zCYXfPlJYpQyU02pIcujV7Mbv9b+Fa3PD6woRALLsk61nI3kPHZ6LQ/Nj1PvH7wDo8Z3uVdDdnF3MSsbdj47Y650V2c1v2yS/hZ/v27dh3333x4IMPSn+/4447cM899+DBBx/EnDlzUFlZiSOOOAI1NTUZrmnq6N87UQI3+Rexqc2qHZ69ST/i/vJoL5eanzq12eu8p+Ziw7Z6jP/Xl9JjN0vC6C285qGQdbp28x5s3+UZnu3bWOFHHBjP//dc/LBuG37/73lah2cx1J13eLadksNLKv30mr0Umh8Hh+ewB+lnzZadicGxUTEbB7wLyE5wmh+F8BMy4hOBjdvrmeO8a35Si/ayl7O9rhF3TPueMyfKBnAnRKFEDCGXFcS2Y1a7oMNPksON2+vxzOyVeOWr1fHzStriNa98gyVVNVIB0dHspXgfk9Fe/Da2/TlpCt2yevMO/PPDn7BlR73zzgxuXvla4dmw92j81C/xfZV+XCWfnwA56qijcMstt+Ckk06y/WaaJu677z5cf/31OOmkkzBgwAA89dRT2LFjB5577rks1DY1PPn8mPLZnTLPT6pmL1O+vAXbWbBCDttxpeLwfOEz83DInR9iXXWtrTP0KvzIZpLiNulMUar50Qs/qvD+LTvqteHrqWh+VLcj82Yv53rI6uRF88OaTholGbotAjd7sT5ZytQJJg6YNAOH3zOT2yayZUcDzvnXl3hl3mppOan5/LD3JP7/nW+r8NBHP+OB939K/ObL7OWg8XLSnqoyHovnd5vkUNanWGsJqm7hyY98Lk1y6KRsUjo8J/7z95Pto4LK9Hzao7Nx57tLEj5YQVLbyAs/7HP79hfn9d3I7JUhli1bhqqqKowZMyaxraioCCNHjsTnn3+uPK6urg7V1dXcXy7AvsOG0Ihswg/ksxBVB5aq2Uvuq8O/HKzmQcxXkzjGxbll5zr/qbkY+PfpXKZcr86sMgdV0dlZPLV4ny3YTtK6Bax9f3u9XPhpjJncsxAFOs6hNioubKq/e2KbSRyX4YVN/ZrnvHScyxnnTS5Pk03zE2xnrGrXTsgEpfvf/xEf//ArrvrP19JjgtL8WM/Disbc0SCP6HGrDXQSSsRi6htj3L1S3Tfx7G59nmS3KZFxWdHj1NQ2+nN4dszzw9eBbdN1je40Xk78smUnAODjH50XiebRX9vC1Vvx4fd8mV5fZRJ+MkRVVRUAoHPnztz2zp07J36TMXnyZFRUVCT+evTokdZ6ukXXzpxC3a2XL6gMz/aO13785z9vwPuLk7l9WM2DypdArF9xgb05yjrhhb9sRU1dI/75YXLW6nXFZFmnbfdt4r9v3lGP2T9vBAD079Qqod2RRZiwz0i2xAEQv6+66BRO2AGUZi+pw7D0jJA2rHQmOXQziMrO76XfXL4hKQQ3CveMJehor0afwo/M1MOaxaTnCsjh2fps5eNi/Zb8ONQ7aTBEAX7Y5Pdx0O0fuD7ewr3my77fpz9uwPa6Rn0QiUQD6+QewGV4liwKyws/9ujNIAnShWjeik047sFP8ebXa4RzeDtJjss+zUf4sbBrSUzlLBgArrvuOmzdujXxt2qVu/wV6cbL2l4x05SaRFQvhNcMz7LMueI9ffyTZbjwmXmJ7+xClirTjliNUkmElO6lTmU2LJt9O81iH525NDFIjR/eG1cesWtTHe3Xx3aGqk60MWa6jvZSPWP2nBa6Tkd2x9Kq+VHcUu6ckvPr3lkRVvOji/YSTaOp+jpxg5kHdWqtZOBzmpAE5vPT9HlzUztWRaG5FYgdNT/M5zVbdmLj9nps3pFMRFqv0ICIz8Z9kkP7trkrNuPcqXM8O3s7Lmzq6PDM/86ePugFTr1OaHVN/6nPV8jPQZqf3KSyshIAbFqe9evX27RBLEVFRWjdujX3lwvoGprsJ/5FtP7LC/HqP2BzBIazIz/rsKrS9oj1K5Gs9eWmw4rFTPzkMSOwzO/CyeGZhTfrscfYNT+6cthTPj2L73TEJRHYzlgXmaN7NrIBP42yjyuHZxleFHnLN7BmL/V9F81eqS7w6/d42aw/iGgvFTKTzOaE5kcuRLu9NC9mL9kSIDIhYO3WnVghLP7qx+GZ5cvlm1CnWIW8IGxIs6c7aToauFXdmTpIND+mMHkJXvNjafTqE4u2Lly9FVe+tABrt+607a+6su11jaiqlude8qr5Ed9h0zTx1crNqK51l4U/3bhLRpIH9OnTB5WVlXjvvfew3377AQDq6+sxc+ZM3H777VmunQ+0KlrxuykVKpR5fjx22qKg4Cp5GCf8JLfrDpWt8q6rqlWPG9/8Fs/Mdgi7FJCGutvyGalP7iTcue0n2GNrBMdoMX2BKgOvODCEDMOTQKNqJys2bkf3tqWeTYosrvL8SH53O2tsjMawchNr9mJ9yviSw0KelVRNBakKT17KCmptL3aQBARfQR9mLy+DuOyRisfHYiaGTf7Atp+fUHeR/327Vrq9dXEB11KsrsHxmSic62Vt3jT57U6anzcW/IKSgjDG7FWp3S95TmDrzgYMvPk9lBdFsPDvY3Hcg/HcWOur6/DM+UOE+tjrWN8Yw94T31UHKXiU10Tt7TvfVuHiZ7/Crp1bYfqfRnorLA3klfCzbds2/PRT0s9j2bJlWLBgAdq1a4eePXviiiuuwK233or+/fujf//+uPXWW1FaWoozzzwzi7WW88q81bh7+hI8Pn4w9upaYftdG+0l8fmRJdpTmr1cdKSmaeKhj37GLp1a2RKMuekY2XavWgPJpvlhzF6WuVJnmrDK8ir4ACqfH/fXGQoZiZfbKceH3tdA/ZsoNEYVAxWbOwnQCw6y08nq8MKXK3Htqwvxm/264d7TBqor6YCbMVt2frfCzy9bdnIDeKNO8yMIcX6dsS2CFH68ONd6L9v+efMOB7OXy3uTSr0APqLo5v8uUmoF3CY51D3Tyf/7Xrq9dUmBp2hZC2Wou/Vf0KSxz1inMVtfXYs/vrAAALD01qM5FwId36zeAsA+iVImkhTYuL3O1WTTLWK1X5wTdyn5YZ03LX26yCvhZ+7cuRg9enTi+5VXXgkAGD9+PJ588klcc8012LlzJy6++GJs3rwZQ4YMwfTp01FeXp6tKksJh4xEVMcfX1iAGVfapWBtOxM1P5B3YqoO1U0jXrBqC+58dwkAoLyIbyamaTravfgXX97B/vk/32CXjuXYu3tc+CtlzF51jTEUF4S1dU1ldXrZjNWLU2kklFTiy8wFbtPsywbQAd1a49tfqoWs3abU4bmuMYoDJs3gC9D5/Li8xPvf/xEA8Nr8X1IUfhSaH+6z/+e4XMj7pMq6C9id4lM2ewXoLLVGscxD4lyBa370Zi+3Z0s1Wd+OpuU/lm3Yjn99tky5n59V3UW2KVJOtC6O8P2VFeruKJAq/MskwlPM5LPH68pmfaK83F3rXopIA0kk+zlpeL22d1Hzo7r/2SKvfH5GjRoF0zRtf08++SSA+M2eOHEi1q5di9raWsycORMDBgzIbqWbYAdD1mSyrVbeINhmZlvVXfgeM0258OOg+YnGTJz/1FzcPX2JbR9WLbtNCNX22g2JMyCLxpiZUM0CQBHzklozQO1MJIWOV57nRx/qzhLX/DTVQzJjdjLrWMiEg64VJQBETY98fag1W+yDpq4Pc6v5CUqpoVShO3SkbjU/lr9P14piAILmR7hascQx936MhWJSPgU/rKvBozN/5hK/ZTJLb5Bre5mmiS07ZcJPejU/sgF/Z9OALSbUs50nhTw/TpQVRbhr37AtnhfI6drEaEzxM7tN1UfLEB2l3bJDkVKjKBKWCh5i+3US9jxHezGfr3n5a+VYly3ySvjJZ9gXiXU9UKk/9dFepvBdHBj1ZTTGTHz4/Xo89+VKzFi8Dg988JNtn1ZFrAlKrICyatJj3OanYd+96p1Nq2F71Jq4xU+oO0tY4dOUDHV3V47sJ2sGJkbfyEybskzIWrOX5IRSH4WA3KBdhbpLdnEbKGKp9Pt1agWAF2rF5iGe55ctO3Huk1/CDWPu/RiT3/keT3yyNLEtVZOPF9yafWSIkYHVtY2JttSoGJDdXpoXbYBs351NQo/T8073vWaLf2rWCjw9a7mnhU1liSTFba7XWOMCG9xfN5tSgz33orXVGHDTu3hmdjKg4qMlv2Lfm6fjq5WbE9ucNN9e5Uq2H3pp7mrS/LRU2MGWHbDUa9uokckiMgFD9e7OXPIrzn1yDv72+rfKc+ijrEzHaC9x1uOmXLaDr2nS/Oh9YgIWfiQLuKoIh5IzG87EJVlaxIvmJ2QkOw3Rp0B2H8OSxH2efX6k9dJU2gOyZ2QY8pkyi1sfayvMfZcm4Ydf3kKY2UrqYgnZbvluTTIJakY1Pynk+RHfRXYpBJUfmduzRT3USzZZ+e/Xa1wl/HO/qrvr6iSIxkxbO/3bG99h7orNiiOSx1lIgx6YfeNmr+QW3cTNT6ZtgNf8yMq/Qejva2obcdlz813VSayXiGySI77DuRLlZUHCT4ZgZ6SsA5sywynTlmzCjmQDK/U7hbp/uXyTY329htrb9lG8wDrtNfvy1TaFpaZL8yMTOm3hxJriQ0bS4VnWCbLVXrNlJz5cst6V1iUcMhJSlRh9I/PPkAkJhqTuOnu+NPw9KOFH8rxDhuFYvkyAkwkbK5p8fvp3ivv16Ryepe3FYyAbmygxSJ8fJwLz+YmZnE+Jyufnm9VbMOntRc71cnkPttc1Svu6mGlP8SA9j0utrJcJ0eBebRNl+zGX8ZFybN34//F6yTXEtQ1RzFuxWRlpx17Pi3NW4oulG5X1YX1+3DYXtnyVgJlc+V5Xjn2b6PMjBmZkm7xyeM5nWE0D27G7MXvZzFzCvjsbolyCQbfRCjp0na2bYjnnPtean+Rv1mzQbWIyrzQ02g/2pvlhfX6YY6yOj9n30qbZ1ZTxg3HYHnzOKfEaDIN1pObbgNS8Ju107NuiMTM+mEn2tzY1RGO47tWFGN6vPdyJuM5INT/cWRXCl6SsqGkixEgrjdFYYomT/p0ts5fa4dnN7NQJVvjJpNmrITCfn2SkF6DWXqzYuAOPf7LMsWw32q+tOxqw783Tlb//69NlOKh/B20Z8kSr9v28dHnWs4yapjIZpw5Vvyb9ZIoBC/HP506dg1lLN+Km4/bEuSP62MqqqW3EH56ehz27tMajH8dNrgsnjkF5cYGtPrzw4+5G6LRRo3friBMGdsN1ry6M76sdE0yIM4lQjqtWAqleNBrFggULsHmzXk3YklFlA1U6hCo+A/ZOfPFafnXdpM+P11qqzwEAfxjZt6k++qzZ4vHsS6UL8RSXCzAdOqWgzV72DlZdfoiN9hKislTHzvrZPmsTO5Qwq1HSzMp0S5ioQmMf/2QZlxMnWVb8/yvzVuPleatx5Utf+xIsG6MxXPTMPDwy82db2Sxi05EKOpIKiNtWb46HuRdFQujeNu4k3ih5FonjpYKYN+mnMJLsMjNp9grO54c3eykjllziRgD8/OcN2t+7tilxLEO37h2LlysosDQaErOXG6IKLaN8VXdBWGq67bOaNDnPfZFM18HW5Z8f/oRPftyQEHwA4PUF/LITFqrFpHWwu4n935TxB+DE/bolJgi6WyT7qVlmeL7iiiswZcoUAHHBZ+TIkdh///3Ro0cPfPTRR0HWr9nArwPj3DDFF4f7TdhXHOyc1vaSIdZJVsUzDugprY8M1S66l5L97Z73fsCwyR8kFu7zWpYT1vOobYgmUv1bHbllIjKhFoDChpEYxWXCrNtbLzN7JYWq5HbRJKc7j67LkftXxAuxVr+Ol+v93r7//Xq8820VbnsnmU9F7vPjbPaSPVuxrGVN/j6925clZ/GMCcNu9nK8BEcKGR+rIPP8sMjufWBre8VMbN7ubPbyU7YKpzFw9Wb1O25hT7Qq389Lu7WeZXyZGdeHJVA5iyfqwny2+fzIzN2JfZPbf5Hcm8Vr5Ytv72Q0P27NkdpkqU11Ckn6ORH2t0VrqrGtrrF5Cj8vv/wy9t13XwDAf//7Xyxbtgzff/89rrjiClx//fWBVrC5wAk/roQHXmXKlSXYzncKIY5Ooe4yxJdF1rFbMyVX75ViH9lM8aJn5sE0Ta6D/76qRplmXVdHt1g+PyNu+wD7/eM9bN5en6hbQVOnaJrqa+U7K3snKF09vel/RNHRAZbDc/wze33i4KczbeqjvdTbvLZREVmorawTDgkOz7K2Irsu8XlbYe69O5SigNGxWwOlWIZs0uG1f+Z8ftIk/MjeETfnUmmx+OghKB2e/VyPdYzefCj/0fIlqaquVS49YSGGurvJHO6ETGD2QlSxvIXMJB0zRb8gQdBgGiL7m8xPRlXV7cz755Q6gK2XhUqLZ1VNJ1BZP33y4684+v5PcOz9nygnYbJljLKBL+Fnw4YNibW0/ve//+GUU07BrrvuivPOOw8LFy4MtILNBZUPjApO88Nsv2/GD5i+aB237zZh1XBZxJETKzbuwBpGy2J/OZMdXNzspS9PdWbZAPTOt1XYurPBc+ebitnLcr60FipdsGpLooO1OkVTE/AdYnxzxE5O3CaiEpys3wxJtJfYMSWd2u3le1kUFOB9fhLbUrGZMsh9jA2hfbsb7EXLj+Xs3Lt9Gbdul6UlE0uQm728wZq90uXwLLv21PL88MI56/DMmQlTMHtVti5W7qNqjh1aFaGsMD4QysyxsvM44SVFg/WeiwkI3aLS/CT8/oT7rnN3YNsv+5OYrVksl4X1+dlR51b4cRZ+E5pwF8LP/xbG19YUk4+ytCrODVdjX8JP586dsWjRIkSjUUybNg2HH344AGDHjh0Ih3NDqss9vHUyqpnxfTN+tO27vU6u+fHSmR1+z0wMv+2DhABgfzlDiZmlm2JVgomuE/O6eGMqM++4Vid5vGEktSuF4aSGS3UdYYckhzrBjNX8iLtxZi+/Pj8eR3SriHqNs7BfZG3QjWwme7SisLEsofnhhR9L8yOe2q+wzF4DJ/zkmOZHBa+V0Dk8+yi76SDdgKZ63OGQgTalhQDi61LpsJt9g9P8NPr1+WFuGLuwsin8j9fL1GrZWM0P+5vYtwPqa2f3dZtTh52MqvrfpNlLXY4ldBa5mBwUhnPDE9pXLc4991yceuqpGDBgAAzDwBFHHAEA+OKLL7D77rsHWsHmAqf5ceXzwwyoDvuKL4h1qJ/OzEo6JjbcCDPYuyk2UQehEqprr22IeQ6FTGXsiZkml8U6HDISSyNEXJm9kmYGWdSHzryk0/yEjGSoO2/2knf+KuFCNQOWbbXK4jQ/0qP16K6ZJSSs2SbbR6YhtJm9WJ8fxuxl3Svx3sjNXs6SGCsUsmavVDSPOmTZjFNa20ton1sUmh9fZq+mslmhUER1j8MhI/EuOJ37kx95p+ma2kac868v8fBHP3PbvVxBYaRpUPcp/Fj37tMfN+DJz5cn62Dy/616yUxjFlyfwOwoE2JemrsaV730tW07u69MaJLBVkPlVyZbw1DEqnIxY9JSPdNciQLzVY2JEyfiiSeewO9//3t89tlnKCoqAgCEw2Fce+21gVawueA1eyr34ji8mOILkkqou3WEeGxE0HQ4JzmMHy/m01HNLkbd9SHW19RJf1ORaig/6yAYMozEyx8JOQ9w8Tw/TfvIcnxozh3RDKBxzY+9s7FHu/D/xbp5IeHzw4T/B2X2knWAtiSHLrQ8AH8/GqKxhKNsnw5lCIWMhMbLGpTEEvyavVghmZ21puKErEOu+Ukl2ov9bLoKdXeLdbxuNq+6x6wpXRcFCiRNnBZ3vbsEH//wK26fxi9W6lfz4wdLSHl1/mq+DlbEJ7tMRUw0ewnvPfPOsvVRLQnxylerbe8oa85UrfMlEtX0MRYhST8nYtWlyEU0pCwrfTbwbXw7+eSTbdvGjx+fUmWaM2LDCRkOakRh1qCjrlGuFfDzTsvs1YB3s5e1z1phwUbVgFHr4PAoI7UIGH5F6WjMTHQ6ulmsRZgzXUkEW03V+Fke/xsvVPGDPV9/tYDrdXkLq5NOVfMjnscwDFcDqlQb5aD5Wb15J6IxE8UFIXRuHZ98RcIh1DfGEtdhM3vJmpiLfph1xtVp7YIirT4/MV7zYzn7Gobh6xxWXYsiancHVXOMhEIwzfi9FfswJ175arVt29adDfjra+59ThM+PylqfgoEVYYp6QNiphh1x5fFFsEKJKoVAKwyWbYyz9W12UthWmcXQ3UT7WX9wmp+lBF5rmqWflwLP/fff7/rQi+//HJflWnO2DUpIW3DTmVtpaTTrQ/NT9MxYtVYzY+rcpr+i46MQSaGS2XwMU1e81PfGEtESBQlotrUnSLr8MxekpPPj1O+khCzbIZuVpY0K0pPo0RWq0dnLkX/Tq249uhLa8gcEo2ZiITlIe06c2LieMkO7D1IRHq1L0uo5QtCBuqRFIpt0V4+NT9s5AxbQrp8fmRaEC/LSIiIzris5if+OxA2Uov2cjNhEAmFDBhNl3rnu/bFlXXIqnrvez94KiPlJIdNlYgIS8wkUi0w22Kiz4/G7OX2WYvthH1/VYucivDuGMnj3/vTyMRnV3l+mg5lhSaVlj9dkwavuBZ+7r33Xlf7GYZBwo8EmWMrNJpJ3uzl9Vz6AViH9YJKzV7Md7dJDlc2+WVYBNnwUzJ7mSanbaqPxhJrz1SUxLOnmtD5/MgdnmXr+rC/jb3vY/zKmPdsnaBhJGZafHJIYSBXPCfAu039za/jSdMGNaX7j5frrQxAEAxMExFF/WImH0cnE9Kd8vwsY4Qfi7g5MZqM9hKKkJvgnMUfViuhy4sSFEFrfthDdzZEbWX9b+Fa7NezjS9NqhvhR6WJDIf0y664oX1ZYeLz2q3O+YJYrDw/srW93JBMjSHX/Ih9uM6VIaQwe7k5vwwxAlgFWw+rvKF926FHu9LEdjc+P0mH56TmR6V9SsGCGyiuhZ9ly5alsx7NHlGTExHMJmInbHKf5Y2ufVlhIlQbiK9VM3fF5qQ/SAop22VmL1UuChnWzzbNT4B+EqlGwLBmr/rGpMN1a0v4MdUvfEThm6PTum2va+SiQgD77C3ECFW66JDGmIltdY1Kh2I/cE6SKT4mlRBtbVvJ+HCIexx+z0zbfWLLBBhn5w5J4cfKz5SI9hJKljUXN7eKTQzJabfSNIMNPtrLPsCxXPb8fADA+GG9PJftxuFZpV5jBf0g8HqL+Dw/3s9naUoiIXnfzfn8iJofoW/mND8uL0SnIVqrSQ7LIgvEiQizJ+urrr1b5bDtQOXKEJQ/YarkiN9180dsz+xq3DJ7t1M0DGCftZYVRZrO5V/zk8wRxG8XzV5O76f1syj8BDlbTqUo0zRRW68QfootzY8mzw+7ACmzk87fSvacxeRuYUO+Zpg4aD35+XIMuOldrJHMdg1otIWae8ZF/qTYQSWcjiXF1DbEcO2rat8MmeADyDU/fTokZ6hWp90YcKg724nzTui+inMkaM2P7Jm3KrLPe/2cw9JAFunClxXFhpicVn6Jcv2kuv4yDZOVtDVVzU/EhebH5vOjcXh2++41xGLKtBY/KN4hEZl2WbxXVt30eX7kk2YZaVKYesa3w/Pq1avx5ptvYuXKlaiv523I99xzT8oVa27oGnttQ5RzFANEzY8cseFbuTaSkUA+1NgJnx9R85PUdLjBeglY50rAey4fHakIUtGYyWt+ojHUNJm9WpfE76NpJm3ZIlxnFWM74Kb/kmN2SrKuin5f8Y7Hfp9V9+2/X9vX+dE6PCt/Abfqtp97KzrWAu7aoNtmyt4qNsGhheV70eDF7OXivKzmhxN0M+nzE9DaXhYdWhXazBJen7lpugsSUCbPMwzPOalsZXNrJqr3KykI266X1fz4eZTWdRUIPj8y07cJXsCymb04zY+7Zx2NmQiHDMQkGqAfqmokRziVJ9dkucnzk9R4O58nFX/WIPEl/Lz//vs4/vjj0adPHyxZsgQDBgzA8uXLYZom9t9//6Dr2CzQrcwuUw+a/JsjRZTQy4usQVutfXBCNWiFWU9cF1hHiwN+kJqfVE0BO+sZnx+p5kf9oqqSEZqyaV8TOyXhp2Iaejbai0Wl4pZpk3STad3MzG1KfGXZzGdrUHSnTXD3HK37XN8Yw+rNTcIPZ/YSND82s5f9PJt3NOCo//sENxyzB0bsIl9ZnL3HvAkpPaofWbsWfb7clGH1D7JH0K6s0JaF16vm5zcPfY6Dmu6Z6PfiptwQk+fHL6qV1UWKC0LYJmTSSPj8mGrNz/+dPhB/fGGB/NwKM5GJ+HvGCiBxE7r9WAsu1N2Dw3Ncc2bf32lpIBni2oYWsuhTEetdczPZyRXNjy+z13XXXYerrroK3377LYqLi/HKK69g1apVGDlyJE455ZSg69gsEB84O7vTLTYZ/6ToPIRRzlJlf19Vg89+2pCSw7N4aEGYH5Td+vyI+SaCjPZKxXYcM/nBntf8sD4/8uNZlb2o3gbkw7ksAkMUXlQyZoNioJUJPyHDUIoTujsm00ypePaLFTjugU855222c7TaUTqE3VWbdyBmAqWFYXQqL0r8bs1YVVnKVZ334rXVOOuJL5TnrWOjvST+XUGTqs/PF0s3Yu+J7+KZ2Svix0rek7alhbZBzuuzWrBqS8L3SifEqITEuIk3ReEn5u55iJp1IGmuUq3tdcqg7jhhYDfHc4vRXjBNPDN7BSb9b3GybjFTW9ewjwVzf9m8M9CcOarrcaP5sToWN1XPa5+fxYsXJ3L6RCIR7Ny5E61atcLNN9+M22+/PdAKNhfEjpeV7mWzOjfRXmK7Z1PMn/XEF/5UuQqzVzhkCA7PzmWJ4eSyclNhzdZa1yGdIjHR7MVpfqz7qF7wMGzINT86fytZ9IPM50dmtlLdtzqJwKLX/Kh/85Jh+/rXvsXCX7bi3hnJ8GLZWmRuhF23faF1T60w915MmDuQHMwaEgI8X7BfPyY+2ospL0ejvW6b9j121Edxw+vfxo+VmNHaSIQfPxMTy0leJ/yoEhiGQ6mbvXSmJBbZYppOZq8Ch/B9cSHkRD0APDJzqXRfWb0Bfz4/pz0229OExYnGhM+P4PDswufHi6tFXmt+ysrKUFcXn/F17doVP/+cTDG+YcMG1WEtGvF5s7MhWefANhBVW1FpfhLH+XJ4lg/eBaGQ50UgTdOu7QhS8wMA506d4+u4mGnP8yOP9pIfHwpBGuqusXqheqdduBA7r1BIbvZSmT1Umh/Vswra3s46jXMzW0v4ceEV7LZGVvmWuYZ1dgaSg1BieQvheL9Nr45zeLbXJ2hS9fnp2CqpDVMN7G1LC2xaAz9+RdubQqpFPxEWNnM4SyiUerSX2wzVMs2P5acUM+XPUndN7LltZi/TXhdZfi92Quwn2itorDGpQGX20lQrmdXamVzJ8+NL+Bk6dCg+++wzAMAxxxyDq666CpMmTcLvfvc7DB06NNAKNhfEB97AaX4kPj8uFkK1OTwLwo8fh8xkqDu/PSwMym5KNmE3ewX9Yn+xbJOv42ImLzjUNkQTmplyRoOm9PlhbgY7ZujW9rLMajrCGsFFhtznR232CtpNhe202XbszefHHTLND4s1k09meBYGHJ914R2e7aa9oJGV6yWyrA/jB7VKsVp627JC2+DuJw2FlRsrpBEUVMlcw0bqSx3ETMbHUXOP2OR7FuwgLzPNiUKNiCVki2aimGkPnRffg2iMN2Uv27Adf3n5G6zatCNty6Y4ofL5SeQdc6H5cRXtlSOqH18Oz/fccw+2bYuH0k2cOBHbtm3Diy++iF122cV1MsSWhq5NSIUfN5ofoZGKKyur2tje3Sqw8Jet0t8SvhpChcVoLzeNPBozbYOzG01AJhA1P5uYrLecw7PiMv0kOdzuYr0dr+G/Mn+x4LwAnFHNWC0tgrtFfN2dy2o6lp9JH0H4KS2Mz+4tgdsW7eVzxlnPDEZcksM0zWBlAqMXLS7bflTveZvSAs7PBPAnzFmrsWs1PxqzVxAuKzEzLkh51fywTtoPvP+T7XebL4+A6n6ZsE+aRK1azDQ5IWfBqi1YsGoLZi3diHFDe2nP6xfDkL9rMxatw+F7dk4EVYjXnXScV9/fpAAa3PuebnwJP3379k18Li0txUMPPRRYhZoruoZTL1ELu/H5cTJ7yc750dWjYBjAyDs/ktczkedHEH58aH5Y4aIwHF/OI1sqXZGYaXIOzxu3xYWfwkiIW95Cee99JDl0g9eZsOgzFK+bev+gVc7sQMuvEG7fpsKtKc5qO4nszh144cdq/5Yfiliq30tnB65MhLrLZv5uBC3rUbATjC075drGtqUSzU8Kwo/OfKXSZIQCSnJoRbbpbpFU+GF8emok/nhOZi9VLiuZuVw0W5uC8GOxctOOtAnVKs7/91wsv+0YjeYn/l+f5yf+300TymuzF+EdXaNwMnupEN/N8mLR58d+TPtWhdoOx3rxxPpGwiEh2suxetje5O9jGEBJ06w8aJ8fv8RivL+Npb4vKQgnrtOE+kVVJSPU+fy4wetsWGb2Ki2IKDuqoDseNsKZFWwtM4Irnx+XVYqZJuoao1jTlL22t+DzYyX5tAayoIQTts06ZUsOApnvjZdTsfWSOcQDcc2P2A/4mZhYWjadw7PK7BUJG56XYpHhJqmrXPOjf9GchB/VeU1JoIR4b0Wzl27foHB6z1Q+TInlLbSrusf/+13IOBv4anqhUAjhcFj5R9jRNQons1dyG7+R7bwKwyHbysqyczoNrollCYQXkF3OAXAnnFnOziUF4YSg5ubF3qVTK5w4sKvjfqkQ1/wwCwE2OW7GO8RkCLuqtqrOPrmoob9X3DC8LU8hM3uVFqnfwaD7Vbaj5DU/8QEg1fP9Zr9kqHE0ZmLVpp2ImUBZYZhz7AWcNT9+Yd8FU7E9SGRClRehle1PLMFDbK5yzY9/k7SfaK8gNT+A/h6VSHx+ihyiucSoJ5HGxHmFH0x7/y3eW9HsxaISWNPJ+uraxARQpflxs7aXm2aaK5ofX2av1157jfve0NCA+fPn46mnnsLf//73QCrW7PCo+RE5d+qXuHj0Ltw21uRQWhS2CTWyvjnkkFtDubCpoPlxgxUJUloYTrwUbmbL7/3pEBiGgdcX2LMXB0XMNLkZqaWlioSS12kKERksqnuhW97CDWzyRDfIND9lherXOugcG+zgxWosvGTN1e12/MCu+HF9Db79pRpR01SGuQOs8CP3+fGLSvOTLvOEbILg5blxwk9T+yguCHPBB21LCwPx+bHwH+oegPDj4p2Thbo7OTQ7+fyYZlwAtjnWm/akiaKgEzNN5X0Rk0/6JRIyXGsnD7z1/eRxPvL8xExg7vJNXG4ji4KwwZn9ckT570/4OeGEE2zbTj75ZOy111548cUXcd5556VcseaG1ufHIc8PAHy45Fd8uORXbhvb35QVRmwdiUrzo9PmRhWzGXFVdy9mr+KCsHKROxnWoBYy0veixEyggREcrIGhIJK8zuraRnwpiSbbvbIcheGQVIgMwufHy3hQLxF+SgrDtsFOrF9QsG1J1Py41SRo12QyjIQfVCxmJp2dBX8fIGn2sqL2ghL0OM0PU2S6zF6ytAZelDLsQGsJx0WRENce2pQWcFnDC8OhlK5H56um0nAEsbwFkMx+rnveMrOXU3ZpJ7MXEG8DNrOXaX/P7GYvE6c/NltaJps4NBUqSgq4ha/dolrewmltr5MfmSX9LRzihZ+8TnKoYsiQIZgxY0aQRTYbtD4/kgHMjWqQfXlLCsM24UfWyOKh1OqXOqG5ECosqqjdNF9W8+OnkwtyxWeRWIyfeVmmkoIQL9Rc9Z+vueMuO3QXvH35wTAUIem6aC83BLHYY2lhGE/97kB0a1OCP4/djfst6I6Hi/ZiOrjGmOl6wH7gA3ukjUXIMBJRjdGYyTg7l9r2bdVk7ttWG6zZi9P8KD4Hicznx4uWqYGpl+UQL669VVwQxg7GvFJcEEqb5kfl8xNEnh/AnebHl/CjW6zVOrdEw2nC3n+LguWvNXX4RbHyuup+eaWitMDXcaK5z02eH2tSIkPUsOWK5icw4Wfnzp144IEH0L1796CKbFZ49vlxUSY7SJZJBAyp2cu15sd+MNdPuahgwudHopVyQ1qFH8HsZc2Q4yH9agrCoUSnKate4rb5NXt5zPMjo7ggjAN6t8Nn1x6KsXt15n4LouNhBSg23YKo+XE7YKtWcY+Xn9QqxExTuqCphZXqwdI4BiXn8etHybenwsAebbjv4kB5//s/4r1F61yXx06m6qOWL1uyq7far23pmRTyy+h8CZVmL0awTQU3i+jKhB+n/sWd5icm1fyI778XfyqZNtcPVsoOr6g0P7r2PuvnjdLtcR9Gflte+/y0bduWG3hN00RNTQ1KS0vxzDPPBFa55oRuxi13eHZuIGyjKi2M2DQGykamE340syjumbsY3ROanwJ/mp90JqyJmfL7zvr8yGBnizIxJbmorE+zV8hI+bqLuVm+yzbhAVZDoFrdPhozA4laCXOan2SYu9TsVcibvYLqZFmNVmIBx5g6DYKFW5+LQkHDwAohtQ1R3PPeD+IhWtiBNqH5Yc5R2iQI1HMLtqbu82NALvPrMzz7PmUCd5of+zzfSbEjaoZE3xXAcuznjzMlvaMoWOq0O/K1Hr0ju2Y3iNdtfdeNSaplNmQCbo7IPv6En3vvvZcbCEOhEDp27IghQ4agbdu2gVXOLw899BDuvPNOrF27FnvttRfuu+8+HHzwwVmtk+7FlPr8uCiTnbmUFbnT/ADyQTtxjItZFOCuAVuan9LCsC9TThAdo4pozJT6VhSE9WZB9p7LLinh8+OzXkGYAooLk7NcsaggOh52QOc1P4LDcxDCTyjp87OzIYo1W+OmAjG7M5B0eA7K7BWLmfjp122ckGzdPyetzz9OHID/zF2Fb1Zvlf7OJpwriIhRV6ymyftVNEh8fljNT0mhXQsSM937aMmwnJdl9VWFdIdDwWh3k4sxq++VzOFZdu4uFcVYuzW+Irr4cyQUQkPUnrFebOdxnx9+23RBc/eGJpgjKM1PgQuznQxR8yNL5iqiE3BlT9g0zZTN+6niS/iZMGFCwNUIjhdffBFXXHEFHnroIYwYMQKPPvoojjrqKCxatAg9e/bMWr10fZjbUHcRUfMjvsz3v/+j43Ei0ZiJX7bsxJ3vLpH+rsoSKsNKclhcYI9Ec0M6zV6mItqiwCGqzak/0S1v4YYAFD9cRy+WFYQ2hJ21spqfRsHnJwizUChkJGaeyzdsh2nGhZwOrQpt+ybMXgE5PD/68VLcPu17bpt1/5y0JCED2s69MBxKCCai5of1+fFzCbJoL1bAKpUIP6lq6nSO+qp16VSL+HpFlZiVxa3Z66BdOuA/81ZLy5CZwaIxu5bHlER7eSEo4ccplF+F6OuUiPbSVEsl4IYM+X2OmfGs3NnEtfDzzTffuC50n3328VWZILjnnntw3nnn4fzzzwcA3HfffXj33Xfx8MMPY/LkyVmrl15qljUcN2YvUfPjrjXpOuWYaeKsx+1RCNYhIcNA1HSXxcYaJAvC6k6uQ6sibNgmj25I57sRM+WdjFN4K+sMKJ/RWOX7NHt5jPayGNyrLeau2AyA7+hdm0I9wLZXVZLDwDQ/jNr851/jvkG9O5RK27A92suqo+FrYBcFH8BdQj0grl3VTTIKIyGpVgbgNT9+7iArhFrvIOt0WiJJhWCaqUWvaUPdFYN5KBSMz48bs5esfrJtupXcd+9SjjnLN3PbpNFeDnVxQpa+wg+ik7tb7D4/8f96v1W1gCuPijURzuhCPHZcCz8DBw6ML5jYdAO0uWKimU/SBAD19fWYN28err32Wm77mDFj8Pnnn0uPqaurS6xQDwDV1dVpqVsQSQ5F2Je3KOJeu6LbLRrT55mwjnUzq050vOGQciDQzU6chLlDd++ED75f71gPGVGN5kcHKxvJzV4pan5CerObClZo02l+gjB7qXJ2+HV41hEyjMQ9Twg/EpMXwJi96hrjS5M0iQ5hw0A0oNgv6xKdBAXVjNeiKBJCTdNnccCNcvfXh9mL9flp8h/hfH4kmp/6aAyrN8ujj9wQTrRbidlL5/AchM+PC1O9TGsjE7xELRwAvHbxcLw2/xecPKg7jn/wM9u5bdFeJlKyuWbb7KVa2FTXFFWZ3EMKR/hccHp2fXeWLVuGpUuXYtmyZXj11VfRp08fPPTQQ5g/fz7mz5+Phx56CP369cMrr7ySzvpq2bBhA6LRKDp35iNcOnfujKqqKukxkydPRkVFReKvR48eaamb1uwlS2rmoky2cw17mEW5Wd5CBbv0gxOWHTii8WPRzU6chDmn9PQ64mYv+1WIa5iJ8B2DfEaTCn41P+zMntf88PsFI/zwvj2yz42xYNZxC4XAmL3iQrnM2RkAipsynMed2ZOOqH6XUJA5jLpdwDHE5CeSwQ6yRcIgxZbsR3vG5flpcGf2ShXVIAfI+zcguCSHqvQc4rlEZN0l26dYk5D9erbFzScMQNtSu6m10WWSQy/UBRTqLhPk3GD3+Wkye3mcwAPqvHI5IPu41/z06tUr8fmUU07B/fffj6OPPjqxbZ999kGPHj3wt7/9DSeeeGKglfSKqJXSOVddd911uPLKKxPfq6ur0yIAeTV7uen02EuKKBrZ7pXlWLu1NrEAYfxATT0dzquO6QC6tSnBRaP64YbXvwWQfCEiYXXHKAowb146IvHZSZjzO7MB1NFeBYrkhbI6aR2efb7dKgdBJ9jOnR20xdICMXsx941f64rfnoL/bAJ2gLQ0iTJnZwBcxuL4ABT/7HeAlSXnTDg8O72fhl54Z4V+sR2zj8iP/NggSeHAOTxL/F9SRTdpUJm9glrV3XoWKtNLZetiqTnb6yLCst2jslB3pPaeBab58Wn2Ui1vETVNvPDlSmleLq9+XXml+WFZuHAh+vTpY9vep08fLFq0KOVK+aVDhw4Ih8M2Lc/69ett2iCLoqIitG7dmvtLB9okhz7z/Ng0P5JGJhM83OT5UWJpfiS7dW5dhLOHJoXkBsbfQCVQiJqfXTuXi6dS4ndmA1jRXgrhR3Ocmw4zlTWtwiG9SVl9nMLsJRQVjPAjN8twmp9oMGavsGHYOuM+kgSH1r5sXSwB1OsgZ1EckUdFAUkNKVt0l4rixGendas44UeI9mI96vxFe9kdnlnNYFo0P5prnbVUngOGjeRLhaTwY3+f25QW4ONrRkvrJ3vPVIM4INceNSrMXtka2tk6+tb8aJa3uPbVhdLkjKpIQdVkLhcSHfq6O3vssQduueUW1NbWJrbV1dXhlltuwR577BFY5bxSWFiIQYMG4b333uO2v/feexg+fHiWahVHpwlws7yFDLahq2Zess5F66/lcGKd4CSWa3UkcYdn+TG6F9Rpxp6K5mfrzgZs2GZP/a7TUgGC5kexT8z0v7Cpk9lL5SPF3t/OrZODsF348VUtDt7sldxu8/kJxOxlN+eqfH5Y8xbrlO/XqVY2mFqXlFwB28D9Z+yHg/t3wDVHJrNphwy9uY0VfsKGgafPOxCdyuMLtXKaHz9mL+YYS1tWyAhYMofnVEn6/Lgn6IVNZc+roqQAhZGQdB0vmTCja7OyvjQqcXgGnHNApQtWk+7X4VnM8Owmz48q1F3n8JxtfL0FjzzyCI477jj06NED++67LwDg66+/hmEYeOuttwKtoFeuvPJKjBs3DoMHD8awYcPw2GOPYeXKlbjwwguzWi/Poe6uor2YzwrNj2yhTF13o1zIM/FfYxJq+skKh+cdnt1pftjdnDQgTpFZfoiEQtprZDtAVf1ipv/Oz8nhuYiJEmIxDAP/PHN/bN5Rj96MT0w6cmmozF68z09qfg8W7NpeAFBeHEG7MrvvBcBrN9gFJ/3IPqZp8qZiq1wh1D1kGDh+3644ft+umPlDcu09w9AL76zgbhgGDu7fEUcOqMS/Z63gfX78mL2Y9mGtEF4gcXi+/bd745a3F6OmKS9SKqjM7jrifoopnzoxYZNpbaxnII32kjwfnSO7TIiWJjnM4rheGA4lTLXB+fzE/+sEcXUuJ/kzzgHZx5/wc+CBB2LZsmV45pln8P3338M0TZx22mk488wzUVYmn5VlitNOOw0bN27EzTffjLVr12LAgAH43//+x/ksZQPPzmIuGgc7sKmcisOStaKCcHjW1ccKh7c64QLNelWFgmmBHfidHZ4DXZquqUy95iXCOUTKYf1NWE4Z1B0//boN81duUZYfctD8FBeEUS0ZrEIGcMw+XWzbgxB9RJ85dpARTV0WMTMgzY9g9uotWc09uW/ycyMzKDmt4SRje31UOhAmUhnE7GVzkxHFjNeC1eBZu1l7szNsLwKkdTy3tpfG5+e0A3ri2H26Yq+b3nV9DhV+1qSrb4wFIpzHNJofq3jZRMmQdB+yddUsZP2myuE5W8T706Z1CplnvkeX1li81l0ks3id1vfXNYkZVQ7PoZA+E3428a3/LC0txe9///sg6xIYF198MS6++OJsV4PDi89P1dZaV/4SbGcbDsnDyeW2bnWZzg7PzvVJdMI+Qt0NbgDRVsXVoOY1x4uTz49ThmfAGhj5c44b2gv/OHEATn5YnnLBQqapYylSpKxXCbRex5aQYW+rpsmXw7bXT3/cgK07GlBRWsDZ/RujQZm9+HP3VkR6AXHh26p/jEk+58e0ItP6AMmBzbpWXvjhtYI6xSQr9FvHWYIA++r7uYeNTg7PhfZzp0rEh6N+TW1D2n1+gtT8qM1e/Lbsan7kZi8vCQ9VDs8LVm1RHqNaFy5k5K7Pj2vh580338RRRx2FgoICvPnmm9p9jz/++JQr1tzQzQbqGXvppz9uwNlTvkBFifOidGzHFVHMvJwW6hRxzlyrM3tZnXj8e72PaC+35wLcLTwY8Sj8RMKGVsJzI3DJzF7WcU7X5KT5KZI44erK9TokGZbNkiFmmmBFQnaQWbKuBic+9Bk+vHpUWnx+RKfYPu3lzs7s/rEmZ+tYwuzlQ/jZIRd+TDN+/X955ZvE+Sw44cfhvIUaDaIltlXXNuDu6fJM6zpYzVwiwzNzPtZnKgizE+DvHtfUNqK8OHX/o2iTllHW3KzHI83zoxBmLPbuVsHvL7lXjdFkO7MmWtkc11mBh/vsQUsu7urm2X5fVSPdrhJu88rn58QTT0RVVRU6deqkDWU3DCNrSQ5zGbcLmz72yVIA6pknC2uDVi0SKGu4erOXw0m1Zi9rFwNAMpqqIKT2+RGd69i9HIUfieB09yn74unZKxKzlEjIgDx/tJy45sedQKbU/EgyYFv7Og02TtFeqsUKVYf40fyIb684qIi+FdZio1zOHzM90V46zQ8QH4AaoiYao6mZvax16URipomX561OZPplO3fR7KW7enZgst5jqyir3re8tUhralDBRXtFk5qfR8cNwvyVW3DUgEqunkHgJ2y9urYBrV1M8pyIxdRmF+tdlub5kZq9THx09Sj8smUn9u4uCD8KYSmRT6rp3cnmuM5q+FgBW4wo1CFeZyqmyVBIvt5bLgg/rsXBWCyGTp06JT6r/kjwkaN71OyL29rDTEjU/EhD3SWdUvrMXrzdy5p1yvyOLET5xcuLJgpOQFwgYkOOvQ58Ttokp1XdgSazi/ByJ7RiDpoY52gvr5ofb7iJzFANNI2CL1AQy1uI0V6Owk9T/VkB1I92QxXybJrAuupklKs4AUl8Nvj79sQ5g7ly2OfITxqSfcW8puVKvCIz3RSEQxi7VyWuPWp3rp5uzE5uVgfXveMqqmsbUxK+LG1G1DS1q6Rb9bNtMwz0bMdrEqMxE707lGHELh1clcFqGBNRUVnU/bDrcnECtqd+VW728oMqz08OyD7+Qt1lbNmyJaiimiVaT3nmxXVj7rLgfX7UDs/iEOjH4TnRQWuOTTo8x7+7CXUXIyg4zY9D6yxQFMpeghunaPZl97SwqWI/U2L2snZ1uianaC/VQKTsoHxofkTEa1EJP7Y8PwGt7cUO0KowdwurPbF5fvwMsKq8JaJJMyIIPBaGwWvMRuzSAX8/fq/Ed9YMYT1v6/hUlkiJKcyNhQrzsptb4+b++dH8dGxV5LhQsA5L8xuLmcrEgNa9VJm93rr8ILx+STKxqjbaSzYxYKIarXaqem492pXg1t/srSw/CNgacukUPEgwokDsR3NqobJI5JXmh+X222/Hiy++mPh+yimnoF27dujWrRu+/vrrwCrXnNCNA2yeHy9qYLvPj34fC11TVg1YRw2IRxLpOrikw3P8Q4OLUHfxReMdnh20JIoOnZ15uXlxI5zwo9fNOC1sCvADr0XCtJFxzY+3jku2v9VR7ayPKpcF+fznDViyLmn3D8rsxa7q3ro4gral+vfD2pcVUvw41aocOEWTJnvfRYdntg2EBfU/a4ZgU0QASKh+/AwQ1bVyc7lqEuBGW+Pm7oUVjq0yzhzSE0cNqMTfjt0zJc2PdU1RF8KPTEscChloXVyAgT3aJLZp8/woQt0TmcQd8uG0KipISdhzA3uZ7DP3cp9tE9IUnlFYGe3lu8jA8PUoHn300cQSEO+99x5mzJiBadOm4aijjsKf//znQCvYXHC7vIWX1PNsm1TNvGTOxl7MXheP6oc3Lx2BUbt1BODT4VmTA0RnX3Z65VQmKtXMXAXbSUQclrdwM5Be8eICWzi6XpvEm050Z1D7/Pif2bPIBJaoaeKXLTuxx43TcMlzX0k1P3dP/4E/JhYLfHmLPh3UYe4W1vNujCUXNvWT5FClAYiZ4BqYyuE5ZPCO9gVh/nthWBPthbjJ2I/i7IR/fibdHklh1HUz+Hkxe43o1wEPnz0IlRXFKQ2sBazZSyH8WI/KTT8AOGl+7NuiJpNJPJR8fjIKw8EkddTBll/oQviRZfsO2uwlO3UuaH58udqvXbs2Ify89dZbOPXUUzFmzBj07t0bQ4YMCbSCzQXds+ZDhN2PGOxAHA4Z0iymbtO6W4gDW0VJAfbp3iZ5rKY+hvC/MWH2UjsR6wYm52gv2cKTfOfjptNnI2GcQnbZU6ru4yc/brAfp7kWNiLNf7SXfH+vna3MPGvGgOe/WAkA+N/CKgzr2962T3sh8WBjQKu6F4SNxGzZyd8HSF5v3OfI2ub9vKr30Na+NNFerLAT1wQlj+P9MZLHAMCMResw9bNl2qUWVKzYuEO6PZVFgF1pfjyEuhdJrl1XrkobU8iavRTPS/THcUKX50f2vptmsp05mb0KNBrwoGDryGt+1HUSQxzEfVOpsyr5bg7IPv40P23btsWqVasAANOmTcPhhx8OIN4QyOFZjk7SZX+SLXWhQlzbKxwyMPPPo7h9VIO5qj3vbOCfn9hp6N4DQ5jBJtYV0oS6hzlhwl0dLVQZnjnNj4tOnxWQHH1+PGimWGymDfb8rAOqQk1sofb5UZm9vCETWGKmKUQQ2fcpK+LnUdFoMA7PBaEQdq+Mr7c3vJ9d6BJJmL1iSCnPj2olctGfi3d4BvdZvJVsH8BlNhcCBZZu2O5L8NHhJc+LiJvbFw651zL27ZgUYp2EEp2mNeJG82Pt61L48Xrfo7Gkmd1J81MQDqXkP+MG0e/MQnVemTnUnuTQf32anebnpJNOwplnnon+/ftj48aNOOqoowAACxYswC677BJoBZsLukfN/qZyJpXBdraWFqRX+zJ0a1OSWHxOpVkxFHUShR/7bEenqbGOif9nFzZ14/Mj7uHo8yO5tnhHlLwyV2Yv0eFZt7wFG+3loVPQlRlhZl9O16zU/CjGNq/jvqxPipkmt6SGrI1aM+9WRRFsq2vEE58u8xWmLRIKGfjtoO44dPdOaKtY1oLFej4yc4QXVJqfuM+P/G0WfX7EDp4VLGXaj3RqBUpTWM/LjWmqa5sSuBW1e7V3v/xKyK6YSGBps6IuND9uTZ9enfSjTDZ31t9MRkFEP7HywuF7dMKMxett29niVf5oLDJHePuEN3jNT14lOWS599570bt3b6xatQp33HEHWrVqBSBuDsu1zMq5gl7zk/zNi/DDNkpukVOmQask75CkcwaAHfV6Faje4blJ89P0PZljRL2GD7dQqMb5WUaBolD2smSOjiIRzufH0Pbh/MKm7jsFXd/LmiTijrHqfVUZnpU+PykscGEY8Xv5/Jcr8eTnyxPbZQOENfMuKQxjW13c32nDNi8ZlvS4EXwARviJxZj8K36EH7XPD9u+WO2WzewlJosUfIDE49KpE0hlJXfV7evfqRXGD++NY/fpgtLCiOuBXbUkiHRfTaGuHJ6bNgfh8yMvX5JMU1FEkD4/bgIfuOARleZHohFULW/hh5Ahf8Z5q/kpKCjA1Vdfbdt+xRVXpFqfZovuWfvW/CjUmqIgJBsAVe251sHspetDLDnDGojdRHtFQvyAwdXRKTJKpvnR+GSoYIVFx7W9fOqARZMgi/jsTI3q3avPTyojqrVG212CM7PMnGW1Gy8O++nAGixZc4Qfh2fVQo06bQ57mvjkQjw2+Zlb2NT6n+K4qBtOSotS0PwotldWFOPsob0c92PZs0tr7rtjxnPNs7O0Zzrhx6v2T+fzI4OLKnTI8yMze4UMf1oQlTnfENogex5VnUQCdXgOGdKGnQtre/k2BD/99NM46KCD0LVrV6xYsQIAcN999+GNN94IrHLNCZ3/A+fz0+i+UYih7hZ81lnVSyLfLmp+bNoYTRdn/ZY0e5mJuikXo9SYkfz7/LCOpvoyAD4qIr6quxo3GZ6djhNhHbedFzZN79pefJny7TK/IGtl8M6ti/yfMAD4PD/xbX58fVXmD9PkByt2Pz7JoWF751nBidU2uk2D4ESDQgAAgLIUND9qk4l6XT4ZB+3SAc+ezwfEOPr8aH63Bu6YxufHegSy4AgZ/Tq2crWfRZTT/MS36R2e+W1+o/Dc9Oucz4+LyWdiX2FbSnl+DFWeH99FBoavO//www/jyiuvxFFHHYUtW7YknJzbtGmD++67L8j6NRt0D9uv2Ut0eJZ9VuX/UTXnnSmYvQS/zcTAoIug4n1+BEHLR7QXwM+A3direc2PQ6i7RlOlQ7w3LKIJRFduujM8c8cqypS1UcvUdfKg7imckcdPn2t15te/thAbt9c3leND86PK8Aze+Vtp9jLsWiJ2X25tL4P/75daRgA4Z1gv7rfUfH74738/fi90a1OCG4/bk9vulFD0hIFdbeZLxwmOphFEEj4/6n7TbbTX65eMwFlDeuKm4/bS7icrX/T58RLt5WXNLRbVfeMcnsG2MfkBMiE/yOUtVMl3c0Dx40/4eeCBB/D444/j+uuvR5jJVzF48GAsXLgwsMo1J7Q+P8xnv8IP20mwg7kqb4xbs5ftRXBRH/Fl0a3qHubfVqE8zcnEYxm4aBwX7y0rRDmFBOvqq0Mb7cV0gMGv7ZXKrE2+vbZBIvw0aX46lhfhobP2931OFj8zTqsNLt2wHXe+G18U1FeeH9VgGgOnZYgp2pohMWeozV7y98Yrdcy7WyyYH8uK3Gl+2GzHSfh6jR/eG59deyjnuAwA/zxT/9y9rjPo9DuX50cp/MT/O5mrB/Zog0m/2RvtXPqWWURjdgFL1dcXRuyCgJtoVBlu8o3xbhHyfWQ+TvZQdy8141Elv8wFnx9fws+yZcuw33772bYXFRVh+/btKVeqOaKN9mJ+9Ovzo1qvJ+7wbG9+Kv2CaPayZ2BWvwnJqBV+e4HG0U90ElX9JkMmqIg+P07v7SsXDePz/IQ9mL08SD+6+ybmitF1NunW/LDClaqDFSMCgaTmpyAcwtF7d0HH8tTNX340Nqo1nJwQd1EnOeRNLLzPD/8cXZu9NFpBL9QxK7iL96HEpdlLtryO28Fv3x5t8Mx56jxv0sVFHcrWtQFLaxKL8dGILIklTgIOMW/TlGk8ZtqXUdGFuovKarfmOJGQYUid2DlhXOhXZMiWcbH7/KQwgVJGe+Wp8NOnTx8sWLDAtv2dd97BHnvskWqdmiU6B6+Vm3bgD0/PRX1jzFueH8G8ZcGZwFwsAcFi9/mB9jtXn8SPwuwmpDYl6Wb3/jU/8gFJpGtFMQb1asfNwgsUZkLZOYPy+SngND+GtmCva3t57beev2AoBvZog5cvHKasc229WvixBiQ3i2E64UvzIxtgXVRFvFbVJMQ0wWkZYgqfHwN65+hCWbRXiuOzJbAVRcK29lDm0uwlu+Xe2rnmN6nw40HTKuBleYugmDrhAFx31O6JnFMxNsmhg9krPrHhr8dv8slQKJ5WQoRtjwa3v/w8Ucl4k4k8Pzkg+/iL9vrzn/+MSy65BLW1tTBNE19++SWef/553HrrrZgyZUrQdWwWOL2E7363Dq/P/0XrtCjCObRxgpDz7F3Fjnp+WQa7/VdXIfk+2oVNBVOB+5PJfQzEu6zrXC2BjJ2FFxWE9Xl+fI5Qutm96K+lO0O61/bar2fbhOlDaRptVCcytUJnixX19IKfe61awJLlwD7tcO7w3rjo2a8S28SjdGt78WYvRbRXyHAIdWfMXom2EYx2ojBiz1XlNgpPGhkakIZT1gekIvwkFjZ14fAcFKN374TRu3fCpc/F206UWUYlWVf5SbfV2Vex92v2MgwD5cURrK/h00mw7ZF9FqrbKEvmGWSeH9WyS7mg+fEl/Jx77rlobGzENddcgx07duDMM89Et27d8MADD+Dggw8Ouo7NAjcvYXVtgyezFzs4cBFDXPJDAz3aJZMeOrG9ziHDszbJYdMMVtge0WRN1uXN8aP56dy6iJ9VaGei8f9sksN2ZYV6zQ/rqKqvHoeuTH55DX0itHSv7cWimi2KTvEsSc1P6sKPH1OFTGCShe4O36UDt80wgJfnrcYTnyzF4+cMTmhRSgrCnJlPTPgYVTg8hwxZhufk5wgn/ASj+bEoivA+dqWFYdf3UhocEZDmRzbe+dXuAsm2Fo2ZiCoEjnQNssl8Uu4dnrfsaLBdjypXmRMGgFbFdhOlygdNafaSjDeZMXv5LjIwfOumL7jgAqxYsQLr169HVVUVvvzyS8yfP58yPCtw8xJGY6Zvh2dZtuf4dgN3nzoQR+zZGS/8fmhiu6o6ouOgN7OXfJ+I4gUAhGgvYRfntb34388a0hMH7dKBM+npOldL2GJvRbtSvcMjX1/3nYLKGRwQNHUheV4mC695ftxWsXVxBA+euZ9QpkL4kfj8JOvnz+x147F74uD+vEDiz+wl2WZz2rdrIg0YuPo/X+P7qhpc/sL8xKAg+lWYEMxeTOPhT2NPIsq2Vz7CzzoiGAojvJnZS6SX7JGnsiI4i6wPdBLKdD+z2bydFjYNGqsfYH1+2G0yqmsbPKfz0NG6WGL2Ump+5CeS3Tdx31RWog8Z8nPngubH02Vt2bIFZ511Fjp27IiuXbvi/vvvR7t27fDPf/4Tu+yyC2bPno1//etf6aprXiN71mKbiJle1/ZKfhYH0MRnw0C3NiV4/JzBGCpZkNL5HO5nAdZvdru2ZnkLTei4U78g5si47ND+EBeQ1Nc3/n8bswJ76xJ9plp+YVOHCjIkZveS37wkWfS+tpe7Sk499wAcu09XoUz5vjrNT4FPzU9FSYFt/Sk/M043i/sasg6Z+Tp/5ZaE5ke8jpgJ1DNmP1bzIwryYhjx7w/pi74dy3D1mF2lK24H5ZQb1/wky3Ib6QV4X95BRHcJbsKqRXQCcEL4iSajvQb1aotTByfTLaRrkDUSgk5SALaen+qM1TsbbJrJVLQqUp8fTdJNGbKUDjqz126dy9GjXYnrOjYbn5+//vWv+PjjjzF+/HhMmzYNf/rTnzBt2jTU1tbif//7H0aOHJmueuY9MofnSMjgGp+4gKQTquUt3Dk8u8NLqLtqgFfZfa3fxONV5xYRNT/W7qZyNs5jlV9d28DVwa3Pj5duSzcosP4furQAgLAgpovy3fat0ohAH5ofq34qDVVB2JB2uIZhF1z8zDhlAoRYTsiwR0MZTXWw2o6V8sGm+dH6/PBtQ3zl27cqwgdXjQIALFi1JblvUCqfJgqFNaS8ZN2W9T9+hHwZfoQf7eRFovnZv2cbXH/Mnnhp7moAadT8NLUpL0kOD+jdznMfp+PAPu3wzrdV3Db28fF54ORlyFIEiAKaGOThJUItFJJHG+dChmdPws/bb7+NqVOn4vDDD8fFF1+MXXbZBbvuuislNnSBbEIVFoQf06Pwo8zwrAh753DZ9mxRYZp3NeG4adP8aMxeOs2PQ7+gWnGeN3vpKhz/V1PLO3lrfX58zs71GZ4ZzY+D2UvV8ajX9vJfP6Xmx43wo9BQFYZDaIjajzcMu6Dux+FZJuvLND8yE2vPdqVYsXEHAOCn9dsA2K8jZpqcdlYl/JjQa1EKuCSHRqJeQSBGe5V5WNpCJZi6Rber1OzlULab94YNdReDINLt8xOT+PyI5xzWtz1G794RZxzYE9+tqeZ+S+WZjxvaC9GYiQ6tinDFiwviS+MorteLkGUIr664YoCXPjBs5G6GZ0/Cz5o1a7DnnvGsnn379kVxcTHOP//8tFSsuSF7CcXOPWbqU9Tbjg+xn50FIT+IjVRXmupUOm0G91JKBiQdYphowoeH0/xoZo5Nv9Uwmh9JNfhjfIa6JwVD+28RIc+QrgKqZG1elzERkToKC9tKC8PYUR+VJjm0SJi9FJqfooIwtkvMZgYM27X5cniWhrrLBDu7QMQm+LQGKTEDbyzG50bhl7dI7mea8mVALAqleX6CkX4KhSzlXjQ/7VvZfd48+fxo9pUn1PN/zdaxUWbSKGpGVY/grcsO8n1e8dzJ9cPi5xYjBXu0K8HvD+kHwD4OpHL9kXAI5x/cFwCwR5fW6FRehNMemyUt28u7ZM/tlvwcCgER00N7EKJXIyEDjYy2LJt4UizHYjEUFCQ9zMPhMMrKyjRHEBayZy121NGY6cnnR2X2CgUo/IgzCd1gKq7tZaFb2ys1zY/oIxL/7zbJobV/TZ2o+XGnpRFLV5mk+DLtZbPanPhCtGrUySIV59WUxddPto3faGkQZHl+LJwcnkW/Hvb8olbLzyKybpIcyvKtALwvk6Xdsg2m0GV45svUqfa5aC/Fe+OXogLe58dLOHWn8mI8d/4QXDo6GbjipVq6wVy2vqHToOxGCxtlsm6Lz0s2yA7p0w4DulVoz+tEUsvDZHhuqquYOJB9o8XqBPXMd6ssR9uyQnSpSPrjsK+Tl1dJt7ZX2KvmJwRpW8wF4ceT5sc0TUyYMAFFRfHsrbW1tbjwwgttAtCrr74aXA2bCbKHLTrsBmX2cqP5USU5FLHPVNT7WmWKL3RBOJTIiCqii546YWBXfP7zRuX57D4/dunHVbSXh/dQtbDp7pXliMZM/NhkLrEfZz/GgtP8aARF1fGAehBx27lKzV6CnNKqKIJfa+q0Zi8nh2eVgGgYadT8CJsMw74tZprYKdFoFUb0Pj/8edhCTa1qXxbtFZC/c5PmJ/ndq/lw+C4duGSnXqIadbvKfX6Sn4sLQiiKhDGsb3tM+67KsTzWzGT5rtg0dZKXO4hx13rWsZh9VXdRw8VeQ5CaHxm3/XZv3PjGdzh3eG9O6FK1gW5t7GlQ7NFefB/tRZgWVxiIT3Bi+efwPH78eO772WefHWhlmjNWo2cdPsWOOmaq1xSSwXVwKp+fVM1eQnV0egmrQYsCQjhkYI8uraXH6MxIpwzqgV7ty/DSnFV4df4vtmPFlzCp+XHn82P9dPMJe+HGN77D9UfHs5Pr7phKU2UobNtu6sELrg7La3gUclybvVyYhiznX9XSD2w5njU/sPv8+NH8yIU4QUiG/b7UN8akwkqhUCd2oBVhizRN/ey2QBLtFZTZq6iA9/nxI0Ry1mgPh+vauUypze7/yTWHomN5ET7+4deE8OPmXGyGZ7F9yZ6pzhzpFtbslXR4TtaHhRd+hHKCknib6FIRj+wFgB/X1TB1MDiHfot/n3cgHp35c8JBHNDn+QkZ/Luzb/cKfL16q7I+ISHYJW81P1OnTk1XPZo91rOOhJIOn2LnHo/2ct8o2PbDNli2A1BJ/G7bnthIdR2h9WKzu1hJvPZUCD/sRE0sOhQyMLRve0z7Vt4RqhIwevX5OWdYbxw1ILkelXa2qXEs1h2X9Ouww2oAnULdXflO+UBWrlimF8dZpc+PYnvc7KXudN3i1uwlopLnRE1VQ9S0JQJVnVvv8JwsV6Ux9YsY6u7HcVy35p72OI0jxb7d7aYmzp9Eoh3V57yKn2xnQzQh/DitLA8EM/Bap5E5PNuzgyevwYsmPVVEt4iQYc863q9jK9xx8r74ctkmLG9y9hfrxLlUCGYvpzspOjxbpu0ckH38JzkkvJFYXZiZSYodq251YhmshoNtkKzJIXWfHy/7Wp04o8lout7+nVtJj+G1RN7qKmZHtaIUOJ8fTZHsb+xCnFqBSRGaHwrpB2udXwebYTqiyYkEePf5cYvsmkVHcFleERUqs5dsMUbAcngWQ92DEX7ES/PSzEQzyrIN25VmPzHaa9Jv9gYA/PGw/rZ9WbOXh1deck77NjHJoa8+gNP8uD9eJazcc+q+GNy7nfZYq54q07KIZUrfurMhafbS+N1ZBBFpZPUDXJLDhNlLnShW9HtiL09sazrcPBJRsNS7LLDH8TuK0V7sGOY0PoSE6NUIc9+yja/lLQjvWC8IO7sVG7vKl0BdZvIzO3CUuBB+3DY9Jxv13t0qsPCXrdy+7B7W9apm/DqHZydEM4n1jV/YVH18qtoSg/tsaPPS6E7Fan4iIb3mR+nzk+K1yNqJmMxQKbhI1Okqs9c+3StQVV2bCCm3CBl2M6Yv4Udm9hJU/l4GczeahOR5+O/H79sVI/t3RIXE340tN9o0WPpZQylk2DNJi8tb+DGt+Nb8KHYetVsnx2NlecJ057aEn+qdDYlIPVeRbUGavWJw1Pyw16AzKRUXhDxNft3WEQCTb8f7tXOrw4f4QBMn31HVWmY5IPuQ5idTJH1+WBMHf/vZNYMG9miDvh31kXTsLIJ9qVwJPy5bny3UXShOumQGq+ZkrrGixD4I6Ja3cNquMpOYkm0yUteW8GUF4fPjNNimGtKuLte+bYeg4VAJsLLnqtL8hEIGpowfbNtu+YbxdUpt0GbLNrh91Md3aFXITUrcaBKS57HPiGWCD8A/Z8uHyk97lAk2hWHeb8zP2pmc8OTJ4Vm+r7ofsu/jti23KYmH5W/Z0ZDQxhUrBHSWIDQ/Vr/17ndVmLdiM7dN5/B80C4dEivCA/y9LXFRdy+Iz1B3V3XDAdslhQyD01SLPqGyY1nh3Gr3uaD5IeEnQ1jvAyf8CB0rG0L80h+G4b0/jXRVJiAIP4XBmb2cfH7Y8hNp3jnv/uTnrm3sadHdzEpVr61oJpH1mdp+NGXND2cbcDCXSY5JFpQgEtanBUiX2UtWrtg/qQSBtpL10FpLBKLkeWSV5TtVwF/blc9E+fumK7ekMIx2Zcnr2bVzufZ8uyl+d5pcsHWwfIP8PEKZpisSNoTZuveS2XbqzeFZvt3Ns5RGvWlObgmWW3bWJ6LTSl1ofoIYeK17ykZKWe+tzeGZNfuEQ3jugqHMMcn9vKzB5gYx2ksnxOo0OLzDsyH0+Q7t3DC4kpNmL+1hGYHMXhnCaiScz48wJVu+cTuAptmnixmnagFPzucnxQHeludHG+1l78RZYa9bm2IsXstnOOXrp9JqyM+n1PwwVd6hyUkTpLNhyNAPXm7zn0RC6jus0y6l7PDs4maI7dVCpvkpZxZd5ExOkF9DXPMj+Pz4uCbVyuGcE62m3NKCCEJFBqqqawEAPduV4j8XDsOyDdtxzcvfJPa74Zg9ULW1FhNG9PZcRxFLU+DP7GXfJoYX+3N49nxI03GqiYob4ceu+dEdZbW7LTsaUN7kj+ZGexKk5ofFukanxaFVv3ldD88Jvs37n+vZlrfwoEoMhfi1FiOk+fHOpEmTMHz4cJSWlqJNmzbSfVauXInjjjsOZWVl6NChAy6//HLU19dntqIqEtFejPAjCDhLquKhif076WebiSIVUU3B+vzw33XOowmfH0GTYcEm4JLVT2n2UtRNNWCzAtvmHQ3SfYAAfH7YzsVlebJdWDV5RMjRwhLSaJdS1/w471Ok6JzPO6gPAOCIPTsntrUuTgpEYli37BpER0pAHzmkQjawxTt+fvaqorgwjPaM5icSNnBA73bYvZJ/J3ftXI4bjt0T3duWeq+kQELz4+MZqkL72efpR4PGCSAeKqbSsLl5NxILvLo8XZsm4aemtjGRqNSNz48s2aJXpNGRTRvFJKBuJ0UqnzoZbtIiiMlu/fZ3YeGZshp3Voi5aFQ/xbH85A7IjbW98kb4qa+vxymnnIKLLrpI+ns0GsUxxxyD7du349NPP8ULL7yAV155BVdddVWGayonoflhGo7o8Gyl/d9VERklompAQZq9BvVqy33XLcyXdPlh1LzM+Q/dw+70yEVPKerg9p2V+fxs2l6n3D9AxQ9ChqHVniRntfbfooLmR23aUucSSt3nx/n4YoU2crfKcnx94xg8evagxDZWGyQu5SA7kwG7dsCX2UvyToirpemKLS3gzV7W+6rKeaRCJuirsBxk/TxB2WOLCBE2qeb58XI4p8lg2otK8yPTXosaCxVsG7PW53On+QnO7MViNfPaRrW2WYS9Pi/LkLgqm/lsOf37ISQIseyzZG/lwbt0kB7La37ix5LZywN///vfAQBPPvmk9Pfp06dj0aJFWLVqFbp27QoAuPvuuzFhwgRMmjQJrVvL88xkClmou8q5dddKd5ofVQNy5/CsL/uVi4bDMGBLAy+Wxn5P5PlhNrLXOHq3TnjorP2xYVsdbnzju3j9XDk8u3trZbtt3h6c5ue1i4crz2cY/h2eWc1PQVid5DBu9lILRqng5niV5iccMmyOvazmh0PRCcscnnu19750jmrxTH4wV19rSWEY3dsmBReVil/ln/HKRcOwcVs9erZ3rxGyor38jE7SdctEzY8vs5fzeylDNONYEzo3ApjM4Vl3VCQcQnlRhFuexpXmJ5A8PxLhp6neYq423dnY+8xaAob2bYfZSzc17eNPWLAlJ9Tsq3V4Fsph3wn2Xsr66XCI9/kpoDw/wTNr1iwMGDAgIfgAwNixY1FXV4d58+Ypj6urq0N1dTX3lw6SPj9qh2eLytbFrspUOakFkeenW5sS7N+zrW273ezFzgLUeX4sjt67C3bpmNRssaaNVDPcynx+tgnrdrF46dSP2bsL9hPuB+8Uqlcr6x6DGLWnM3ulz+HZeR+VT4KYbwkAWjE+P+yCofFO2H4yw+C1A8P7tcdfjtzduVICcrOX4XowLykMY5dOyfZp1cme8FF+Lwb1aocxe1V6qHFq0V4q3xO3Dt4q2EO8vJd86LazICK+Q/FtsG1TIQrdbjQ/QQy80pQKKZoX2brv26NN4rOXiEOuPqzAH9JrpnX3hOujDUMIdU+iEghZAYldkiTbNBvhp6qqCp07d+a2tW3bFoWFhaiqUqdKnzx5MioqKhJ/PXr0SEv9rGfNRrQUKTQ/sk5D1gcoNT+FqTs8q/wtxNLY9s46tVqIEVkABO9/ZoFHleZHWUv5fm5fLL8zWtk2A3qNQrJjt+9jzwQsL0fntJgJzY8qd4+YbwngO0JWs6VSvxswEGbeh3tOHSh1pHZC9exFEwAA/Pt3B+KvR/MCVkkBL/xYmkuxGQcZlpyM9kpt8LQQ77GftuHX7MWeq0jRXlhkEzgv9RXXDFRlFmfp0KrIcR8nZIKEv+VYkp/36toaNxyzB6aeewDXFrwkP+QQ2oDfHkLUII3dKz7Oti8rdFxHUTR7We9Rixd+Jk6cCKPJAVL1N3fuXNflyToC0zS1s4frrrsOW7duTfytWrXK17U4Yb3kbsxeskFGtiaSqgG5MXs5oVzGQdjOfpc5PBc4RAbolrdw/kGYoTZ9dvteBZG/hC1Lt0viN8k+urWAWHROiynKPq5mraqBxUunr/ZZ4icGfjVZ8mgv3snaKvuQXTvi3BF9uH1LCsLox2gmLc2hTfMTYFhyY0oOz/Ztce0hq/nxXi7X3j1UjK2PXx8WLwkWrVw/QLzftNrx5JP25v4DwJPnHoDh/drjrlP29VUvvo6Sbb5SCiQpCIVw/sF9MXq3TklTKFLR/PBt3rfDs+A4PWq3Tnj14uF4/6qR3BgkNcEa/Dgl085ni6z6/Fx66aU4/fTTtfv07t3bVVmVlZX44osvuG2bN29GQ0ODTSPEUlRUlFilPp1YbZnP8yNvjGwyuTMO7InPftqAEbt0wPNfruR3TMHnxwnVcVrzjUT4cTq/m6gS3ZwlHDIQsxxGJcf/bkQf/OuzZTh2ny5465u13G9eOgNVeDb7WXetbn1+AE10m6F2eE7H2l4iKjOGF+HHMOTq97g63bktOCGbEIgaM10UUmlhGGVFEfTtUIY1W3diz66tm/bjywzSOTWlPD8KDYRo8vCKofjseByr+fE5aHuRu1izF/tMzjiwJ47ftyu3Ht2o3Tq5yjTtBjdryFloTUoKFwE2Wt6v5kdcOkh3L3XRV2FJH225RDgllLWtv9i0Ty5ofrIq/HTo0AEdOtg9xP0wbNgwTJo0CWvXrkWXLl0AxJ2gi4qKMGjQIIej04/1sNnGUBiWd6Cs5mfySXvDNE1Mfud7234qp8riQia6xqfwo1w9nI0iEXZJmr2ctVsWbsxyul3iL5zawfCGY/bAOcN6YUd91Cb8eDJ7Sbfxg6gbnx9xjzalBTbNj9KvRxcJlqIONxWzl8y0qcIw1NFevFDiukgOWZ9qQO1HIp7HEvCmXXEIdjZEE47bYiqJIFfjPqBpzSt/mh/JbFv0+fFRsKg12L9nG3y1cgt6OThys7dFlRHcCd6crK87axoVndC9LMTrFel9Vwk/Gpdnzj+SuXmscBDxKfyIAqzfCYUY7cXCa3Ukxxq82cvahaK9PLBy5Ups2rQJK1euRDQaxYIFCwAAu+yyC1q1aoUxY8Zgzz33xLhx43DnnXdi06ZNuPrqq3HBBRdkPdILYKK92FB3xcxI7DRUzrSH9O+Ivx+/ly0HCTsD0q0srUM5GHKzMvFFsLYntzlpBVLJ8yMeb3HN2N1w7pNzcPbQngiFDPTuUIaVwlpS8fN50fzItBX8Z6/RXh//eTTatyrEVS99rSyXLyN9Pj+y+/jouEF47ouV2L2yHCfu1w2btstzZjnJPoWRUGLdOqXPj6HXyLhFXLU6Xj+52St+Xn7dLyuEvTAS4t5PtjYqZ2evfHLNaHy3ZivGNjlI+xmcZIeI68P5c3jmJzAPnLEf/j1rBU4/UO8TyWl+XPj8SMtwEHj+fvxeGNo3vkREG0b4UQnn6UB2T/2toZb8HOGWPIlJ97Fw01TEd8ivvK6blHD+PArNj0xAavGaHy/ceOONeOqppxLf99tvPwDAhx9+iFGjRiEcDuPtt9/GxRdfjBEjRqCkpARnnnkm7rrrrmxVmcNSKxZoMjxbyMwLsoZrmsD44b21x3tdLNVC6fOj+ByvjyzaS+LwrHhhlMKPR6Fi9O6dsODGI7hZoWzA8tQZyDogro765S2sndl9LM2dbi0gFl2Sw1Tz/MgOH7tXZWJgBoB5KzYp6yXjv5cehFfnr0aPtqW4+a1F8fNAPrjZ/HJ89tTyPD9C5IttUDASQpPKkZlPRhdMt9mjXSl6tEtqUsQrfuTsQbjwGXWkKqAYhG0+TqkJVYWREDq1LsbVY3dzPI7X/LhweJb5aLGHSarO9nmsw3PQa2PpkDVPZS4jzTg/YpcOmL5one141uzl9902hCgtvxMKcXkLFkfhR9D8JPbJvuyTP8LPk08+qczxY9GzZ0+89dZbmamQR6Sh7gp1pmzGJOvkVOpUtly/qwSrZvM6YUW2qruzwzNTnirKSTMTVI2RbYT1plgVeLc2Jfhly05cPca5M0+eR38d4gCrOl62S1RYHVBcV8nqPPyG0rvBVZ4fhRlD5f+yd/cK7N29Aq/P/4U7j1TzA1FAcayOFNlAY0I0ddlnxFYwvupa/Gbi9YI4yO3bo0KxZxLVbJu9f/4yPCc/e/Xpsij0a/Zi2z+S76sM1uG5tCBzw5kb/xYdn/5lNOat2IyjBnTBTW/Gc55x+XOYCZHfeY04Ue3ToQxrt9ZK99XJIjqNLDvZkF6/wY9TueTz02xC3XMd61GzES2qPD+yqBo3C0/K8BN+CeiivdjPwosg2Uce6s6+MPKyVee01dPl9bGz0D8e1h9LbjnSlsBRh+wsbL1ChpPDs7rsqPgc2YGL04aoy0jZ7OXK54dvl89fMBSLbh7rqKXhsngbCjOmoZ9hukXWqW7aXi9o6YRTs/48CsGGPSZtwo/w3a8/nBgVGITZyy2cxsi3oy7/ffqfDlHuyzo8u1nRPShUGjcZsm66e9tSnDCwGzc5ZPtKVhvs980WJ6p3n7ovjtu3q3RfL0kOueO489mPNSBqh+L/c8Hnh4SfDGE9bN7h2X77Q4ZcWyIVfjTn+/PY3XDM3l0wvJ8/h3JVh8k7I/IkfH6Ybc6L4KU4aLvs2NkBbkd9o2dnTHnHxnYuDqu6a36za36Y41z6wbCJBP3gRtYQfSpal0RcmYDColAj7SSFCCXfwo9924ZtdY6aHwuVYMM+h3Q50oqX7Mb050bzk6rZSzVJk2EyTdmvD44hDNplRZHEwqUirM9PSZZ9flSynk6wMDghk9H8SMLDvSIe16WiBA+csR8GdPPmA8tOurQOz4ooTllEWC5ofvLG7JXvmBKzl8zhubggLB1EZS+WLjzxktG7+KhlHMNQ25lFk4ysPtwL7eANyzmfquqjPd57x7DDh6CgctJN1kNfF+sn2S66aC+b4MDQujiC6qY1jVZusjt0e8GNX4Go+XEreIraPXmkjGCa8jmOyTrV9dV1WgdgN1mJ2UPYFeuDRLwv7lZCt2+LBJDnh9P8eNAcVZQW4KwhPREyDFsCQhnW5Izdl59g6c/Nmrf36JK5wBZVcslUCKs0Pz6L5bX0zHmkE2lNqHtI/V46+fw0FW47PhcWNiXhJ0PEpA7PcuFHhkyqTlfz0anb+QGf3y/pm5LcJtP8qFajVw7APjUqKvzkaJHVzRC+6cYIqxOX7aJLcujWD6ZvR3eL4aaCTfhxee9Fc5ZUhyY4ZPodSGR96q/b6rRmLzfOzGyty4u8Z552gx/Nj8p5XPfdzfnZI7yYvQBg0m/iiQXXV9fiiU+W4Zh9uij3rawoxpzrD+cESqlfoeISerQrQbuyQrQpKcAFB/f1VM9UUC0rIsddT630+fGpHVcJkV6DCXQTsJjEpCUiW/8rF8xeJPxkCMuywdp1ZUkOVREScp+f9LQg3cuhW3Qw6fCc/MVp9mooPqv2EfHiz3DXKftixqJ1OOPAnq6PSdTB4TQhQy8M6KppT3Io76hswiaA968aiXkrNuOYvdUDTFCIq7q77UTFUFmpIGnwGgq/wk+ncnvC0i4VxVhfXacsm/2qdnhOfm6VJs2PSCo+P2zX4PSOnDiwK15fsAYXjezHlMtofnwmK+zUuhjfTBzjKDx1FJ6ZVDhWHFtaGMGnfxkNA0ZGo71kl+Q3oawFqyWPBqD5UQWneM37pDe9681zBnjRz9ojF8xe5POTIeSaH/vLqtL8SFWVaWo/Ws0P+1ll/+U0P/q1vbgivCt+PJlHTh7UHY+MG+RqwUXbeSR1EH0TtD4/TQUcs0/c4bBbm+TK4TrNj5haXqRfx1Y4dXCPlDteN0TCIU6Yda354RPrKAc3XQJNt1x39B62bfedNlCpTYt/ZzU/KodnRvOTJuFHbD+pZGdn3wuncu44eV+8evFwXMVEP7KHeDF7iXjVGsXPLR+0VZQWRjIq+AAK062PUHeWUiYdB2/28qn5UWyXRg67zEItHsppfqQ+P/wkPenzoz5fpiDNT4awnjW/tpcHzU8mzV5azY/8M6BY2NTB4VkMa3XaR8Tvwq1eka5EznzWLT0R/z3+//A9OuH1S0agb8eyxG+NUVHzk0SWWj5BFjqQ4oJwYr0r1z4/Quep8p/i25a/59qxvAj3nLovrmxKHHn4Hp3Qt2Mr27NS4cbnp1W6HJ6F727ur9w/0OAcj520aIWRUGK5Alm5fgSYVJCZa1LNYxU0nqK9HN7TS0b3w+rNO7Efs5K7U+ZkN4jLW1h4Fap1fRC3YrtCoyszjZHPTwsi4fDMmb08+PxI2mtlRXEwlXNxLgudoiYh/HCzRn3H6WbA02t+MtMpOmVZVTnyJn9PduIDmU4OkKiAFfckQ5eqpbgghG1NFiR/Zi9DLkgaRmDaK1mYt863rIHJheUmyWHahB/h8t0I9rJbFg4ZnDbRX6h78rNfs5dfdBOsXEH2rtfUNvgq689jd7dtC8LspTpOnjNOjS7aSxbGrivbcupusOX3yDwk/GQIqy2z2p4iyYxKpflhG+xtJ+2NoX3bJ9YdChrXPj9Nn8sKw9heH8XB/eORG6rF+iwG9WoLwwD6d+KddFVndZuDIp3IHZ75e6GT83S11EZ76ToeTZnpghXO3eaQsqnNZYIknDUUbpGZDXVmrzomC7rK54c9Pl2h7qK5x5XDs0z4MYJd2ysVs5cfnJaSyQVkz0bUnlnoIqlUsH2C3/dC5Z/pNWccb3oXj9Ob5wwYXOElTetOppqaIwhI+MkQsgzPqlB3GWyD7da2BL07lEn3CwK3jrvW5/euHInPftqAEwZ2AyBofiQCXquiCBbffCQKwiGs3ZrM3OrnHc+ErwvgXDenwVuf54fvebjOhhUchGvNhuqY9Ylx2ymLWbzlZi/9qtNekEWN6SLJ3GhJ2I49E2YvtwKLTIsWCRtoiKrbjVeyafZKbMtoDZyRPZ+O5UX4/h9HYve/TUu5/GgASQ5ZVH6EbtBFe/FaHWezlzW5yAXhhxyeM0RyYVNmRiUNdXeO9gpqhqxC31naNT9d25TglME9EsKcm2iv4oIwwkI+Ej8hnem+FxZyUw1fD7/Cz/694jNGSyvItotcM3uxmpEg8/wY4J3AU4GtV0Si+UnVDJSJJIduBRZZsxL9z3zl+WH7qQybvVS+KrmETMsbMgwUF4SxV1c+35CfOQor/AQ9xTl5UHcAsC2IrYIPWOB/c2f2Su5UnEPCD2l+MkRyYVP92l7KaK8AwoDdohV91O+BdB9ZtBeLEAjkGb/J8Dyfx0nzYzj4Sml++9uxe6JH21IcPzAeCcZFVGmiq7Jt9goyz0/IMNCrfRkeHTcI7coKJXu4JyQRIthz+mpnzEHpWt4CLiYN6iOShEMG94Of/oLL1ZVhqVt2tlwTgnSmuVcvHo7N2xswdPL7APy9p1eN2RWnPTYb5wzrha9Wbrb9vl/PNp7KY9+6owZU4q3LDuKCLnRw77lwMU4ZngFeQLL6j50k/LQcrAbA+sBIzV6KZRd04YZBo+tn+EHEuSLOeX5Su5jM+fzot+lWXLd+V1FRUoA/Ht4/8Z0VinWLCmYD1iHYreDJmb0M/b1kV5H3CxfZ4sLsJdbB6bdMODy7bteS/YJY24t9L2X9VDrR5RLLFXTRXkWRMCorUhOQh/Rtj2//PhZlhWEcff+nie3/vfQgfF9VjRP27eapPN6J3JCsa6gW0XRaSDcZnk2J2Wtng78Ft4OEhJ8MkfD5YRqSzLm5QpESnuu8s2j/cJODg+28HEPdhZfSc30yFu0lm+nxnbSb5S3cwDrFp6oZCxo/Zi+75ie9FyId+DlBVX5cK806ZWyUppiULyj8vOOqaK/UHZ6Tn7Ma6m5/fDmBfIkW58HfC5aQzWZ73rWyFfbu7n5BZgun++fW4VnEKSRfXNuLzF4tkKTPj97s1VqRQC2TGgDd4OTG7MUnSHMIdVd8dkumND9OlYuHaqt/9/LM2HaRSV8vN7DCjy+HZwfNTxDw/i52s5eq3jpfnsJICG9eOgKmmUafH+azG1PT3afsi2e/WGHbHgkJC5v6mSBk0eyVD9FeKufedBBlBIyITzt/KnVj+1hRRpItWipi5mi0Fzk8ZwirAXDOmBKtSEWJXPPDm1iCrZsXZLMy2z7MZ8dV3T1qNq5oMg+dOSS+REVWNT/sZ8Mp2sv9uZRmL82igpmiuNCPwzMr/MiPCVKwk2l+3DjRlhXpTRX7dG+DfYUcTUHi1eH5t4O6S68lboJNfk811D3TZi/20nMhE7AMp7xfLH5C3VliKeZsiqM/zm2eH1uEqYPZy4DC7FWffeGHND8ZIrHulUOn1Foh/GRU86MpntUKqWbAvNnLSfPjfC1s53HBwX1x/L5d0bt93FkvU5of2ezXi0DqxaQXCcufda5pfvw5PGdA8yN5V9w8q3T58rjFj8Ai20uMovQX3ca8w5mKKmgi3WbRIPD0LqYowGV7HSxdWzThZPbi9ymyzF6N2Rd+SPOTISzh3a/mJ5xiZ+YF7bvGnLpDmdz3ga2dU4I0N5ok0amub8dWiQEuU3l+2pbaI5D4pTkMW74eFr+aH96mzheS6ozSD5zZy2eGZ/kMMUjNT/JzItQdfB1kZGrBUhVsHd22a9mliD4/frSj7BGZescS55ZqGnJLIJLdk1iafHijAQg/TrLaw2ftj5KCMG47aW/bb2xbEqvCdnmRcAgXjeqHcUN7JbZ1b1tKmp+WjvUSd2hVhHFDeyEcMlAuydCs0vyIi2gGyS0nDsCzX6zE4rXVjvuyL0L7VvKQZLZ+zpofb4jXnimzl+xaeTOFfXV2fl/39WQdnrm1c3Ig0Y8qD5UO29pekn2C9fmxCxFuTEplGofnTCC2J3fH2K8lLPj8pGr2yo1Q94xWwRHZu9iokH5SFV1SEar6dijD0g3bMbRPe+1+VnSZNIqN2SZei6iV+suR8aU6jtq7Eis27sDAHm24fZJJDinaq8VgPf+QYeAfJw5Q7qfU/KTR7HX20F44e2gv9L72bQDuQ93Vwo9eu6Xa1w+Z6pc7tLJruQzhWzo0P3yae36/rPj8KPJQ6eAHcnlKgCAfo0zQcZMsMvtmL/07/sk1o3HwHR/yx0jKsWt+fNSFXRXeyW8vYHSahlxB9nxkfUQQ6PoVJ6b/6RDUNcZcOem7mVzZXH4UVRverwOG92vah9lO0V4tkAfO3A+1DTHs2rmVdj+18MN+zt40iH3n27sye7lPcuj1/EDmfH5Ugp5FyNBrfrwIrOxMm+1cRKEh20kO3cIL7ulPYifTWhiK31nSFcXlFs7UJNTxoF06oEe7UvsxMrOXsNHPO8IekXHND3M6y7SbY4ofrt9667KD0LG8yNe74YZUfH4i4ZCj9t0Loqm9KBLi1sZTHJSgJIeSHJLPT4bYq2sFBvVqKzV1saijvZxnrkGhK579rYMLs5eToObV10PcP2NmL5mgJ/grNUbVnYCX8Yd91lGHPBqZRrXwpw5xbaB0OzzLtKT8ytT8/ueO6I3WxRFcNKpfcJXwgRv/N9sxkvcniCSHqR6fCvmg+WHnOT3alqJz62LlvqmuwZdth2cdT583BN3alOCJcwYr92Hrb5nNaxuiWVmbkIWEnxxDlVCMHUCymeqdPXd7hZqX7ZALPIS6uzs//z1Tmp+2kuSTohOt3uzlr57aRTez0He0USTh1CEKqOk2e8nz/Kjfn5uO2wtf/e0IdA1obTG/yJyy9+gSXyfqpP3lGX2VDs+ssJdv0V6s5se0b8sF6phopZK0LXcSJxWzV9CI8sqBfdrhs2sPxeF7dlYec/qB8bQkB/Rum0iVETOBes1kMROQ2SuHOGiXDsrfdGs8BY1OuOLNXgE4PHsVfoTvmZqVyq6Dm6lDH5Xh95HFYibalhZg844GHKHpYDLFqN064fA9OmPPLu4WRQT0SdIsghToZWHefKi7/VxBmgb8IqvjyxcOww/rajBQkV9Idi1BZHj2or0NGukiwjlm+GJNXE55kFIVXXJJ+PHDBQf3xcAebbB3twruXtXWx1CkWM4pE5Dwk0M8fd6Byt+cOu9MwXZCHRRp/r1EirC/qmQHdrM4SGZzqQ/2zIZhBObzwxIzgRlXjsR3a6pxcH9eOM5GqHs4ZOCJ8WoVtwwuWkTxkIN8jE5JDnPBfChDZvYqK4pgv55tXR1jEQ7xooKvtb3YCUzGzV7Jz9lo427o17EVrji8PzqVq81dQZFLso8fU1U4ZGBo3/bc92jMRG1jFBXwrkkOChJ+cgjd7Jc3e2WiNnIaGFWlKs8P2/M6rQvkdcZv0/xk4F68dvFwV/tFo8FrfqKmifatinDIrh39FZADsIOvUvOTpjw/1nvDDuC5kDJAhp88PzLCBh9R50fwDqoufmDrnqtmLwC44vBdXe2XqmtLLvn8BFGTkoIwttU1Zj3XDwk/eUI4RzrvzTvqE59blygyPDOfHUPd3ZyUefkzneenvFg98xYFN1WeDyAFzY9m2pdDfaKWsGQwE0lXnh9ZMsxs+szp8KPddZXnx5fPT/Jzphc25TU/+U9LN3uJDO3bDnWNsaxPQkj4yRNSnckFxabtSeFHNYiw2x0XNvXs8CyYvbJqAmQ+G8GFurMEkd0122jXBkrH+SRmV37JkLRXwRdstdzWUbabYYjRXt7rks21vbh33NL8ZLQGuUVOaX4CqMoT4w9IvZAAIOEnTxBzpWQLVvhR4UXzk6rwkrFV3SXwDs/6aC+/tdRqfnyWmWncODwHqcGTRTqFmY25sEaaDD6Lu1vNj/N2P9cbChkYN7QXqmsb0Lu9Pb9Qpkjk+cnRZ+aGVAX+5qb5yRVI+MkTwhJVfjbY6Eb4YZ0l0+yUk+57oSudD5/Wd1KpODznO5zPj8rsFeD5ZJFOkRyZPOgIGfLP+mPkOwaRp0eXiT5T5JDSI2vkUh+Qqw7ofsh+fCfhikxGe+mKr3fK5glvOUJkOT28cOHIvjAM4IwDe3g/OGAadQ7PPt80nUCV7SRhbmFn7SoVfrA+P8nPkTz1+XG9sKmLsnJV09VSyI+3tOWRF8LP8uXLcd5556FPnz4oKSlBv379cNNNN6G+ntdCrFy5EscddxzKysrQoUMHXH755bZ9mgPZNPW4wZvDc2rX0qt9GZb84yhMPmmflMrxhcF/TIvDs0bAycdONTPRXnYtKa/5ydX3JzizVzYzNAdJPrZxG83iIuLkyXzLFXkh/Hz//feIxWJ49NFH8d133+Hee+/FI488gr/+9a+JfaLRKI455hhs374dn376KV544QW88soruOqqq7JY8/TgV4vgunxNXznpN3FV+P+dPlBTQPJj0A7PMtLpkOk24SMAbTi6b5+f5tTbQK2tSle0l+Xsmys+czp4bY18n7F7xRNdjky0tfSZvXIBq73krLzawmhOvVFe+PwceeSROPLIIxPf+/btiyVLluDhhx/GXXfdBQCYPn06Fi1ahFWrVqFr164AgLvvvhsTJkzApEmT0Lp166zUPR1kc+Z61pBeOHFgN+0ikOws3kuou+rFytUXToz2umhUP3RtU4K3v1mLmT/8yu0bxPIWIvkoF2U81F3m85OjwgAf7SWv492nDsSRi6pw2B5xIWivrq0xY/E6e1nNxOxlNZc8voRm5SeTj32OirzQ/MjYunUr2rVrl/g+a9YsDBgwICH4AMDYsWNRV1eHefPmZaOKaSPbZi+n1a+9ZIfNVf8LN4jROUWRME4d3AODerWV7OvvHLnk7BgESp+fAM1efPuLd3H5EO0lE9pEWhVF8Jv9uqN10wLJF43qhysO768tN781P9muAcHTfB5IXgo/P//8Mx544AFceOGFiW1VVVXo3Jlf+6ht27YoLCxEVVWVsqy6ujpUV1dzf7lOuvvuVAciq6+NhAxH4SbXu2W395rd7YKD++LUwd1xzD5dEttydcDNNBnR/HAJQeP/8yHai9PWuKxkcUGYyzRsHcbe52xPllKhOQy1JMDlJlkVfiZOnAijKRW76m/u3LncMWvWrMGRRx6JU045Beeffz73m2ygNU1TOwBPnjwZFRUVib8ePbIfNSQjn9TYlvDkJszdzaXkauehqnpJYRh3nLwvDt2tU2Jbrg64mUbt8BwcYYkGJRx21qpkG35Vd39lWNfGmlrS7SOYViyfn5yfJqnJ1f7LD6WFeeEp44qsXsmll16K008/XbtP7969E5/XrFmD0aNHY9iwYXjssce4/SorK/HFF19w2zZv3oyGhgabRojluuuuw5VXXpn4Xl1dnbMCkEW61dipjg3W8U7OzvF9c7tT09WOq7rDZeT6dWYKldkrSIGEC3UP231+cvVRBDHBsTRG7G3OVWHPC83gEvKaSb8ZgFe/+gWXHbpLtqsSGFkVfjp06IAOHTo47wjgl19+wejRozFo0CBMnToVIWFgHTZsGCZNmoS1a9eiS5e4uWH69OkoKirCoEGDlOUWFRWhqEixQGeOkutaBKujSneCw2zDJTmUSD/sMJ+rz2zvbhW4ZHS/jJ3vwN7tpNuDHNxkS8GE8yLUPYl/zU/8Pytk5v7Vqkk4PGe1FqnRHByezxrSC2cN6ZXtagRKXuiw1qxZg1GjRqFnz56466678OuvyUiayspKAMCYMWOw5557Yty4cbjzzjuxadMmXH311bjggguaRaRXPiRpS2INOPmsb4/jNtTd6ZHk6jP772UHZeQ8X984Bpt21KN3hzLp7+la1V0a7ZWjz4JvT/7qWFESd4Tu0Co5oSsuCKdUr2zSnExGRG6RF8LP9OnT8dNPP+Gnn35C9+7dud+sPBDhcBhvv/02Lr74YowYMQIlJSU488wzE6Hw+c6uncpxYJ926Fie+1oqa5wpaOaaHyfyJQNzJqgoLUBFaYF6h3SHujOre2Z4kXLX8PX2V0b/TuUA4gLP3BsOR8gw8jvaqxloTagbyE3yQviZMGECJkyY4Lhfz5498dZbb6W/QlkgFDLw0h+GZeRcqXaVfs1eKmEhHzpA2ZWmUuvyoghq6hrRrqwwhVLyhyDH55DEvyeSB5pTP8tbiOzSqVXiM6v9yVesLiFXn5kbcr/3apnk6ByIyGcsE4Ybh+dcx7XDc8C8dOEwHL5HZzx3wZD0nSSHCHJwY+UG62M++PzwC+WmLvw0J3LziRH5TF5ofoj8okU6PAes+tmjS2s8MX6w/wLyjCBbCifcSDQ/uWoFSiXaq7w4gpraRhy6eyfnnfOI5mAyag7X0Bwh4Yewkeos3DraaUX3fIcfY3N0RM0T0r28RT5keGZr5VVAm/nn0dhW24iubUoCrVO2ScgNufnIiDymeY9ORFawhKfm4PCsGye5ND+S/fLBVylXSNfyFklBPB/y/Pg3zbUrK0TP9qVBVynr5HPQwLih8dDwPx6mX37ECavtNleTZrYg4aeF0r7JkbZza7tTZHAOz8E0r3zt//K13tkgSIFE5iycFz4/ASQ5bK7k4934x4kDsPjmI7F394qUynnj0hE4dp8umNKCzOCZgMxeLZQXfj8UD3zwEy5PcVYiI7G8Ra46V3hCl+fHcLEX4Ya0mb1CVqh7Hgg/zOdm8eoEQL5He5UUpp5jaa+uFXjwzP0DqA3BQsJPC6V/53Lcf8Z+8h9T7Geak8OzW7OXDFL8uCddSQ5l0V65mucnFbNXc4VMx0S6yNFugMhn/Do8q8xEudr98Wt70WCVCula3iKv8vwwn5t5rIBncvOJEfkMvWJE4CQWNm0Gmh8dTmYv8vlxT/o0HfkT7RUycl9AyzT0DhHpgoQfInCS6ym1nOaVT9FeuTiupqtKlsYn3/L8hHPxIWWBxMKmdDuIgGk5oxPhmh5tUwyZbU4+P9muQAD83+kDs10FR4Ie3M4c0hMjd+2IvbvFI23yIdqLJVcFtExjhbpTHi0iaEj4IRK8+PuhOHrvStz+231SKiexvEWuepamgUx2zlYW39/s183V/icM7IZzR/ROY41SJ2gzz62/2RtP/e7AZLRXXuT5YT/naCUzTG7qTonmAEV7EQmG9G2PIX3bp1yOzMm0JZIuf4X7z9gPn/zwK0bt5m8pg5boR5EPmh+K9pLQAtsqkRlI+CECJxHt1Qw0P27HILnPT3poVRTBUXt3SVPpzRPK85OfkM8PkS7yf3Qicg5rcAkq2isfNBWyK92zS+uM10NFPtzDdMJFe+VorydLzkjEscy2h+zaMbsVIZoNpPkhAufAPu1QMbsAw/ulbkIDcjdqikU2Mx3Uqy0eGzcIfTqUZb5CBEckL8xeyc+5WsdMYzk8nzq4Bwb2aEvvEhEYJPwQgXPIrh2x4MYjPDtt5qKQk6oj85i9KgOqCZEKspXecw0ye9lJmr0M7FZZntW6EM2LHFUAE/mOn2iVXDTNuPf5odEqlwkZ8s85BWl+bORin0A0D0j4IQii2RPKi+Utcj8RY6bJRW0w0Twg4YcgAiBHx1OiiXwwKXELslKDAkCaHyJ9kPBDEBqayxBktvBRJB9y6MgWZG3ptPBmS6QREn4IIgAo/X5uw2pVwjmq+snNWhFE84SEH4Igmj2hPNCqcMtbkChEEGmFhB+C0ODW9yJXB1SLlm49yI9Q99wX0DJNSzfXEumDhB8iZ1B2c3nQ/9FYldvkQwJBg+mNc9Qyl3Hy4NUn8hQSfoicJx86wBwdT4kmeM1PFiuiga0WRXvFIcUPkS5I+CGIFkBLH0QqSgsSn3NVsMjVemUTyvNDpAta3oIgAoAcVHObbm1KcPMJe6G8OHe7PGpBdlq60E6kj9ztCQiiiV06tcrauWky3nw4Z1jvbFdBCxftRe2OINIKCT9EzvPb/btjy456HNC7XbaroiTXBysyH+Q+/PIWOd6gMgS1WiJdkPBD5DzhkIHfH9IvK+emMYjIFHyeHwIgsxeRPsjhmSACgJxViVShJiSDpB8iPeSN8HP88cejZ8+eKC4uRpcuXTBu3DisWbOG22flypU47rjjUFZWhg4dOuDyyy9HfX19lmpMeIUSmqUPurW5DyU5tEPtlkgXeSP8jB49Gi+99BKWLFmCV155BT///DNOPvnkxO/RaBTHHHMMtm/fjk8//RQvvPACXnnlFVx11VVZrDXhhVzs59xGcdFYRaQKLW9hJxf7BKJ5kDc+P3/6058Sn3v16oVrr70WJ554IhoaGlBQUIDp06dj0aJFWLVqFbp27QoAuPvuuzFhwgRMmjQJrVu3zlbViRZAPs3Uy4siqKlrzHY1CAE+yWHWqpFTkDaYSBd5o/lh2bRpE5599lkMHz4cBQXx5GWzZs3CgAEDEoIPAIwdOxZ1dXWYN2+esqy6ujpUV1dzfwThlVwfq9gh5NkLhmDfHm3w4u+HZq0+hB1+8dVcb1EEkd/klfDzl7/8BWVlZWjfvj1WrlyJN954I/FbVVUVOnfuzO3ftm1bFBYWoqqqSlnm5MmTUVFRkfjr0aNH2upP5B/NcQzap3sbvHHJCAzp2z7bVSEYKNrLDul9iHSRVeFn4sSJMAxD+zd37tzE/n/+858xf/58TJ8+HeFwGOeccw6nFpXNlkzT1M6irrvuOmzdujXxt2rVqmAvkmgR0EydSBVqQ3bI6kWki6z6/Fx66aU4/fTTtfv07t078blDhw7o0KEDdt11V+yxxx7o0aMHZs+ejWHDhqGyshJffPEFd+zmzZvR0NBg0wixFBUVoaioKKXrIIhchwaR/ILkoDjk80Oki6wKP5Yw4wfrpairqwMADBs2DJMmTcLatWvRpUsXAMD06dNRVFSEQYMGBVNhosUw+aS9cfu073H/6fu52p8GKyJIqDnFIdGHSBd5Ee315Zdf4ssvv8RBBx2Etm3bYunSpbjxxhvRr18/DBs2DAAwZswY7Lnnnhg3bhzuvPNObNq0CVdffTUuuOACivQiPHPGgT1x+gE9XJsiaLAigiQUohYFgKQfIm3khcNzSUkJXn31VRx22GHYbbfd8Lvf/Q4DBgzAzJkzEyarcDiMt99+G8XFxRgxYgROPfVUnHjiibjrrruyXHvCNTnW0Xnywch51U+O3VxCS663pkxBrZZIF3mh+dl7773xwQcfOO7Xs2dPvPXWWxmoEUEQBEEQ+UpeaH4IItehmToRKDmvScwM5PBMpAsSfggiAHJ9rKIxJL/I8eaUMajZEumChB+CSIGzhvREr/alOHFgt2xXhWhGhHJdms4QJLQT6SIvfH6IlkE+9nOTfrO3YyJNwk7XimKs2Vqb7WrkLNSc4ph52SsQ+QBpfggiRfJB8Mm1GfRblx+Mzq0puShBENmBhB+CIDJOu7JCHLp7p2xXI2fJfXE6M+Sa0E40H0j4IXIGiuxIH2Q+yC/yQJmYEajVEumChB+CILICybpqDNL9AAD6dijLdhWIZgoJPwRBZAUSfjS0cNnnrcsOwrH7dMGj42hdRiI9kPBDEC0AKxS/b0eaSecDLVz2wYBuFXjwzP3Rqz21VyI9UKg7QbQAhu/SATOuHInubUuyXZUE5IekJh8iCAkinyHhhyBaCLt0apXtKhAuIdGHINILmb0IgiByDFL8EER6IeGHIIisQA7PasIhkn4IIp2Q8EPkDDQWtizoeds5Z1gv7NGlNcbuVZntqhBEs4Z8fgiCyAqDe7XFy/NWZ7saOcXNJwzIdhUIokVAwg9BEFnhlME9EAmHMKhX22xXhSCIFgYJPwRBZIVwyMDJg7pnuxoEQbRAyOeHyBnIAZYgCILIBCT8EARBEATRoiDhhyAIgiCIFgUJP1nmmiN3AwBMPG7PLNeEIAiCIFoG5PCcZS4etQtOP6An2pUVZrsqWYfWeiIIgiAyAWl+cgASfAiCIAgic5DwQxAEQRBEi4KEH4IgCIIgWhQk/BAEQRAE0aIg4YcgCIIgiBYFCT8EQRAEQbQoSPghCIIgCKJFQcIPQRAEQRAtChJ+iJyhKBLOdhUIgiCIFkDeCT91dXUYOHAgDMPAggULuN9WrlyJ4447DmVlZejQoQMuv/xy1NfXZ6eihGvuP2M/9GpfivtP3y/bVSEIgiBaAHm3vMU111yDrl274uuvv+a2R6NRHHPMMejYsSM+/fRTbNy4EePHj4dpmnjggQeyVFvCDcfv2xXH79s129UgCIIgWgh5pfl55513MH36dNx1112236ZPn45FixbhmWeewX777YfDDz8cd999Nx5//HFUV1dnobYEQRAEQeQieSP8rFu3DhdccAGefvpplJaW2n6fNWsWBgwYgK5dkxqEsWPHoq6uDvPmzVOWW1dXh+rqau6PIAiCIIjmS14IP6ZpYsKECbjwwgsxePBg6T5VVVXo3Lkzt61t27YoLCxEVVWVsuzJkyejoqIi8dejR49A604QBEEQRG6RVeFn4sSJMAxD+zd37lw88MADqK6uxnXXXactzzAM2zbTNKXbLa677jps3bo18bdq1aqUr4sgCIIgiNwlqw7Pl156KU4//XTtPr1798Ytt9yC2bNno6ioiPtt8ODBOOuss/DUU0+hsrISX3zxBff75s2b0dDQYNMIsRQVFdnKJQiCIAii+WKYpmlmuxJOrFy5kvPFWbNmDcaOHYuXX34ZQ4YMQffu3fHOO+/g2GOPxerVq9GlSxcAwIsvvojx48dj/fr1aN26tatzVVdXo6KiAlu3bnV9DEEQBEEQ2cXL+J0Xoe49e/bkvrdq1QoA0K9fP3Tv3h0AMGbMGOy5554YN24c7rzzTmzatAlXX301LrjgAhJiCIIgCIJIkBcOz24Ih8N4++23UVxcjBEjRuDUU0/FiSeeKA2LJwiCIAii5ZIXZq9MQmYvgiAIgsg/vIzfzUbzQxAEQRAE4QYSfgiCIAiCaFGQ8EMQBEEQRIuChB+CIAiCIFoUJPwQBEEQBNGiyIs8P5nECn6jBU4JgiAIIn+wxm03Qewk/AjU1NQAAC1wShAEQRB5SE1NDSoqKrT7UJ4fgVgshjVr1qC8vFy7IKpXqqur0aNHD6xatarF5Q9qydcO0PXT9bfc66drb5nXbpHpe2CaJmpqatC1a1eEQnqvHtL8CIRCocSSGemgdevWLfZFaMnXDtD10/W33Ouna2+Z126RyXvgpPGxIIdngiAIgiBaFCT8EARBEATRoiDhJ0MUFRXhpptuQlFRUbarknFa8rUDdP10/S33+unaW+a1W+TyPSCHZ4IgCIIgWhSk+SEIgiAIokVBwg9BEARBEC0KEn4IgiAIgmhRkPBDEARBEESLokULP5MnT8YBBxyA8vJydOrUCSeeeCKWLFnC7WOaJiZOnIiuXbuipKQEo0aNwnfffZf4fdOmTbjsssuw2267obS0FD179sTll1+OrVu3JvZZvnw5zjvvPPTp0wclJSXo168fbrrpJtTX1zvWceHChRg5ciRKSkrQrVs33Hzzzdy6JWvXrsWZZ56J3XbbDaFQCFdccUWLuXaWzz77DJFIBAMHDmwR1z5hwgQYhmH722uvvRzLzod7UFtbiwkTJmDvvfdGJBLBiSeeKN1v5syZGDRoEIqLi9G3b1888sgjOXX9AHD88cejZ8+eKC4uRpcuXTBu3DisWbPGsY75/u6n89pZcvHdT+e1p/Lu5/r1p/u9Fy+0xTJ27Fhz6tSp5rfffmsuWLDAPOaYY8yePXua27ZtS+xz2223meXl5eYrr7xiLly40DzttNPMLl26mNXV1aZpmubChQvNk046yXzzzTfNn376yXz//ffN/v37m7/97W8TZbzzzjvmhAkTzHfffdf8+eefzTfeeMPs1KmTedVVV2nrt3XrVrNz587m6aefbi5cuNB85ZVXzPLycvOuu+5K7LNs2TLz8ssvN5966ilz4MCB5h//+McWc+0WW7ZsMfv27WuOGTPG3HfffVvEtW/ZssVcu3Zt4m/VqlVmu3btzJtuusnx+vPhHmzbts288MILzccee8wcO3asecIJJ9j2Wbp0qVlaWmr+8Y9/NBctWmQ+/vjjZkFBgfnyyy/nzPWbpmnec8895qxZs8zly5ebn332mTls2DBz2LBh2vo1h3c/nddukavvfjqvPZV3P9evP93vPUuLFn5E1q9fbwIwZ86caZqmacZiMbOystK87bbbEvvU1taaFRUV5iOPPKIs56WXXjILCwvNhoYG5T533HGH2adPH219HnroIbOiosKsra1NbJs8ebLZtWtXMxaL2fYfOXKk6w5QJJ+v/bTTTjNvuOEG86abbnLVAYrk87VbvPbaa6ZhGOby5cu1ZavItXvAMn78eGkneM0115i77747t+0Pf/iDOXToUNdlW2Ty+t944w3TMAyzvr5euU9zffeDvvZ8evfT8dxNM7V3P9eunyXd732LNnuJWGq7du3aAQCWLVuGqqoqjBkzJrFPUVERRo4cic8//1xbTuvWrRGJqJdO27p1a+I8KmbNmoWRI0dyCaLGjh2LNWvWYPny5W4uyTX5eu1Tp07Fzz//jJtuuklbno58vXaWKVOm4PDDD0evXr20ZevqBeTOPXDDrFmzuPoB8fs0d+5cNDQ0eCorU9e/adMmPPvssxg+fDgKCgqU5TTHdz/oa8+ndz+dzz2Vdz/Xrt8NQb33JPw0YZomrrzyShx00EEYMGAAAKCq6v/bu7+QpvowDuDfqSnWctNZW2EplMoyofLChP7plVFhBFHaXyRokhFdSH8uSgnCbrrIKJDSbqS8MeqiwAu1VZBQHHAYVIpi00IKTMkydM978ebebU7dq5vu7Hw/sIv9djzn9z3z0Wfz/NxXAIDZbPba1mw2ux/z9f37d1y7dg2nT5+e9ljd3d2oqamBzWabcU5fv371e2zPuQWDWrN/+vQJFy9eRENDw4y/bGei1uyevnz5gufPn+PUqVMz7nc64XgOAjHdeRofH8e3b98C3s9C5L9w4QKWLVsGk8mEvr4+PHnyZE7ZPOcWDGrNrpbaD/XzPp/aD8f8gQhW3bP5+au8vBwdHR14+PDhlMd0Op3XfRGZMgYAw8PD2LNnDzZs2DDtq5GBgQEUFhbi4MGDXt+wWVlZ0Ov10Ov12L1794zH9jc+H2rMPjExgZKSElRVVSEjIyPwsD7UmN3XgwcPYDQap704cDbheg4CEYz6WIj8FRUVUBQFzc3NiI6OxvHjx91zjfTaD3Z2NdV+qJ/3+dR+uOYPRDBqY24tc4Q5e/Ysnj59CrvdjpSUFPe4xWIB8G+nuWrVKvf44ODglM5zZGQEhYWF0Ov1ePz4sd+39gYGBpCfn4+8vDzU1tZ6Pfbs2TP3W3bx8fHu4/t224ODgwCmduZzpdbsIyMjePv2LRRFQXl5OQDA5XJBRBATE4Pm5mYUFBREZHZPIoK6ujocO3YMsbGxM+b1J1zPQSCmO08xMTEwmUwB7WOh8icnJyM5ORkZGRmwWq1Ys2YN3rx5g7y8vIiv/WBnV1Pth/J5n0/th2v+QASj7gFoe7WXy+WSM2fOyOrVq+Xjx49+H7dYLHLjxg332NjY2JSLv378+CFbt26VnTt3ys+fP/0ey+l0Snp6uhw+fFjGx8cDmt+dO3fEaDTK2NiYe6y6ujooFz2qPfvExIQ4HA6vW1lZmWRmZorD4fBavRBp2T21trYKAHE4HAHte1K4nwNPM134aLVavcZsNltAFz4uZH5ffX19AkBaW1un3SZSat9XMLKrpfZDkd3TXGo/3PN7CkXde9J081NWViYGg0Ha2tq8lg6Ojo66t6murhaDwSBNTU3icDikuLjYa9nf8PCw5ObmSnZ2tnR1dXntZ/IHfX9/v6xfv14KCgrE6XR6bTOToaEhMZvNUlxcLA6HQ5qamiQhIWHKkk9FUURRFMnJyZGSkhJRFEU6Ozs1kd1ToCs+Iin70aNHJTc3d9bMajsHIiKdnZ2iKIrs27dPdu3a5f4+nzS55PX8+fPy/v17uX//fsBLXhcqf3t7u9TU1IiiKNLb2ystLS2ybds2WbdundeKHl+RUPuhzu4p3Gp/IbLPpfbDPb9IaOvek6abHwB+b/X19e5tXC6XXL16VSwWi8TFxcmOHTu8Ou3J7tvfraenR0RE6uvrp91mNh0dHbJ9+3aJi4sTi8UilZWVU14B+NtvamqqJrJ7CvQHYKRkHxoakvj4eKmtrZ11f2o8B6mpqbN+XVtbm2zevFliY2MlLS1N7t69G1b5Ozo6JD8/X5KSkiQuLk7S0tLEZrOJ0+mcdY5qr/1QZ/cUbrUf6uxzrX015A9l3XvS/T0hRERERJrA1V5ERESkKWx+iIiISFPY/BAREZGmsPkhIiIiTWHzQ0RERJrC5oeIiIg0hc0PERERaQqbHyKKKJWVldi0adNiT4OIwhj/ySERqcZsn9p84sQJ3L59G2NjY//vQw6JSFPY/BCRanh+mnNjYyOuXLmCDx8+uMfi4+NhMBgWY2pEpCL8sxcRqYbFYnHfDAYDdDrdlDHfP3udPHkS+/fvx/Xr12E2m2E0GlFVVYXx8XFUVFQgKSkJKSkpqKur8zpWf38/Dh06hMTERJhMJhQVFaG3t3dhAxNRSLD5IaKI19LSgoGBAdjtdty8eROVlZXYu3cvEhMT0d7eDpvNBpvNhs+fPwMARkdHkZ+fD71eD7vdjlevXkGv16OwsBB//vxZ5DRENF9sfogo4iUlJeHWrVvIzMxEaWkpMjMzMTo6isuXLyM9PR2XLl1CbGwsXr9+DQB49OgRoqKicO/ePWRnZ8NqtaK+vh59fX1oa2tb3DBENG8xiz0BIqJQy8rKQlTUf6/1zGYzNm7c6L4fHR0Nk8mEwcFBAMC7d+/Q1dWF5cuXe+3n9+/f6O7uXphJE1HIsPkhooi3ZMkSr/s6nc7vmMvlAgC4XC7k5OSgoaFhyr5WrFgRuokS0YJg80NE5GPLli1obGzEypUrkZCQsNjTIaIg4zU/REQ+jhw5guTkZBQVFeHly5fo6enBixcvcO7cOTidzsWeHhHNE5sfIiIfS5cuhd1ux9q1a3HgwAFYrVaUlpbi169ffCeIKALwnxwSERGRpvCdHyIiItIUNj9ERESkKWx+iIiISFPY/BAREZGmsPkhIiIiTWHzQ0RERJrC5oeIiIg0hc0PERERaQqbHyIiItIUNj9ERESkKWx+iIiISFPY/BAREZGm/ANSAm8iJLRMwwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\statsmodels\\graphics\\tsaplots.py:348: FutureWarning: The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals = results_arma.resid\n",
    "\n",
    "# Plot the residuals\n",
    "plt.plot(residuals)\n",
    "plt.title('Residuals of AR(1) Model')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot ACF and PACF of residuals\n",
    "plot_acf(residuals, lags=20)\n",
    "plt.title('Autocorrelation Function (ACF) of Residuals')\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(residuals, lags=20)\n",
    "plt.title('Partial Autocorrelation Function (PACF) of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bc67d854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 140.51\n"
     ]
    }
   ],
   "source": [
    "# Remove NaN values from 'Concentration' and 'FittedValues' columns\n",
    "mask = ~np.isnan(data['Concentration']) & ~np.isnan(data['FittedValues'])\n",
    "y_true = data['Concentration'][mask]\n",
    "y_pred = data['FittedValues'][mask]\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba2bfb3",
   "metadata": {},
   "source": [
    "#### Our MSE is very high, 140. that means ARIMA is not working well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c57ba95e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>FittedValues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.826087</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>50.943430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44.717391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.898076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>58.812500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44.426841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>52.604167</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>54.633318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>35.173913</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50.968446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues\n",
       "Date                                                                         \n",
       "2022-01-01  2022      1    1      34.826087          6        1     50.943430\n",
       "2022-01-02  2022      1    2      44.717391          0        1     37.898076\n",
       "2022-01-03  2022      1    3      58.812500          1        0     44.426841\n",
       "2022-01-04  2022      1    4      52.604167          2        0     54.633318\n",
       "2022-01-05  2022      1    5      35.173913          3        0     50.968446"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f7404",
   "metadata": {},
   "source": [
    "## Now we calculate the lagged values of Concentration (making a new variable with the value from day before, a week before, a month before, and a year before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "def39893",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
      "Date                                                                            \n",
      "2022-01-01  2022      1    1      34.826087          6        1     50.943430   \n",
      "2022-01-02  2022      1    2      44.717391          0        1     37.898076   \n",
      "2022-01-03  2022      1    3      58.812500          1        0     44.426841   \n",
      "2022-01-04  2022      1    4      52.604167          2        0     54.633318   \n",
      "2022-01-05  2022      1    5      35.173913          3        0     50.968446   \n",
      "\n",
      "             day_lag1  day_lag7  day_lag30  day_lag365  \n",
      "Date                                                    \n",
      "2022-01-01        NaN       NaN        NaN         NaN  \n",
      "2022-01-02  34.826087       NaN        NaN         NaN  \n",
      "2022-01-03  44.717391       NaN        NaN         NaN  \n",
      "2022-01-04  58.812500       NaN        NaN         NaN  \n",
      "2022-01-05  52.604167       NaN        NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "##### This code needs work, not every year is 365 not every month is 30\n",
    "\n",
    "\n",
    "# Assuming 'Date' is your index\n",
    "data['day_lag1'] = data['Concentration'].shift(1)\n",
    "data['day_lag7'] = data['Concentration'].shift(7)\n",
    "\n",
    "# If 'Date' is not the index, you can use the following instead\n",
    "# data['day_lag1'] = data['Concentration'].shift(1).reset_index(drop=True)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day_lag30'] = data.apply(lambda row: data.loc[\n",
    "    (data['Year'] == row['Year']) & \n",
    "    (data['Month'] == row['Month'] - 1) & \n",
    "    (data['Day'] == row['Day']), \n",
    "    'Concentration'].values[0] if row['Month'] > 1 and not data.loc[\n",
    "    (data['Year'] == row['Year']) & \n",
    "    (data['Month'] == row['Month'] - 1) & \n",
    "    (data['Day'] == row['Day']), \n",
    "    'Concentration'].empty else None, axis=1)\n",
    "\n",
    "data['day_lag365'] = data.apply(lambda row: data.loc[\n",
    "    (data['Year'] == row['Year'] - 1) & \n",
    "    (data['Month'] == row['Month']) & \n",
    "    (data['Day'] == row['Day']), \n",
    "    'Concentration'].values[0] if row['Year'] > data['Year'].min() and not data.loc[\n",
    "    (data['Year'] == row['Year'] - 1) & \n",
    "    (data['Month'] == row['Month']) & \n",
    "    (data['Day'] == row['Day']), \n",
    "    'Concentration'].empty else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad17fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na_rows = data[data['day_lag30'].notna()]\n",
    "print(non_na_rows.head(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "8b279067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for day_lag1 with dropped values: 143.68913509835645\n",
      "MSE for day_lag7 with dropped values: 325.62450275835545\n",
      "MSE for day_lag30 with dropped values: 622.0144939860954\n",
      "MSE for day_lag365 with dropped values: 540.1895102379201\n"
     ]
    }
   ],
   "source": [
    "# Columns to calculate MSE for\n",
    "lag_columns = ['day_lag1', 'day_lag7', 'day_lag30', 'day_lag365']\n",
    "\n",
    "# Create a new DataFrame for the dropped missing values\n",
    "data_dropped = data.dropna()\n",
    "\n",
    "# Loop through lag columns and calculate MSE for dropped DataFrame\n",
    "for lag_column in lag_columns:\n",
    "    mse_dropped = mean_squared_error(data_dropped['Concentration'], data_dropped[lag_column], squared=True)\n",
    "    print(f'MSE for {lag_column} with dropped values: {mse_dropped}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a73e26",
   "metadata": {},
   "source": [
    "### Again very High MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7ce6d388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>FittedValues</th>\n",
       "      <th>day_lag1</th>\n",
       "      <th>day_lag7</th>\n",
       "      <th>day_lag30</th>\n",
       "      <th>day_lag365</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.826087</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>50.943430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44.717391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.898076</td>\n",
       "      <td>34.826087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>58.812500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44.426841</td>\n",
       "      <td>44.717391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>52.604167</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>54.633318</td>\n",
       "      <td>58.812500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>35.173913</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50.968446</td>\n",
       "      <td>52.604167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
       "Date                                                                            \n",
       "2022-01-01  2022      1    1      34.826087          6        1     50.943430   \n",
       "2022-01-02  2022      1    2      44.717391          0        1     37.898076   \n",
       "2022-01-03  2022      1    3      58.812500          1        0     44.426841   \n",
       "2022-01-04  2022      1    4      52.604167          2        0     54.633318   \n",
       "2022-01-05  2022      1    5      35.173913          3        0     50.968446   \n",
       "\n",
       "             day_lag1  day_lag7  day_lag30  day_lag365  \n",
       "Date                                                    \n",
       "2022-01-01        NaN       NaN        NaN         NaN  \n",
       "2022-01-02  34.826087       NaN        NaN         NaN  \n",
       "2022-01-03  44.717391       NaN        NaN         NaN  \n",
       "2022-01-04  58.812500       NaN        NaN         NaN  \n",
       "2022-01-05  52.604167       NaN        NaN         NaN  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5b8c59",
   "metadata": {},
   "source": [
    "## Now we normalize and Converge the signals (days) from euclidian to the angular domain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "00318313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
      "Date                                                                            \n",
      "2022-01-01  2022      1    1       0.298815          6        1      0.466547   \n",
      "2022-01-02  2022      1    2       0.388855          0        1      0.327173   \n",
      "2022-01-03  2022      1    3       0.517163          1        0      0.396925   \n",
      "2022-01-04  2022      1    4       0.460649          2        0      0.505970   \n",
      "2022-01-05  2022      1    5       0.301981          3        0      0.466815   \n",
      "2022-01-06  2022      1    6       0.270624          4        0      0.343341   \n",
      "2022-01-07  2022      1    7       0.387445          5        0      0.304628   \n",
      "2022-01-08  2022      1    8       0.416362          6        1      0.388693   \n",
      "2022-01-09  2022      1    9       0.386118          0        1      0.428560   \n",
      "2022-01-10  2022      1   10       0.064100          1        0      0.408978   \n",
      "2022-01-11  2022      1   11       0.125067          2        0      0.147431   \n",
      "2022-01-12  2022      1   12       0.029774          3        0      0.160503   \n",
      "2022-01-13  2022      1   13       0.006258          4        0      0.106219   \n",
      "2022-01-14  2022      1   14       0.020779          5        0      0.071960   \n",
      "2022-01-15  2022      1   15       0.054049          6        1      0.100682   \n",
      "2022-01-16  2022      1   16       0.088944          0        1      0.066488   \n",
      "2022-01-17  2022      1   17       0.109434          1        0      0.110738   \n",
      "2022-01-18  2022      1   18       0.096909          2        0      0.146506   \n",
      "2022-01-19  2022      1   19       0.120614          3        0      0.113443   \n",
      "2022-01-20  2022      1   20       0.479687          4        0      0.134075   \n",
      "2022-01-21  2022      1   21       0.278020          5        0      0.381509   \n",
      "2022-01-22  2022      1   22       0.274417          6        1      0.284489   \n",
      "2022-01-23  2022      1   23       0.294857          0        1      0.269091   \n",
      "2022-01-24  2022      1   24       0.237815          1        0      0.277497   \n",
      "2022-01-25  2022      1   25       0.024464          2        0      0.196586   \n",
      "2022-01-26  2022      1   26       0.095581          3        0      0.088783   \n",
      "2022-01-27  2022      1   27       0.225109          4        0      0.138901   \n",
      "2022-01-28  2022      1   28       0.097288          5        0      0.200195   \n",
      "2022-01-29  2022      1   29       0.391824          6        1      0.102719   \n",
      "2022-01-30  2022      1   30       0.392187          0        1      0.346674   \n",
      "2022-01-31  2022      1   31       0.596435          1        0      0.384829   \n",
      "2022-02-01  2022      2    1       0.369462          2        0      0.492721   \n",
      "2022-02-02  2022      2    2       0.357482          3        0      0.359827   \n",
      "2022-02-03  2022      2    3       0.350654          4        0      0.312919   \n",
      "2022-02-04  2022      2    4       0.435953          5        0      0.376209   \n",
      "2022-02-05  2022      2    5       0.434098          6        1      0.396489   \n",
      "2022-02-06  2022      2    6       0.557368          0        1      0.407478   \n",
      "2022-02-07  2022      2    7       0.463493          1        0      0.519806   \n",
      "2022-02-08  2022      2    8       0.457128          2        0      0.439747   \n",
      "2022-02-09  2022      2    9       0.374739          3        0      0.464669   \n",
      "2022-02-10  2022      2   10       0.255263          4        0      0.369381   \n",
      "2022-02-11  2022      2   11       0.289118          5        0      0.277285   \n",
      "2022-02-12  2022      2   12       0.334345          6        1      0.334044   \n",
      "2022-02-13  2022      2   13       0.526266          0        1      0.339135   \n",
      "2022-02-14  2022      2   14       0.534701          1        0      0.507016   \n",
      "2022-02-15  2022      2   15       0.427271          2        0      0.505986   \n",
      "2022-02-16  2022      2   16       0.489475          3        0      0.426891   \n",
      "2022-02-17  2022      2   17       0.622367          4        0      0.501522   \n",
      "2022-02-18  2022      2   18       0.556040          5        0      0.562843   \n",
      "2022-02-19  2022      2   19       0.574246          6        1      0.555912   \n",
      "2022-02-20  2022      2   20       0.581205          0        1      0.569380   \n",
      "2022-02-21  2022      2   21       0.604779          1        0      0.568624   \n",
      "2022-02-22  2022      2   22       0.345534          2        0      0.590364   \n",
      "2022-02-23  2022      2   23       0.380346          3        0      0.389898   \n",
      "2022-02-24  2022      2   24       0.489475          4        0      0.429659   \n",
      "2022-02-25  2022      2   25       0.444149          5        0      0.503496   \n",
      "2022-02-26  2022      2   26       0.287140          6        1      0.449600   \n",
      "2022-02-27  2022      2   27       0.419685          0        1      0.369219   \n",
      "2022-02-28  2022      2   28       0.347620          1        0      0.432865   \n",
      "2022-03-01  2022      3    1       0.158115          2        0      0.385504   \n",
      "2022-03-02  2022      3    2       0.157216          3        0      0.230122   \n",
      "2022-03-03  2022      3    3       0.200834          4        0      0.234262   \n",
      "2022-03-04  2022      3    4       0.267944          5        0      0.253007   \n",
      "2022-03-05  2022      3    5       0.206524          6        1      0.285923   \n",
      "2022-03-06  2022      3    6       0.357984          0        1      0.270896   \n",
      "2022-03-07  2022      3    7       0.416082          1        0      0.355737   \n",
      "2022-03-08  2022      3    8       0.379860          2        0      0.416586   \n",
      "2022-03-09  2022      3    9       0.426455          3        0      0.373618   \n",
      "2022-03-10  2022      3   10       0.562299          4        0      0.431001   \n",
      "2022-03-11  2022      3   11       0.573298          5        0      0.536255   \n",
      "2022-03-12  2022      3   12       0.656206          6        1      0.532195   \n",
      "2022-03-13  2022      3   13       0.725014          0        1      0.629487   \n",
      "2022-03-14  2022      3   14       0.449080          1        0      0.675264   \n",
      "2022-03-15  2022      3   15       0.292433          2        0      0.471538   \n",
      "2022-03-16  2022      3   16       0.202640          3        0      0.345560   \n",
      "2022-03-17  2022      3   17       0.419216          4        0      0.258792   \n",
      "2022-03-18  2022      3   18       0.343410          5        0      0.432793   \n",
      "2022-03-19  2022      3   19       0.561614          6        1      0.398846   \n",
      "2022-03-20  2022      3   20       0.493078          0        1      0.538941   \n",
      "2022-03-21  2022      3   21       0.356006          1        0      0.506768   \n",
      "2022-03-22  2022      3   22       0.439219          2        0      0.356591   \n",
      "2022-03-23  2022      3   23       0.464062          3        0      0.486151   \n",
      "2022-03-24  2022      3   24       0.445848          4        0      0.466931   \n",
      "2022-03-25  2022      3   25       0.540869          5        0      0.451391   \n",
      "2022-03-26  2022      3   26       0.615210          6        1      0.554560   \n",
      "2022-03-27  2022      3   27       0.307106          0        1      0.571035   \n",
      "2022-03-28  2022      3   28            NaN          1        0           NaN   \n",
      "2022-03-29  2022      3   29            NaN          2        0           NaN   \n",
      "2022-03-30  2022      3   30       0.391428          3        0      0.395153   \n",
      "2022-03-31  2022      3   31       0.432185          4        0      0.401784   \n",
      "2022-04-01  2022      4    1       0.482268          5        0      0.447654   \n",
      "2022-04-02  2022      4    2       0.611087          6        1      0.492731   \n",
      "2022-04-03  2022      4    3       0.505784          0        1      0.613934   \n",
      "2022-04-04  2022      4    4       0.423882          1        0      0.527159   \n",
      "2022-04-05  2022      4    5       0.321087          2        0      0.420639   \n",
      "2022-04-06  2022      4    6       0.468045          3        0      0.383949   \n",
      "2022-04-07  2022      4    7       0.577091          4        0      0.478888   \n",
      "2022-04-08  2022      4    8       0.431600          5        0      0.594612   \n",
      "2022-04-09  2022      4    9       0.509008          6        1      0.450480   \n",
      "2022-04-10  2022      4   10       0.484734          0        1      0.503039   \n",
      "2022-04-11  2022      4   11       0.550540          1        0      0.518701   \n",
      "2022-04-12  2022      4   12       0.494727          2        0      0.541125   \n",
      "2022-04-13  2022      4   13       0.159492          3        0      0.547964   \n",
      "2022-04-14  2022      4   14       0.284658          4        0      0.216143   \n",
      "2022-04-15  2022      4   15       0.331863          5        0      0.333106   \n",
      "2022-04-16  2022      4   16       0.478096          6        1      0.390919   \n",
      "2022-04-17  2022      4   17       0.517732          0        1      0.466760   \n",
      "2022-04-18  2022      4   18       0.556469          1        0      0.570456   \n",
      "2022-04-19  2022      4   19       0.497440          2        0      0.489860   \n",
      "2022-04-20  2022      4   20       0.560781          3        0      0.528059   \n",
      "2022-04-21  2022      4   21       0.569728          4        0      0.568729   \n",
      "2022-04-22  2022      4   22       0.458752          5        0      0.559387   \n",
      "2022-04-23  2022      4   23       0.601176          6        1      0.506502   \n",
      "2022-04-24  2022      4   24       0.694597          0        1      0.549245   \n",
      "2022-04-25  2022      4   25       0.398635          1        0      0.712422   \n",
      "2022-04-26  2022      4   26       0.518490          2        0      0.447841   \n",
      "2022-04-27  2022      4   27       0.592881          3        0      0.529915   \n",
      "2022-04-28  2022      4   28       0.587521          4        0      0.598992   \n",
      "2022-04-29  2022      4   29       0.384601          5        0      0.557278   \n",
      "2022-04-30  2022      4   30       0.583778          6        1      0.522334   \n",
      "2022-05-01  2022      5    1       0.517542          0        1      0.543888   \n",
      "2022-05-02  2022      5    2       0.532335          1        0      0.531479   \n",
      "2022-05-03  2022      5    3       0.528368          2        0      0.558914   \n",
      "2022-05-04  2022      5    4       0.456476          3        0      0.573200   \n",
      "2022-05-05  2022      5    5       0.318035          4        0      0.516359   \n",
      "2022-05-06  2022      5    6       0.409040          5        0      0.326798   \n",
      "2022-05-07  2022      5    7       0.392187          6        1      0.464434   \n",
      "2022-05-08  2022      5    8       0.543713          0        1      0.459690   \n",
      "2022-05-09  2022      5    9       0.573290          1        0      0.556216   \n",
      "2022-05-10  2022      5   10       0.528921          2        0      0.581269   \n",
      "2022-05-11  2022      5   11       0.585625          3        0      0.493264   \n",
      "2022-05-12  2022      5   12       0.498685          4        0      0.645864   \n",
      "2022-05-13  2022      5   13       0.535559          5        0      0.526214   \n",
      "2022-05-14  2022      5   14       0.652001          6        1      0.532064   \n",
      "2022-05-15  2022      5   15       0.733779          0        1      0.651456   \n",
      "2022-05-16  2022      5   16       0.543144          1        0      0.693219   \n",
      "2022-05-17  2022      5   17       0.516594          2        0      0.641480   \n",
      "2022-05-18  2022      5   18       0.673225          3        0      0.510713   \n",
      "2022-05-19  2022      5   19       0.515835          4        0      0.646901   \n",
      "2022-05-20  2022      5   20       0.422254          5        0      0.572802   \n",
      "2022-05-21  2022      5   21       0.592287          6        1      0.494739   \n",
      "2022-05-22  2022      5   22       0.653518          0        1      0.640648   \n",
      "2022-05-23  2022      5   23       0.437339          1        0      0.578709   \n",
      "2022-05-24  2022      5   24       0.486416          2        0      0.524911   \n",
      "2022-05-25  2022      5   25       0.489664          3        0      0.568844   \n",
      "2022-05-26  2022      5   26       0.498957          4        0      0.505108   \n",
      "2022-05-27  2022      5   27       0.550928          5        0      0.518500   \n",
      "2022-05-28  2022      5   28       0.527973          6        1      0.556883   \n",
      "2022-05-29  2022      5   29       0.502181          0        1      0.612422   \n",
      "2022-05-30  2022      5   30       0.457326          1        0      0.537375   \n",
      "2022-05-31  2022      5   31       0.461218          2        0      0.456005   \n",
      "2022-06-01  2022      6    1       0.526266          3        0      0.502611   \n",
      "2022-06-02  2022      6    2       0.664897          4        0      0.572065   \n",
      "2022-06-03  2022      6    3       0.777315          5        0      0.694799   \n",
      "2022-06-04  2022      6    4       0.801631          6        1      0.718812   \n",
      "2022-06-05  2022      6    5       0.415513          0        1      0.758420   \n",
      "2022-06-06  2022      6    6       0.507788          1        0      0.522465   \n",
      "2022-06-07  2022      6    7       0.357671          2        0      0.549040   \n",
      "2022-06-08  2022      6    8       0.271383          3        0      0.427439   \n",
      "2022-06-09  2022      6    9       0.422299          4        0      0.304690   \n",
      "2022-06-10  2022      6   10       0.410203          5        0      0.525334   \n",
      "2022-06-11  2022      6   11       0.478855          6        1      0.464583   \n",
      "2022-06-12  2022      6   12       0.549543          0        1      0.486417   \n",
      "2022-06-13  2022      6   13       0.547696          1        0      0.565368   \n",
      "2022-06-14  2022      6   14       0.646880          2        0      0.536200   \n",
      "2022-06-15  2022      6   15       0.851326          3        0      0.710619   \n",
      "2022-06-16  2022      6   16       0.801890          4        0      0.777583   \n",
      "2022-06-17  2022      6   17       0.830944          5        0      0.756309   \n",
      "2022-06-18  2022      6   18       0.935826          6        1      0.832344   \n",
      "2022-06-19  2022      6   19       0.520956          0        1      0.897166   \n",
      "2022-06-20  2022      6   20       0.530059          1        0      0.609831   \n",
      "2022-06-21  2022      6   21       0.441494          2        0      0.534725   \n",
      "2022-06-22  2022      6   22       0.699033          3        0      0.524000   \n",
      "2022-06-23  2022      6   23       0.655604          4        0      0.715756   \n",
      "2022-06-24  2022      6   24       0.487801          5        0      0.721601   \n",
      "2022-06-25  2022      6   25       0.384032          6        1      0.527797   \n",
      "2022-06-26  2022      6   26       0.393324          0        1      0.436919   \n",
      "2022-06-27  2022      6   27       0.272496          1        0      0.474541   \n",
      "2022-06-28  2022      6   28       0.494216          2        0      0.384282   \n",
      "2022-06-29  2022      6   29       0.602883          3        0      0.546647   \n",
      "2022-06-30  2022      6   30       0.319989          4        0      0.584725   \n",
      "2022-07-01  2022      7    1       0.366016          5        0      0.388647   \n",
      "2022-07-02  2022      7    2       0.512611          6        1      0.465493   \n",
      "2022-07-03  2022      7    3       0.482656          0        1      0.521199   \n",
      "2022-07-04  2022      7    4       0.461597          1        0      0.493089   \n",
      "2022-07-05  2022      7    5       0.491940          2        0      0.509657   \n",
      "2022-07-06  2022      7    6       0.543606          3        0      0.527720   \n",
      "2022-07-07  2022      7    7       0.411910          4        0      0.564480   \n",
      "2022-07-08  2022      7    8       0.515835          5        0      0.435411   \n",
      "2022-07-09  2022      7    9       0.534701          6        1      0.534163   \n",
      "2022-07-10  2022      7   10       0.441874          0        1      0.576936   \n",
      "2022-07-11  2022      7   11       0.453063          1        0      0.467706   \n",
      "2022-07-12  2022      7   12       0.500862          2        0      0.493521   \n",
      "2022-07-13  2022      7   13       0.681775          3        0      0.498020   \n",
      "2022-07-14  2022      7   14       0.499716          4        0      0.680732   \n",
      "2022-07-15  2022      7   15       0.476521          5        0      0.560744   \n",
      "2022-07-16  2022      7   16       0.537076          6        1      0.475975   \n",
      "2022-07-17  2022      7   17       0.608762          0        1      0.562733   \n",
      "2022-07-18  2022      7   18       0.851749          1        0      0.587716   \n",
      "2022-07-19  2022      7   19       0.984259          2        0      0.859029   \n",
      "2022-07-20  2022      7   20       0.715342          3        0      0.929823   \n",
      "2022-07-21  2022      7   21       0.433777          4        0      0.681507   \n",
      "2022-07-22  2022      7   22       0.438839          5        0      0.524680   \n",
      "2022-07-23  2022      7   23       0.609141          6        1      0.482341   \n",
      "2022-07-24  2022      7   24       0.702314          0        1      0.659996   \n",
      "2022-07-25  2022      7   25       0.495543          1        0      0.707888   \n",
      "2022-07-26  2022      7   26       0.451166          2        0      0.540182   \n",
      "2022-07-27  2022      7   27       0.500070          3        0      0.528331   \n",
      "2022-07-28  2022      7   28       0.620140          4        0      0.518908   \n",
      "2022-07-29  2022      7   29       0.772046          5        0      0.654986   \n",
      "2022-07-30  2022      7   30       0.674214          6        1      0.775612   \n",
      "2022-07-31  2022      7   31       0.411720          0        1      0.684770   \n",
      "2022-08-01  2022      8    1       0.506353          1        0      0.488877   \n",
      "2022-08-02  2022      8    2       0.486811          2        0      0.525895   \n",
      "2022-08-03  2022      8    3       0.418737          3        0      0.555880   \n",
      "2022-08-04  2022      8    4       0.351982          4        0      0.489551   \n",
      "2022-08-05  2022      8    5       0.494250          5        0      0.432003   \n",
      "2022-08-06  2022      8    6       0.486630          6        1      0.504427   \n",
      "2022-08-07  2022      8    7       0.648777          0        1      0.520875   \n",
      "2022-08-08  2022      8    8       0.622795          1        0      0.682397   \n",
      "2022-08-09  2022      8    9       0.619398          2        0      0.640903   \n",
      "2022-08-10  2022      8   10       0.811682          3        0      0.603950   \n",
      "2022-08-11  2022      8   11       0.924142          4        0      0.785350   \n",
      "2022-08-12  2022      8   12       0.948689          5        0      0.896142   \n",
      "2022-08-13  2022      8   13       0.867438          6        1      0.942876   \n",
      "2022-08-14  2022      8   14       0.898540          0        1      0.844639   \n",
      "2022-08-15  2022      8   15       0.821247          1        0      0.851581   \n",
      "2022-08-16  2022      8   16       0.915608          2        0      0.861745   \n",
      "2022-08-17  2022      8   17       0.622795          3        0      0.928715   \n",
      "2022-08-18  2022      8   18       0.715177          4        0      0.704819   \n",
      "2022-08-19  2022      8   19       0.345344          5        0      0.709246   \n",
      "2022-08-20  2022      8   20       0.438270          6        1      0.483520   \n",
      "2022-08-21  2022      8   21       0.416006          0        1      0.539112   \n",
      "2022-08-22  2022      8   22       0.869748          1        0      0.539574   \n",
      "2022-08-23  2022      8   23       0.464252          2        0      0.805224   \n",
      "2022-08-24  2022      8   24       0.660914          3        0      0.574237   \n",
      "2022-08-25  2022      8   25       0.799166          4        0      0.695110   \n",
      "2022-08-26  2022      8   26       0.569926          5        0      0.831559   \n",
      "2022-08-27  2022      8   27       0.515266          6        1      0.577054   \n",
      "2022-08-28  2022      8   28       0.610468          0        1      0.604599   \n",
      "2022-08-29  2022      8   29       0.568145          1        0      0.671386   \n",
      "2022-08-30  2022      8   30       0.585815          2        0      0.594098   \n",
      "2022-08-31  2022      8   31       0.637398          3        0      0.661215   \n",
      "2022-09-01  2022      9    1       0.658185          4        0      0.637972   \n",
      "2022-09-02  2022      9    2       0.610279          5        0      0.713475   \n",
      "2022-09-03  2022      9    3       0.628295          6        1      0.661230   \n",
      "2022-09-04  2022      9    4       0.565333          0        1      0.638976   \n",
      "2022-09-05  2022      9    5       0.672235          1        0      0.638234   \n",
      "2022-09-06  2022      9    6       0.520939          2        0      0.671074   \n",
      "2022-09-07  2022      9    7       0.504457          3        0      0.620464   \n",
      "2022-09-08  2022      9    8       0.413196          4        0      0.544060   \n",
      "2022-09-09  2022      9    9       0.422340          5        0      0.480774   \n",
      "2022-09-10  2022      9   10       0.414565          6        1      0.496127   \n",
      "2022-09-11  2022      9   11       0.432391          0        1      0.482318   \n",
      "2022-09-12  2022      9   12       0.399393          1        0      0.509366   \n",
      "2022-09-13  2022      9   13       0.294519          2        0      0.435886   \n",
      "2022-09-14  2022      9   14       0.211347          3        0      0.373043   \n",
      "2022-09-15  2022      9   15       0.282761          4        0      0.313115   \n",
      "2022-09-16  2022      9   16       0.374739          5        0      0.342517   \n",
      "2022-09-17  2022      9   17       0.301981          6        1      0.420071   \n",
      "2022-09-18  2022      9   18       0.324483          0        1      0.342536   \n",
      "2022-09-19  2022      9   19       0.311018          1        0      0.385490   \n",
      "2022-09-20  2022      9   20       0.286942          2        0      0.355364   \n",
      "2022-09-21  2022      9   21       0.230988          3        0      0.311634   \n",
      "2022-09-22  2022      9   22       0.280106          4        0      0.301578   \n",
      "2022-09-23  2022      9   23       0.280807          5        0      0.306080   \n",
      "2022-09-24  2022      9   24       0.394083          6        1      0.330317   \n",
      "2022-09-25  2022      9   25       0.342310          0        1      0.390082   \n",
      "2022-09-26  2022      9   26       0.314844          1        0      0.361444   \n",
      "2022-09-27  2022      9   27       0.312536          2        0      0.349734   \n",
      "2022-09-28  2022      9   28       0.251280          3        0      0.328361   \n",
      "2022-09-29  2022      9   29       0.189184          4        0      0.283878   \n",
      "2022-09-30  2022      9   30       0.266831          5        0      0.229932   \n",
      "2022-10-01  2022     10    1       0.412289          6        1      0.296030   \n",
      "2022-10-02  2022     10    2       0.331665          0        1      0.405728   \n",
      "2022-10-03  2022     10    3       0.149630          1        0      0.339249   \n",
      "2022-10-04  2022     10    4       0.257159          2        0      0.204381   \n",
      "2022-10-05  2022     10    5       0.411585          3        0      0.267312   \n",
      "2022-10-06  2022     10    6       0.350085          4        0      0.392919   \n",
      "2022-10-07  2022     10    7       0.285606          5        0      0.365086   \n",
      "2022-10-08  2022     10    8       0.358484          6        1      0.315100   \n",
      "2022-10-09  2022     10    9       0.045515          0        1      0.342639   \n",
      "2022-10-10  2022     10   10       0.359568          1        0      0.096538   \n",
      "2022-10-11  2022     10   11       0.034895          2        0      0.360458   \n",
      "2022-10-12  2022     10   12       0.149992          3        0      0.130982   \n",
      "2022-10-13  2022     10   13       0.179405          4        0      0.138448   \n",
      "2022-10-14  2022     10   14       0.194725          5        0      0.231479   \n",
      "2022-10-15  2022     10   15       0.320121          6        1      0.161289   \n",
      "2022-10-16  2022     10   16       0.325242          0        1      0.371259   \n",
      "2022-10-17  2022     10   17       0.177508          1        0      0.302338   \n",
      "2022-10-18  2022     10   18       0.225109          2        0      0.156816   \n",
      "2022-10-19  2022     10   19       0.190594          3        0      0.270665   \n",
      "2022-10-20  2022     10   20       0.169395          4        0      0.172306   \n",
      "2022-10-21  2022     10   21       0.356913          5        0      0.234601   \n",
      "2022-10-22  2022     10   22       0.333965          6        1      0.305642   \n",
      "2022-10-23  2022     10   23       0.321639          0        1      0.293959   \n",
      "2022-10-24  2022     10   24       0.452548          1        0      0.357166   \n",
      "2022-10-25  2022     10   25       0.355016          2        0      0.394539   \n",
      "2022-10-26  2022     10   26            NaN          3        0           NaN   \n",
      "2022-10-27  2022     10   27            NaN          4        0           NaN   \n",
      "2022-10-28  2022     10   28            NaN          5        0           NaN   \n",
      "2022-10-29  2022     10   29            NaN          6        1           NaN   \n",
      "2022-10-30  2022     10   30            NaN          0        1           NaN   \n",
      "2022-10-31  2022     10   31            NaN          1        0           NaN   \n",
      "2022-11-01  2022     11    1            NaN          2        0           NaN   \n",
      "2022-11-02  2022     11    2            NaN          3        0           NaN   \n",
      "2022-11-03  2022     11    3            NaN          4        0           NaN   \n",
      "2022-11-04  2022     11    4            NaN          5        0           NaN   \n",
      "2022-11-05  2022     11    5            NaN          6        1           NaN   \n",
      "2022-11-06  2022     11    6            NaN          0        1           NaN   \n",
      "2022-11-07  2022     11    7       0.458790          1        0      0.358060   \n",
      "2022-11-08  2022     11    8       0.416461          2        0      0.397774   \n",
      "2022-11-09  2022     11    9       0.404893          3        0      0.417848   \n",
      "2022-11-10  2022     11   10       0.283493          4        0      0.412450   \n",
      "2022-11-11  2022     11   11       0.246918          5        0      0.283279   \n",
      "2022-11-12  2022     11   12       0.055187          6        1      0.262579   \n",
      "2022-11-13  2022     11   13       0.043239          0        1      0.112646   \n",
      "2022-11-14  2022     11   14       0.032652          1        0      0.117939   \n",
      "2022-11-15  2022     11   15       0.296226          2        0      0.091609   \n",
      "2022-11-16  2022     11   16       0.331500          3        0      0.250625   \n",
      "2022-11-17  2022     11   17       0.469001          4        0      0.346229   \n",
      "2022-11-18  2022     11   18       0.253935          5        0      0.426100   \n",
      "2022-11-19  2022     11   19       0.038498          6        1      0.284872   \n",
      "2022-11-20  2022     11   20       0.018206          0        1      0.050636   \n",
      "2022-11-21  2022     11   21       0.315803          1        0      0.061931   \n",
      "2022-11-22  2022     11   22       0.389342          2        0      0.318607   \n",
      "2022-11-23  2022     11   23       0.317593          3        0      0.371202   \n",
      "2022-11-24  2022     11   24       0.391668          4        0      0.314759   \n",
      "2022-11-25  2022     11   25       0.239712          5        0      0.330450   \n",
      "2022-11-26  2022     11   26       0.177904          6        1      0.250787   \n",
      "2022-11-27  2022     11   27       0.275934          0        1      0.224054   \n",
      "2022-11-28  2022     11   28       0.135976          1        0      0.280065   \n",
      "2022-11-29  2022     11   29       0.041874          2        0      0.140084   \n",
      "2022-11-30  2022     11   30            NaN          3        0           NaN   \n",
      "2022-12-01  2022     12    1       0.061970          4        0      0.078178   \n",
      "2022-12-02  2022     12    2       0.095581          5        0      0.124956   \n",
      "2022-12-03  2022     12    3       0.076237          6        1      0.112610   \n",
      "2022-12-04  2022     12    4       0.043998          0        1      0.096438   \n",
      "2022-12-05  2022     12    5       0.002968          1        0      0.059070   \n",
      "2022-12-06  2022     12    6       0.068083          2        0      0.042643   \n",
      "2022-12-07  2022     12    7       0.134496          3        0      0.094772   \n",
      "2022-12-08  2022     12    8       0.135555          4        0      0.112944   \n",
      "2022-12-09  2022     12    9       0.080789          5        0      0.130957   \n",
      "2022-12-10  2022     12   10       0.155699          6        1      0.092695   \n",
      "2022-12-11  2022     12   11       0.248155          0        1      0.147203   \n",
      "2022-12-12  2022     12   12       0.096529          1        0      0.214595   \n",
      "2022-12-13  2022     12   13       0.015930          2        0      0.089124   \n",
      "2022-12-14  2022     12   14       0.015238          3        0      0.050035   \n",
      "2022-12-15  2022     12   15       0.000000          4        0      0.026920   \n",
      "2022-12-16  2022     12   16       0.031291          5        0      0.000000   \n",
      "2022-12-17  2022     12   17       0.010290          6        1      0.048807   \n",
      "2022-12-18  2022     12   18       0.104305          0        1      0.018499   \n",
      "2022-12-19  2022     12   19       0.279158          1        0      0.092307   \n",
      "2022-12-20  2022     12   20       0.278630          2        0      0.219512   \n",
      "2022-12-21  2022     12   21       0.238195          3        0      0.229050   \n",
      "2022-12-22  2022     12   22       0.264366          4        0      0.227428   \n",
      "2022-12-23  2022     12   23       0.366890          5        0      0.217338   \n",
      "2022-12-24  2022     12   24       0.385359          6        1      0.298061   \n",
      "2022-12-25  2022     12   25       0.254314          0        1      0.342356   \n",
      "2022-12-26  2022     12   26       0.405280          1        0      0.250635   \n",
      "2022-12-27  2022     12   27       0.366584          2        0      0.359650   \n",
      "2022-12-28  2022     12   28       0.437322          3        0      0.309684   \n",
      "2022-12-29  2022     12   29       0.483447          4        0      0.391163   \n",
      "2022-12-30  2022     12   30       0.382118          5        0      0.476457   \n",
      "2022-12-31  2022     12   31            NaN          6        1           NaN   \n",
      "2023-01-01  2023      1    1       0.432805          0        1      0.342164   \n",
      "2023-01-02  2023      1    2       0.419496          1        0      0.400297   \n",
      "2023-01-03  2023      1    3       0.361654          2        0      0.388790   \n",
      "2023-01-04  2023      1    4       0.479975          3        0      0.372076   \n",
      "2023-01-05  2023      1    5       0.405272          4        0      0.483123   \n",
      "2023-01-06  2023      1    6       0.378532          5        0      0.356246   \n",
      "2023-01-07  2023      1    7       0.449410          6        1      0.383253   \n",
      "2023-01-08  2023      1    8       0.574815          0        1      0.454806   \n",
      "2023-01-09  2023      1    9       0.476200          1        0      0.538440   \n",
      "2023-01-10  2023      1   10       0.360953          2        0      0.482407   \n",
      "2023-01-11  2023      1   11       0.467665          3        0      0.342920   \n",
      "2023-01-12  2023      1   12       0.476958          4        0      0.483717   \n",
      "2023-01-13  2023      1   13       0.533662          5        0      0.478942   \n",
      "2023-01-14  2023      1   14       0.485822          6        1      0.518913   \n",
      "2023-01-15  2023      1   15       0.567609          0        1      0.501405   \n",
      "2023-01-16  2023      1   16       0.488716          1        0      0.513673   \n",
      "2023-01-17  2023      1   17       0.188590          2        0      0.537062   \n",
      "2023-01-18  2023      1   18       0.118528          3        0      0.251055   \n",
      "2023-01-19  2023      1   19       0.181680          4        0      0.190666   \n",
      "2023-01-20  2023      1   20       0.207983          5        0      0.231368   \n",
      "2023-01-21  2023      1   21       0.150768          6        1      0.238044   \n",
      "2023-01-22  2023      1   22       0.260762          0        1      0.269650   \n",
      "2023-01-23  2023      1   23       0.106069          1        0      0.248117   \n",
      "2023-01-24  2023      1   24       0.185663          2        0      0.148525   \n",
      "2023-01-25  2023      1   25       0.088944          3        0      0.218352   \n",
      "2023-01-26  2023      1   26       0.215701          4        0      0.161043   \n",
      "2023-01-27  2023      1   27       0.376825          5        0      0.240561   \n",
      "2023-01-28  2023      1   28       0.354258          6        1      0.324941   \n",
      "2023-01-29  2023      1   29       0.165635          0        1      0.343413   \n",
      "2023-01-30  2023      1   30       0.383463          1        0      0.231140   \n",
      "2023-01-31  2023      1   31       0.215437          2        0      0.354831   \n",
      "2023-02-01  2023      2    1       0.437150          3        0      0.215688   \n",
      "2023-02-02  2023      2    2       0.451735          4        0      0.386630   \n",
      "2023-02-03  2023      2    3       0.458373          5        0      0.484764   \n",
      "2023-02-04  2023      2    4       0.220648          6        1      0.410873   \n",
      "2023-02-05  2023      2    5       0.468045          0        1      0.251505   \n",
      "2023-02-06  2023      2    6       0.193628          1        0      0.403397   \n",
      "2023-02-07  2023      2    7       0.083510          2        0      0.263556   \n",
      "2023-02-08  2023      2    8       0.110753          3        0      0.163950   \n",
      "2023-02-09  2023      2    9       0.135027          4        0      0.132985   \n",
      "2023-02-10  2023      2   10       0.120713          5        0      0.128720   \n",
      "2023-02-11  2023      2   11       0.238005          6        1      0.181676   \n",
      "2023-02-12  2023      2   12       0.316518          0        1      0.283314   \n",
      "2023-02-13  2023      2   13       0.098154          1        0      0.281248   \n",
      "2023-02-14  2023      2   14       0.071876          2        0      0.100780   \n",
      "2023-02-15  2023      2   15       0.113977          3        0      0.112211   \n",
      "2023-02-16  2023      2   16       0.231928          4        0      0.173751   \n",
      "2023-02-17  2023      2   17       0.464062          5        0      0.213802   \n",
      "2023-02-18  2023      2   18       0.533852          6        1      0.391250   \n",
      "2023-02-19  2023      2   19       0.435756          0        1      0.473064   \n",
      "2023-02-20  2023      2   20       0.430116          1        0      0.432393   \n",
      "2023-02-21  2023      2   21            NaN          2        0           NaN   \n",
      "2023-02-22  2023      2   22            NaN          3        0           NaN   \n",
      "2023-02-23  2023      2   23            NaN          4        0           NaN   \n",
      "2023-02-24  2023      2   24       0.492699          5        0      0.411512   \n",
      "2023-02-25  2023      2   25       0.389437          6        1      0.409438   \n",
      "2023-02-26  2023      2   26            NaN          0        1           NaN   \n",
      "2023-02-27  2023      2   27       0.421582          1        0      0.386167   \n",
      "2023-02-28  2023      2   28       0.309294          2        0      0.441503   \n",
      "2023-03-01  2023      3    1       0.333086          3        0      0.334070   \n",
      "2023-03-02  2023      3    2       0.265174          4        0      0.301936   \n",
      "2023-03-03  2023      3    3       0.341569          5        0      0.279711   \n",
      "2023-03-04  2023      3    4       0.586573          6        1      0.372301   \n",
      "2023-03-05  2023      3    5       0.470510          0        1      0.568416   \n",
      "2023-03-06  2023      3    6       0.406600          1        0      0.429704   \n",
      "2023-03-07  2023      3    7       0.446615          2        0      0.387428   \n",
      "2023-03-08  2023      3    8       0.282003          3        0      0.468527   \n",
      "2023-03-09  2023      3    9       0.220450          4        0      0.317239   \n",
      "2023-03-10  2023      3   10       0.479992          5        0      0.269798   \n",
      "2023-03-11  2023      3   11       0.401100          6        1      0.432200   \n",
      "2023-03-12  2023      3   12       0.533118          0        1      0.410755   \n",
      "2023-03-13  2023      3   13       0.420254          1        0      0.552430   \n",
      "2023-03-14  2023      3   14       0.531007          2        0      0.424092   \n",
      "2023-03-15  2023      3   15       0.459305          3        0      0.469383   \n",
      "2023-03-16  2023      3   16       0.561350          4        0      0.481143   \n",
      "2023-03-17  2023      3   17       0.480751          5        0      0.554206   \n",
      "2023-03-18  2023      3   18       0.531766          6        1      0.523997   \n",
      "2023-03-19  2023      3   19       0.461283          0        1      0.472303   \n",
      "2023-03-20  2023      3   20       0.420064          1        0      0.474216   \n",
      "2023-03-21  2023      3   21       0.419387          2        0      0.472213   \n",
      "2023-03-22  2023      3   22       0.517569          3        0      0.454274   \n",
      "2023-03-23  2023      3   23       0.622416          4        0      0.506969   \n",
      "2023-03-24  2023      3   24       0.607624          5        0      0.568136   \n",
      "2023-03-25  2023      3   25       0.653139          6        1      0.640998   \n",
      "2023-03-26  2023      3   26       0.568557          0        1      0.659828   \n",
      "2023-03-27  2023      3   27       0.616628          1        0      0.552856   \n",
      "2023-03-28  2023      3   28       0.441494          2        0      0.590491   \n",
      "2023-03-29  2023      3   29       0.401669          3        0      0.497873   \n",
      "2023-03-30  2023      3   30       0.602658          4        0      0.482391   \n",
      "2023-03-31  2023      3   31       0.577660          5        0      0.593919   \n",
      "2023-04-01  2023      4    1       0.402996          6        1      0.548383   \n",
      "2023-04-02  2023      4    2       0.448816          0        1      0.478537   \n",
      "2023-04-03  2023      4    3       0.417030          1        0      0.515568   \n",
      "2023-04-04  2023      4    4       0.489285          2        0      0.438771   \n",
      "2023-04-05  2023      4    5       0.426133          3        0      0.486228   \n",
      "2023-04-06  2023      4    6       0.431006          4        0      0.481985   \n",
      "2023-04-07  2023      4    7       0.555471          5        0      0.491474   \n",
      "2023-04-08  2023      4    8       0.526456          6        1      0.562897   \n",
      "2023-04-09  2023      4    9       0.453962          0        1      0.502185   \n",
      "2023-04-10  2023      4   10       0.575574          1        0      0.499313   \n",
      "2023-04-11  2023      4   11       0.637019          2        0      0.613674   \n",
      "2023-04-12  2023      4   12       0.647103          3        0      0.620858   \n",
      "2023-04-13  2023      4   13       0.641760          4        0      0.627959   \n",
      "2023-04-14  2023      4   14       0.484544          5        0      0.641941   \n",
      "2023-04-15  2023      4   15       0.562801          6        1      0.547829   \n",
      "2023-04-16  2023      4   16       0.481699          0        1      0.585004   \n",
      "2023-04-17  2023      4   17       0.551489          1        0      0.497645   \n",
      "2023-04-18  2023      4   18       0.465637          2        0      0.566523   \n",
      "2023-04-19  2023      4   19       0.586383          3        0      0.545632   \n",
      "2023-04-20  2023      4   20       0.633795          4        0      0.590446   \n",
      "2023-04-21  2023      4   21       0.529556          5        0      0.636936   \n",
      "2023-04-22  2023      4   22       0.204438          6        1      0.540064   \n",
      "2023-04-23  2023      4   23       0.559264          0        1      0.336271   \n",
      "2023-04-24  2023      4   24       0.680448          1        0      0.571455   \n",
      "2023-04-25  2023      4   25       0.659966          2        0      0.650179   \n",
      "2023-04-26  2023      4   26       0.512042          3        0      0.666851   \n",
      "2023-04-27  2023      4   27       0.601786          4        0      0.587570   \n",
      "2023-04-28  2023      4   28       0.324294          5        0      0.589323   \n",
      "2023-04-29  2023      4   29       0.636260          6        1      0.385832   \n",
      "2023-04-30  2023      4   30       0.634834          0        1      0.631269   \n",
      "2023-05-01  2023      5    1       0.541248          1        0      0.694261   \n",
      "2023-05-02  2023      5    2       0.560212          2        0      0.553852   \n",
      "2023-05-03  2023      5    3       0.592683          3        0      0.581148   \n",
      "2023-05-04  2023      5    4       0.598521          4        0      0.582727   \n",
      "2023-05-05  2023      5    5       0.529111          5        0      0.646536   \n",
      "2023-05-06  2023      5    6       0.472365          6        1      0.606743   \n",
      "2023-05-07  2023      5    7       0.333965          0        1      0.467610   \n",
      "2023-05-08  2023      5    8       0.283520          1        0      0.405624   \n",
      "2023-05-09  2023      5    9       0.283182          2        0      0.361889   \n",
      "2023-05-10  2023      5   10       0.366395          3        0      0.393976   \n",
      "2023-05-11  2023      5   11       0.443356          4        0      0.405852   \n",
      "2023-05-12  2023      5   12       0.359370          5        0      0.428600   \n",
      "2023-05-13  2023      5   13       0.682344          6        1      0.438041   \n",
      "2023-05-14  2023      5   14       0.619002          0        1      0.665173   \n",
      "2023-05-15  2023      5   15       0.491354          1        0      0.629662   \n",
      "2023-05-16  2023      5   16       0.549023          2        0      0.474871   \n",
      "2023-05-17  2023      5   17       0.533283          3        0      0.571232   \n",
      "2023-05-18  2023      5   18       0.616537          4        0      0.565062   \n",
      "2023-05-19  2023      5   19       0.658185          5        0      0.619277   \n",
      "2023-05-20  2023      5   20       0.692775          6        1      0.662683   \n",
      "2023-05-21  2023      5   21       0.605158          0        1      0.646586   \n",
      "2023-05-22  2023      5   22       0.518672          1        0      0.660999   \n",
      "2023-05-23  2023      5   23       0.631709          2        0      0.553363   \n",
      "2023-05-24  2023      5   24       0.523628          3        0      0.628459   \n",
      "2023-05-25  2023      5   25       0.613462          4        0      0.561850   \n",
      "2023-05-26  2023      5   26       0.680637          5        0      0.618691   \n",
      "2023-05-27  2023      5   27       0.750427          6        1      0.737156   \n",
      "2023-05-28  2023      5   28       0.740310          0        1      0.701986   \n",
      "2023-05-29  2023      5   29       0.668690          1        0      0.750581   \n",
      "2023-05-30  2023      5   30       0.659776          2        0      0.694923   \n",
      "2023-05-31  2023      5   31       0.655019          3        0      0.682360   \n",
      "2023-06-01  2023      6    1       0.609141          4        0      0.704164   \n",
      "2023-06-02  2023      6    2       0.721601          5        0      0.603239   \n",
      "2023-06-03  2023      6    3       0.712407          6        1      0.766906   \n",
      "2023-06-04  2023      6    4       0.751185          0        1      0.738567   \n",
      "2023-06-05  2023      6    5       0.676465          1        0      0.754909   \n",
      "2023-06-06  2023      6    6       0.738529          2        0      0.726478   \n",
      "2023-06-07  2023      6    7       0.698464          3        0      0.717127   \n",
      "2023-06-08  2023      6    8       0.783235          4        0      0.781115   \n",
      "2023-06-09  2023      6    9       0.904446          5        0      0.781009   \n",
      "2023-06-10  2023      6   10       0.979708          6        1      0.896895   \n",
      "2023-06-11  2023      6   11       0.877679          0        1      0.969189   \n",
      "2023-06-12  2023      6   12       0.900403          1        0      0.883634   \n",
      "2023-06-13  2023      6   13       1.000000          2        0      0.950126   \n",
      "2023-06-14  2023      6   14       0.960743          3        0      0.959366   \n",
      "2023-06-15  2023      6   15       0.837078          4        0      0.979016   \n",
      "2023-06-16  2023      6   16       0.979898          5        0      0.906614   \n",
      "2023-06-17  2023      6   17       0.966622          6        1      0.983869   \n",
      "2023-06-18  2023      6   18       0.881801          0        1      1.000000   \n",
      "2023-06-19  2023      6   19       0.657798          1        0      0.899118   \n",
      "2023-06-20  2023      6   20       0.604161          2        0      0.795278   \n",
      "2023-06-21  2023      6   21       0.558385          3        0      0.691094   \n",
      "2023-06-22  2023      6   22       0.450358          4        0      0.644550   \n",
      "2023-06-23  2023      6   23       0.599411          5        0      0.582761   \n",
      "2023-06-24  2023      6   24       0.627908          6        1      0.681105   \n",
      "2023-06-25  2023      6   25       0.861559          0        1      0.727021   \n",
      "2023-06-26  2023      6   26       0.642708          1        0      0.842330   \n",
      "2023-06-27  2023      6   27       0.554490          2        0      0.732188   \n",
      "2023-06-28  2023      6   28       0.462166          3        0      0.635715   \n",
      "2023-06-29  2023      6   29       0.451546          4        0      0.568566   \n",
      "2023-06-30  2023      6   30       0.528764          5        0      0.522385   \n",
      "2023-07-01  2023      7    1       0.355775          6        1      0.598303   \n",
      "2023-07-02  2023      7    2       0.632657          0        1      0.490782   \n",
      "2023-07-03  2023      7    3       0.561416          1        0      0.650620   \n",
      "2023-07-04  2023      7    4       0.518474          2        0      0.619951   \n",
      "2023-07-05  2023      7    5       0.521714          3        0      0.548126   \n",
      "2023-07-06  2023      7    6       0.560823          4        0      0.623419   \n",
      "2023-07-07  2023      7    7       0.677413          5        0      0.583257   \n",
      "2023-07-08  2023      7    8       0.710980          6        1      0.682569   \n",
      "2023-07-09  2023      7    9       0.606140          0        1      0.743802   \n",
      "2023-07-10  2023      7   10       0.596814          1        0      0.635365   \n",
      "2023-07-11  2023      7   11       0.513180          2        0      0.666136   \n",
      "2023-07-12  2023      7   12       0.513329          3        0      0.527552   \n",
      "2023-07-13  2023      7   13       0.527593          4        0      0.569399   \n",
      "2023-07-14  2023      7   14       0.637588          5        0      0.612391   \n",
      "2023-07-15  2023      7   15       0.474542          6        1      0.639298   \n",
      "2023-07-16  2023      7   16       0.457994          0        1      0.554049   \n",
      "2023-07-17  2023      7   17       0.482458          1        0      0.476990   \n",
      "2023-07-18  2023      7   18       0.546772          2        0      0.564354   \n",
      "2023-07-19  2023      7   19       0.457425          3        0      0.586008   \n",
      "2023-07-20  2023      7   20       0.389911          4        0      0.500079   \n",
      "2023-07-21  2023      7   21       0.421903          5        0      0.462367   \n",
      "2023-07-22  2023      7   22       0.511853          6        1      0.449173   \n",
      "2023-07-23  2023      7   23       0.406410          0        1      0.572587   \n",
      "2023-07-24  2023      7   24       0.383908          1        0      0.459486   \n",
      "2023-07-25  2023      7   25       0.448891          2        0      0.424881   \n",
      "2023-07-26  2023      7   26       0.531955          3        0      0.489619   \n",
      "2023-07-27  2023      7   27       0.296836          4        0      0.530722   \n",
      "2023-07-28  2023      7   28       0.285606          5        0      0.411402   \n",
      "2023-07-29  2023      7   29       0.393135          6        1      0.324842   \n",
      "2023-07-30  2023      7   30       0.464054          0        1      0.412268   \n",
      "2023-07-31  2023      7   31       0.332448          1        0      0.486680   \n",
      "2023-08-01  2023      8    1       0.448891          2        0      0.406907   \n",
      "2023-08-02  2023      8    2       0.430215          3        0      0.481596   \n",
      "2023-08-03  2023      8    3       0.426702          4        0      0.405275   \n",
      "2023-08-04  2023      8    4       0.396548          5        0      0.450346   \n",
      "2023-08-05  2023      8    5       0.391997          6        1      0.471527   \n",
      "2023-08-06  2023      8    6       0.491957          0        1      0.410775   \n",
      "2023-08-07  2023      8    7       0.476768          1        0      0.482667   \n",
      "2023-08-08  2023      8    8       0.384411          2        0      0.464502   \n",
      "2023-08-09  2023      8    9       0.471574          3        0      0.455950   \n",
      "2023-08-10  2023      8   10       0.534041          4        0      0.505031   \n",
      "2023-08-11  2023      8   11       0.544472          5        0      0.485851   \n",
      "2023-08-12  2023      8   12       0.447233          6        1      0.544454   \n",
      "2023-08-13  2023      8   13       0.483785          0        1      0.496462   \n",
      "2023-08-14  2023      8   14       0.525507          1        0      0.517747   \n",
      "2023-08-15  2023      8   15       0.528368          2        0      0.510231   \n",
      "2023-08-16  2023      8   16       0.559264          3        0      0.501911   \n",
      "2023-08-17  2023      8   17       0.424616          4        0      0.611529   \n",
      "2023-08-18  2023      8   18       0.461283          5        0      0.473991   \n",
      "2023-08-19  2023      8   19       0.515266          6        1      0.461779   \n",
      "2023-08-20  2023      8   20       0.474113          0        1      0.509276   \n",
      "2023-08-21  2023      8   21       0.479885          1        0      0.501891   \n",
      "2023-08-22  2023      8   22       0.423668          2        0      0.564312   \n",
      "2023-08-23  2023      8   23       0.510525          3        0      0.423916   \n",
      "2023-08-24  2023      8   24       0.410623          4        0      0.486823   \n",
      "2023-08-25  2023      8   25       0.324863          5        0      0.474790   \n",
      "2023-08-26  2023      8   26       0.460080          6        1      0.397242   \n",
      "2023-08-27  2023      8   27       0.455149          0        1      0.501875   \n",
      "2023-08-28  2023      8   28       0.421771          1        0      0.408292   \n",
      "2023-08-29  2023      8   29       0.378532          2        0      0.466123   \n",
      "2023-08-30  2023      8   30       0.419331          3        0      0.472752   \n",
      "2023-08-31  2023      8   31       0.421202          4        0      0.416289   \n",
      "2023-09-01  2023      9    1       0.277072          5        0      0.435614   \n",
      "2023-09-02  2023      9    2       0.295253          6        1      0.300704   \n",
      "2023-09-03  2023      9    3       0.468424          0        1      0.396672   \n",
      "2023-09-04  2023      9    4       0.512991          1        0      0.485569   \n",
      "2023-09-05  2023      9    5       0.523025          2        0      0.454646   \n",
      "2023-09-06  2023      9    6       0.602693          3        0      0.546065   \n",
      "2023-09-07  2023      9    7       0.623554          4        0      0.593501   \n",
      "2023-09-08  2023      9    8       0.669663          5        0      0.635752   \n",
      "2023-09-09  2023      9    9       0.701119          6        1      0.620744   \n",
      "2023-09-10  2023      9   10       0.730324          0        1      0.654193   \n",
      "2023-09-11  2023      9   11       0.637415          1        0      0.755523   \n",
      "2023-09-12  2023      9   12       0.412479          2        0      0.644232   \n",
      "2023-09-13  2023      9   13       0.428409          3        0      0.461509   \n",
      "2023-09-14  2023      9   14       0.372431          4        0      0.441124   \n",
      "2023-09-15  2023      9   15       0.421392          5        0      0.442215   \n",
      "2023-09-16  2023      9   16       0.448511          6        1      0.507082   \n",
      "2023-09-17  2023      9   17       0.359378          0        1      0.472783   \n",
      "2023-09-18  2023      9   18       0.470189          1        0      0.382923   \n",
      "2023-09-19  2023      9   19       0.404476          2        0      0.494550   \n",
      "2023-09-20  2023      9   20       0.574729          3        0      0.479540   \n",
      "2023-09-21  2023      9   21       0.390480          4        0      0.578539   \n",
      "2023-09-22  2023      9   22       0.385739          5        0      0.416587   \n",
      "2023-09-23  2023      9   23       0.304950          6        1      0.396852   \n",
      "2023-09-24  2023      9   24       0.407738          0        1      0.407202   \n",
      "2023-09-25  2023      9   25       0.430305          1        0      0.428357   \n",
      "2023-09-26  2023      9   26       0.293670          2        0      0.454504   \n",
      "2023-09-27  2023      9   27       0.385739          3        0      0.324383   \n",
      "2023-09-28  2023      9   28       0.433340          4        0      0.423127   \n",
      "2023-09-29  2023      9   29       0.315240          5        0      0.481689   \n",
      "2023-09-30  2023      9   30       0.322587          6        1      0.324186   \n",
      "2023-10-01  2023     10    1       0.486061          0        1      0.372022   \n",
      "2023-10-02  2023     10    2       0.488197          1        0      0.469716   \n",
      "2023-10-03  2023     10    3       0.557747          2        0      0.509581   \n",
      "2023-10-04  2023     10    4       0.378153          3        0      0.567512   \n",
      "2023-10-05  2023     10    5       0.346705          4        0      0.376712   \n",
      "2023-10-06  2023     10    6       0.432985          5        0      0.382196   \n",
      "2023-10-07  2023     10    7       0.518111          6        1      0.454616   \n",
      "2023-10-08  2023     10    8       0.374409          0        1      0.525121   \n",
      "2023-10-09  2023     10    9       0.246374          1        0      0.421333   \n",
      "2023-10-10  2023     10   10            NaN          2        0           NaN   \n",
      "\n",
      "            day_lag1  day_lag7   day_lag30  day_lag365  \n",
      "Date                                                    \n",
      "2022-01-01       NaN       NaN         NaN         NaN  \n",
      "2022-01-02  0.298815       NaN         NaN         NaN  \n",
      "2022-01-03  0.388855       NaN         NaN         NaN  \n",
      "2022-01-04  0.517163       NaN         NaN         NaN  \n",
      "2022-01-05  0.460649       NaN         NaN         NaN  \n",
      "2022-01-06  0.301981       NaN         NaN         NaN  \n",
      "2022-01-07  0.270624       NaN         NaN         NaN  \n",
      "2022-01-08  0.387445  0.298815         NaN         NaN  \n",
      "2022-01-09  0.416362  0.388855         NaN         NaN  \n",
      "2022-01-10  0.386118  0.517163         NaN         NaN  \n",
      "2022-01-11  0.064100  0.460649         NaN         NaN  \n",
      "2022-01-12  0.125067  0.301981         NaN         NaN  \n",
      "2022-01-13  0.029774  0.270624         NaN         NaN  \n",
      "2022-01-14  0.006258  0.387445         NaN         NaN  \n",
      "2022-01-15  0.020779  0.416362         NaN         NaN  \n",
      "2022-01-16  0.054049  0.386118         NaN         NaN  \n",
      "2022-01-17  0.088944  0.064100         NaN         NaN  \n",
      "2022-01-18  0.109434  0.125067         NaN         NaN  \n",
      "2022-01-19  0.096909  0.029774         NaN         NaN  \n",
      "2022-01-20  0.120614  0.006258         NaN         NaN  \n",
      "2022-01-21  0.479687  0.020779         NaN         NaN  \n",
      "2022-01-22  0.278020  0.054049         NaN         NaN  \n",
      "2022-01-23  0.274417  0.088944         NaN         NaN  \n",
      "2022-01-24  0.294857  0.109434         NaN         NaN  \n",
      "2022-01-25  0.237815  0.096909         NaN         NaN  \n",
      "2022-01-26  0.024464  0.120614         NaN         NaN  \n",
      "2022-01-27  0.095581  0.479687         NaN         NaN  \n",
      "2022-01-28  0.225109  0.278020         NaN         NaN  \n",
      "2022-01-29  0.097288  0.274417         NaN         NaN  \n",
      "2022-01-30  0.391824  0.294857         NaN         NaN  \n",
      "2022-01-31  0.392187  0.237815   34.826087         NaN  \n",
      "2022-02-01  0.596435  0.024464   44.717391         NaN  \n",
      "2022-02-02  0.369462  0.095581   58.812500         NaN  \n",
      "2022-02-03  0.357482  0.225109   52.604167         NaN  \n",
      "2022-02-04  0.350654  0.097288   35.173913         NaN  \n",
      "2022-02-05  0.435953  0.391824   31.729167         NaN  \n",
      "2022-02-06  0.434098  0.392187   44.562500         NaN  \n",
      "2022-02-07  0.557368  0.596435   47.739130         NaN  \n",
      "2022-02-08  0.463493  0.369462   44.416667         NaN  \n",
      "2022-02-09  0.457128  0.357482    9.041667         NaN  \n",
      "2022-02-10  0.374739  0.350654   15.739130         NaN  \n",
      "2022-02-11  0.255263  0.435953    5.270833         NaN  \n",
      "2022-02-12  0.289118  0.434098    2.687500         NaN  \n",
      "2022-02-13  0.334345  0.557368    4.282609         NaN  \n",
      "2022-02-14  0.526266  0.463493    7.937500         NaN  \n",
      "2022-02-15  0.534701  0.457128   11.770833         NaN  \n",
      "2022-02-16  0.427271  0.374739   14.021739         NaN  \n",
      "2022-02-17  0.489475  0.255263   12.645833         NaN  \n",
      "2022-02-18  0.622367  0.289118   15.250000         NaN  \n",
      "2022-02-19  0.556040  0.334345   54.695652         NaN  \n",
      "2022-02-20  0.574246  0.526266   32.541667         NaN  \n",
      "2022-02-21  0.581205  0.534701   32.145833         NaN  \n",
      "2022-02-22  0.604779  0.427271   34.391304         NaN  \n",
      "2022-02-23  0.345534  0.489475   28.125000         NaN  \n",
      "2022-02-24  0.380346  0.622367    4.687500         NaN  \n",
      "2022-02-25  0.489475  0.556040   12.500000         NaN  \n",
      "2022-02-26  0.444149  0.574246   26.729167         NaN  \n",
      "2022-02-27  0.287140  0.581205   12.687500         NaN  \n",
      "2022-02-28  0.419685  0.604779   45.043478         NaN  \n",
      "2022-03-01  0.347620  0.345534   45.083333         NaN  \n",
      "2022-03-02  0.158115  0.380346   67.520833         NaN  \n",
      "2022-03-03  0.157216  0.489475   42.586957         NaN  \n",
      "2022-03-04  0.200834  0.444149   41.270833         NaN  \n",
      "2022-03-05  0.267944  0.287140   40.520833         NaN  \n",
      "2022-03-06  0.206524  0.419685   49.891304         NaN  \n",
      "2022-03-07  0.357984  0.347620   49.687500         NaN  \n",
      "2022-03-08  0.416082  0.158115   63.229167         NaN  \n",
      "2022-03-09  0.379860  0.157216   52.916667         NaN  \n",
      "2022-03-10  0.426455  0.200834   52.217391         NaN  \n",
      "2022-03-11  0.562299  0.267944   43.166667         NaN  \n",
      "2022-03-12  0.573298  0.206524   30.041667         NaN  \n",
      "2022-03-13  0.656206  0.357984   33.760870         NaN  \n",
      "2022-03-14  0.725014  0.416082   38.729167         NaN  \n",
      "2022-03-15  0.449080  0.379860   59.812500         NaN  \n",
      "2022-03-16  0.292433  0.426455   60.739130         NaN  \n",
      "2022-03-17  0.202640  0.562299   48.937500         NaN  \n",
      "2022-03-18  0.419216  0.573298   55.770833         NaN  \n",
      "2022-03-19  0.343410  0.656206   70.369565         NaN  \n",
      "2022-03-20  0.561614  0.725014   63.083333         NaN  \n",
      "2022-03-21  0.493078  0.449080   65.083333         NaN  \n",
      "2022-03-22  0.356006  0.292433   65.847826         NaN  \n",
      "2022-03-23  0.439219  0.202640   68.437500         NaN  \n",
      "2022-03-24  0.464062  0.419216   39.958333         NaN  \n",
      "2022-03-25  0.445848  0.343410   43.782609         NaN  \n",
      "2022-03-26  0.540869  0.561614   55.770833         NaN  \n",
      "2022-03-27  0.615210  0.493078   50.791667         NaN  \n",
      "2022-03-28  0.307106  0.356006   33.543478         NaN  \n",
      "2022-03-29       NaN  0.439219   48.104167         NaN  \n",
      "2022-03-30       NaN  0.464062   40.187500         NaN  \n",
      "2022-03-31  0.391428  0.445848   19.369565         NaN  \n",
      "2022-04-01  0.432185  0.540869   19.270833         NaN  \n",
      "2022-04-02  0.482268  0.615210   24.062500         NaN  \n",
      "2022-04-03  0.611087  0.307106   31.434783         NaN  \n",
      "2022-04-04  0.505784       NaN   24.687500         NaN  \n",
      "2022-04-05  0.423882       NaN   41.326087         NaN  \n",
      "2022-04-06  0.321087  0.391428   47.708333         NaN  \n",
      "2022-04-07  0.468045  0.432185   43.729167         NaN  \n",
      "2022-04-08  0.577091  0.482268   48.847826         NaN  \n",
      "2022-04-09  0.431600  0.611087   63.770833         NaN  \n",
      "2022-04-10  0.509008  0.505784   64.979167         NaN  \n",
      "2022-04-11  0.484734  0.423882   74.086957         NaN  \n",
      "2022-04-12  0.550540  0.321087   81.645833         NaN  \n",
      "2022-04-13  0.494727  0.468045   51.333333         NaN  \n",
      "2022-04-14  0.159492  0.577091   34.125000         NaN  \n",
      "2022-04-15  0.284658  0.431600   24.260870         NaN  \n",
      "2022-04-16  0.331863  0.509008   48.052632         NaN  \n",
      "2022-04-17  0.478096  0.484734   39.725000         NaN  \n",
      "2022-04-18  0.517732  0.550540   63.695652         NaN  \n",
      "2022-04-19  0.556469  0.494727   56.166667         NaN  \n",
      "2022-04-20  0.497440  0.159492   41.108696         NaN  \n",
      "2022-04-21  0.560781  0.284658   50.250000         NaN  \n",
      "2022-04-22  0.569728  0.331863   52.979167         NaN  \n",
      "2022-04-23  0.458752  0.478096   50.978261         NaN  \n",
      "2022-04-24  0.601176  0.517732   61.416667         NaN  \n",
      "2022-04-25  0.694597  0.556469   69.583333         NaN  \n",
      "2022-04-26  0.398635  0.497440   35.736842         NaN  \n",
      "2022-04-27  0.518490  0.560781         NaN         NaN  \n",
      "2022-04-28  0.592881  0.569728         NaN         NaN  \n",
      "2022-04-29  0.587521  0.458752   45.000000         NaN  \n",
      "2022-04-30  0.384601  0.601176   49.477273         NaN  \n",
      "2022-05-01  0.583778  0.694597   54.979167         NaN  \n",
      "2022-05-02  0.517542  0.398635   69.130435         NaN  \n",
      "2022-05-03  0.532335  0.518490   57.562500         NaN  \n",
      "2022-05-04  0.528368  0.592881   48.565217         NaN  \n",
      "2022-05-05  0.456476  0.587521   37.272727         NaN  \n",
      "2022-05-06  0.318035  0.384601   53.416667         NaN  \n",
      "2022-05-07  0.409040  0.583778   65.395833         NaN  \n",
      "2022-05-08  0.392187  0.517542   49.413043         NaN  \n",
      "2022-05-09  0.543713  0.532335   57.916667         NaN  \n",
      "2022-05-10  0.573290  0.528368   55.250000         NaN  \n",
      "2022-05-11  0.528921  0.456476   62.479167         NaN  \n",
      "2022-05-12  0.585625  0.318035   56.347826         NaN  \n",
      "2022-05-13  0.498685  0.409040   19.520833         NaN  \n",
      "2022-05-14  0.535559  0.392187   33.270833         NaN  \n",
      "2022-05-15  0.652001  0.543713   38.456522         NaN  \n",
      "2022-05-16  0.733779  0.573290   54.520833         NaN  \n",
      "2022-05-17  0.543144  0.528921   58.875000         NaN  \n",
      "2022-05-18  0.516594  0.585625   63.130435         NaN  \n",
      "2022-05-19  0.673225  0.498685   56.645833         NaN  \n",
      "2022-05-20  0.515835  0.535559   63.604167         NaN  \n",
      "2022-05-21  0.422254  0.652001   64.586957         NaN  \n",
      "2022-05-22  0.592287  0.733779   52.395833         NaN  \n",
      "2022-05-23  0.653518  0.543144   68.041667         NaN  \n",
      "2022-05-24  0.437339  0.516594   78.304348         NaN  \n",
      "2022-05-25  0.486416  0.673225   45.791667         NaN  \n",
      "2022-05-26  0.489664  0.515835   58.958333         NaN  \n",
      "2022-05-27  0.498957  0.422254   67.130435         NaN  \n",
      "2022-05-28  0.550928  0.592287   66.541667         NaN  \n",
      "2022-05-29  0.527973  0.653518   44.250000         NaN  \n",
      "2022-05-30  0.502181  0.437339   66.130435         NaN  \n",
      "2022-05-31  0.457326  0.486416   58.854167         NaN  \n",
      "2022-06-01  0.461218  0.489664   60.479167         NaN  \n",
      "2022-06-02  0.526266  0.498957   60.043478         NaN  \n",
      "2022-06-03  0.664897  0.550928   52.145833         NaN  \n",
      "2022-06-04  0.777315  0.527973   36.937500         NaN  \n",
      "2022-06-05  0.801631  0.502181   46.934783         NaN  \n",
      "2022-06-06  0.415513  0.457326   45.083333         NaN  \n",
      "2022-06-07  0.507788  0.461218   61.729167         NaN  \n",
      "2022-06-08  0.357671  0.526266   64.978261         NaN  \n",
      "2022-06-09  0.271383  0.664897   60.104167         NaN  \n",
      "2022-06-10  0.422299  0.777315   66.333333         NaN  \n",
      "2022-06-11  0.410203  0.801631   56.782609         NaN  \n",
      "2022-06-12  0.478855  0.415513   60.833333         NaN  \n",
      "2022-06-13  0.549543  0.507788   73.625000         NaN  \n",
      "2022-06-14  0.547696  0.357671   82.608696         NaN  \n",
      "2022-06-15  0.646880  0.271383   61.666667         NaN  \n",
      "2022-06-16  0.851326  0.422299   58.750000         NaN  \n",
      "2022-06-17  0.801890  0.410203   75.956522         NaN  \n",
      "2022-06-18  0.830944  0.478855   58.666667         NaN  \n",
      "2022-06-19  0.935826  0.549543   48.386364         NaN  \n",
      "2022-06-20  0.520956  0.547696   67.065217         NaN  \n",
      "2022-06-21  0.530059  0.646880   73.791667         NaN  \n",
      "2022-06-22  0.441494  0.851326   50.043478         NaN  \n",
      "2022-06-23  0.699033  0.801890   55.434783         NaN  \n",
      "2022-06-24  0.655604  0.830944   55.791667         NaN  \n",
      "2022-06-25  0.487801  0.935826   56.812500         NaN  \n",
      "2022-06-26  0.384032  0.520956   62.521739         NaN  \n",
      "2022-06-27  0.393324  0.530059   60.000000         NaN  \n",
      "2022-06-28  0.272496  0.441494   57.166667         NaN  \n",
      "2022-06-29  0.494216  0.699033   52.239130         NaN  \n",
      "2022-06-30  0.602883  0.655604   52.666667         NaN  \n",
      "2022-07-01  0.319989  0.487801   59.812500         NaN  \n",
      "2022-07-02  0.366016  0.384032   75.041667         NaN  \n",
      "2022-07-03  0.512611  0.393324   87.391304         NaN  \n",
      "2022-07-04  0.482656  0.272496   90.062500         NaN  \n",
      "2022-07-05  0.461597  0.494216   47.645833         NaN  \n",
      "2022-07-06  0.491940  0.602883   57.782609         NaN  \n",
      "2022-07-07  0.543606  0.319989   41.291667         NaN  \n",
      "2022-07-08  0.411910  0.366016   31.812500         NaN  \n",
      "2022-07-09  0.515835  0.512611   48.391304         NaN  \n",
      "2022-07-10  0.534701  0.482656   47.062500         NaN  \n",
      "2022-07-11  0.441874  0.461597   54.604167         NaN  \n",
      "2022-07-12  0.453063  0.491940   62.369565         NaN  \n",
      "2022-07-13  0.500862  0.543606   62.166667         NaN  \n",
      "2022-07-14  0.681775  0.411910   73.062500         NaN  \n",
      "2022-07-15  0.499716  0.515835   95.521739         NaN  \n",
      "2022-07-16  0.476521  0.534701   90.090909         NaN  \n",
      "2022-07-17  0.537076  0.441874   93.282609         NaN  \n",
      "2022-07-18  0.608762  0.453063  104.804348         NaN  \n",
      "2022-07-19  0.851749  0.500862   59.229167         NaN  \n",
      "2022-07-20  0.984259  0.681775   60.229167         NaN  \n",
      "2022-07-21  0.715342  0.499716   50.500000         NaN  \n",
      "2022-07-22  0.433777  0.476521   78.791667         NaN  \n",
      "2022-07-23  0.438839  0.537076   74.020833         NaN  \n",
      "2022-07-24  0.609141  0.608762   55.586957         NaN  \n",
      "2022-07-25  0.702314  0.851749   44.187500         NaN  \n",
      "2022-07-26  0.495543  0.984259   45.208333         NaN  \n",
      "2022-07-27  0.451166  0.715342   31.934783         NaN  \n",
      "2022-07-28  0.500070  0.433777   56.291667         NaN  \n",
      "2022-07-29  0.620140  0.438839   68.229167         NaN  \n",
      "2022-07-30  0.772046  0.609141   37.152174         NaN  \n",
      "2022-07-31  0.674214  0.702314   42.208333         NaN  \n",
      "2022-08-01  0.411720  0.495543   58.312500         NaN  \n",
      "2022-08-02  0.506353  0.451166   55.021739         NaN  \n",
      "2022-08-03  0.486811  0.500070   52.708333         NaN  \n",
      "2022-08-04  0.418737  0.620140   56.041667         NaN  \n",
      "2022-08-05  0.351982  0.772046   61.717391         NaN  \n",
      "2022-08-06  0.494250  0.674214   47.250000         NaN  \n",
      "2022-08-07  0.486630  0.411720   58.666667         NaN  \n",
      "2022-08-08  0.648777  0.506353   60.739130         NaN  \n",
      "2022-08-09  0.622795  0.486811   50.541667         NaN  \n",
      "2022-08-10  0.619398  0.418737   51.770833         NaN  \n",
      "2022-08-11  0.811682  0.351982   57.021739         NaN  \n",
      "2022-08-12  0.924142  0.494250   76.895833         NaN  \n",
      "2022-08-13  0.948689  0.486630   56.895833         NaN  \n",
      "2022-08-14  0.867438  0.648777   54.347826         NaN  \n",
      "2022-08-15  0.898540  0.622795   61.000000         NaN  \n",
      "2022-08-16  0.821247  0.619398   68.875000         NaN  \n",
      "2022-08-17  0.915608  0.811682   95.568182         NaN  \n",
      "2022-08-18  0.622795  0.924142  110.125000         NaN  \n",
      "2022-08-19  0.715177  0.948689   80.583333         NaN  \n",
      "2022-08-20  0.345344  0.867438   49.652174         NaN  \n",
      "2022-08-21  0.438270  0.898540   50.208333         NaN  \n",
      "2022-08-22  0.416006  0.821247   68.916667         NaN  \n",
      "2022-08-23  0.869748  0.915608   79.152174         NaN  \n",
      "2022-08-24  0.464252  0.622795   56.437500         NaN  \n",
      "2022-08-25  0.660914  0.715177   51.562500         NaN  \n",
      "2022-08-26  0.799166  0.345344   56.934783         NaN  \n",
      "2022-08-27  0.569926  0.438270   70.125000         NaN  \n",
      "2022-08-28  0.515266  0.416006   86.812500         NaN  \n",
      "2022-08-29  0.610468  0.869748   76.065217         NaN  \n",
      "2022-08-30  0.568145  0.464252   47.229167         NaN  \n",
      "2022-08-31  0.585815  0.660914   57.625000         NaN  \n",
      "2022-09-01  0.637398  0.799166   55.478261         NaN  \n",
      "2022-09-02  0.658185  0.569926   48.000000         NaN  \n",
      "2022-09-03  0.610279  0.515266   40.666667         NaN  \n",
      "2022-09-04  0.628295  0.610468   56.295455         NaN  \n",
      "2022-09-05  0.565333  0.568145   55.458333         NaN  \n",
      "2022-09-06  0.672235  0.585815   73.270833         NaN  \n",
      "2022-09-07  0.520939  0.637398   70.416667         NaN  \n",
      "2022-09-08  0.504457  0.658185   70.043478         NaN  \n",
      "2022-09-09  0.413196  0.610279   91.166667         NaN  \n",
      "2022-09-10  0.422340  0.628295  103.520833         NaN  \n",
      "2022-09-11  0.414565  0.565333  106.217391         NaN  \n",
      "2022-09-12  0.432391  0.672235   97.291667         NaN  \n",
      "2022-09-13  0.399393  0.520939  100.708333         NaN  \n",
      "2022-09-14  0.294519  0.504457   92.217391         NaN  \n",
      "2022-09-15  0.211347  0.413196  102.583333         NaN  \n",
      "2022-09-16  0.282761  0.422340   70.416667         NaN  \n",
      "2022-09-17  0.374739  0.414565   80.565217         NaN  \n",
      "2022-09-18  0.301981  0.432391   39.937500         NaN  \n",
      "2022-09-19  0.324483  0.399393   50.145833         NaN  \n",
      "2022-09-20  0.311018  0.294519   47.700000         NaN  \n",
      "2022-09-21  0.286942  0.211347   97.545455         NaN  \n",
      "2022-09-22  0.230988  0.282761   53.000000         NaN  \n",
      "2022-09-23  0.280106  0.374739   74.604167         NaN  \n",
      "2022-09-24  0.280807  0.301981   89.791667         NaN  \n",
      "2022-09-25  0.394083  0.324483   64.608696         NaN  \n",
      "2022-09-26  0.342310  0.311018   58.604167         NaN  \n",
      "2022-09-27  0.314844  0.286942   69.062500         NaN  \n",
      "2022-09-28  0.312536  0.230988   64.413043         NaN  \n",
      "2022-09-29  0.251280  0.280106   66.354167         NaN  \n",
      "2022-09-30  0.189184  0.280807   72.020833         NaN  \n",
      "2022-10-01  0.266831  0.394083   74.304348         NaN  \n",
      "2022-10-02  0.412289  0.342310   69.041667         NaN  \n",
      "2022-10-03  0.331665  0.314844   71.020833         NaN  \n",
      "2022-10-04  0.149630  0.312536   64.104167         NaN  \n",
      "2022-10-05  0.257159  0.251280   75.847826         NaN  \n",
      "2022-10-06  0.411585  0.189184   59.227273         NaN  \n",
      "2022-10-07  0.350085  0.266831   57.416667         NaN  \n",
      "2022-10-08  0.285606  0.412289   47.391304         NaN  \n",
      "2022-10-09  0.358484  0.331665   48.395833         NaN  \n",
      "2022-10-10  0.045515  0.149630   47.541667         NaN  \n",
      "2022-10-11  0.359568  0.257159   49.500000         NaN  \n",
      "2022-10-12  0.034895  0.411585   45.875000         NaN  \n",
      "2022-10-13  0.149992  0.350085   34.354167         NaN  \n",
      "2022-10-14  0.179405  0.285606   25.217391         NaN  \n",
      "2022-10-15  0.194725  0.358484   33.062500         NaN  \n",
      "2022-10-16  0.320121  0.045515   43.166667         NaN  \n",
      "2022-10-17  0.325242  0.359568   35.173913         NaN  \n",
      "2022-10-18  0.177508  0.034895   37.645833         NaN  \n",
      "2022-10-19  0.225109  0.149992   36.166667         NaN  \n",
      "2022-10-20  0.190594  0.179405   33.521739         NaN  \n",
      "2022-10-21  0.169395  0.194725   27.375000         NaN  \n",
      "2022-10-22  0.356913  0.320121   32.770833         NaN  \n",
      "2022-10-23  0.333965  0.325242   32.847826         NaN  \n",
      "2022-10-24  0.321639  0.177508   45.291667         NaN  \n",
      "2022-10-25  0.452548  0.225109   39.604167         NaN  \n",
      "2022-10-26  0.355016  0.190594   36.586957         NaN  \n",
      "2022-10-27       NaN  0.169395   36.333333         NaN  \n",
      "2022-10-28       NaN  0.356913   29.604167         NaN  \n",
      "2022-10-29       NaN  0.333965   22.782609         NaN  \n",
      "2022-10-30       NaN  0.321639   31.312500         NaN  \n",
      "2022-10-31       NaN  0.452548   47.291667         NaN  \n",
      "2022-11-01       NaN  0.355016   38.434783         NaN  \n",
      "2022-11-02       NaN       NaN   18.437500         NaN  \n",
      "2022-11-03       NaN       NaN   30.250000         NaN  \n",
      "2022-11-04       NaN       NaN   47.214286         NaN  \n",
      "2022-11-05       NaN       NaN   40.458333         NaN  \n",
      "2022-11-06       NaN       NaN   33.375000         NaN  \n",
      "2022-11-07       NaN       NaN   41.380952         NaN  \n",
      "2022-11-08  0.458790       NaN    7.000000         NaN  \n",
      "2022-11-09  0.416461       NaN   41.500000         NaN  \n",
      "2022-11-10  0.404893       NaN    5.833333         NaN  \n",
      "2022-11-11  0.283493       NaN   18.477273         NaN  \n",
      "2022-11-12  0.246918       NaN   21.708333         NaN  \n",
      "2022-11-13  0.055187       NaN   23.391304         NaN  \n",
      "2022-11-14  0.043239  0.458790   37.166667         NaN  \n",
      "2022-11-15  0.032652  0.416461   37.729167         NaN  \n",
      "2022-11-16  0.296226  0.404893   21.500000         NaN  \n",
      "2022-11-17  0.331500  0.283493   26.729167         NaN  \n",
      "2022-11-18  0.469001  0.246918   22.937500         NaN  \n",
      "2022-11-19  0.253935  0.055187   20.608696         NaN  \n",
      "2022-11-20  0.038498  0.043239   41.208333         NaN  \n",
      "2022-11-21  0.018206  0.032652   38.687500         NaN  \n",
      "2022-11-22  0.315803  0.296226   37.333333         NaN  \n",
      "2022-11-23  0.389342  0.331500   51.714286         NaN  \n",
      "2022-11-24  0.317593  0.469001   41.000000         NaN  \n",
      "2022-11-25  0.391668  0.253935         NaN         NaN  \n",
      "2022-11-26  0.239712  0.038498         NaN         NaN  \n",
      "2022-11-27  0.177904  0.018206         NaN         NaN  \n",
      "2022-11-28  0.275934  0.315803         NaN         NaN  \n",
      "2022-11-29  0.135976  0.389342         NaN         NaN  \n",
      "2022-11-30  0.041874  0.317593         NaN         NaN  \n",
      "2022-12-01       NaN  0.391668         NaN         NaN  \n",
      "2022-12-02  0.061970  0.239712         NaN         NaN  \n",
      "2022-12-03  0.095581  0.177904         NaN         NaN  \n",
      "2022-12-04  0.076237  0.275934         NaN         NaN  \n",
      "2022-12-05  0.043998  0.135976         NaN         NaN  \n",
      "2022-12-06  0.002968  0.041874         NaN         NaN  \n",
      "2022-12-07  0.068083       NaN   52.400000         NaN  \n",
      "2022-12-08  0.134496  0.061970   47.750000         NaN  \n",
      "2022-12-09  0.135555  0.095581   46.479167         NaN  \n",
      "2022-12-10  0.080789  0.076237   33.142857         NaN  \n",
      "2022-12-11  0.155699  0.043998   29.125000         NaN  \n",
      "2022-12-12  0.248155  0.002968    8.062500         NaN  \n",
      "2022-12-13  0.096529  0.068083    6.750000         NaN  \n",
      "2022-12-14  0.015930  0.134496    5.586957         NaN  \n",
      "2022-12-15  0.015238  0.135555   34.541667         NaN  \n",
      "2022-12-16  0.000000  0.080789   38.416667         NaN  \n",
      "2022-12-17  0.031291  0.155699   53.521739         NaN  \n",
      "2022-12-18  0.010290  0.248155   29.895833         NaN  \n",
      "2022-12-19  0.104305  0.096529    6.229167         NaN  \n",
      "2022-12-20  0.279158  0.015930    4.000000         NaN  \n",
      "2022-12-21  0.278630  0.015238   36.692308         NaN  \n",
      "2022-12-22  0.238195  0.000000   44.770833         NaN  \n",
      "2022-12-23  0.264366  0.031291   36.888889         NaN  \n",
      "2022-12-24  0.366890  0.010290   45.026316         NaN  \n",
      "2022-12-25  0.385359  0.104305   28.333333         NaN  \n",
      "2022-12-26  0.254314  0.279158   21.543478         NaN  \n",
      "2022-12-27  0.405280  0.278630   32.312500         NaN  \n",
      "2022-12-28  0.366584  0.238195   16.937500         NaN  \n",
      "2022-12-29  0.437322  0.264366    6.600000         NaN  \n",
      "2022-12-30  0.483447  0.366890         NaN         NaN  \n",
      "2022-12-31  0.382118  0.385359    8.807692         NaN  \n",
      "2023-01-01       NaN  0.254314   12.500000   34.826087  \n",
      "2023-01-02  0.432805  0.405280   10.375000   44.717391  \n",
      "2023-01-03  0.419496  0.366584    6.833333   58.812500  \n",
      "2023-01-04  0.361654  0.437322    2.326087   52.604167  \n",
      "2023-01-05  0.479975  0.483447    9.479167   35.173913  \n",
      "2023-01-06  0.405272  0.382118   16.775000   31.729167  \n",
      "2023-01-07  0.378532       NaN   16.891304   44.562500  \n",
      "2023-01-08  0.449410  0.432805   10.875000   47.739130  \n",
      "2023-01-09  0.574815  0.419496   19.104167   44.416667  \n",
      "2023-01-10  0.476200  0.361654   29.260870    9.041667  \n",
      "2023-01-11  0.360953  0.479975   12.604167   15.739130  \n",
      "2023-01-12  0.467665  0.405272    3.750000    5.270833  \n",
      "2023-01-13  0.476958  0.378532    3.673913    2.687500  \n",
      "2023-01-14  0.533662  0.449410    2.000000    4.282609  \n",
      "2023-01-15  0.485822  0.574815    5.437500    7.937500  \n",
      "2023-01-16  0.567609  0.476200    3.130435   11.770833  \n",
      "2023-01-17  0.488716  0.360953   13.458333   14.021739  \n",
      "2023-01-18  0.188590  0.467665   32.666667   12.645833  \n",
      "2023-01-19  0.118528  0.476958   32.608696   15.250000  \n",
      "2023-01-20  0.181680  0.533662   28.166667   54.695652  \n",
      "2023-01-21  0.207983  0.485822   31.041667   32.541667  \n",
      "2023-01-22  0.150768  0.567609   42.304348   32.145833  \n",
      "2023-01-23  0.260762  0.488716   44.333333   34.391304  \n",
      "2023-01-24  0.106069  0.188590   29.937500   28.125000  \n",
      "2023-01-25  0.185663  0.118528   46.521739    4.687500  \n",
      "2023-01-26  0.088944  0.181680   42.270833   12.500000  \n",
      "2023-01-27  0.215701  0.207983   50.041667   26.729167  \n",
      "2023-01-28  0.376825  0.150768   55.108696   12.687500  \n",
      "2023-01-29  0.354258  0.260762   43.977273   45.043478  \n",
      "2023-01-30  0.165635  0.106069         NaN   45.083333  \n",
      "2023-01-31  0.383463  0.185663   49.545455   67.520833  \n",
      "2023-02-01  0.215437  0.088944   48.083333   42.586957  \n",
      "2023-02-02  0.437150  0.215701   41.729167   41.270833  \n",
      "2023-02-03  0.451735  0.376825   54.727273   40.520833  \n",
      "2023-02-04  0.458373  0.354258   46.520833   49.891304  \n",
      "2023-02-05  0.220648  0.165635   43.583333   49.687500  \n",
      "2023-02-06  0.468045  0.383463   51.369565   63.229167  \n",
      "2023-02-07  0.193628  0.215437   65.145833   52.916667  \n",
      "2023-02-08  0.083510  0.437150   54.312500   52.217391  \n",
      "2023-02-09  0.110753  0.451735   41.652174   43.166667  \n",
      "2023-02-10  0.135027  0.458373   53.375000   30.041667  \n",
      "2023-02-11  0.120713  0.220648   54.395833   33.760870  \n",
      "2023-02-12  0.238005  0.468045   60.625000   38.729167  \n",
      "2023-02-13  0.316518  0.193628   55.369565   59.812500  \n",
      "2023-02-14  0.098154  0.083510   64.354167   60.739130  \n",
      "2023-02-15  0.071876  0.110753   55.687500   48.937500  \n",
      "2023-02-16  0.113977  0.135027   22.717391   55.770833  \n",
      "2023-02-17  0.231928  0.120713   15.020833   70.369565  \n",
      "2023-02-18  0.464062  0.238005   21.958333   63.083333  \n",
      "2023-02-19  0.533852  0.316518   24.847826   65.083333  \n",
      "2023-02-20  0.435756  0.098154   18.562500   65.847826  \n",
      "2023-02-21  0.430116  0.071876   30.645833   68.437500  \n",
      "2023-02-22       NaN  0.113977   13.652174   39.958333  \n",
      "2023-02-23       NaN  0.231928   22.395833   43.782609  \n",
      "2023-02-24       NaN  0.464062   11.770833   55.770833  \n",
      "2023-02-25  0.492699  0.533852   25.695652   50.791667  \n",
      "2023-02-26  0.389437  0.435756   43.395833   33.543478  \n",
      "2023-02-27       NaN  0.430116   40.916667   48.104167  \n",
      "2023-02-28  0.421582       NaN   20.195652   40.187500  \n",
      "2023-03-01  0.309294       NaN   44.125000   19.369565  \n",
      "2023-03-02  0.333086       NaN   25.666667   19.270833  \n",
      "2023-03-03  0.265174  0.492699   50.022727   24.062500  \n",
      "2023-03-04  0.341569  0.389437   51.625000   31.434783  \n",
      "2023-03-05  0.586573       NaN   52.354167   24.687500  \n",
      "2023-03-06  0.470510  0.421582   26.239130   41.326087  \n",
      "2023-03-07  0.406600  0.309294   53.416667   47.708333  \n",
      "2023-03-08  0.446615  0.333086   23.270833   43.729167  \n",
      "2023-03-09  0.282003  0.265174   11.173913   48.847826  \n",
      "2023-03-10  0.220450  0.341569   14.166667   63.770833  \n",
      "2023-03-11  0.479992  0.586573   16.833333   64.979167  \n",
      "2023-03-12  0.401100  0.470510   15.260870   74.086957  \n",
      "2023-03-13  0.533118  0.406600   28.145833   81.645833  \n",
      "2023-03-14  0.420254  0.446615   36.770833   51.333333  \n",
      "2023-03-15  0.531007  0.282003   12.782609   34.125000  \n",
      "2023-03-16  0.459305  0.220450    9.895833   24.260870  \n",
      "2023-03-17  0.561350  0.479992   14.520833   48.052632  \n",
      "2023-03-18  0.480751  0.401100   27.478261   39.725000  \n",
      "2023-03-19  0.531766  0.533118   52.979167   63.695652  \n",
      "2023-03-20  0.461283  0.420254   60.645833   56.166667  \n",
      "2023-03-21  0.420064  0.531007   49.869565   41.108696  \n",
      "2023-03-22  0.419387  0.459305   49.250000   50.250000  \n",
      "2023-03-23  0.517569  0.561350         NaN   52.979167  \n",
      "2023-03-24  0.622416  0.480751         NaN   50.978261  \n",
      "2023-03-25  0.607624  0.531766         NaN   61.416667  \n",
      "2023-03-26  0.653139  0.461283   56.125000   69.583333  \n",
      "2023-03-27  0.568557  0.420064   44.781250   35.736842  \n",
      "2023-03-28  0.616628  0.419387         NaN         NaN  \n",
      "2023-03-29  0.441494  0.517569   48.312500         NaN  \n",
      "2023-03-30  0.401669  0.622416   35.977273   45.000000  \n",
      "2023-03-31  0.602658  0.607624   38.590909   49.477273  \n",
      "2023-04-01  0.577660  0.653139   31.130435   54.979167  \n",
      "2023-04-02  0.402996  0.568557   39.522727   69.130435  \n",
      "2023-04-03  0.448816  0.616628   66.437500   57.562500  \n",
      "2023-04-04  0.417030  0.441494   53.687500   48.565217  \n",
      "2023-04-05  0.489285  0.401669   46.666667   37.272727  \n",
      "2023-04-06  0.426133  0.602658   51.062500   53.416667  \n",
      "2023-04-07  0.431006  0.577660   32.979167   65.395833  \n",
      "2023-04-08  0.555471  0.402996   26.217391   49.413043  \n",
      "2023-04-09  0.526456  0.448816   54.729167   57.916667  \n",
      "2023-04-10  0.453962  0.417030   46.062500   55.250000  \n",
      "2023-04-11  0.575574  0.489285   60.565217   62.479167  \n",
      "2023-04-12  0.637019  0.426133   48.166667   56.347826  \n",
      "2023-04-13  0.647103  0.431006   60.333333   19.520833  \n",
      "2023-04-14  0.641760  0.555471   52.456522   33.270833  \n",
      "2023-04-15  0.484544  0.526456   63.666667   38.456522  \n",
      "2023-04-16  0.562801  0.453962   54.812500   54.520833  \n",
      "2023-04-17  0.481699  0.575574   60.416667   58.875000  \n",
      "2023-04-18  0.551489  0.637019   52.673913   63.130435  \n",
      "2023-04-19  0.465637  0.647103   48.145833   56.645833  \n",
      "2023-04-20  0.586383  0.641760   48.071429   63.604167  \n",
      "2023-04-21  0.633795  0.484544   58.857143   64.586957  \n",
      "2023-04-22  0.529556  0.562801   70.375000   52.395833  \n",
      "2023-04-23  0.204438  0.481699   68.750000   68.041667  \n",
      "2023-04-24  0.559264  0.551489   73.750000   78.304348  \n",
      "2023-04-25  0.680448  0.465637   64.458333   45.791667  \n",
      "2023-04-26  0.659966  0.586383   69.739130   58.958333  \n",
      "2023-04-27  0.512042  0.633795   50.500000   67.130435  \n",
      "2023-04-28  0.601786  0.529556   46.125000   66.541667  \n",
      "2023-04-29  0.324294  0.204438   68.204545   44.250000  \n",
      "2023-04-30  0.636260  0.559264   65.458333   66.130435  \n",
      "2023-05-01  0.634834  0.680448   46.270833   58.854167  \n",
      "2023-05-02  0.541248  0.659966   51.304348   60.479167  \n",
      "2023-05-03  0.560212  0.512042   47.812500   60.043478  \n",
      "2023-05-04  0.592683  0.601786   55.750000   52.145833  \n",
      "2023-05-05  0.598521  0.324294   48.812500   36.937500  \n",
      "2023-05-06  0.529111  0.636260   49.347826   46.934783  \n",
      "2023-05-07  0.472365  0.634834   63.020833   45.083333  \n",
      "2023-05-08  0.333965  0.541248   59.833333   61.729167  \n",
      "2023-05-09  0.283520  0.560212   51.869565   64.978261  \n",
      "2023-05-10  0.283182  0.592683   65.229167   60.104167  \n",
      "2023-05-11  0.366395  0.598521   71.979167   66.333333  \n",
      "2023-05-12  0.443356  0.529111   73.086957   56.782609  \n",
      "2023-05-13  0.359370  0.472365   72.500000   60.833333  \n",
      "2023-05-14  0.682344  0.333965   55.229167   73.625000  \n",
      "2023-05-15  0.619002  0.283520   63.826087   82.608696  \n",
      "2023-05-16  0.491354  0.283182   54.916667   61.666667  \n",
      "2023-05-17  0.549023  0.366395   62.583333   58.750000  \n",
      "2023-05-18  0.533283  0.443356   53.152174   75.956522  \n",
      "2023-05-19  0.616537  0.359370   66.416667   58.666667  \n",
      "2023-05-20  0.658185  0.682344   71.625000   48.386364  \n",
      "2023-05-21  0.692775  0.619002   60.173913   67.065217  \n",
      "2023-05-22  0.605158  0.491354   24.458333   73.791667  \n",
      "2023-05-23  0.518672  0.549023   63.437500   50.043478  \n",
      "2023-05-24  0.631709  0.533283   76.750000   55.434783  \n",
      "2023-05-25  0.523628  0.616537   74.500000   55.791667  \n",
      "2023-05-26  0.613462  0.658185   58.250000   56.812500  \n",
      "2023-05-27  0.680637  0.692775   68.108696   62.521739  \n",
      "2023-05-28  0.750427  0.605158   37.625000   60.000000  \n",
      "2023-05-29  0.740310  0.518672   71.895833   57.166667  \n",
      "2023-05-30  0.668690  0.631709   71.739130   52.239130  \n",
      "2023-05-31  0.659776  0.523628   61.458333   52.666667  \n",
      "2023-06-01  0.655019  0.613462   63.541667   59.812500  \n",
      "2023-06-02  0.609141  0.680637   67.108696   75.041667  \n",
      "2023-06-03  0.721601  0.750427   67.750000   87.391304  \n",
      "2023-06-04  0.712407  0.740310   60.125000   90.062500  \n",
      "2023-06-05  0.751185  0.668690   53.891304   47.645833  \n",
      "2023-06-06  0.676465  0.659776   38.687500   57.782609  \n",
      "2023-06-07  0.738529  0.655019   33.145833   41.291667  \n",
      "2023-06-08  0.698464  0.609141   33.108696   31.812500  \n",
      "2023-06-09  0.783235  0.721601   42.250000   48.391304  \n",
      "2023-06-10  0.904446  0.712407   50.704545   47.062500  \n",
      "2023-06-11  0.979708  0.751185   41.478261   54.604167  \n",
      "2023-06-12  0.877679  0.676465   76.958333   62.369565  \n",
      "2023-06-13  0.900403  0.738529   70.000000   62.166667  \n",
      "2023-06-14  1.000000  0.698464   55.977273   73.062500  \n",
      "2023-06-15  0.960743  0.783235   62.312500   95.521739  \n",
      "2023-06-16  0.837078  0.904446   60.583333   90.090909  \n",
      "2023-06-17  0.979898  0.979708   69.729167   93.282609  \n",
      "2023-06-18  0.966622  0.877679   74.304348  104.804348  \n",
      "2023-06-19  0.881801  0.900403   78.104167   59.229167  \n",
      "2023-06-20  0.657798  1.000000   68.479167   60.229167  \n",
      "2023-06-21  0.604161  0.960743   58.978261   50.500000  \n",
      "2023-06-22  0.558385  0.837078   71.395833   78.791667  \n",
      "2023-06-23  0.450358  0.979898   59.522727   74.020833  \n",
      "2023-06-24  0.599411  0.966622   69.391304   55.586957  \n",
      "2023-06-25  0.627908  0.881801   76.770833   44.187500  \n",
      "2023-06-26  0.861559  0.657798   84.437500   45.208333  \n",
      "2023-06-27  0.642708  0.604161   83.326087   31.934783  \n",
      "2023-06-28  0.554490  0.558385   75.458333   56.291667  \n",
      "2023-06-29  0.462166  0.450358   74.479167   68.229167  \n",
      "2023-06-30  0.451546  0.599411   73.956522   37.152174  \n",
      "2023-07-01  0.528764  0.627908   68.916667   42.208333  \n",
      "2023-07-02  0.355775  0.861559   81.270833   58.312500  \n",
      "2023-07-03  0.632657  0.642708   80.260870   55.021739  \n",
      "2023-07-04  0.561416  0.554490   84.520833   52.708333  \n",
      "2023-07-05  0.518474  0.462166   76.312500   56.041667  \n",
      "2023-07-06  0.521714  0.451546   83.130435   61.717391  \n",
      "2023-07-07  0.560823  0.528764   78.729167   47.250000  \n",
      "2023-07-08  0.677413  0.355775   88.041667   58.666667  \n",
      "2023-07-09  0.710980  0.632657  101.357143   60.739130  \n",
      "2023-07-10  0.606140  0.561416  109.625000   50.541667  \n",
      "2023-07-11  0.596814  0.518474   98.416667   51.770833  \n",
      "2023-07-12  0.513180  0.521714  100.913043   57.021739  \n",
      "2023-07-13  0.513329  0.560823  111.854167   76.895833  \n",
      "2023-07-14  0.527593  0.677413  107.541667   56.895833  \n",
      "2023-07-15  0.637588  0.710980   93.956522   54.347826  \n",
      "2023-07-16  0.474542  0.606140  109.645833   61.000000  \n",
      "2023-07-17  0.457994  0.596814  108.187500   68.875000  \n",
      "2023-07-18  0.482458  0.513180   98.869565   95.568182  \n",
      "2023-07-19  0.546772  0.513329   74.261905  110.125000  \n",
      "2023-07-20  0.457425  0.527593   68.369565   80.583333  \n",
      "2023-07-21  0.389911  0.637588   63.340909   49.652174  \n",
      "2023-07-22  0.421903  0.474542   51.473684   50.208333  \n",
      "2023-07-23  0.511853  0.457994   67.847826   68.916667  \n",
      "2023-07-24  0.406410  0.482458   70.978261   79.152174  \n",
      "2023-07-25  0.383908  0.546772   96.645833   56.437500  \n",
      "2023-07-26  0.448891  0.457425   72.604167   51.562500  \n",
      "2023-07-27  0.531955  0.389911   62.913043   56.934783  \n",
      "2023-07-28  0.296836  0.421903   52.770833   70.125000  \n",
      "2023-07-29  0.285606  0.511853   51.604167   86.812500  \n",
      "2023-07-30  0.393135  0.406410   60.086957   76.065217  \n",
      "2023-07-31  0.464054  0.383908   41.083333   47.229167  \n",
      "2023-08-01  0.332448  0.448891   71.500000   57.625000  \n",
      "2023-08-02  0.448891  0.531955   63.673913   55.478261  \n",
      "2023-08-03  0.430215  0.296836   58.956522   48.000000  \n",
      "2023-08-04  0.426702  0.285606   59.312500   40.666667  \n",
      "2023-08-05  0.396548  0.393135   63.608696   56.295455  \n",
      "2023-08-06  0.391997  0.464054   76.416667   55.458333  \n",
      "2023-08-07  0.491957  0.332448   80.104167   73.270833  \n",
      "2023-08-08  0.476768  0.448891   68.586957   70.416667  \n",
      "2023-08-09  0.384411  0.430215   67.562500   70.043478  \n",
      "2023-08-10  0.471574  0.426702   58.375000   91.166667  \n",
      "2023-08-11  0.534041  0.396548   58.391304  103.520833  \n",
      "2023-08-12  0.544472  0.391997   59.958333  106.217391  \n",
      "2023-08-13  0.447233  0.491957   72.041667   97.291667  \n",
      "2023-08-14  0.483785  0.476768   54.130435  100.708333  \n",
      "2023-08-15  0.525507  0.384411   52.312500   92.217391  \n",
      "2023-08-16  0.528368  0.471574   55.000000  102.583333  \n",
      "2023-08-17  0.559264  0.534041   62.065217   70.416667  \n",
      "2023-08-18  0.424616  0.544472   52.250000   80.565217  \n",
      "2023-08-19  0.461283  0.447233   44.833333   39.937500  \n",
      "2023-08-20  0.515266  0.483785   48.347826   50.145833  \n",
      "2023-08-21  0.474113  0.525507   58.229167   47.700000  \n",
      "2023-08-22  0.479885  0.528368   46.645833   97.545455  \n",
      "2023-08-23  0.423668  0.559264   44.173913   53.000000  \n",
      "2023-08-24  0.510525  0.424616   51.312500   74.604167  \n",
      "2023-08-25  0.410623  0.461283   60.437500   89.791667  \n",
      "2023-08-26  0.324863  0.515266   34.608696   64.608696  \n",
      "2023-08-27  0.460080  0.474113   33.375000   58.604167  \n",
      "2023-08-28  0.455149  0.479885   45.187500   69.062500  \n",
      "2023-08-29  0.421771  0.423668   52.978261   64.413043  \n",
      "2023-08-30  0.378532  0.510525   38.520833   66.354167  \n",
      "2023-08-31  0.419331  0.410623   51.312500   72.020833  \n",
      "2023-09-01  0.421202  0.324863   49.260870   74.304348  \n",
      "2023-09-02  0.277072  0.460080   48.875000   69.041667  \n",
      "2023-09-03  0.295253  0.455149   45.562500   71.020833  \n",
      "2023-09-04  0.468424  0.421771   45.062500   64.104167  \n",
      "2023-09-05  0.512991  0.378532   56.043478   75.847826  \n",
      "2023-09-06  0.523025  0.419331   54.375000   59.227273  \n",
      "2023-09-07  0.602693  0.421202   44.229167   57.416667  \n",
      "2023-09-08  0.623554  0.277072   53.804348   47.391304  \n",
      "2023-09-09  0.669663  0.295253   60.666667   48.395833  \n",
      "2023-09-10  0.701119  0.468424   61.812500   47.541667  \n",
      "2023-09-11  0.730324  0.512991   51.130435   49.500000  \n",
      "2023-09-12  0.637415  0.523025   55.145833   45.875000  \n",
      "2023-09-13  0.412479  0.602693   59.729167   34.354167  \n",
      "2023-09-14  0.428409  0.623554   60.043478   25.217391  \n",
      "2023-09-15  0.372431  0.669663   63.437500   33.062500  \n",
      "2023-09-16  0.421392  0.701119   48.645833   43.166667  \n",
      "2023-09-17  0.448511  0.730324   52.673913   35.173913  \n",
      "2023-09-18  0.359378  0.637415   58.604167   37.645833  \n",
      "2023-09-19  0.470189  0.412479   54.083333   36.166667  \n",
      "2023-09-20  0.404476  0.428409   54.717391   33.521739  \n",
      "2023-09-21  0.574729  0.372431   48.541667   27.375000  \n",
      "2023-09-22  0.390480  0.421392   58.083333   32.770833  \n",
      "2023-09-23  0.385739  0.448511   47.108696   32.847826  \n",
      "2023-09-24  0.304950  0.359378   37.687500   45.291667  \n",
      "2023-09-25  0.407738  0.470189   52.541667   39.604167  \n",
      "2023-09-26  0.430305  0.404476   52.000000   36.586957  \n",
      "2023-09-27  0.293670  0.574729   48.333333   36.333333  \n",
      "2023-09-28  0.385739  0.390480   43.583333   29.604167  \n",
      "2023-09-29  0.433340  0.385739   48.065217   22.782609  \n",
      "2023-09-30  0.315240  0.304950   48.270833   31.312500  \n",
      "2023-10-01  0.322587  0.407738   32.437500   47.291667  \n",
      "2023-10-02  0.486061  0.430305   34.434783   38.434783  \n",
      "2023-10-03  0.488197  0.293670   53.458333   18.437500  \n",
      "2023-10-04  0.557747  0.385739   58.354167   30.250000  \n",
      "2023-10-05  0.378153  0.433340   59.456522   47.214286  \n",
      "2023-10-06  0.346705  0.315240   68.208333   40.458333  \n",
      "2023-10-07  0.432985  0.322587   70.500000   33.375000  \n",
      "2023-10-08  0.518111  0.486061   75.565217   41.380952  \n",
      "2023-10-09  0.374409  0.488197   79.020833    7.000000  \n",
      "2023-10-10  0.246374  0.557747   82.229167   41.500000  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Select columns to normalize\n",
    "columns_to_normalize = ['Concentration', 'FittedValues', 'day_lag1', 'day_lag7']\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "data_normalized = data.copy()  # Make a copy to avoid modifying the original data\n",
    "data_normalized[columns_to_normalize] = scaler.fit_transform(data_normalized[columns_to_normalize])\n",
    "\n",
    "# Display the normalized data\n",
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "a63b9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
      "Date                                                                            \n",
      "2022-01-01  2022      1    1      34.826087          6        1     50.943430   \n",
      "2022-01-02  2022      1    2      44.717391          0        1     37.898076   \n",
      "2022-01-03  2022      1    3      58.812500          1        0     44.426841   \n",
      "2022-01-04  2022      1    4      52.604167          2        0     54.633318   \n",
      "2022-01-05  2022      1    5      35.173913          3        0     50.968446   \n",
      "2022-01-06  2022      1    6      31.729167          4        0     39.411398   \n",
      "2022-01-07  2022      1    7      44.562500          5        0     35.787911   \n",
      "2022-01-08  2022      1    8      47.739130          6        1     43.656286   \n",
      "2022-01-09  2022      1    9      44.416667          0        1     47.387870   \n",
      "2022-01-10  2022      1   10       9.041667          1        0     45.554935   \n",
      "2022-01-11  2022      1   11      15.739130          2        0     21.074397   \n",
      "2022-01-12  2022      1   12       5.270833          3        0     22.297874   \n",
      "2022-01-13  2022      1   13       2.687500          4        0     17.216941   \n",
      "2022-01-14  2022      1   14       4.282609          5        0     14.010359   \n",
      "2022-01-15  2022      1   15       7.937500          6        1     16.698706   \n",
      "2022-01-16  2022      1   16      11.770833          0        1     13.498197   \n",
      "2022-01-17  2022      1   17      14.021739          1        0     17.639890   \n",
      "2022-01-18  2022      1   18      12.645833          2        0     20.987792   \n",
      "2022-01-19  2022      1   19      15.250000          3        0     17.893159   \n",
      "2022-01-20  2022      1   20      54.695652          4        0     19.824240   \n",
      "2022-01-21  2022      1   21      32.541667          5        0     42.983861   \n",
      "2022-01-22  2022      1   22      32.145833          6        1     33.902859   \n",
      "2022-01-23  2022      1   23      34.391304          0        1     32.461619   \n",
      "2022-01-24  2022      1   24      28.125000          1        0     33.248454   \n",
      "2022-01-25  2022      1   25       4.687500          2        0     25.675193   \n",
      "2022-01-26  2022      1   26      12.500000          3        0     15.585004   \n",
      "2022-01-27  2022      1   27      26.729167          4        0     20.275989   \n",
      "2022-01-28  2022      1   28      12.687500          5        0     26.013030   \n",
      "2022-01-29  2022      1   29      45.043478          6        1     16.889325   \n",
      "2022-01-30  2022      1   30      45.083333          0        1     39.723369   \n",
      "2022-01-31  2022      1   31      67.520833          1        0     43.294632   \n",
      "2022-02-01  2022      2    1      42.586957          2        0     53.393274   \n",
      "2022-02-02  2022      2    2      41.270833          3        0     40.954454   \n",
      "2022-02-03  2022      2    3      40.520833          4        0     36.563885   \n",
      "2022-02-04  2022      2    4      49.891304          5        0     42.487781   \n",
      "2022-02-05  2022      2    5      49.687500          6        1     44.386011   \n",
      "2022-02-06  2022      2    6      63.229167          0        1     45.414570   \n",
      "2022-02-07  2022      2    7      52.916667          1        0     55.928358   \n",
      "2022-02-08  2022      2    8      52.217391          2        0     48.434892   \n",
      "2022-02-09  2022      2    9      43.166667          3        0     50.767612   \n",
      "2022-02-10  2022      2   10      30.041667          4        0     41.848678   \n",
      "2022-02-11  2022      2   11      33.760870          5        0     33.228566   \n",
      "2022-02-12  2022      2   12      38.729167          6        1     38.541199   \n",
      "2022-02-13  2022      2   13      59.812500          0        1     39.017714   \n",
      "2022-02-14  2022      2   14      60.739130          1        0     54.731216   \n",
      "2022-02-15  2022      2   15      48.937500          2        0     54.634819   \n",
      "2022-02-16  2022      2   16      55.770833          3        0     47.231593   \n",
      "2022-02-17  2022      2   17      70.369565          4        0     54.216995   \n",
      "2022-02-18  2022      2   18      63.083333          5        0     59.956621   \n",
      "2022-02-19  2022      2   19      65.083333          6        1     59.307883   \n",
      "2022-02-20  2022      2   20      65.847826          0        1     60.568490   \n",
      "2022-02-21  2022      2   21      68.437500          1        0     60.497703   \n",
      "2022-02-22  2022      2   22      39.958333          2        0     62.532573   \n",
      "2022-02-23  2022      2   23      43.782609          3        0     43.769112   \n",
      "2022-02-24  2022      2   24      55.770833          4        0     47.490655   \n",
      "2022-02-25  2022      2   25      50.791667          5        0     54.401793   \n",
      "2022-02-26  2022      2   26      33.543478          6        1     49.357204   \n",
      "2022-02-27  2022      2   27      48.104167          0        1     41.833565   \n",
      "2022-02-28  2022      2   28      40.187500          1        0     47.790799   \n",
      "2022-03-01  2022      3    1      19.369565          2        0     43.357812   \n",
      "2022-03-02  2022      3    2      19.270833          3        0     28.814202   \n",
      "2022-03-03  2022      3    3      24.062500          4        0     29.201708   \n",
      "2022-03-04  2022      3    4      31.434783          5        0     30.956188   \n",
      "2022-03-05  2022      3    5      24.687500          6        1     34.037125   \n",
      "2022-03-06  2022      3    6      41.326087          0        1     32.630561   \n",
      "2022-03-07  2022      3    7      47.708333          1        0     40.571671   \n",
      "2022-03-08  2022      3    8      43.729167          2        0     46.267063   \n",
      "2022-03-09  2022      3    9      48.847826          3        0     42.245308   \n",
      "2022-03-10  2022      3   10      63.770833          4        0     47.616308   \n",
      "2022-03-11  2022      3   11      64.979167          5        0     57.468016   \n",
      "2022-03-12  2022      3   12      74.086957          6        1     57.087999   \n",
      "2022-03-13  2022      3   13      81.645833          0        1     66.194479   \n",
      "2022-03-14  2022      3   14      51.333333          1        0     70.479101   \n",
      "2022-03-15  2022      3   15      34.125000          2        0     51.410553   \n",
      "2022-03-16  2022      3   16      24.260870          3        0     39.619066   \n",
      "2022-03-17  2022      3   17      48.052632          4        0     31.497715   \n",
      "2022-03-18  2022      3   18      39.725000          5        0     47.784009   \n",
      "2022-03-19  2022      3   19      63.695652          6        1     44.606670   \n",
      "2022-03-20  2022      3   20      56.166667          0        1     57.719419   \n",
      "2022-03-21  2022      3   21      41.108696          1        0     54.708045   \n",
      "2022-03-22  2022      3   22      50.250000          2        0     40.651583   \n",
      "2022-03-23  2022      3   23      52.979167          3        0     52.778297   \n",
      "2022-03-24  2022      3   24      50.978261          4        0     50.979286   \n",
      "2022-03-25  2022      3   25      61.416667          5        0     49.524798   \n",
      "2022-03-26  2022      3   26      69.583333          6        1     59.181328   \n",
      "2022-03-27  2022      3   27      35.736842          0        1     60.723363   \n",
      "2022-03-28  2022      3   28            NaN          1        0           NaN   \n",
      "2022-03-29  2022      3   29            NaN          2        0           NaN   \n",
      "2022-03-30  2022      3   30      45.000000          3        0     44.260982   \n",
      "2022-03-31  2022      3   31      49.477273          4        0     44.881609   \n",
      "2022-04-01  2022      4    1      54.979167          5        0     49.174988   \n",
      "2022-04-02  2022      4    2      69.130435          6        1     53.394184   \n",
      "2022-04-03  2022      4    3      57.562500          0        1     64.738656   \n",
      "2022-04-04  2022      4    4      48.565217          1        0     56.616580   \n",
      "2022-04-05  2022      4    5      37.272727          2        0     46.646452   \n",
      "2022-04-06  2022      4    6      53.416667          3        0     43.212309   \n",
      "2022-04-07  2022      4    7      65.395833          4        0     52.098478   \n",
      "2022-04-08  2022      4    8      49.413043          5        0     62.930167   \n",
      "2022-04-09  2022      4    9      57.916667          6        1     49.439535   \n",
      "2022-04-10  2022      4   10      55.250000          0        1     54.358973   \n",
      "2022-04-11  2022      4   11      62.479167          1        0     55.824917   \n",
      "2022-04-12  2022      4   12      56.347826          2        0     57.923837   \n",
      "2022-04-13  2022      4   13      19.520833          3        0     58.563922   \n",
      "2022-04-14  2022      4   14      33.270833          4        0     27.505750   \n",
      "2022-04-15  2022      4   15      38.456522          5        0     38.453390   \n",
      "2022-04-16  2022      4   16      54.520833          6        1     43.864670   \n",
      "2022-04-17  2022      4   17      58.875000          0        1     50.963349   \n",
      "2022-04-18  2022      4   18      63.130435          1        0     60.669188   \n",
      "2022-04-19  2022      4   19      56.645833          2        0     53.125461   \n",
      "2022-04-20  2022      4   20      63.604167          3        0     56.700907   \n",
      "2022-04-21  2022      4   21      64.586957          4        0     60.507556   \n",
      "2022-04-22  2022      4   22      52.395833          5        0     59.633187   \n",
      "2022-04-23  2022      4   23      68.041667          6        1     54.683161   \n",
      "2022-04-24  2022      4   24      78.304348          0        1     58.683847   \n",
      "2022-04-25  2022      4   25      45.791667          1        0     73.957110   \n",
      "2022-04-26  2022      4   26      58.958333          2        0     49.192519   \n",
      "2022-04-27  2022      4   27      67.130435          3        0     56.874627   \n",
      "2022-04-28  2022      4   28      66.541667          4        0     63.340117   \n",
      "2022-04-29  2022      4   29      44.250000          5        0     59.435712   \n",
      "2022-04-30  2022      4   30      66.130435          6        1     56.165027   \n",
      "2022-05-01  2022      5    1      58.854167          0        1     58.182446   \n",
      "2022-05-02  2022      5    2      60.479167          1        0     57.020965   \n",
      "2022-05-03  2022      5    3      60.043478          2        0     59.588913   \n",
      "2022-05-04  2022      5    4      52.145833          3        0     60.926006   \n",
      "2022-05-05  2022      5    5      36.937500          4        0     55.605793   \n",
      "2022-05-06  2022      5    6      46.934783          5        0     37.863002   \n",
      "2022-05-07  2022      5    7      45.083333          6        1     50.745655   \n",
      "2022-05-08  2022      5    8      61.729167          0        1     50.301583   \n",
      "2022-05-09  2022      5    9      64.978261          1        0     59.336300   \n",
      "2022-05-10  2022      5   10      60.104167          2        0     61.681236   \n",
      "2022-05-11  2022      5   11      66.333333          3        0     53.444083   \n",
      "2022-05-12  2022      5   12      56.782609          4        0     67.727298   \n",
      "2022-05-13  2022      5   13      60.833333          5        0     56.528143   \n",
      "2022-05-14  2022      5   14      73.625000          6        1     57.075775   \n",
      "2022-05-15  2022      5   15      82.608696          0        1     68.250708   \n",
      "2022-05-16  2022      5   16      61.666667          1        0     72.159739   \n",
      "2022-05-17  2022      5   17      58.750000          2        0     67.317030   \n",
      "2022-05-18  2022      5   18      75.956522          3        0     55.077263   \n",
      "2022-05-19  2022      5   19      58.666667          4        0     67.824345   \n",
      "2022-05-20  2022      5   20      48.386364          5        0     60.888741   \n",
      "2022-05-21  2022      5   21      67.065217          6        1     53.582113   \n",
      "2022-05-22  2022      5   22      73.791667          0        1     67.239133   \n",
      "2022-05-23  2022      5   23      50.043478          1        0     61.441696   \n",
      "2022-05-24  2022      5   24      55.434783          2        0     56.406174   \n",
      "2022-05-25  2022      5   25      55.791667          3        0     60.518341   \n",
      "2022-05-26  2022      5   26      56.812500          4        0     54.552686   \n",
      "2022-05-27  2022      5   27      62.521739          5        0     55.806170   \n",
      "2022-05-28  2022      5   28      60.000000          6        1     59.398815   \n",
      "2022-05-29  2022      5   29      57.166667          0        1     64.597206   \n",
      "2022-05-30  2022      5   30      52.239130          1        0     57.572851   \n",
      "2022-05-31  2022      5   31      52.666667          2        0     49.956674   \n",
      "2022-06-01  2022      6    1      59.812500          3        0     54.318936   \n",
      "2022-06-02  2022      6    2      75.041667          4        0     60.819796   \n",
      "2022-06-03  2022      6    3      87.391304          5        0     72.307628   \n",
      "2022-06-04  2022      6    4      90.062500          6        1     74.555161   \n",
      "2022-06-05  2022      6    5      47.645833          0        1     78.262455   \n",
      "2022-06-06  2022      6    6      57.782609          1        0     56.177265   \n",
      "2022-06-07  2022      6    7      41.291667          2        0     58.664670   \n",
      "2022-06-08  2022      6    8      31.812500          3        0     47.282878   \n",
      "2022-06-09  2022      6    9      48.391304          4        0     35.793730   \n",
      "2022-06-10  2022      6   10      47.062500          5        0     56.445780   \n",
      "2022-06-11  2022      6   11      54.604167          6        1     50.759547   \n",
      "2022-06-12  2022      6   12      62.369565          0        1     52.803185   \n",
      "2022-06-13  2022      6   13      62.166667          1        0     60.192996   \n",
      "2022-06-14  2022      6   14      73.062500          2        0     57.462844   \n",
      "2022-06-15  2022      6   15      95.521739          3        0     73.788300   \n",
      "2022-06-16  2022      6   16      90.090909          4        0     80.056136   \n",
      "2022-06-17  2022      6   17      93.282609          5        0     78.064895   \n",
      "2022-06-18  2022      6   18     104.804348          6        1     85.181739   \n",
      "2022-06-19  2022      6   19      59.229167          0        1     91.249032   \n",
      "2022-06-20  2022      6   20      60.229167          1        0     64.354633   \n",
      "2022-06-21  2022      6   21      50.500000          2        0     57.324778   \n",
      "2022-06-22  2022      6   22      78.791667          3        0     56.320937   \n",
      "2022-06-23  2022      6   23      74.020833          4        0     74.269202   \n",
      "2022-06-24  2022      6   24      55.586957          5        0     74.816218   \n",
      "2022-06-25  2022      6   25      44.187500          6        1     56.676370   \n",
      "2022-06-26  2022      6   26      45.208333          0        1     48.170208   \n",
      "2022-06-27  2022      6   27      31.934783          1        0     51.691600   \n",
      "2022-06-28  2022      6   28      56.291667          2        0     43.243444   \n",
      "2022-06-29  2022      6   29      68.229167          3        0     58.440695   \n",
      "2022-06-30  2022      6   30      37.152174          4        0     62.004761   \n",
      "2022-07-01  2022      7    1      42.208333          5        0     43.651983   \n",
      "2022-07-02  2022      7    2      58.312500          6        1     50.844695   \n",
      "2022-07-03  2022      7    3      55.021739          0        1     56.058764   \n",
      "2022-07-04  2022      7    4      52.708333          1        0     53.427734   \n",
      "2022-07-05  2022      7    5      56.041667          2        0     54.978466   \n",
      "2022-07-06  2022      7    6      61.717391          3        0     56.669125   \n",
      "2022-07-07  2022      7    7      47.250000          4        0     60.109811   \n",
      "2022-07-08  2022      7    8      58.666667          5        0     48.029113   \n",
      "2022-07-09  2022      7    9      60.739130          6        1     57.272228   \n",
      "2022-07-10  2022      7   10      50.541667          0        1     61.275730   \n",
      "2022-07-11  2022      7   11      51.770833          1        0     51.051897   \n",
      "2022-07-12  2022      7   12      57.021739          2        0     53.468112   \n",
      "2022-07-13  2022      7   13      76.895833          3        0     53.889232   \n",
      "2022-07-14  2022      7   14      56.895833          4        0     70.990902   \n",
      "2022-07-15  2022      7   15      54.347826          5        0     59.760187   \n",
      "2022-07-16  2022      7   16      61.000000          6        1     51.825887   \n",
      "2022-07-17  2022      7   17      68.875000          0        1     59.946355   \n",
      "2022-07-18  2022      7   18      95.568182          1        0     62.284695   \n",
      "2022-07-19  2022      7   19     110.125000          2        0     87.679443   \n",
      "2022-07-20  2022      7   20      80.583333          3        0     94.305669   \n",
      "2022-07-21  2022      7   21      49.652174          4        0     71.063528   \n",
      "2022-07-22  2022      7   22      50.208333          5        0     56.384628   \n",
      "2022-07-23  2022      7   23      68.916667          6        1     52.421728   \n",
      "2022-07-24  2022      7   24      79.152174          0        1     69.050113   \n",
      "2022-07-25  2022      7   25      56.437500          1        0     73.532730   \n",
      "2022-07-26  2022      7   26      51.562500          2        0     57.835597   \n",
      "2022-07-27  2022      7   27      56.934783          3        0     56.726356   \n",
      "2022-07-28  2022      7   28      70.125000          4        0     55.844306   \n",
      "2022-07-29  2022      7   29      86.812500          5        0     68.581146   \n",
      "2022-07-30  2022      7   30      76.065217          6        1     79.871641   \n",
      "2022-07-31  2022      7   31      47.229167          0        1     71.368885   \n",
      "2022-08-01  2022      8    1      57.625000          1        0     53.033477   \n",
      "2022-08-02  2022      8    2      55.478261          2        0     56.498310   \n",
      "2022-08-03  2022      8    3      48.000000          3        0     59.304901   \n",
      "2022-08-04  2022      8    4      40.666667          4        0     53.096562   \n",
      "2022-08-05  2022      8    5      56.295455          5        0     47.710122   \n",
      "2022-08-06  2022      8    6      55.458333          6        1     54.488931   \n",
      "2022-08-07  2022      8    7      73.270833          0        1     56.028448   \n",
      "2022-08-08  2022      8    8      70.416667          1        0     71.146804   \n",
      "2022-08-09  2022      8    9      70.043478          2        0     67.262967   \n",
      "2022-08-10  2022      8   10      91.166667          3        0     63.804213   \n",
      "2022-08-11  2022      8   11     103.520833          4        0     80.783072   \n",
      "2022-08-12  2022      8   12     106.217391          5        0     91.153174   \n",
      "2022-08-13  2022      8   13      97.291667          6        1     95.527406   \n",
      "2022-08-14  2022      8   14     100.708333          0        1     86.332484   \n",
      "2022-08-15  2022      8   15      92.217391          1        0     86.982299   \n",
      "2022-08-16  2022      8   16     102.583333          2        0     87.933644   \n",
      "2022-08-17  2022      8   17      70.416667          3        0     94.201924   \n",
      "2022-08-18  2022      8   18      80.565217          4        0     73.245505   \n",
      "2022-08-19  2022      8   19      39.937500          5        0     73.659826   \n",
      "2022-08-20  2022      8   20      50.145833          6        1     52.532029   \n",
      "2022-08-21  2022      8   21      47.700000          0        1     57.735377   \n",
      "2022-08-22  2022      8   22      97.545455          1        0     57.778629   \n",
      "2022-08-23  2022      8   23      53.000000          2        0     82.643292   \n",
      "2022-08-24  2022      8   24      74.604167          3        0     61.023104   \n",
      "2022-08-25  2022      8   25      89.791667          4        0     72.336754   \n",
      "2022-08-26  2022      8   26      64.608696          5        0     85.108246   \n",
      "2022-08-27  2022      8   27      58.604167          6        1     61.286739   \n",
      "2022-08-28  2022      8   28      69.062500          0        1     63.864931   \n",
      "2022-08-29  2022      8   29      64.413043          1        0     70.116179   \n",
      "2022-08-30  2022      8   30      66.354167          2        0     62.882086   \n",
      "2022-08-31  2022      8   31      72.020833          3        0     69.164134   \n",
      "2022-09-01  2022      9    1      74.304348          4        0     66.988639   \n",
      "2022-09-02  2022      9    2      69.041667          5        0     74.055696   \n",
      "2022-09-03  2022      9    3      71.020833          6        1     69.165598   \n",
      "2022-09-04  2022      9    4      64.104167          0        1     67.082590   \n",
      "2022-09-05  2022      9    5      75.847826          1        0     67.013146   \n",
      "2022-09-06  2022      9    6      59.227273          2        0     70.086917   \n",
      "2022-09-07  2022      9    7      57.416667          3        0     65.349912   \n",
      "2022-09-08  2022      9    8      47.391304          4        0     58.198585   \n",
      "2022-09-09  2022      9    9      48.395833          5        0     52.274991   \n",
      "2022-09-10  2022      9   10      47.541667          6        1     53.712048   \n",
      "2022-09-11  2022      9   11      49.500000          0        1     52.419549   \n",
      "2022-09-12  2022      9   12      45.875000          1        0     54.951239   \n",
      "2022-09-13  2022      9   13      34.354167          2        0     48.073521   \n",
      "2022-09-14  2022      9   14      25.217391          3        0     42.191451   \n",
      "2022-09-15  2022      9   15      33.062500          4        0     36.582260   \n",
      "2022-09-16  2022      9   16      43.166667          5        0     39.334226   \n",
      "2022-09-17  2022      9   17      35.173913          6        1     46.593294   \n",
      "2022-09-18  2022      9   18      37.645833          0        1     39.336029   \n",
      "2022-09-19  2022      9   19      36.166667          1        0     43.356533   \n",
      "2022-09-20  2022      9   20      33.521739          2        0     40.536768   \n",
      "2022-09-21  2022      9   21      27.375000          3        0     36.443608   \n",
      "2022-09-22  2022      9   22      32.770833          4        0     35.502455   \n",
      "2022-09-23  2022      9   23      32.847826          5        0     35.923756   \n",
      "2022-09-24  2022      9   24      45.291667          6        1     38.192343   \n",
      "2022-09-25  2022      9   25      39.604167          0        1     43.786334   \n",
      "2022-09-26  2022      9   26      36.586957          1        0     41.105790   \n",
      "2022-09-27  2022      9   27      36.333333          2        0     40.009808   \n",
      "2022-09-28  2022      9   28      29.604167          3        0     38.009319   \n",
      "2022-09-29  2022      9   29      22.782609          4        0     33.845693   \n",
      "2022-09-30  2022      9   30      31.312500          5        0     28.796373   \n",
      "2022-10-01  2022     10    1      47.291667          6        1     34.983127   \n",
      "2022-10-02  2022     10    2      38.434783          0        1     45.250804   \n",
      "2022-10-03  2022     10    3      18.437500          1        0     39.028402   \n",
      "2022-10-04  2022     10    4      30.250000          2        0     26.404852   \n",
      "2022-10-05  2022     10    5      47.214286          3        0     32.295117   \n",
      "2022-10-06  2022     10    6      40.458333          4        0     44.051830   \n",
      "2022-10-07  2022     10    7      33.375000          5        0     41.446740   \n",
      "2022-10-08  2022     10    8      41.380952          6        1     36.768095   \n",
      "2022-10-09  2022     10    9       7.000000          0        1     39.345700   \n",
      "2022-10-10  2022     10   10      41.500000          1        0     16.310863   \n",
      "2022-10-11  2022     10   11       5.833333          2        0     41.013493   \n",
      "2022-10-12  2022     10   12      18.477273          3        0     19.534776   \n",
      "2022-10-13  2022     10   13      21.708333          4        0     20.233566   \n",
      "2022-10-14  2022     10   14      23.391304          5        0     28.941202   \n",
      "2022-10-15  2022     10   15      37.166667          6        1     22.371509   \n",
      "2022-10-16  2022     10   16      37.729167          0        1     42.024518   \n",
      "2022-10-17  2022     10   17      21.500000          1        0     35.573522   \n",
      "2022-10-18  2022     10   18      26.729167          2        0     21.952788   \n",
      "2022-10-19  2022     10   19      22.937500          3        0     32.608966   \n",
      "2022-10-20  2022     10   20      20.608696          4        0     23.402641   \n",
      "2022-10-21  2022     10   21      41.208333          5        0     29.233444   \n",
      "2022-10-22  2022     10   22      38.687500          6        1     35.882788   \n",
      "2022-10-23  2022     10   23      37.333333          0        1     34.789269   \n",
      "2022-10-24  2022     10   24      51.714286          1        0     40.705408   \n",
      "2022-10-25  2022     10   25      41.000000          2        0     44.203480   \n",
      "2022-10-26  2022     10   26            NaN          3        0           NaN   \n",
      "2022-10-27  2022     10   27            NaN          4        0           NaN   \n",
      "2022-10-28  2022     10   28            NaN          5        0           NaN   \n",
      "2022-10-29  2022     10   29            NaN          6        1           NaN   \n",
      "2022-10-30  2022     10   30            NaN          0        1           NaN   \n",
      "2022-10-31  2022     10   31            NaN          1        0           NaN   \n",
      "2022-11-01  2022     11    1            NaN          2        0           NaN   \n",
      "2022-11-02  2022     11    2            NaN          3        0           NaN   \n",
      "2022-11-03  2022     11    3            NaN          4        0           NaN   \n",
      "2022-11-04  2022     11    4            NaN          5        0           NaN   \n",
      "2022-11-05  2022     11    5            NaN          6        1           NaN   \n",
      "2022-11-06  2022     11    6            NaN          0        1           NaN   \n",
      "2022-11-07  2022     11    7      52.400000          1        0     40.789120   \n",
      "2022-11-08  2022     11    8      47.750000          2        0     44.506316   \n",
      "2022-11-09  2022     11    9      46.479167          3        0     46.385218   \n",
      "2022-11-10  2022     11   10      33.142857          4        0     45.879947   \n",
      "2022-11-11  2022     11   11      29.125000          5        0     33.789614   \n",
      "2022-11-12  2022     11   12       8.062500          6        1     31.852119   \n",
      "2022-11-13  2022     11   13       6.750000          0        1     17.818492   \n",
      "2022-11-14  2022     11   14       5.586957          1        0     18.313917   \n",
      "2022-11-15  2022     11   15      34.541667          2        0     15.849511   \n",
      "2022-11-16  2022     11   16      38.416667          3        0     30.733289   \n",
      "2022-11-17  2022     11   17      53.521739          4        0     39.681724   \n",
      "2022-11-18  2022     11   18      29.895833          5        0     47.157607   \n",
      "2022-11-19  2022     11   19       6.229167          6        1     33.938743   \n",
      "2022-11-20  2022     11   20       4.000000          0        1     12.014413   \n",
      "2022-11-21  2022     11   21      36.692308          1        0     13.071652   \n",
      "2022-11-22  2022     11   22      44.770833          2        0     37.096334   \n",
      "2022-11-23  2022     11   23      36.888889          3        0     42.019125   \n",
      "2022-11-24  2022     11   24      45.026316          4        0     36.736106   \n",
      "2022-11-25  2022     11   25      28.333333          5        0     38.204849   \n",
      "2022-11-26  2022     11   26      21.543478          6        1     30.748425   \n",
      "2022-11-27  2022     11   27      32.312500          0        1     28.246199   \n",
      "2022-11-28  2022     11   28      16.937500          1        0     33.488770   \n",
      "2022-11-29  2022     11   29       6.600000          2        0     20.386703   \n",
      "2022-11-30  2022     11   30            NaN          3        0           NaN   \n",
      "2022-12-01  2022     12    1       8.807692          4        0     14.592329   \n",
      "2022-12-02  2022     12    2      12.500000          5        0     18.970749   \n",
      "2022-12-03  2022     12    3      10.375000          6        1     17.815180   \n",
      "2022-12-04  2022     12    4       6.833333          0        1     16.301504   \n",
      "2022-12-05  2022     12    5       2.326087          1        0     12.803883   \n",
      "2022-12-06  2022     12    6       9.479167          2        0     11.266280   \n",
      "2022-12-07  2022     12    7      16.775000          3        0     16.145569   \n",
      "2022-12-08  2022     12    8      16.891304          4        0     17.846402   \n",
      "2022-12-09  2022     12    9      10.875000          5        0     19.532376   \n",
      "2022-12-10  2022     12   10      19.104167          6        1     15.951132   \n",
      "2022-12-11  2022     12   11      29.260870          0        1     21.053062   \n",
      "2022-12-12  2022     12   12      12.604167          1        0     27.360869   \n",
      "2022-12-13  2022     12   13       3.750000          2        0     15.616891   \n",
      "2022-12-14  2022     12   14       3.673913          3        0     11.958200   \n",
      "2022-12-15  2022     12   15       2.000000          4        0      9.794649   \n",
      "2022-12-16  2022     12   16       5.437500          5        0      7.274936   \n",
      "2022-12-17  2022     12   17       3.130435          6        1     11.843192   \n",
      "2022-12-18  2022     12   18      13.458333          0        1      9.006408   \n",
      "2022-12-19  2022     12   19      32.666667          1        0     15.914762   \n",
      "2022-12-20  2022     12   20      32.608696          2        0     27.821094   \n",
      "2022-12-21  2022     12   21      28.166667          3        0     28.713831   \n",
      "2022-12-22  2022     12   22      31.041667          4        0     28.562063   \n",
      "2022-12-23  2022     12   23      42.304348          5        0     27.617623   \n",
      "2022-12-24  2022     12   24      44.333333          6        1     35.173237   \n",
      "2022-12-25  2022     12   25      29.937500          0        1     39.319204   \n",
      "2022-12-26  2022     12   26      46.521739          1        0     30.734205   \n",
      "2022-12-27  2022     12   27      42.270833          2        0     40.937899   \n",
      "2022-12-28  2022     12   28      50.041667          3        0     36.261155   \n",
      "2022-12-29  2022     12   29      55.108696          4        0     43.887499   \n",
      "2022-12-30  2022     12   30      43.977273          5        0     51.870920   \n",
      "2022-12-31  2022     12   31            NaN          6        1           NaN   \n",
      "2023-01-01  2023      1    1      49.545455          0        1     39.301261   \n",
      "2023-01-02  2023      1    2      48.083333          1        0     44.742468   \n",
      "2023-01-03  2023      1    3      41.729167          2        0     43.665370   \n",
      "2023-01-04  2023      1    4      54.727273          3        0     42.100968   \n",
      "2023-01-05  2023      1    5      46.520833          4        0     52.494902   \n",
      "2023-01-06  2023      1    6      43.583333          5        0     40.619276   \n",
      "2023-01-07  2023      1    7      51.369565          6        1     43.147141   \n",
      "2023-01-08  2023      1    8      65.145833          0        1     49.844451   \n",
      "2023-01-09  2023      1    9      54.312500          1        0     57.672493   \n",
      "2023-01-10  2023      1   10      41.652174          2        0     52.427869   \n",
      "2023-01-11  2023      1   11      53.375000          3        0     39.372007   \n",
      "2023-01-12  2023      1   12      54.395833          4        0     52.550485   \n",
      "2023-01-13  2023      1   13      60.625000          5        0     52.103583   \n",
      "2023-01-14  2023      1   14      55.369565          6        1     55.844792   \n",
      "2023-01-15  2023      1   15      64.354167          0        1     54.206047   \n",
      "2023-01-16  2023      1   16      55.687500          1        0     55.354362   \n",
      "2023-01-17  2023      1   17      22.717391          2        0     57.543533   \n",
      "2023-01-18  2023      1   18      15.020833          3        0     30.773484   \n",
      "2023-01-19  2023      1   19      21.958333          4        0     25.121120   \n",
      "2023-01-20  2023      1   20      24.847826          5        0     28.930779   \n",
      "2023-01-21  2023      1   21      18.562500          6        1     29.555713   \n",
      "2023-01-22  2023      1   22      30.645833          0        1     32.513982   \n",
      "2023-01-23  2023      1   23      13.652174          1        0     30.498535   \n",
      "2023-01-24  2023      1   24      22.395833          2        0     21.176737   \n",
      "2023-01-25  2023      1   25      11.770833          3        0     27.712525   \n",
      "2023-01-26  2023      1   26      25.695652          4        0     22.348475   \n",
      "2023-01-27  2023      1   27      43.395833          5        0     29.791239   \n",
      "2023-01-28  2023      1   28      40.916667          6        1     37.689129   \n",
      "2023-01-29  2023      1   29      20.195652          0        1     39.418179   \n",
      "2023-01-30  2023      1   30      44.125000          1        0     28.909432   \n",
      "2023-01-31  2023      1   31      25.666667          2        0     40.486891   \n",
      "2023-02-01  2023      2    1      50.022727          3        0     27.463212   \n",
      "2023-02-02  2023      2    2      51.625000          4        0     43.463246   \n",
      "2023-02-03  2023      2    3      52.354167          5        0     52.648514   \n",
      "2023-02-04  2023      2    4      26.239130          6        1     45.732320   \n",
      "2023-02-05  2023      2    5      53.416667          0        1     30.815581   \n",
      "2023-02-06  2023      2    6      23.270833          1        0     45.032583   \n",
      "2023-02-07  2023      2    7      11.173913          2        0     31.943560   \n",
      "2023-02-08  2023      2    8      14.166667          3        0     22.620557   \n",
      "2023-02-09  2023      2    9      16.833333          4        0     19.722241   \n",
      "2023-02-10  2023      2   10      15.260870          5        0     19.323021   \n",
      "2023-02-11  2023      2   11      28.145833          6        1     24.279664   \n",
      "2023-02-12  2023      2   12      36.770833          0        1     33.792908   \n",
      "2023-02-13  2023      2   13      12.782609          1        0     33.599493   \n",
      "2023-02-14  2023      2   14       9.895833          2        0     16.707905   \n",
      "2023-02-15  2023      2   15      14.520833          3        0     17.777789   \n",
      "2023-02-16  2023      2   16      27.478261          4        0     23.537911   \n",
      "2023-02-17  2023      2   17      52.979167          5        0     27.286664   \n",
      "2023-02-18  2023      2   18      60.645833          6        1     43.895675   \n",
      "2023-02-19  2023      2   19      49.869565          0        1     51.553344   \n",
      "2023-02-20  2023      2   20      49.250000          1        0     47.746628   \n",
      "2023-02-21  2023      2   21            NaN          2        0           NaN   \n",
      "2023-02-22  2023      2   22            NaN          3        0           NaN   \n",
      "2023-02-23  2023      2   23            NaN          4        0           NaN   \n",
      "2023-02-24  2023      2   24      56.125000          5        0     45.792197   \n",
      "2023-02-25  2023      2   25      44.781250          6        1     45.598018   \n",
      "2023-02-26  2023      2   26            NaN          0        1           NaN   \n",
      "2023-02-27  2023      2   27      48.312500          1        0     43.419848   \n",
      "2023-02-28  2023      2   28      35.977273          2        0     48.599312   \n",
      "2023-03-01  2023      3    1      38.590909          3        0     38.543619   \n",
      "2023-03-02  2023      3    2      31.130435          4        0     35.535954   \n",
      "2023-03-03  2023      3    3      39.522727          5        0     33.455638   \n",
      "2023-03-04  2023      3    4      66.437500          6        1     42.122051   \n",
      "2023-03-05  2023      3    5      53.687500          0        1     60.478249   \n",
      "2023-03-06  2023      3    6      46.666667          1        0     47.494905   \n",
      "2023-03-07  2023      3    7      51.062500          2        0     43.537938   \n",
      "2023-03-08  2023      3    8      32.979167          3        0     51.128730   \n",
      "2023-03-09  2023      3    9      26.217391          4        0     36.968313   \n",
      "2023-03-10  2023      3   10      54.729167          5        0     32.527794   \n",
      "2023-03-11  2023      3   11      46.062500          6        1     47.728556   \n",
      "2023-03-12  2023      3   12      60.565217          0        1     45.721275   \n",
      "2023-03-13  2023      3   13      48.166667          1        0     58.981999   \n",
      "2023-03-14  2023      3   14      60.333333          2        0     46.969626   \n",
      "2023-03-15  2023      3   15      52.456522          3        0     51.208823   \n",
      "2023-03-16  2023      3   16      63.666667          4        0     52.309562   \n",
      "2023-03-17  2023      3   17      54.812500          5        0     59.148234   \n",
      "2023-03-18  2023      3   18      60.416667          6        1     56.320675   \n",
      "2023-03-19  2023      3   19      52.673913          0        1     51.482101   \n",
      "2023-03-20  2023      3   20      48.145833          1        0     51.661228   \n",
      "2023-03-21  2023      3   21      48.071429          2        0     51.473757   \n",
      "2023-03-22  2023      3   22      58.857143          3        0     49.794657   \n",
      "2023-03-23  2023      3   23      70.375000          4        0     54.726847   \n",
      "2023-03-24  2023      3   24      68.750000          5        0     60.452053   \n",
      "2023-03-25  2023      3   25      73.750000          6        1     67.271883   \n",
      "2023-03-26  2023      3   26      64.458333          0        1     69.034383   \n",
      "2023-03-27  2023      3   27      69.739130          1        0     59.021828   \n",
      "2023-03-28  2023      3   28      50.500000          2        0     62.544490   \n",
      "2023-03-29  2023      3   29      46.125000          3        0     53.875431   \n",
      "2023-03-30  2023      3   30      68.204545          4        0     52.426341   \n",
      "2023-03-31  2023      3   31      65.458333          5        0     62.865337   \n",
      "2023-04-01  2023      4    1      46.270833          6        1     58.603209   \n",
      "2023-04-02  2023      4    2      51.304348          0        1     52.065646   \n",
      "2023-04-03  2023      4    3      47.812500          1        0     55.531696   \n",
      "2023-04-04  2023      4    4      55.750000          2        0     48.343607   \n",
      "2023-04-05  2023      4    5      48.812500          3        0     52.785506   \n",
      "2023-04-06  2023      4    6      49.347826          4        0     52.388384   \n",
      "2023-04-07  2023      4    7      63.020833          5        0     53.276519   \n",
      "2023-04-08  2023      4    8      59.833333          6        1     59.961682   \n",
      "2023-04-09  2023      4    9      51.869565          0        1     54.279048   \n",
      "2023-04-10  2023      4   10      65.229167          1        0     54.010258   \n",
      "2023-04-11  2023      4   11      71.979167          2        0     64.714319   \n",
      "2023-04-12  2023      4   12      73.086957          3        0     65.386788   \n",
      "2023-04-13  2023      4   13      72.500000          4        0     66.051391   \n",
      "2023-04-14  2023      4   14      55.229167          5        0     67.360156   \n",
      "2023-04-15  2023      4   15      63.826087          6        1     58.551323   \n",
      "2023-04-16  2023      4   16      54.916667          0        1     62.030916   \n",
      "2023-04-17  2023      4   17      62.583333          1        0     53.854179   \n",
      "2023-04-18  2023      4   18      53.152174          2        0     60.301070   \n",
      "2023-04-19  2023      4   19      66.416667          3        0     58.345671   \n",
      "2023-04-20  2023      4   20      71.625000          4        0     62.540218   \n",
      "2023-04-21  2023      4   21      60.173913          5        0     66.891684   \n",
      "2023-04-22  2023      4   22      24.458333          6        1     57.824481   \n",
      "2023-04-23  2023      4   23      63.437500          0        1     38.749643   \n",
      "2023-04-24  2023      4   24      76.750000          1        0     60.762693   \n",
      "2023-04-25  2023      4   25      74.500000          2        0     68.131218   \n",
      "2023-04-26  2023      4   26      58.250000          3        0     69.691689   \n",
      "2023-04-27  2023      4   27      68.108696          4        0     62.271071   \n",
      "2023-04-28  2023      4   28      37.625000          5        0     62.435164   \n",
      "2023-04-29  2023      4   29      71.895833          6        1     43.388527   \n",
      "2023-04-30  2023      4   30      71.739130          0        1     66.361231   \n",
      "2023-05-01  2023      5    1      61.458333          1        0     72.257285   \n",
      "2023-05-02  2023      5    2      63.541667          2        0     59.115027   \n",
      "2023-05-03  2023      5    3      67.108696          3        0     61.669970   \n",
      "2023-05-04  2023      5    4      67.750000          4        0     61.817726   \n",
      "2023-05-05  2023      5    5      60.125000          5        0     67.790209   \n",
      "2023-05-06  2023      5    6      53.891304          6        1     64.065636   \n",
      "2023-05-07  2023      5    7      38.687500          0        1     51.042884   \n",
      "2023-05-08  2023      5    8      33.145833          1        0     45.241019   \n",
      "2023-05-09  2023      5    9      33.108696          2        0     41.147513   \n",
      "2023-05-10  2023      5   10      42.250000          3        0     44.150810   \n",
      "2023-05-11  2023      5   11      50.704545          4        0     45.262404   \n",
      "2023-05-12  2023      5   12      41.478261          5        0     47.391580   \n",
      "2023-05-13  2023      5   13      76.958333          6        1     48.275268   \n",
      "2023-05-14  2023      5   14      70.000000          0        1     69.534604   \n",
      "2023-05-15  2023      5   15      55.977273          1        0     66.210818   \n",
      "2023-05-16  2023      5   16      62.312500          2        0     51.722507   \n",
      "2023-05-17  2023      5   17      60.583333          3        0     60.741780   \n",
      "2023-05-18  2023      5   18      69.729167          4        0     60.164362   \n",
      "2023-05-19  2023      5   19      74.304348          5        0     65.238769   \n",
      "2023-05-20  2023      5   20      78.104167          6        1     69.301600   \n",
      "2023-05-21  2023      5   21      68.479167          0        1     67.794894   \n",
      "2023-05-22  2023      5   22      58.978261          1        0     69.143914   \n",
      "2023-05-23  2023      5   23      71.395833          2        0     59.069319   \n",
      "2023-05-24  2023      5   24      59.522727          3        0     66.098189   \n",
      "2023-05-25  2023      5   25      69.391304          4        0     59.863692   \n",
      "2023-05-26  2023      5   26      76.770833          5        0     65.183964   \n",
      "2023-05-27  2023      5   27      84.437500          6        1     76.272151   \n",
      "2023-05-28  2023      5   28      83.326087          0        1     72.980342   \n",
      "2023-05-29  2023      5   29      75.458333          1        0     77.528772   \n",
      "2023-05-30  2023      5   30      74.479167          2        0     72.319198   \n",
      "2023-05-31  2023      5   31      73.956522          3        0     71.143359   \n",
      "2023-06-01  2023      6    1      68.916667          4        0     73.184202   \n",
      "2023-06-02  2023      6    2      81.270833          5        0     63.737620   \n",
      "2023-06-03  2023      6    3      80.260870          6        1     79.056780   \n",
      "2023-06-04  2023      6    4      84.520833          0        1     76.404217   \n",
      "2023-06-05  2023      6    5      76.312500          1        0     77.933892   \n",
      "2023-06-06  2023      6    6      83.130435          2        0     75.272705   \n",
      "2023-06-07  2023      6    7      78.729167          3        0     74.397522   \n",
      "2023-06-08  2023      6    8      88.041667          4        0     80.386689   \n",
      "2023-06-09  2023      6    9     101.357143          5        0     80.376832   \n",
      "2023-06-10  2023      6   10     109.625000          6        1     91.223605   \n",
      "2023-06-11  2023      6   11      98.416667          0        1     97.990310   \n",
      "2023-06-12  2023      6   12     100.913043          1        0     89.982404   \n",
      "2023-06-13  2023      6   13     111.854167          2        0     96.206032   \n",
      "2023-06-14  2023      6   14     107.541667          3        0     97.070861   \n",
      "2023-06-15  2023      6   15      93.956522          4        0     98.910131   \n",
      "2023-06-16  2023      6   16     109.645833          5        0     92.133313   \n",
      "2023-06-17  2023      6   17     108.187500          6        1     99.364383   \n",
      "2023-06-18  2023      6   18      98.869565          0        1    100.874189   \n",
      "2023-06-19  2023      6   19      74.261905          1        0     91.431743   \n",
      "2023-06-20  2023      6   20      68.369565          2        0     81.712375   \n",
      "2023-06-21  2023      6   21      63.340909          3        0     71.960776   \n",
      "2023-06-22  2023      6   22      51.473684          4        0     67.604376   \n",
      "2023-06-23  2023      6   23      67.847826          5        0     61.820955   \n",
      "2023-06-24  2023      6   24      70.978261          6        1     71.025853   \n",
      "2023-06-25  2023      6   25      96.645833          0        1     75.323590   \n",
      "2023-06-26  2023      6   26      72.604167          1        0     86.116350   \n",
      "2023-06-27  2023      6   27      62.913043          2        0     75.807157   \n",
      "2023-06-28  2023      6   28      52.770833          3        0     66.777425   \n",
      "2023-06-29  2023      6   29      51.604167          4        0     60.492261   \n",
      "2023-06-30  2023      6   30      60.086957          5        0     56.169826   \n",
      "2023-07-01  2023      7    1      41.083333          6        1     63.275675   \n",
      "2023-07-02  2023      7    2      71.500000          0        1     53.211780   \n",
      "2023-07-03  2023      7    3      63.673913          1        0     68.172473   \n",
      "2023-07-04  2023      7    4      58.956522          2        0     65.301904   \n",
      "2023-07-05  2023      7    5      59.312500          3        0     58.579127   \n",
      "2023-07-06  2023      7    6      63.608696          4        0     65.626465   \n",
      "2023-07-07  2023      7    7      76.416667          5        0     61.867371   \n",
      "2023-07-08  2023      7    8      80.104167          6        1     71.162910   \n",
      "2023-07-09  2023      7    9      68.586957          0        1     76.894275   \n",
      "2023-07-10  2023      7   10      67.562500          1        0     66.744672   \n",
      "2023-07-11  2023      7   11      58.375000          2        0     69.624811   \n",
      "2023-07-12  2023      7   12      58.391304          3        0     56.653415   \n",
      "2023-07-13  2023      7   13      59.958333          4        0     60.570296   \n",
      "2023-07-14  2023      7   14      72.041667          5        0     64.594261   \n",
      "2023-07-15  2023      7   15      54.130435          6        1     67.112795   \n",
      "2023-07-16  2023      7   16      52.312500          0        1     59.133470   \n",
      "2023-07-17  2023      7   17      55.000000          1        0     51.920873   \n",
      "2023-07-18  2023      7   18      62.065217          2        0     60.098041   \n",
      "2023-07-19  2023      7   19      52.250000          3        0     62.124867   \n",
      "2023-07-20  2023      7   20      44.833333          4        0     54.081977   \n",
      "2023-07-21  2023      7   21      48.347826          5        0     50.552136   \n",
      "2023-07-22  2023      7   22      58.229167          6        1     49.317206   \n",
      "2023-07-23  2023      7   23      46.645833          0        1     60.868681   \n",
      "2023-07-24  2023      7   24      44.173913          1        0     50.282525   \n",
      "2023-07-25  2023      7   25      51.312500          2        0     47.043454   \n",
      "2023-07-26  2023      7   26      60.437500          3        0     53.102901   \n",
      "2023-07-27  2023      7   27      34.608696          4        0     56.950103   \n",
      "2023-07-28  2023      7   28      33.375000          5        0     45.781819   \n",
      "2023-07-29  2023      7   29      45.187500          6        1     37.679917   \n",
      "2023-07-30  2023      7   30      52.978261          0        1     45.862930   \n",
      "2023-07-31  2023      7   31      38.520833          1        0     52.827827   \n",
      "2023-08-01  2023      8    1      51.312500          2        0     45.361136   \n",
      "2023-08-02  2023      8    2      49.260870          3        0     52.351986   \n",
      "2023-08-03  2023      8    3      48.875000          4        0     45.208350   \n",
      "2023-08-04  2023      8    4      45.562500          5        0     49.427021   \n",
      "2023-08-05  2023      8    5      45.062500          6        1     51.409471   \n",
      "2023-08-06  2023      8    6      56.043478          0        1     45.723208   \n",
      "2023-08-07  2023      8    7      54.375000          1        0     52.452163   \n",
      "2023-08-08  2023      8    8      44.229167          2        0     50.751954   \n",
      "2023-08-09  2023      8    9      53.804348          3        0     49.951518   \n",
      "2023-08-10  2023      8   10      60.666667          4        0     54.545424   \n",
      "2023-08-11  2023      8   11      61.812500          5        0     52.750269   \n",
      "2023-08-12  2023      8   12      51.130435          6        1     58.235399   \n",
      "2023-08-13  2023      8   13      55.145833          0        1     53.743435   \n",
      "2023-08-14  2023      8   14      59.729167          1        0     55.735709   \n",
      "2023-08-15  2023      8   15      60.043478          2        0     55.032214   \n",
      "2023-08-16  2023      8   16      63.437500          3        0     54.253467   \n",
      "2023-08-17  2023      8   17      48.645833          4        0     64.513580   \n",
      "2023-08-18  2023      8   18      52.673913          5        0     51.640157   \n",
      "2023-08-19  2023      8   19      58.604167          6        1     50.497059   \n",
      "2023-08-20  2023      8   20      54.083333          0        1     54.942825   \n",
      "2023-08-21  2023      8   21      54.717391          1        0     54.251583   \n",
      "2023-08-22  2023      8   22      48.541667          2        0     60.094117   \n",
      "2023-08-23  2023      8   23      58.083333          3        0     46.953130   \n",
      "2023-08-24  2023      8   24      47.108696          4        0     52.841248   \n",
      "2023-08-25  2023      8   25      37.687500          5        0     51.714931   \n",
      "2023-08-26  2023      8   26      52.541667          6        1     44.456523   \n",
      "2023-08-27  2023      8   27      52.000000          0        1     54.250106   \n",
      "2023-08-28  2023      8   28      48.333333          1        0     45.490767   \n",
      "2023-08-29  2023      8   29      43.583333          2        0     50.903717   \n",
      "2023-08-30  2023      8   30      48.065217          3        0     51.524156   \n",
      "2023-08-31  2023      8   31      48.270833          4        0     46.239267   \n",
      "2023-09-01  2023      9    1      32.437500          5        0     48.048078   \n",
      "2023-09-02  2023      9    2      34.434783          6        1     35.420648   \n",
      "2023-09-03  2023      9    3      53.458333          0        1     44.403170   \n",
      "2023-09-04  2023      9    4      58.354167          1        0     52.723846   \n",
      "2023-09-05  2023      9    5      59.456522          2        0     49.829482   \n",
      "2023-09-06  2023      9    6      68.208333          3        0     58.386205   \n",
      "2023-09-07  2023      9    7      70.500000          4        0     62.826168   \n",
      "2023-09-08  2023      9    8      75.565217          5        0     66.780865   \n",
      "2023-09-09  2023      9    9      79.020833          6        1     65.376139   \n",
      "2023-09-10  2023      9   10      82.229167          0        1     68.506896   \n",
      "2023-09-11  2023      9   11      72.022727          1        0     77.991309   \n",
      "2023-09-12  2023      9   12      47.312500          2        0     67.574601   \n",
      "2023-09-13  2023      9   13      49.062500          3        0     50.471792   \n",
      "2023-09-14  2023      9   14      42.913043          4        0     48.563795   \n",
      "2023-09-15  2023      9   15      48.291667          5        0     48.665908   \n",
      "2023-09-16  2023      9   16      51.270833          6        1     54.737387   \n",
      "2023-09-17  2023      9   17      41.479167          0        1     51.527044   \n",
      "2023-09-18  2023      9   18      53.652174          1        0     43.116231   \n",
      "2023-09-19  2023      9   19      46.433333          2        0     53.564456   \n",
      "2023-09-20  2023      9   20      65.136364          3        0     52.159559   \n",
      "2023-09-21  2023      9   21      44.895833          4        0     61.425785   \n",
      "2023-09-22  2023      9   22      44.375000          5        0     46.267200   \n",
      "2023-09-23  2023      9   23      35.500000          6        1     44.419970   \n",
      "2023-09-24  2023      9   24      46.791667          0        1     45.388745   \n",
      "2023-09-25  2023      9   25      49.270833          1        0     47.368787   \n",
      "2023-09-26  2023      9   26      34.260870          2        0     49.816130   \n",
      "2023-09-27  2023      9   27      44.375000          3        0     37.636960   \n",
      "2023-09-28  2023      9   28      49.604167          4        0     46.879341   \n",
      "2023-09-29  2023      9   29      36.630435          5        0     52.360686   \n",
      "2023-09-30  2023      9   30      37.437500          6        1     37.618513   \n",
      "2023-10-01  2023     10    1      55.395833          0        1     42.095962   \n",
      "2023-10-02  2023     10    2      55.630435          1        0     51.239971   \n",
      "2023-10-03  2023     10    3      63.270833          2        0     54.971335   \n",
      "2023-10-04  2023     10    4      43.541667          3        0     60.393612   \n",
      "2023-10-05  2023     10    5      40.086957          4        0     42.534891   \n",
      "2023-10-06  2023     10    6      49.565217          5        0     43.048204   \n",
      "2023-10-07  2023     10    7      58.916667          6        1     49.826700   \n",
      "2023-10-08  2023     10    8      43.130435          0        1     56.425910   \n",
      "2023-10-09  2023     10    9      29.065217          1        0     46.711346   \n",
      "2023-10-10  2023     10   10            NaN          2        0           NaN   \n",
      "\n",
      "              day_lag1    day_lag7   day_lag30  day_lag365  \n",
      "Date                                                        \n",
      "2022-01-01         NaN         NaN         NaN         NaN  \n",
      "2022-01-02   34.826087         NaN         NaN         NaN  \n",
      "2022-01-03   44.717391         NaN         NaN         NaN  \n",
      "2022-01-04   58.812500         NaN         NaN         NaN  \n",
      "2022-01-05   52.604167         NaN         NaN         NaN  \n",
      "2022-01-06   35.173913         NaN         NaN         NaN  \n",
      "2022-01-07   31.729167         NaN         NaN         NaN  \n",
      "2022-01-08   44.562500   34.826087         NaN         NaN  \n",
      "2022-01-09   47.739130   44.717391         NaN         NaN  \n",
      "2022-01-10   44.416667   58.812500         NaN         NaN  \n",
      "2022-01-11    9.041667   52.604167         NaN         NaN  \n",
      "2022-01-12   15.739130   35.173913         NaN         NaN  \n",
      "2022-01-13    5.270833   31.729167         NaN         NaN  \n",
      "2022-01-14    2.687500   44.562500         NaN         NaN  \n",
      "2022-01-15    4.282609   47.739130         NaN         NaN  \n",
      "2022-01-16    7.937500   44.416667         NaN         NaN  \n",
      "2022-01-17   11.770833    9.041667         NaN         NaN  \n",
      "2022-01-18   14.021739   15.739130         NaN         NaN  \n",
      "2022-01-19   12.645833    5.270833         NaN         NaN  \n",
      "2022-01-20   15.250000    2.687500         NaN         NaN  \n",
      "2022-01-21   54.695652    4.282609         NaN         NaN  \n",
      "2022-01-22   32.541667    7.937500         NaN         NaN  \n",
      "2022-01-23   32.145833   11.770833         NaN         NaN  \n",
      "2022-01-24   34.391304   14.021739         NaN         NaN  \n",
      "2022-01-25   28.125000   12.645833         NaN         NaN  \n",
      "2022-01-26    4.687500   15.250000         NaN         NaN  \n",
      "2022-01-27   12.500000   54.695652         NaN         NaN  \n",
      "2022-01-28   26.729167   32.541667         NaN         NaN  \n",
      "2022-01-29   12.687500   32.145833         NaN         NaN  \n",
      "2022-01-30   45.043478   34.391304         NaN         NaN  \n",
      "2022-01-31   45.083333   28.125000   34.826087         NaN  \n",
      "2022-02-01   67.520833    4.687500   44.717391         NaN  \n",
      "2022-02-02   42.586957   12.500000   58.812500         NaN  \n",
      "2022-02-03   41.270833   26.729167   52.604167         NaN  \n",
      "2022-02-04   40.520833   12.687500   35.173913         NaN  \n",
      "2022-02-05   49.891304   45.043478   31.729167         NaN  \n",
      "2022-02-06   49.687500   45.083333   44.562500         NaN  \n",
      "2022-02-07   63.229167   67.520833   47.739130         NaN  \n",
      "2022-02-08   52.916667   42.586957   44.416667         NaN  \n",
      "2022-02-09   52.217391   41.270833    9.041667         NaN  \n",
      "2022-02-10   43.166667   40.520833   15.739130         NaN  \n",
      "2022-02-11   30.041667   49.891304    5.270833         NaN  \n",
      "2022-02-12   33.760870   49.687500    2.687500         NaN  \n",
      "2022-02-13   38.729167   63.229167    4.282609         NaN  \n",
      "2022-02-14   59.812500   52.916667    7.937500         NaN  \n",
      "2022-02-15   60.739130   52.217391   11.770833         NaN  \n",
      "2022-02-16   48.937500   43.166667   14.021739         NaN  \n",
      "2022-02-17   55.770833   30.041667   12.645833         NaN  \n",
      "2022-02-18   70.369565   33.760870   15.250000         NaN  \n",
      "2022-02-19   63.083333   38.729167   54.695652         NaN  \n",
      "2022-02-20   65.083333   59.812500   32.541667         NaN  \n",
      "2022-02-21   65.847826   60.739130   32.145833         NaN  \n",
      "2022-02-22   68.437500   48.937500   34.391304         NaN  \n",
      "2022-02-23   39.958333   55.770833   28.125000         NaN  \n",
      "2022-02-24   43.782609   70.369565    4.687500         NaN  \n",
      "2022-02-25   55.770833   63.083333   12.500000         NaN  \n",
      "2022-02-26   50.791667   65.083333   26.729167         NaN  \n",
      "2022-02-27   33.543478   65.847826   12.687500         NaN  \n",
      "2022-02-28   48.104167   68.437500   45.043478         NaN  \n",
      "2022-03-01   40.187500   39.958333   45.083333         NaN  \n",
      "2022-03-02   19.369565   43.782609   67.520833         NaN  \n",
      "2022-03-03   19.270833   55.770833   42.586957         NaN  \n",
      "2022-03-04   24.062500   50.791667   41.270833         NaN  \n",
      "2022-03-05   31.434783   33.543478   40.520833         NaN  \n",
      "2022-03-06   24.687500   48.104167   49.891304         NaN  \n",
      "2022-03-07   41.326087   40.187500   49.687500         NaN  \n",
      "2022-03-08   47.708333   19.369565   63.229167         NaN  \n",
      "2022-03-09   43.729167   19.270833   52.916667         NaN  \n",
      "2022-03-10   48.847826   24.062500   52.217391         NaN  \n",
      "2022-03-11   63.770833   31.434783   43.166667         NaN  \n",
      "2022-03-12   64.979167   24.687500   30.041667         NaN  \n",
      "2022-03-13   74.086957   41.326087   33.760870         NaN  \n",
      "2022-03-14   81.645833   47.708333   38.729167         NaN  \n",
      "2022-03-15   51.333333   43.729167   59.812500         NaN  \n",
      "2022-03-16   34.125000   48.847826   60.739130         NaN  \n",
      "2022-03-17   24.260870   63.770833   48.937500         NaN  \n",
      "2022-03-18   48.052632   64.979167   55.770833         NaN  \n",
      "2022-03-19   39.725000   74.086957   70.369565         NaN  \n",
      "2022-03-20   63.695652   81.645833   63.083333         NaN  \n",
      "2022-03-21   56.166667   51.333333   65.083333         NaN  \n",
      "2022-03-22   41.108696   34.125000   65.847826         NaN  \n",
      "2022-03-23   50.250000   24.260870   68.437500         NaN  \n",
      "2022-03-24   52.979167   48.052632   39.958333         NaN  \n",
      "2022-03-25   50.978261   39.725000   43.782609         NaN  \n",
      "2022-03-26   61.416667   63.695652   55.770833         NaN  \n",
      "2022-03-27   69.583333   56.166667   50.791667         NaN  \n",
      "2022-03-28   35.736842   41.108696   33.543478         NaN  \n",
      "2022-03-29         NaN   50.250000   48.104167         NaN  \n",
      "2022-03-30         NaN   52.979167   40.187500         NaN  \n",
      "2022-03-31   45.000000   50.978261   19.369565         NaN  \n",
      "2022-04-01   49.477273   61.416667   19.270833         NaN  \n",
      "2022-04-02   54.979167   69.583333   24.062500         NaN  \n",
      "2022-04-03   69.130435   35.736842   31.434783         NaN  \n",
      "2022-04-04   57.562500         NaN   24.687500         NaN  \n",
      "2022-04-05   48.565217         NaN   41.326087         NaN  \n",
      "2022-04-06   37.272727   45.000000   47.708333         NaN  \n",
      "2022-04-07   53.416667   49.477273   43.729167         NaN  \n",
      "2022-04-08   65.395833   54.979167   48.847826         NaN  \n",
      "2022-04-09   49.413043   69.130435   63.770833         NaN  \n",
      "2022-04-10   57.916667   57.562500   64.979167         NaN  \n",
      "2022-04-11   55.250000   48.565217   74.086957         NaN  \n",
      "2022-04-12   62.479167   37.272727   81.645833         NaN  \n",
      "2022-04-13   56.347826   53.416667   51.333333         NaN  \n",
      "2022-04-14   19.520833   65.395833   34.125000         NaN  \n",
      "2022-04-15   33.270833   49.413043   24.260870         NaN  \n",
      "2022-04-16   38.456522   57.916667   48.052632         NaN  \n",
      "2022-04-17   54.520833   55.250000   39.725000         NaN  \n",
      "2022-04-18   58.875000   62.479167   63.695652         NaN  \n",
      "2022-04-19   63.130435   56.347826   56.166667         NaN  \n",
      "2022-04-20   56.645833   19.520833   41.108696         NaN  \n",
      "2022-04-21   63.604167   33.270833   50.250000         NaN  \n",
      "2022-04-22   64.586957   38.456522   52.979167         NaN  \n",
      "2022-04-23   52.395833   54.520833   50.978261         NaN  \n",
      "2022-04-24   68.041667   58.875000   61.416667         NaN  \n",
      "2022-04-25   78.304348   63.130435   69.583333         NaN  \n",
      "2022-04-26   45.791667   56.645833   35.736842         NaN  \n",
      "2022-04-27   58.958333   63.604167         NaN         NaN  \n",
      "2022-04-28   67.130435   64.586957         NaN         NaN  \n",
      "2022-04-29   66.541667   52.395833   45.000000         NaN  \n",
      "2022-04-30   44.250000   68.041667   49.477273         NaN  \n",
      "2022-05-01   66.130435   78.304348   54.979167         NaN  \n",
      "2022-05-02   58.854167   45.791667   69.130435         NaN  \n",
      "2022-05-03   60.479167   58.958333   57.562500         NaN  \n",
      "2022-05-04   60.043478   67.130435   48.565217         NaN  \n",
      "2022-05-05   52.145833   66.541667   37.272727         NaN  \n",
      "2022-05-06   36.937500   44.250000   53.416667         NaN  \n",
      "2022-05-07   46.934783   66.130435   65.395833         NaN  \n",
      "2022-05-08   45.083333   58.854167   49.413043         NaN  \n",
      "2022-05-09   61.729167   60.479167   57.916667         NaN  \n",
      "2022-05-10   64.978261   60.043478   55.250000         NaN  \n",
      "2022-05-11   60.104167   52.145833   62.479167         NaN  \n",
      "2022-05-12   66.333333   36.937500   56.347826         NaN  \n",
      "2022-05-13   56.782609   46.934783   19.520833         NaN  \n",
      "2022-05-14   60.833333   45.083333   33.270833         NaN  \n",
      "2022-05-15   73.625000   61.729167   38.456522         NaN  \n",
      "2022-05-16   82.608696   64.978261   54.520833         NaN  \n",
      "2022-05-17   61.666667   60.104167   58.875000         NaN  \n",
      "2022-05-18   58.750000   66.333333   63.130435         NaN  \n",
      "2022-05-19   75.956522   56.782609   56.645833         NaN  \n",
      "2022-05-20   58.666667   60.833333   63.604167         NaN  \n",
      "2022-05-21   48.386364   73.625000   64.586957         NaN  \n",
      "2022-05-22   67.065217   82.608696   52.395833         NaN  \n",
      "2022-05-23   73.791667   61.666667   68.041667         NaN  \n",
      "2022-05-24   50.043478   58.750000   78.304348         NaN  \n",
      "2022-05-25   55.434783   75.956522   45.791667         NaN  \n",
      "2022-05-26   55.791667   58.666667   58.958333         NaN  \n",
      "2022-05-27   56.812500   48.386364   67.130435         NaN  \n",
      "2022-05-28   62.521739   67.065217   66.541667         NaN  \n",
      "2022-05-29   60.000000   73.791667   44.250000         NaN  \n",
      "2022-05-30   57.166667   50.043478   66.130435         NaN  \n",
      "2022-05-31   52.239130   55.434783   58.854167         NaN  \n",
      "2022-06-01   52.666667   55.791667   60.479167         NaN  \n",
      "2022-06-02   59.812500   56.812500   60.043478         NaN  \n",
      "2022-06-03   75.041667   62.521739   52.145833         NaN  \n",
      "2022-06-04   87.391304   60.000000   36.937500         NaN  \n",
      "2022-06-05   90.062500   57.166667   46.934783         NaN  \n",
      "2022-06-06   47.645833   52.239130   45.083333         NaN  \n",
      "2022-06-07   57.782609   52.666667   61.729167         NaN  \n",
      "2022-06-08   41.291667   59.812500   64.978261         NaN  \n",
      "2022-06-09   31.812500   75.041667   60.104167         NaN  \n",
      "2022-06-10   48.391304   87.391304   66.333333         NaN  \n",
      "2022-06-11   47.062500   90.062500   56.782609         NaN  \n",
      "2022-06-12   54.604167   47.645833   60.833333         NaN  \n",
      "2022-06-13   62.369565   57.782609   73.625000         NaN  \n",
      "2022-06-14   62.166667   41.291667   82.608696         NaN  \n",
      "2022-06-15   73.062500   31.812500   61.666667         NaN  \n",
      "2022-06-16   95.521739   48.391304   58.750000         NaN  \n",
      "2022-06-17   90.090909   47.062500   75.956522         NaN  \n",
      "2022-06-18   93.282609   54.604167   58.666667         NaN  \n",
      "2022-06-19  104.804348   62.369565   48.386364         NaN  \n",
      "2022-06-20   59.229167   62.166667   67.065217         NaN  \n",
      "2022-06-21   60.229167   73.062500   73.791667         NaN  \n",
      "2022-06-22   50.500000   95.521739   50.043478         NaN  \n",
      "2022-06-23   78.791667   90.090909   55.434783         NaN  \n",
      "2022-06-24   74.020833   93.282609   55.791667         NaN  \n",
      "2022-06-25   55.586957  104.804348   56.812500         NaN  \n",
      "2022-06-26   44.187500   59.229167   62.521739         NaN  \n",
      "2022-06-27   45.208333   60.229167   60.000000         NaN  \n",
      "2022-06-28   31.934783   50.500000   57.166667         NaN  \n",
      "2022-06-29   56.291667   78.791667   52.239130         NaN  \n",
      "2022-06-30   68.229167   74.020833   52.666667         NaN  \n",
      "2022-07-01   37.152174   55.586957   59.812500         NaN  \n",
      "2022-07-02   42.208333   44.187500   75.041667         NaN  \n",
      "2022-07-03   58.312500   45.208333   87.391304         NaN  \n",
      "2022-07-04   55.021739   31.934783   90.062500         NaN  \n",
      "2022-07-05   52.708333   56.291667   47.645833         NaN  \n",
      "2022-07-06   56.041667   68.229167   57.782609         NaN  \n",
      "2022-07-07   61.717391   37.152174   41.291667         NaN  \n",
      "2022-07-08   47.250000   42.208333   31.812500         NaN  \n",
      "2022-07-09   58.666667   58.312500   48.391304         NaN  \n",
      "2022-07-10   60.739130   55.021739   47.062500         NaN  \n",
      "2022-07-11   50.541667   52.708333   54.604167         NaN  \n",
      "2022-07-12   51.770833   56.041667   62.369565         NaN  \n",
      "2022-07-13   57.021739   61.717391   62.166667         NaN  \n",
      "2022-07-14   76.895833   47.250000   73.062500         NaN  \n",
      "2022-07-15   56.895833   58.666667   95.521739         NaN  \n",
      "2022-07-16   54.347826   60.739130   90.090909         NaN  \n",
      "2022-07-17   61.000000   50.541667   93.282609         NaN  \n",
      "2022-07-18   68.875000   51.770833  104.804348         NaN  \n",
      "2022-07-19   95.568182   57.021739   59.229167         NaN  \n",
      "2022-07-20  110.125000   76.895833   60.229167         NaN  \n",
      "2022-07-21   80.583333   56.895833   50.500000         NaN  \n",
      "2022-07-22   49.652174   54.347826   78.791667         NaN  \n",
      "2022-07-23   50.208333   61.000000   74.020833         NaN  \n",
      "2022-07-24   68.916667   68.875000   55.586957         NaN  \n",
      "2022-07-25   79.152174   95.568182   44.187500         NaN  \n",
      "2022-07-26   56.437500  110.125000   45.208333         NaN  \n",
      "2022-07-27   51.562500   80.583333   31.934783         NaN  \n",
      "2022-07-28   56.934783   49.652174   56.291667         NaN  \n",
      "2022-07-29   70.125000   50.208333   68.229167         NaN  \n",
      "2022-07-30   86.812500   68.916667   37.152174         NaN  \n",
      "2022-07-31   76.065217   79.152174   42.208333         NaN  \n",
      "2022-08-01   47.229167   56.437500   58.312500         NaN  \n",
      "2022-08-02   57.625000   51.562500   55.021739         NaN  \n",
      "2022-08-03   55.478261   56.934783   52.708333         NaN  \n",
      "2022-08-04   48.000000   70.125000   56.041667         NaN  \n",
      "2022-08-05   40.666667   86.812500   61.717391         NaN  \n",
      "2022-08-06   56.295455   76.065217   47.250000         NaN  \n",
      "2022-08-07   55.458333   47.229167   58.666667         NaN  \n",
      "2022-08-08   73.270833   57.625000   60.739130         NaN  \n",
      "2022-08-09   70.416667   55.478261   50.541667         NaN  \n",
      "2022-08-10   70.043478   48.000000   51.770833         NaN  \n",
      "2022-08-11   91.166667   40.666667   57.021739         NaN  \n",
      "2022-08-12  103.520833   56.295455   76.895833         NaN  \n",
      "2022-08-13  106.217391   55.458333   56.895833         NaN  \n",
      "2022-08-14   97.291667   73.270833   54.347826         NaN  \n",
      "2022-08-15  100.708333   70.416667   61.000000         NaN  \n",
      "2022-08-16   92.217391   70.043478   68.875000         NaN  \n",
      "2022-08-17  102.583333   91.166667   95.568182         NaN  \n",
      "2022-08-18   70.416667  103.520833  110.125000         NaN  \n",
      "2022-08-19   80.565217  106.217391   80.583333         NaN  \n",
      "2022-08-20   39.937500   97.291667   49.652174         NaN  \n",
      "2022-08-21   50.145833  100.708333   50.208333         NaN  \n",
      "2022-08-22   47.700000   92.217391   68.916667         NaN  \n",
      "2022-08-23   97.545455  102.583333   79.152174         NaN  \n",
      "2022-08-24   53.000000   70.416667   56.437500         NaN  \n",
      "2022-08-25   74.604167   80.565217   51.562500         NaN  \n",
      "2022-08-26   89.791667   39.937500   56.934783         NaN  \n",
      "2022-08-27   64.608696   50.145833   70.125000         NaN  \n",
      "2022-08-28   58.604167   47.700000   86.812500         NaN  \n",
      "2022-08-29   69.062500   97.545455   76.065217         NaN  \n",
      "2022-08-30   64.413043   53.000000   47.229167         NaN  \n",
      "2022-08-31   66.354167   74.604167   57.625000         NaN  \n",
      "2022-09-01   72.020833   89.791667   55.478261         NaN  \n",
      "2022-09-02   74.304348   64.608696   48.000000         NaN  \n",
      "2022-09-03   69.041667   58.604167   40.666667         NaN  \n",
      "2022-09-04   71.020833   69.062500   56.295455         NaN  \n",
      "2022-09-05   64.104167   64.413043   55.458333         NaN  \n",
      "2022-09-06   75.847826   66.354167   73.270833         NaN  \n",
      "2022-09-07   59.227273   72.020833   70.416667         NaN  \n",
      "2022-09-08   57.416667   74.304348   70.043478         NaN  \n",
      "2022-09-09   47.391304   69.041667   91.166667         NaN  \n",
      "2022-09-10   48.395833   71.020833  103.520833         NaN  \n",
      "2022-09-11   47.541667   64.104167  106.217391         NaN  \n",
      "2022-09-12   49.500000   75.847826   97.291667         NaN  \n",
      "2022-09-13   45.875000   59.227273  100.708333         NaN  \n",
      "2022-09-14   34.354167   57.416667   92.217391         NaN  \n",
      "2022-09-15   25.217391   47.391304  102.583333         NaN  \n",
      "2022-09-16   33.062500   48.395833   70.416667         NaN  \n",
      "2022-09-17   43.166667   47.541667   80.565217         NaN  \n",
      "2022-09-18   35.173913   49.500000   39.937500         NaN  \n",
      "2022-09-19   37.645833   45.875000   50.145833         NaN  \n",
      "2022-09-20   36.166667   34.354167   47.700000         NaN  \n",
      "2022-09-21   33.521739   25.217391   97.545455         NaN  \n",
      "2022-09-22   27.375000   33.062500   53.000000         NaN  \n",
      "2022-09-23   32.770833   43.166667   74.604167         NaN  \n",
      "2022-09-24   32.847826   35.173913   89.791667         NaN  \n",
      "2022-09-25   45.291667   37.645833   64.608696         NaN  \n",
      "2022-09-26   39.604167   36.166667   58.604167         NaN  \n",
      "2022-09-27   36.586957   33.521739   69.062500         NaN  \n",
      "2022-09-28   36.333333   27.375000   64.413043         NaN  \n",
      "2022-09-29   29.604167   32.770833   66.354167         NaN  \n",
      "2022-09-30   22.782609   32.847826   72.020833         NaN  \n",
      "2022-10-01   31.312500   45.291667   74.304348         NaN  \n",
      "2022-10-02   47.291667   39.604167   69.041667         NaN  \n",
      "2022-10-03   38.434783   36.586957   71.020833         NaN  \n",
      "2022-10-04   18.437500   36.333333   64.104167         NaN  \n",
      "2022-10-05   30.250000   29.604167   75.847826         NaN  \n",
      "2022-10-06   47.214286   22.782609   59.227273         NaN  \n",
      "2022-10-07   40.458333   31.312500   57.416667         NaN  \n",
      "2022-10-08   33.375000   47.291667   47.391304         NaN  \n",
      "2022-10-09   41.380952   38.434783   48.395833         NaN  \n",
      "2022-10-10    7.000000   18.437500   47.541667         NaN  \n",
      "2022-10-11   41.500000   30.250000   49.500000         NaN  \n",
      "2022-10-12    5.833333   47.214286   45.875000         NaN  \n",
      "2022-10-13   18.477273   40.458333   34.354167         NaN  \n",
      "2022-10-14   21.708333   33.375000   25.217391         NaN  \n",
      "2022-10-15   23.391304   41.380952   33.062500         NaN  \n",
      "2022-10-16   37.166667    7.000000   43.166667         NaN  \n",
      "2022-10-17   37.729167   41.500000   35.173913         NaN  \n",
      "2022-10-18   21.500000    5.833333   37.645833         NaN  \n",
      "2022-10-19   26.729167   18.477273   36.166667         NaN  \n",
      "2022-10-20   22.937500   21.708333   33.521739         NaN  \n",
      "2022-10-21   20.608696   23.391304   27.375000         NaN  \n",
      "2022-10-22   41.208333   37.166667   32.770833         NaN  \n",
      "2022-10-23   38.687500   37.729167   32.847826         NaN  \n",
      "2022-10-24   37.333333   21.500000   45.291667         NaN  \n",
      "2022-10-25   51.714286   26.729167   39.604167         NaN  \n",
      "2022-10-26   41.000000   22.937500   36.586957         NaN  \n",
      "2022-10-27         NaN   20.608696   36.333333         NaN  \n",
      "2022-10-28         NaN   41.208333   29.604167         NaN  \n",
      "2022-10-29         NaN   38.687500   22.782609         NaN  \n",
      "2022-10-30         NaN   37.333333   31.312500         NaN  \n",
      "2022-10-31         NaN   51.714286   47.291667         NaN  \n",
      "2022-11-01         NaN   41.000000   38.434783         NaN  \n",
      "2022-11-02         NaN         NaN   18.437500         NaN  \n",
      "2022-11-03         NaN         NaN   30.250000         NaN  \n",
      "2022-11-04         NaN         NaN   47.214286         NaN  \n",
      "2022-11-05         NaN         NaN   40.458333         NaN  \n",
      "2022-11-06         NaN         NaN   33.375000         NaN  \n",
      "2022-11-07         NaN         NaN   41.380952         NaN  \n",
      "2022-11-08   52.400000         NaN    7.000000         NaN  \n",
      "2022-11-09   47.750000         NaN   41.500000         NaN  \n",
      "2022-11-10   46.479167         NaN    5.833333         NaN  \n",
      "2022-11-11   33.142857         NaN   18.477273         NaN  \n",
      "2022-11-12   29.125000         NaN   21.708333         NaN  \n",
      "2022-11-13    8.062500         NaN   23.391304         NaN  \n",
      "2022-11-14    6.750000   52.400000   37.166667         NaN  \n",
      "2022-11-15    5.586957   47.750000   37.729167         NaN  \n",
      "2022-11-16   34.541667   46.479167   21.500000         NaN  \n",
      "2022-11-17   38.416667   33.142857   26.729167         NaN  \n",
      "2022-11-18   53.521739   29.125000   22.937500         NaN  \n",
      "2022-11-19   29.895833    8.062500   20.608696         NaN  \n",
      "2022-11-20    6.229167    6.750000   41.208333         NaN  \n",
      "2022-11-21    4.000000    5.586957   38.687500         NaN  \n",
      "2022-11-22   36.692308   34.541667   37.333333         NaN  \n",
      "2022-11-23   44.770833   38.416667   51.714286         NaN  \n",
      "2022-11-24   36.888889   53.521739   41.000000         NaN  \n",
      "2022-11-25   45.026316   29.895833         NaN         NaN  \n",
      "2022-11-26   28.333333    6.229167         NaN         NaN  \n",
      "2022-11-27   21.543478    4.000000         NaN         NaN  \n",
      "2022-11-28   32.312500   36.692308         NaN         NaN  \n",
      "2022-11-29   16.937500   44.770833         NaN         NaN  \n",
      "2022-11-30    6.600000   36.888889         NaN         NaN  \n",
      "2022-12-01         NaN   45.026316         NaN         NaN  \n",
      "2022-12-02    8.807692   28.333333         NaN         NaN  \n",
      "2022-12-03   12.500000   21.543478         NaN         NaN  \n",
      "2022-12-04   10.375000   32.312500         NaN         NaN  \n",
      "2022-12-05    6.833333   16.937500         NaN         NaN  \n",
      "2022-12-06    2.326087    6.600000         NaN         NaN  \n",
      "2022-12-07    9.479167         NaN   52.400000         NaN  \n",
      "2022-12-08   16.775000    8.807692   47.750000         NaN  \n",
      "2022-12-09   16.891304   12.500000   46.479167         NaN  \n",
      "2022-12-10   10.875000   10.375000   33.142857         NaN  \n",
      "2022-12-11   19.104167    6.833333   29.125000         NaN  \n",
      "2022-12-12   29.260870    2.326087    8.062500         NaN  \n",
      "2022-12-13   12.604167    9.479167    6.750000         NaN  \n",
      "2022-12-14    3.750000   16.775000    5.586957         NaN  \n",
      "2022-12-15    3.673913   16.891304   34.541667         NaN  \n",
      "2022-12-16    2.000000   10.875000   38.416667         NaN  \n",
      "2022-12-17    5.437500   19.104167   53.521739         NaN  \n",
      "2022-12-18    3.130435   29.260870   29.895833         NaN  \n",
      "2022-12-19   13.458333   12.604167    6.229167         NaN  \n",
      "2022-12-20   32.666667    3.750000    4.000000         NaN  \n",
      "2022-12-21   32.608696    3.673913   36.692308         NaN  \n",
      "2022-12-22   28.166667    2.000000   44.770833         NaN  \n",
      "2022-12-23   31.041667    5.437500   36.888889         NaN  \n",
      "2022-12-24   42.304348    3.130435   45.026316         NaN  \n",
      "2022-12-25   44.333333   13.458333   28.333333         NaN  \n",
      "2022-12-26   29.937500   32.666667   21.543478         NaN  \n",
      "2022-12-27   46.521739   32.608696   32.312500         NaN  \n",
      "2022-12-28   42.270833   28.166667   16.937500         NaN  \n",
      "2022-12-29   50.041667   31.041667    6.600000         NaN  \n",
      "2022-12-30   55.108696   42.304348         NaN         NaN  \n",
      "2022-12-31   43.977273   44.333333    8.807692         NaN  \n",
      "2023-01-01         NaN   29.937500   12.500000   34.826087  \n",
      "2023-01-02   49.545455   46.521739   10.375000   44.717391  \n",
      "2023-01-03   48.083333   42.270833    6.833333   58.812500  \n",
      "2023-01-04   41.729167   50.041667    2.326087   52.604167  \n",
      "2023-01-05   54.727273   55.108696    9.479167   35.173913  \n",
      "2023-01-06   46.520833   43.977273   16.775000   31.729167  \n",
      "2023-01-07   43.583333         NaN   16.891304   44.562500  \n",
      "2023-01-08   51.369565   49.545455   10.875000   47.739130  \n",
      "2023-01-09   65.145833   48.083333   19.104167   44.416667  \n",
      "2023-01-10   54.312500   41.729167   29.260870    9.041667  \n",
      "2023-01-11   41.652174   54.727273   12.604167   15.739130  \n",
      "2023-01-12   53.375000   46.520833    3.750000    5.270833  \n",
      "2023-01-13   54.395833   43.583333    3.673913    2.687500  \n",
      "2023-01-14   60.625000   51.369565    2.000000    4.282609  \n",
      "2023-01-15   55.369565   65.145833    5.437500    7.937500  \n",
      "2023-01-16   64.354167   54.312500    3.130435   11.770833  \n",
      "2023-01-17   55.687500   41.652174   13.458333   14.021739  \n",
      "2023-01-18   22.717391   53.375000   32.666667   12.645833  \n",
      "2023-01-19   15.020833   54.395833   32.608696   15.250000  \n",
      "2023-01-20   21.958333   60.625000   28.166667   54.695652  \n",
      "2023-01-21   24.847826   55.369565   31.041667   32.541667  \n",
      "2023-01-22   18.562500   64.354167   42.304348   32.145833  \n",
      "2023-01-23   30.645833   55.687500   44.333333   34.391304  \n",
      "2023-01-24   13.652174   22.717391   29.937500   28.125000  \n",
      "2023-01-25   22.395833   15.020833   46.521739    4.687500  \n",
      "2023-01-26   11.770833   21.958333   42.270833   12.500000  \n",
      "2023-01-27   25.695652   24.847826   50.041667   26.729167  \n",
      "2023-01-28   43.395833   18.562500   55.108696   12.687500  \n",
      "2023-01-29   40.916667   30.645833   43.977273   45.043478  \n",
      "2023-01-30   20.195652   13.652174         NaN   45.083333  \n",
      "2023-01-31   44.125000   22.395833   49.545455   67.520833  \n",
      "2023-02-01   25.666667   11.770833   48.083333   42.586957  \n",
      "2023-02-02   50.022727   25.695652   41.729167   41.270833  \n",
      "2023-02-03   51.625000   43.395833   54.727273   40.520833  \n",
      "2023-02-04   52.354167   40.916667   46.520833   49.891304  \n",
      "2023-02-05   26.239130   20.195652   43.583333   49.687500  \n",
      "2023-02-06   53.416667   44.125000   51.369565   63.229167  \n",
      "2023-02-07   23.270833   25.666667   65.145833   52.916667  \n",
      "2023-02-08   11.173913   50.022727   54.312500   52.217391  \n",
      "2023-02-09   14.166667   51.625000   41.652174   43.166667  \n",
      "2023-02-10   16.833333   52.354167   53.375000   30.041667  \n",
      "2023-02-11   15.260870   26.239130   54.395833   33.760870  \n",
      "2023-02-12   28.145833   53.416667   60.625000   38.729167  \n",
      "2023-02-13   36.770833   23.270833   55.369565   59.812500  \n",
      "2023-02-14   12.782609   11.173913   64.354167   60.739130  \n",
      "2023-02-15    9.895833   14.166667   55.687500   48.937500  \n",
      "2023-02-16   14.520833   16.833333   22.717391   55.770833  \n",
      "2023-02-17   27.478261   15.260870   15.020833   70.369565  \n",
      "2023-02-18   52.979167   28.145833   21.958333   63.083333  \n",
      "2023-02-19   60.645833   36.770833   24.847826   65.083333  \n",
      "2023-02-20   49.869565   12.782609   18.562500   65.847826  \n",
      "2023-02-21   49.250000    9.895833   30.645833   68.437500  \n",
      "2023-02-22         NaN   14.520833   13.652174   39.958333  \n",
      "2023-02-23         NaN   27.478261   22.395833   43.782609  \n",
      "2023-02-24         NaN   52.979167   11.770833   55.770833  \n",
      "2023-02-25   56.125000   60.645833   25.695652   50.791667  \n",
      "2023-02-26   44.781250   49.869565   43.395833   33.543478  \n",
      "2023-02-27         NaN   49.250000   40.916667   48.104167  \n",
      "2023-02-28   48.312500         NaN   20.195652   40.187500  \n",
      "2023-03-01   35.977273         NaN   44.125000   19.369565  \n",
      "2023-03-02   38.590909         NaN   25.666667   19.270833  \n",
      "2023-03-03   31.130435   56.125000   50.022727   24.062500  \n",
      "2023-03-04   39.522727   44.781250   51.625000   31.434783  \n",
      "2023-03-05   66.437500         NaN   52.354167   24.687500  \n",
      "2023-03-06   53.687500   48.312500   26.239130   41.326087  \n",
      "2023-03-07   46.666667   35.977273   53.416667   47.708333  \n",
      "2023-03-08   51.062500   38.590909   23.270833   43.729167  \n",
      "2023-03-09   32.979167   31.130435   11.173913   48.847826  \n",
      "2023-03-10   26.217391   39.522727   14.166667   63.770833  \n",
      "2023-03-11   54.729167   66.437500   16.833333   64.979167  \n",
      "2023-03-12   46.062500   53.687500   15.260870   74.086957  \n",
      "2023-03-13   60.565217   46.666667   28.145833   81.645833  \n",
      "2023-03-14   48.166667   51.062500   36.770833   51.333333  \n",
      "2023-03-15   60.333333   32.979167   12.782609   34.125000  \n",
      "2023-03-16   52.456522   26.217391    9.895833   24.260870  \n",
      "2023-03-17   63.666667   54.729167   14.520833   48.052632  \n",
      "2023-03-18   54.812500   46.062500   27.478261   39.725000  \n",
      "2023-03-19   60.416667   60.565217   52.979167   63.695652  \n",
      "2023-03-20   52.673913   48.166667   60.645833   56.166667  \n",
      "2023-03-21   48.145833   60.333333   49.869565   41.108696  \n",
      "2023-03-22   48.071429   52.456522   49.250000   50.250000  \n",
      "2023-03-23   58.857143   63.666667         NaN   52.979167  \n",
      "2023-03-24   70.375000   54.812500         NaN   50.978261  \n",
      "2023-03-25   68.750000   60.416667         NaN   61.416667  \n",
      "2023-03-26   73.750000   52.673913   56.125000   69.583333  \n",
      "2023-03-27   64.458333   48.145833   44.781250   35.736842  \n",
      "2023-03-28   69.739130   48.071429         NaN         NaN  \n",
      "2023-03-29   50.500000   58.857143   48.312500         NaN  \n",
      "2023-03-30   46.125000   70.375000   35.977273   45.000000  \n",
      "2023-03-31   68.204545   68.750000   38.590909   49.477273  \n",
      "2023-04-01   65.458333   73.750000   31.130435   54.979167  \n",
      "2023-04-02   46.270833   64.458333   39.522727   69.130435  \n",
      "2023-04-03   51.304348   69.739130   66.437500   57.562500  \n",
      "2023-04-04   47.812500   50.500000   53.687500   48.565217  \n",
      "2023-04-05   55.750000   46.125000   46.666667   37.272727  \n",
      "2023-04-06   48.812500   68.204545   51.062500   53.416667  \n",
      "2023-04-07   49.347826   65.458333   32.979167   65.395833  \n",
      "2023-04-08   63.020833   46.270833   26.217391   49.413043  \n",
      "2023-04-09   59.833333   51.304348   54.729167   57.916667  \n",
      "2023-04-10   51.869565   47.812500   46.062500   55.250000  \n",
      "2023-04-11   65.229167   55.750000   60.565217   62.479167  \n",
      "2023-04-12   71.979167   48.812500   48.166667   56.347826  \n",
      "2023-04-13   73.086957   49.347826   60.333333   19.520833  \n",
      "2023-04-14   72.500000   63.020833   52.456522   33.270833  \n",
      "2023-04-15   55.229167   59.833333   63.666667   38.456522  \n",
      "2023-04-16   63.826087   51.869565   54.812500   54.520833  \n",
      "2023-04-17   54.916667   65.229167   60.416667   58.875000  \n",
      "2023-04-18   62.583333   71.979167   52.673913   63.130435  \n",
      "2023-04-19   53.152174   73.086957   48.145833   56.645833  \n",
      "2023-04-20   66.416667   72.500000   48.071429   63.604167  \n",
      "2023-04-21   71.625000   55.229167   58.857143   64.586957  \n",
      "2023-04-22   60.173913   63.826087   70.375000   52.395833  \n",
      "2023-04-23   24.458333   54.916667   68.750000   68.041667  \n",
      "2023-04-24   63.437500   62.583333   73.750000   78.304348  \n",
      "2023-04-25   76.750000   53.152174   64.458333   45.791667  \n",
      "2023-04-26   74.500000   66.416667   69.739130   58.958333  \n",
      "2023-04-27   58.250000   71.625000   50.500000   67.130435  \n",
      "2023-04-28   68.108696   60.173913   46.125000   66.541667  \n",
      "2023-04-29   37.625000   24.458333   68.204545   44.250000  \n",
      "2023-04-30   71.895833   63.437500   65.458333   66.130435  \n",
      "2023-05-01   71.739130   76.750000   46.270833   58.854167  \n",
      "2023-05-02   61.458333   74.500000   51.304348   60.479167  \n",
      "2023-05-03   63.541667   58.250000   47.812500   60.043478  \n",
      "2023-05-04   67.108696   68.108696   55.750000   52.145833  \n",
      "2023-05-05   67.750000   37.625000   48.812500   36.937500  \n",
      "2023-05-06   60.125000   71.895833   49.347826   46.934783  \n",
      "2023-05-07   53.891304   71.739130   63.020833   45.083333  \n",
      "2023-05-08   38.687500   61.458333   59.833333   61.729167  \n",
      "2023-05-09   33.145833   63.541667   51.869565   64.978261  \n",
      "2023-05-10   33.108696   67.108696   65.229167   60.104167  \n",
      "2023-05-11   42.250000   67.750000   71.979167   66.333333  \n",
      "2023-05-12   50.704545   60.125000   73.086957   56.782609  \n",
      "2023-05-13   41.478261   53.891304   72.500000   60.833333  \n",
      "2023-05-14   76.958333   38.687500   55.229167   73.625000  \n",
      "2023-05-15   70.000000   33.145833   63.826087   82.608696  \n",
      "2023-05-16   55.977273   33.108696   54.916667   61.666667  \n",
      "2023-05-17   62.312500   42.250000   62.583333   58.750000  \n",
      "2023-05-18   60.583333   50.704545   53.152174   75.956522  \n",
      "2023-05-19   69.729167   41.478261   66.416667   58.666667  \n",
      "2023-05-20   74.304348   76.958333   71.625000   48.386364  \n",
      "2023-05-21   78.104167   70.000000   60.173913   67.065217  \n",
      "2023-05-22   68.479167   55.977273   24.458333   73.791667  \n",
      "2023-05-23   58.978261   62.312500   63.437500   50.043478  \n",
      "2023-05-24   71.395833   60.583333   76.750000   55.434783  \n",
      "2023-05-25   59.522727   69.729167   74.500000   55.791667  \n",
      "2023-05-26   69.391304   74.304348   58.250000   56.812500  \n",
      "2023-05-27   76.770833   78.104167   68.108696   62.521739  \n",
      "2023-05-28   84.437500   68.479167   37.625000   60.000000  \n",
      "2023-05-29   83.326087   58.978261   71.895833   57.166667  \n",
      "2023-05-30   75.458333   71.395833   71.739130   52.239130  \n",
      "2023-05-31   74.479167   59.522727   61.458333   52.666667  \n",
      "2023-06-01   73.956522   69.391304   63.541667   59.812500  \n",
      "2023-06-02   68.916667   76.770833   67.108696   75.041667  \n",
      "2023-06-03   81.270833   84.437500   67.750000   87.391304  \n",
      "2023-06-04   80.260870   83.326087   60.125000   90.062500  \n",
      "2023-06-05   84.520833   75.458333   53.891304   47.645833  \n",
      "2023-06-06   76.312500   74.479167   38.687500   57.782609  \n",
      "2023-06-07   83.130435   73.956522   33.145833   41.291667  \n",
      "2023-06-08   78.729167   68.916667   33.108696   31.812500  \n",
      "2023-06-09   88.041667   81.270833   42.250000   48.391304  \n",
      "2023-06-10  101.357143   80.260870   50.704545   47.062500  \n",
      "2023-06-11  109.625000   84.520833   41.478261   54.604167  \n",
      "2023-06-12   98.416667   76.312500   76.958333   62.369565  \n",
      "2023-06-13  100.913043   83.130435   70.000000   62.166667  \n",
      "2023-06-14  111.854167   78.729167   55.977273   73.062500  \n",
      "2023-06-15  107.541667   88.041667   62.312500   95.521739  \n",
      "2023-06-16   93.956522  101.357143   60.583333   90.090909  \n",
      "2023-06-17  109.645833  109.625000   69.729167   93.282609  \n",
      "2023-06-18  108.187500   98.416667   74.304348  104.804348  \n",
      "2023-06-19   98.869565  100.913043   78.104167   59.229167  \n",
      "2023-06-20   74.261905  111.854167   68.479167   60.229167  \n",
      "2023-06-21   68.369565  107.541667   58.978261   50.500000  \n",
      "2023-06-22   63.340909   93.956522   71.395833   78.791667  \n",
      "2023-06-23   51.473684  109.645833   59.522727   74.020833  \n",
      "2023-06-24   67.847826  108.187500   69.391304   55.586957  \n",
      "2023-06-25   70.978261   98.869565   76.770833   44.187500  \n",
      "2023-06-26   96.645833   74.261905   84.437500   45.208333  \n",
      "2023-06-27   72.604167   68.369565   83.326087   31.934783  \n",
      "2023-06-28   62.913043   63.340909   75.458333   56.291667  \n",
      "2023-06-29   52.770833   51.473684   74.479167   68.229167  \n",
      "2023-06-30   51.604167   67.847826   73.956522   37.152174  \n",
      "2023-07-01   60.086957   70.978261   68.916667   42.208333  \n",
      "2023-07-02   41.083333   96.645833   81.270833   58.312500  \n",
      "2023-07-03   71.500000   72.604167   80.260870   55.021739  \n",
      "2023-07-04   63.673913   62.913043   84.520833   52.708333  \n",
      "2023-07-05   58.956522   52.770833   76.312500   56.041667  \n",
      "2023-07-06   59.312500   51.604167   83.130435   61.717391  \n",
      "2023-07-07   63.608696   60.086957   78.729167   47.250000  \n",
      "2023-07-08   76.416667   41.083333   88.041667   58.666667  \n",
      "2023-07-09   80.104167   71.500000  101.357143   60.739130  \n",
      "2023-07-10   68.586957   63.673913  109.625000   50.541667  \n",
      "2023-07-11   67.562500   58.956522   98.416667   51.770833  \n",
      "2023-07-12   58.375000   59.312500  100.913043   57.021739  \n",
      "2023-07-13   58.391304   63.608696  111.854167   76.895833  \n",
      "2023-07-14   59.958333   76.416667  107.541667   56.895833  \n",
      "2023-07-15   72.041667   80.104167   93.956522   54.347826  \n",
      "2023-07-16   54.130435   68.586957  109.645833   61.000000  \n",
      "2023-07-17   52.312500   67.562500  108.187500   68.875000  \n",
      "2023-07-18   55.000000   58.375000   98.869565   95.568182  \n",
      "2023-07-19   62.065217   58.391304   74.261905  110.125000  \n",
      "2023-07-20   52.250000   59.958333   68.369565   80.583333  \n",
      "2023-07-21   44.833333   72.041667   63.340909   49.652174  \n",
      "2023-07-22   48.347826   54.130435   51.473684   50.208333  \n",
      "2023-07-23   58.229167   52.312500   67.847826   68.916667  \n",
      "2023-07-24   46.645833   55.000000   70.978261   79.152174  \n",
      "2023-07-25   44.173913   62.065217   96.645833   56.437500  \n",
      "2023-07-26   51.312500   52.250000   72.604167   51.562500  \n",
      "2023-07-27   60.437500   44.833333   62.913043   56.934783  \n",
      "2023-07-28   34.608696   48.347826   52.770833   70.125000  \n",
      "2023-07-29   33.375000   58.229167   51.604167   86.812500  \n",
      "2023-07-30   45.187500   46.645833   60.086957   76.065217  \n",
      "2023-07-31   52.978261   44.173913   41.083333   47.229167  \n",
      "2023-08-01   38.520833   51.312500   71.500000   57.625000  \n",
      "2023-08-02   51.312500   60.437500   63.673913   55.478261  \n",
      "2023-08-03   49.260870   34.608696   58.956522   48.000000  \n",
      "2023-08-04   48.875000   33.375000   59.312500   40.666667  \n",
      "2023-08-05   45.562500   45.187500   63.608696   56.295455  \n",
      "2023-08-06   45.062500   52.978261   76.416667   55.458333  \n",
      "2023-08-07   56.043478   38.520833   80.104167   73.270833  \n",
      "2023-08-08   54.375000   51.312500   68.586957   70.416667  \n",
      "2023-08-09   44.229167   49.260870   67.562500   70.043478  \n",
      "2023-08-10   53.804348   48.875000   58.375000   91.166667  \n",
      "2023-08-11   60.666667   45.562500   58.391304  103.520833  \n",
      "2023-08-12   61.812500   45.062500   59.958333  106.217391  \n",
      "2023-08-13   51.130435   56.043478   72.041667   97.291667  \n",
      "2023-08-14   55.145833   54.375000   54.130435  100.708333  \n",
      "2023-08-15   59.729167   44.229167   52.312500   92.217391  \n",
      "2023-08-16   60.043478   53.804348   55.000000  102.583333  \n",
      "2023-08-17   63.437500   60.666667   62.065217   70.416667  \n",
      "2023-08-18   48.645833   61.812500   52.250000   80.565217  \n",
      "2023-08-19   52.673913   51.130435   44.833333   39.937500  \n",
      "2023-08-20   58.604167   55.145833   48.347826   50.145833  \n",
      "2023-08-21   54.083333   59.729167   58.229167   47.700000  \n",
      "2023-08-22   54.717391   60.043478   46.645833   97.545455  \n",
      "2023-08-23   48.541667   63.437500   44.173913   53.000000  \n",
      "2023-08-24   58.083333   48.645833   51.312500   74.604167  \n",
      "2023-08-25   47.108696   52.673913   60.437500   89.791667  \n",
      "2023-08-26   37.687500   58.604167   34.608696   64.608696  \n",
      "2023-08-27   52.541667   54.083333   33.375000   58.604167  \n",
      "2023-08-28   52.000000   54.717391   45.187500   69.062500  \n",
      "2023-08-29   48.333333   48.541667   52.978261   64.413043  \n",
      "2023-08-30   43.583333   58.083333   38.520833   66.354167  \n",
      "2023-08-31   48.065217   47.108696   51.312500   72.020833  \n",
      "2023-09-01   48.270833   37.687500   49.260870   74.304348  \n",
      "2023-09-02   32.437500   52.541667   48.875000   69.041667  \n",
      "2023-09-03   34.434783   52.000000   45.562500   71.020833  \n",
      "2023-09-04   53.458333   48.333333   45.062500   64.104167  \n",
      "2023-09-05   58.354167   43.583333   56.043478   75.847826  \n",
      "2023-09-06   59.456522   48.065217   54.375000   59.227273  \n",
      "2023-09-07   68.208333   48.270833   44.229167   57.416667  \n",
      "2023-09-08   70.500000   32.437500   53.804348   47.391304  \n",
      "2023-09-09   75.565217   34.434783   60.666667   48.395833  \n",
      "2023-09-10   79.020833   53.458333   61.812500   47.541667  \n",
      "2023-09-11   82.229167   58.354167   51.130435   49.500000  \n",
      "2023-09-12   72.022727   59.456522   55.145833   45.875000  \n",
      "2023-09-13   47.312500   68.208333   59.729167   34.354167  \n",
      "2023-09-14   49.062500   70.500000   60.043478   25.217391  \n",
      "2023-09-15   42.913043   75.565217   63.437500   33.062500  \n",
      "2023-09-16   48.291667   79.020833   48.645833   43.166667  \n",
      "2023-09-17   51.270833   82.229167   52.673913   35.173913  \n",
      "2023-09-18   41.479167   72.022727   58.604167   37.645833  \n",
      "2023-09-19   53.652174   47.312500   54.083333   36.166667  \n",
      "2023-09-20   46.433333   49.062500   54.717391   33.521739  \n",
      "2023-09-21   65.136364   42.913043   48.541667   27.375000  \n",
      "2023-09-22   44.895833   48.291667   58.083333   32.770833  \n",
      "2023-09-23   44.375000   51.270833   47.108696   32.847826  \n",
      "2023-09-24   35.500000   41.479167   37.687500   45.291667  \n",
      "2023-09-25   46.791667   53.652174   52.541667   39.604167  \n",
      "2023-09-26   49.270833   46.433333   52.000000   36.586957  \n",
      "2023-09-27   34.260870   65.136364   48.333333   36.333333  \n",
      "2023-09-28   44.375000   44.895833   43.583333   29.604167  \n",
      "2023-09-29   49.604167   44.375000   48.065217   22.782609  \n",
      "2023-09-30   36.630435   35.500000   48.270833   31.312500  \n",
      "2023-10-01   37.437500   46.791667   32.437500   47.291667  \n",
      "2023-10-02   55.395833   49.270833   34.434783   38.434783  \n",
      "2023-10-03   55.630435   34.260870   53.458333   18.437500  \n",
      "2023-10-04   63.270833   44.375000   58.354167   30.250000  \n",
      "2023-10-05   43.541667   49.604167   59.456522   47.214286  \n",
      "2023-10-06   40.086957   36.630435   68.208333   40.458333  \n",
      "2023-10-07   49.565217   37.437500   70.500000   33.375000  \n",
      "2023-10-08   58.916667   55.395833   75.565217   41.380952  \n",
      "2023-10-09   43.130435   55.630435   79.020833    7.000000  \n",
      "2023-10-10   29.065217   63.270833   82.229167   41.500000  \n"
     ]
    }
   ],
   "source": [
    "## Assuming data_normalized is the DataFrame with normalized columns\n",
    "data_restored = data_normalized.copy()\n",
    "\n",
    "# Inverse transform the selected columns\n",
    "data_restored[columns_to_normalize] = scaler.inverse_transform(data_normalized[columns_to_normalize])\n",
    "\n",
    "# Display the restored data\n",
    "print(data_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc5d9c",
   "metadata": {},
   "source": [
    "## Now we remove the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "091d4bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values in 'Concentration' column:\n",
      "            Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
      "Date                                                                            \n",
      "2022-03-28  2022      3   28            NaN          1        0           NaN   \n",
      "2022-03-29  2022      3   29            NaN          2        0           NaN   \n",
      "2022-10-26  2022     10   26            NaN          3        0           NaN   \n",
      "2022-10-27  2022     10   27            NaN          4        0           NaN   \n",
      "2022-10-28  2022     10   28            NaN          5        0           NaN   \n",
      "2022-10-29  2022     10   29            NaN          6        1           NaN   \n",
      "2022-10-30  2022     10   30            NaN          0        1           NaN   \n",
      "2022-10-31  2022     10   31            NaN          1        0           NaN   \n",
      "2022-11-01  2022     11    1            NaN          2        0           NaN   \n",
      "2022-11-02  2022     11    2            NaN          3        0           NaN   \n",
      "2022-11-03  2022     11    3            NaN          4        0           NaN   \n",
      "2022-11-04  2022     11    4            NaN          5        0           NaN   \n",
      "2022-11-05  2022     11    5            NaN          6        1           NaN   \n",
      "2022-11-06  2022     11    6            NaN          0        1           NaN   \n",
      "2022-11-30  2022     11   30            NaN          3        0           NaN   \n",
      "2022-12-31  2022     12   31            NaN          6        1           NaN   \n",
      "2023-02-21  2023      2   21            NaN          2        0           NaN   \n",
      "2023-02-22  2023      2   22            NaN          3        0           NaN   \n",
      "2023-02-23  2023      2   23            NaN          4        0           NaN   \n",
      "2023-02-26  2023      2   26            NaN          0        1           NaN   \n",
      "2023-10-10  2023     10   10            NaN          2        0           NaN   \n",
      "\n",
      "             day_lag1   day_lag7  day_lag30  day_lag365  \n",
      "Date                                                     \n",
      "2022-03-28  35.736842  41.108696  33.543478         NaN  \n",
      "2022-03-29        NaN  50.250000  48.104167         NaN  \n",
      "2022-10-26  41.000000  22.937500  36.586957         NaN  \n",
      "2022-10-27        NaN  20.608696  36.333333         NaN  \n",
      "2022-10-28        NaN  41.208333  29.604167         NaN  \n",
      "2022-10-29        NaN  38.687500  22.782609         NaN  \n",
      "2022-10-30        NaN  37.333333  31.312500         NaN  \n",
      "2022-10-31        NaN  51.714286  47.291667         NaN  \n",
      "2022-11-01        NaN  41.000000  38.434783         NaN  \n",
      "2022-11-02        NaN        NaN  18.437500         NaN  \n",
      "2022-11-03        NaN        NaN  30.250000         NaN  \n",
      "2022-11-04        NaN        NaN  47.214286         NaN  \n",
      "2022-11-05        NaN        NaN  40.458333         NaN  \n",
      "2022-11-06        NaN        NaN  33.375000         NaN  \n",
      "2022-11-30   6.600000  36.888889        NaN         NaN  \n",
      "2022-12-31  43.977273  44.333333   8.807692         NaN  \n",
      "2023-02-21  49.250000   9.895833  30.645833   68.437500  \n",
      "2023-02-22        NaN  14.520833  13.652174   39.958333  \n",
      "2023-02-23        NaN  27.478261  22.395833   43.782609  \n",
      "2023-02-26  44.781250  49.869565  43.395833   33.543478  \n",
      "2023-10-10  29.065217  63.270833  82.229167   41.500000  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the 'Concentration' column\n",
    "rows_with_missing_values = data[data['Concentration'].isna()]\n",
    "\n",
    "# Display rows with missing values\n",
    "print(\"Rows with missing values in 'Concentration' column:\")\n",
    "print(rows_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "3d0f867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
      "Date                                                                            \n",
      "2022-01-01  2022      1    1       0.298815          6        1      0.466547   \n",
      "2022-01-02  2022      1    2       0.388855          0        1      0.327173   \n",
      "2022-01-03  2022      1    3       0.517163          1        0      0.396925   \n",
      "2022-01-04  2022      1    4       0.460649          2        0      0.505970   \n",
      "2022-01-05  2022      1    5       0.301981          3        0      0.466815   \n",
      "2022-01-06  2022      1    6       0.270624          4        0      0.343341   \n",
      "2022-01-07  2022      1    7       0.387445          5        0      0.304628   \n",
      "2022-01-08  2022      1    8       0.416362          6        1      0.388693   \n",
      "2022-01-09  2022      1    9       0.386118          0        1      0.428560   \n",
      "2022-01-10  2022      1   10       0.064100          1        0      0.408978   \n",
      "2022-01-11  2022      1   11       0.125067          2        0      0.147431   \n",
      "2022-01-12  2022      1   12       0.029774          3        0      0.160503   \n",
      "2022-01-13  2022      1   13       0.006258          4        0      0.106219   \n",
      "2022-01-14  2022      1   14       0.020779          5        0      0.071960   \n",
      "2022-01-15  2022      1   15       0.054049          6        1      0.100682   \n",
      "2022-01-16  2022      1   16       0.088944          0        1      0.066488   \n",
      "2022-01-17  2022      1   17       0.109434          1        0      0.110738   \n",
      "2022-01-18  2022      1   18       0.096909          2        0      0.146506   \n",
      "2022-01-19  2022      1   19       0.120614          3        0      0.113443   \n",
      "2022-01-20  2022      1   20       0.479687          4        0      0.134075   \n",
      "2022-01-21  2022      1   21       0.278020          5        0      0.381509   \n",
      "2022-01-22  2022      1   22       0.274417          6        1      0.284489   \n",
      "2022-01-23  2022      1   23       0.294857          0        1      0.269091   \n",
      "2022-01-24  2022      1   24       0.237815          1        0      0.277497   \n",
      "2022-01-25  2022      1   25       0.024464          2        0      0.196586   \n",
      "2022-01-26  2022      1   26       0.095581          3        0      0.088783   \n",
      "2022-01-27  2022      1   27       0.225109          4        0      0.138901   \n",
      "2022-01-28  2022      1   28       0.097288          5        0      0.200195   \n",
      "2022-01-29  2022      1   29       0.391824          6        1      0.102719   \n",
      "2022-01-30  2022      1   30       0.392187          0        1      0.346674   \n",
      "2022-01-31  2022      1   31       0.596435          1        0      0.384829   \n",
      "2022-02-01  2022      2    1       0.369462          2        0      0.492721   \n",
      "2022-02-02  2022      2    2       0.357482          3        0      0.359827   \n",
      "2022-02-03  2022      2    3       0.350654          4        0      0.312919   \n",
      "2022-02-04  2022      2    4       0.435953          5        0      0.376209   \n",
      "2022-02-05  2022      2    5       0.434098          6        1      0.396489   \n",
      "2022-02-06  2022      2    6       0.557368          0        1      0.407478   \n",
      "2022-02-07  2022      2    7       0.463493          1        0      0.519806   \n",
      "2022-02-08  2022      2    8       0.457128          2        0      0.439747   \n",
      "2022-02-09  2022      2    9       0.374739          3        0      0.464669   \n",
      "2022-02-10  2022      2   10       0.255263          4        0      0.369381   \n",
      "2022-02-11  2022      2   11       0.289118          5        0      0.277285   \n",
      "2022-02-12  2022      2   12       0.334345          6        1      0.334044   \n",
      "2022-02-13  2022      2   13       0.526266          0        1      0.339135   \n",
      "2022-02-14  2022      2   14       0.534701          1        0      0.507016   \n",
      "2022-02-15  2022      2   15       0.427271          2        0      0.505986   \n",
      "2022-02-16  2022      2   16       0.489475          3        0      0.426891   \n",
      "2022-02-17  2022      2   17       0.622367          4        0      0.501522   \n",
      "2022-02-18  2022      2   18       0.556040          5        0      0.562843   \n",
      "2022-02-19  2022      2   19       0.574246          6        1      0.555912   \n",
      "2022-02-20  2022      2   20       0.581205          0        1      0.569380   \n",
      "2022-02-21  2022      2   21       0.604779          1        0      0.568624   \n",
      "2022-02-22  2022      2   22       0.345534          2        0      0.590364   \n",
      "2022-02-23  2022      2   23       0.380346          3        0      0.389898   \n",
      "2022-02-24  2022      2   24       0.489475          4        0      0.429659   \n",
      "2022-02-25  2022      2   25       0.444149          5        0      0.503496   \n",
      "2022-02-26  2022      2   26       0.287140          6        1      0.449600   \n",
      "2022-02-27  2022      2   27       0.419685          0        1      0.369219   \n",
      "2022-02-28  2022      2   28       0.347620          1        0      0.432865   \n",
      "2022-03-01  2022      3    1       0.158115          2        0      0.385504   \n",
      "2022-03-02  2022      3    2       0.157216          3        0      0.230122   \n",
      "2022-03-03  2022      3    3       0.200834          4        0      0.234262   \n",
      "2022-03-04  2022      3    4       0.267944          5        0      0.253007   \n",
      "2022-03-05  2022      3    5       0.206524          6        1      0.285923   \n",
      "2022-03-06  2022      3    6       0.357984          0        1      0.270896   \n",
      "2022-03-07  2022      3    7       0.416082          1        0      0.355737   \n",
      "2022-03-08  2022      3    8       0.379860          2        0      0.416586   \n",
      "2022-03-09  2022      3    9       0.426455          3        0      0.373618   \n",
      "2022-03-10  2022      3   10       0.562299          4        0      0.431001   \n",
      "2022-03-11  2022      3   11       0.573298          5        0      0.536255   \n",
      "2022-03-12  2022      3   12       0.656206          6        1      0.532195   \n",
      "2022-03-13  2022      3   13       0.725014          0        1      0.629487   \n",
      "2022-03-14  2022      3   14       0.449080          1        0      0.675264   \n",
      "2022-03-15  2022      3   15       0.292433          2        0      0.471538   \n",
      "2022-03-16  2022      3   16       0.202640          3        0      0.345560   \n",
      "2022-03-17  2022      3   17       0.419216          4        0      0.258792   \n",
      "2022-03-18  2022      3   18       0.343410          5        0      0.432793   \n",
      "2022-03-19  2022      3   19       0.561614          6        1      0.398846   \n",
      "2022-03-20  2022      3   20       0.493078          0        1      0.538941   \n",
      "2022-03-21  2022      3   21       0.356006          1        0      0.506768   \n",
      "2022-03-22  2022      3   22       0.439219          2        0      0.356591   \n",
      "2022-03-23  2022      3   23       0.464062          3        0      0.486151   \n",
      "2022-03-24  2022      3   24       0.445848          4        0      0.466931   \n",
      "2022-03-25  2022      3   25       0.540869          5        0      0.451391   \n",
      "2022-03-26  2022      3   26       0.615210          6        1      0.554560   \n",
      "2022-03-27  2022      3   27       0.307106          0        1      0.571035   \n",
      "2022-03-30  2022      3   30       0.391428          3        0      0.395153   \n",
      "2022-03-31  2022      3   31       0.432185          4        0      0.401784   \n",
      "2022-04-01  2022      4    1       0.482268          5        0      0.447654   \n",
      "2022-04-02  2022      4    2       0.611087          6        1      0.492731   \n",
      "2022-04-03  2022      4    3       0.505784          0        1      0.613934   \n",
      "2022-04-04  2022      4    4       0.423882          1        0      0.527159   \n",
      "2022-04-05  2022      4    5       0.321087          2        0      0.420639   \n",
      "2022-04-06  2022      4    6       0.468045          3        0      0.383949   \n",
      "2022-04-07  2022      4    7       0.577091          4        0      0.478888   \n",
      "2022-04-08  2022      4    8       0.431600          5        0      0.594612   \n",
      "2022-04-09  2022      4    9       0.509008          6        1      0.450480   \n",
      "2022-04-10  2022      4   10       0.484734          0        1      0.503039   \n",
      "2022-04-11  2022      4   11       0.550540          1        0      0.518701   \n",
      "2022-04-12  2022      4   12       0.494727          2        0      0.541125   \n",
      "2022-04-13  2022      4   13       0.159492          3        0      0.547964   \n",
      "2022-04-14  2022      4   14       0.284658          4        0      0.216143   \n",
      "2022-04-15  2022      4   15       0.331863          5        0      0.333106   \n",
      "2022-04-16  2022      4   16       0.478096          6        1      0.390919   \n",
      "2022-04-17  2022      4   17       0.517732          0        1      0.466760   \n",
      "2022-04-18  2022      4   18       0.556469          1        0      0.570456   \n",
      "2022-04-19  2022      4   19       0.497440          2        0      0.489860   \n",
      "2022-04-20  2022      4   20       0.560781          3        0      0.528059   \n",
      "2022-04-21  2022      4   21       0.569728          4        0      0.568729   \n",
      "2022-04-22  2022      4   22       0.458752          5        0      0.559387   \n",
      "2022-04-23  2022      4   23       0.601176          6        1      0.506502   \n",
      "2022-04-24  2022      4   24       0.694597          0        1      0.549245   \n",
      "2022-04-25  2022      4   25       0.398635          1        0      0.712422   \n",
      "2022-04-26  2022      4   26       0.518490          2        0      0.447841   \n",
      "2022-04-27  2022      4   27       0.592881          3        0      0.529915   \n",
      "2022-04-28  2022      4   28       0.587521          4        0      0.598992   \n",
      "2022-04-29  2022      4   29       0.384601          5        0      0.557278   \n",
      "2022-04-30  2022      4   30       0.583778          6        1      0.522334   \n",
      "2022-05-01  2022      5    1       0.517542          0        1      0.543888   \n",
      "2022-05-02  2022      5    2       0.532335          1        0      0.531479   \n",
      "2022-05-03  2022      5    3       0.528368          2        0      0.558914   \n",
      "2022-05-04  2022      5    4       0.456476          3        0      0.573200   \n",
      "2022-05-05  2022      5    5       0.318035          4        0      0.516359   \n",
      "2022-05-06  2022      5    6       0.409040          5        0      0.326798   \n",
      "2022-05-07  2022      5    7       0.392187          6        1      0.464434   \n",
      "2022-05-08  2022      5    8       0.543713          0        1      0.459690   \n",
      "2022-05-09  2022      5    9       0.573290          1        0      0.556216   \n",
      "2022-05-10  2022      5   10       0.528921          2        0      0.581269   \n",
      "2022-05-11  2022      5   11       0.585625          3        0      0.493264   \n",
      "2022-05-12  2022      5   12       0.498685          4        0      0.645864   \n",
      "2022-05-13  2022      5   13       0.535559          5        0      0.526214   \n",
      "2022-05-14  2022      5   14       0.652001          6        1      0.532064   \n",
      "2022-05-15  2022      5   15       0.733779          0        1      0.651456   \n",
      "2022-05-16  2022      5   16       0.543144          1        0      0.693219   \n",
      "2022-05-17  2022      5   17       0.516594          2        0      0.641480   \n",
      "2022-05-18  2022      5   18       0.673225          3        0      0.510713   \n",
      "2022-05-19  2022      5   19       0.515835          4        0      0.646901   \n",
      "2022-05-20  2022      5   20       0.422254          5        0      0.572802   \n",
      "2022-05-21  2022      5   21       0.592287          6        1      0.494739   \n",
      "2022-05-22  2022      5   22       0.653518          0        1      0.640648   \n",
      "2022-05-23  2022      5   23       0.437339          1        0      0.578709   \n",
      "2022-05-24  2022      5   24       0.486416          2        0      0.524911   \n",
      "2022-05-25  2022      5   25       0.489664          3        0      0.568844   \n",
      "2022-05-26  2022      5   26       0.498957          4        0      0.505108   \n",
      "2022-05-27  2022      5   27       0.550928          5        0      0.518500   \n",
      "2022-05-28  2022      5   28       0.527973          6        1      0.556883   \n",
      "2022-05-29  2022      5   29       0.502181          0        1      0.612422   \n",
      "2022-05-30  2022      5   30       0.457326          1        0      0.537375   \n",
      "2022-05-31  2022      5   31       0.461218          2        0      0.456005   \n",
      "2022-06-01  2022      6    1       0.526266          3        0      0.502611   \n",
      "2022-06-02  2022      6    2       0.664897          4        0      0.572065   \n",
      "2022-06-03  2022      6    3       0.777315          5        0      0.694799   \n",
      "2022-06-04  2022      6    4       0.801631          6        1      0.718812   \n",
      "2022-06-05  2022      6    5       0.415513          0        1      0.758420   \n",
      "2022-06-06  2022      6    6       0.507788          1        0      0.522465   \n",
      "2022-06-07  2022      6    7       0.357671          2        0      0.549040   \n",
      "2022-06-08  2022      6    8       0.271383          3        0      0.427439   \n",
      "2022-06-09  2022      6    9       0.422299          4        0      0.304690   \n",
      "2022-06-10  2022      6   10       0.410203          5        0      0.525334   \n",
      "2022-06-11  2022      6   11       0.478855          6        1      0.464583   \n",
      "2022-06-12  2022      6   12       0.549543          0        1      0.486417   \n",
      "2022-06-13  2022      6   13       0.547696          1        0      0.565368   \n",
      "2022-06-14  2022      6   14       0.646880          2        0      0.536200   \n",
      "2022-06-15  2022      6   15       0.851326          3        0      0.710619   \n",
      "2022-06-16  2022      6   16       0.801890          4        0      0.777583   \n",
      "2022-06-17  2022      6   17       0.830944          5        0      0.756309   \n",
      "2022-06-18  2022      6   18       0.935826          6        1      0.832344   \n",
      "2022-06-19  2022      6   19       0.520956          0        1      0.897166   \n",
      "2022-06-20  2022      6   20       0.530059          1        0      0.609831   \n",
      "2022-06-21  2022      6   21       0.441494          2        0      0.534725   \n",
      "2022-06-22  2022      6   22       0.699033          3        0      0.524000   \n",
      "2022-06-23  2022      6   23       0.655604          4        0      0.715756   \n",
      "2022-06-24  2022      6   24       0.487801          5        0      0.721601   \n",
      "2022-06-25  2022      6   25       0.384032          6        1      0.527797   \n",
      "2022-06-26  2022      6   26       0.393324          0        1      0.436919   \n",
      "2022-06-27  2022      6   27       0.272496          1        0      0.474541   \n",
      "2022-06-28  2022      6   28       0.494216          2        0      0.384282   \n",
      "2022-06-29  2022      6   29       0.602883          3        0      0.546647   \n",
      "2022-06-30  2022      6   30       0.319989          4        0      0.584725   \n",
      "2022-07-01  2022      7    1       0.366016          5        0      0.388647   \n",
      "2022-07-02  2022      7    2       0.512611          6        1      0.465493   \n",
      "2022-07-03  2022      7    3       0.482656          0        1      0.521199   \n",
      "2022-07-04  2022      7    4       0.461597          1        0      0.493089   \n",
      "2022-07-05  2022      7    5       0.491940          2        0      0.509657   \n",
      "2022-07-06  2022      7    6       0.543606          3        0      0.527720   \n",
      "2022-07-07  2022      7    7       0.411910          4        0      0.564480   \n",
      "2022-07-08  2022      7    8       0.515835          5        0      0.435411   \n",
      "2022-07-09  2022      7    9       0.534701          6        1      0.534163   \n",
      "2022-07-10  2022      7   10       0.441874          0        1      0.576936   \n",
      "2022-07-11  2022      7   11       0.453063          1        0      0.467706   \n",
      "2022-07-12  2022      7   12       0.500862          2        0      0.493521   \n",
      "2022-07-13  2022      7   13       0.681775          3        0      0.498020   \n",
      "2022-07-14  2022      7   14       0.499716          4        0      0.680732   \n",
      "2022-07-15  2022      7   15       0.476521          5        0      0.560744   \n",
      "2022-07-16  2022      7   16       0.537076          6        1      0.475975   \n",
      "2022-07-17  2022      7   17       0.608762          0        1      0.562733   \n",
      "2022-07-18  2022      7   18       0.851749          1        0      0.587716   \n",
      "2022-07-19  2022      7   19       0.984259          2        0      0.859029   \n",
      "2022-07-20  2022      7   20       0.715342          3        0      0.929823   \n",
      "2022-07-21  2022      7   21       0.433777          4        0      0.681507   \n",
      "2022-07-22  2022      7   22       0.438839          5        0      0.524680   \n",
      "2022-07-23  2022      7   23       0.609141          6        1      0.482341   \n",
      "2022-07-24  2022      7   24       0.702314          0        1      0.659996   \n",
      "2022-07-25  2022      7   25       0.495543          1        0      0.707888   \n",
      "2022-07-26  2022      7   26       0.451166          2        0      0.540182   \n",
      "2022-07-27  2022      7   27       0.500070          3        0      0.528331   \n",
      "2022-07-28  2022      7   28       0.620140          4        0      0.518908   \n",
      "2022-07-29  2022      7   29       0.772046          5        0      0.654986   \n",
      "2022-07-30  2022      7   30       0.674214          6        1      0.775612   \n",
      "2022-07-31  2022      7   31       0.411720          0        1      0.684770   \n",
      "2022-08-01  2022      8    1       0.506353          1        0      0.488877   \n",
      "2022-08-02  2022      8    2       0.486811          2        0      0.525895   \n",
      "2022-08-03  2022      8    3       0.418737          3        0      0.555880   \n",
      "2022-08-04  2022      8    4       0.351982          4        0      0.489551   \n",
      "2022-08-05  2022      8    5       0.494250          5        0      0.432003   \n",
      "2022-08-06  2022      8    6       0.486630          6        1      0.504427   \n",
      "2022-08-07  2022      8    7       0.648777          0        1      0.520875   \n",
      "2022-08-08  2022      8    8       0.622795          1        0      0.682397   \n",
      "2022-08-09  2022      8    9       0.619398          2        0      0.640903   \n",
      "2022-08-10  2022      8   10       0.811682          3        0      0.603950   \n",
      "2022-08-11  2022      8   11       0.924142          4        0      0.785350   \n",
      "2022-08-12  2022      8   12       0.948689          5        0      0.896142   \n",
      "2022-08-13  2022      8   13       0.867438          6        1      0.942876   \n",
      "2022-08-14  2022      8   14       0.898540          0        1      0.844639   \n",
      "2022-08-15  2022      8   15       0.821247          1        0      0.851581   \n",
      "2022-08-16  2022      8   16       0.915608          2        0      0.861745   \n",
      "2022-08-17  2022      8   17       0.622795          3        0      0.928715   \n",
      "2022-08-18  2022      8   18       0.715177          4        0      0.704819   \n",
      "2022-08-19  2022      8   19       0.345344          5        0      0.709246   \n",
      "2022-08-20  2022      8   20       0.438270          6        1      0.483520   \n",
      "2022-08-21  2022      8   21       0.416006          0        1      0.539112   \n",
      "2022-08-22  2022      8   22       0.869748          1        0      0.539574   \n",
      "2022-08-23  2022      8   23       0.464252          2        0      0.805224   \n",
      "2022-08-24  2022      8   24       0.660914          3        0      0.574237   \n",
      "2022-08-25  2022      8   25       0.799166          4        0      0.695110   \n",
      "2022-08-26  2022      8   26       0.569926          5        0      0.831559   \n",
      "2022-08-27  2022      8   27       0.515266          6        1      0.577054   \n",
      "2022-08-28  2022      8   28       0.610468          0        1      0.604599   \n",
      "2022-08-29  2022      8   29       0.568145          1        0      0.671386   \n",
      "2022-08-30  2022      8   30       0.585815          2        0      0.594098   \n",
      "2022-08-31  2022      8   31       0.637398          3        0      0.661215   \n",
      "2022-09-01  2022      9    1       0.658185          4        0      0.637972   \n",
      "2022-09-02  2022      9    2       0.610279          5        0      0.713475   \n",
      "2022-09-03  2022      9    3       0.628295          6        1      0.661230   \n",
      "2022-09-04  2022      9    4       0.565333          0        1      0.638976   \n",
      "2022-09-05  2022      9    5       0.672235          1        0      0.638234   \n",
      "2022-09-06  2022      9    6       0.520939          2        0      0.671074   \n",
      "2022-09-07  2022      9    7       0.504457          3        0      0.620464   \n",
      "2022-09-08  2022      9    8       0.413196          4        0      0.544060   \n",
      "2022-09-09  2022      9    9       0.422340          5        0      0.480774   \n",
      "2022-09-10  2022      9   10       0.414565          6        1      0.496127   \n",
      "2022-09-11  2022      9   11       0.432391          0        1      0.482318   \n",
      "2022-09-12  2022      9   12       0.399393          1        0      0.509366   \n",
      "2022-09-13  2022      9   13       0.294519          2        0      0.435886   \n",
      "2022-09-14  2022      9   14       0.211347          3        0      0.373043   \n",
      "2022-09-15  2022      9   15       0.282761          4        0      0.313115   \n",
      "2022-09-16  2022      9   16       0.374739          5        0      0.342517   \n",
      "2022-09-17  2022      9   17       0.301981          6        1      0.420071   \n",
      "2022-09-18  2022      9   18       0.324483          0        1      0.342536   \n",
      "2022-09-19  2022      9   19       0.311018          1        0      0.385490   \n",
      "2022-09-20  2022      9   20       0.286942          2        0      0.355364   \n",
      "2022-09-21  2022      9   21       0.230988          3        0      0.311634   \n",
      "2022-09-22  2022      9   22       0.280106          4        0      0.301578   \n",
      "2022-09-23  2022      9   23       0.280807          5        0      0.306080   \n",
      "2022-09-24  2022      9   24       0.394083          6        1      0.330317   \n",
      "2022-09-25  2022      9   25       0.342310          0        1      0.390082   \n",
      "2022-09-26  2022      9   26       0.314844          1        0      0.361444   \n",
      "2022-09-27  2022      9   27       0.312536          2        0      0.349734   \n",
      "2022-09-28  2022      9   28       0.251280          3        0      0.328361   \n",
      "2022-09-29  2022      9   29       0.189184          4        0      0.283878   \n",
      "2022-09-30  2022      9   30       0.266831          5        0      0.229932   \n",
      "2022-10-01  2022     10    1       0.412289          6        1      0.296030   \n",
      "2022-10-02  2022     10    2       0.331665          0        1      0.405728   \n",
      "2022-10-03  2022     10    3       0.149630          1        0      0.339249   \n",
      "2022-10-04  2022     10    4       0.257159          2        0      0.204381   \n",
      "2022-10-05  2022     10    5       0.411585          3        0      0.267312   \n",
      "2022-10-06  2022     10    6       0.350085          4        0      0.392919   \n",
      "2022-10-07  2022     10    7       0.285606          5        0      0.365086   \n",
      "2022-10-08  2022     10    8       0.358484          6        1      0.315100   \n",
      "2022-10-09  2022     10    9       0.045515          0        1      0.342639   \n",
      "2022-10-10  2022     10   10       0.359568          1        0      0.096538   \n",
      "2022-10-11  2022     10   11       0.034895          2        0      0.360458   \n",
      "2022-10-12  2022     10   12       0.149992          3        0      0.130982   \n",
      "2022-10-13  2022     10   13       0.179405          4        0      0.138448   \n",
      "2022-10-14  2022     10   14       0.194725          5        0      0.231479   \n",
      "2022-10-15  2022     10   15       0.320121          6        1      0.161289   \n",
      "2022-10-16  2022     10   16       0.325242          0        1      0.371259   \n",
      "2022-10-17  2022     10   17       0.177508          1        0      0.302338   \n",
      "2022-10-18  2022     10   18       0.225109          2        0      0.156816   \n",
      "2022-10-19  2022     10   19       0.190594          3        0      0.270665   \n",
      "2022-10-20  2022     10   20       0.169395          4        0      0.172306   \n",
      "2022-10-21  2022     10   21       0.356913          5        0      0.234601   \n",
      "2022-10-22  2022     10   22       0.333965          6        1      0.305642   \n",
      "2022-10-23  2022     10   23       0.321639          0        1      0.293959   \n",
      "2022-10-24  2022     10   24       0.452548          1        0      0.357166   \n",
      "2022-10-25  2022     10   25       0.355016          2        0      0.394539   \n",
      "2022-11-07  2022     11    7       0.458790          1        0      0.358060   \n",
      "2022-11-08  2022     11    8       0.416461          2        0      0.397774   \n",
      "2022-11-09  2022     11    9       0.404893          3        0      0.417848   \n",
      "2022-11-10  2022     11   10       0.283493          4        0      0.412450   \n",
      "2022-11-11  2022     11   11       0.246918          5        0      0.283279   \n",
      "2022-11-12  2022     11   12       0.055187          6        1      0.262579   \n",
      "2022-11-13  2022     11   13       0.043239          0        1      0.112646   \n",
      "2022-11-14  2022     11   14       0.032652          1        0      0.117939   \n",
      "2022-11-15  2022     11   15       0.296226          2        0      0.091609   \n",
      "2022-11-16  2022     11   16       0.331500          3        0      0.250625   \n",
      "2022-11-17  2022     11   17       0.469001          4        0      0.346229   \n",
      "2022-11-18  2022     11   18       0.253935          5        0      0.426100   \n",
      "2022-11-19  2022     11   19       0.038498          6        1      0.284872   \n",
      "2022-11-20  2022     11   20       0.018206          0        1      0.050636   \n",
      "2022-11-21  2022     11   21       0.315803          1        0      0.061931   \n",
      "2022-11-22  2022     11   22       0.389342          2        0      0.318607   \n",
      "2022-11-23  2022     11   23       0.317593          3        0      0.371202   \n",
      "2022-11-24  2022     11   24       0.391668          4        0      0.314759   \n",
      "2022-11-25  2022     11   25       0.239712          5        0      0.330450   \n",
      "2022-11-26  2022     11   26       0.177904          6        1      0.250787   \n",
      "2022-11-27  2022     11   27       0.275934          0        1      0.224054   \n",
      "2022-11-28  2022     11   28       0.135976          1        0      0.280065   \n",
      "2022-11-29  2022     11   29       0.041874          2        0      0.140084   \n",
      "2022-12-01  2022     12    1       0.061970          4        0      0.078178   \n",
      "2022-12-02  2022     12    2       0.095581          5        0      0.124956   \n",
      "2022-12-03  2022     12    3       0.076237          6        1      0.112610   \n",
      "2022-12-04  2022     12    4       0.043998          0        1      0.096438   \n",
      "2022-12-05  2022     12    5       0.002968          1        0      0.059070   \n",
      "2022-12-06  2022     12    6       0.068083          2        0      0.042643   \n",
      "2022-12-07  2022     12    7       0.134496          3        0      0.094772   \n",
      "2022-12-08  2022     12    8       0.135555          4        0      0.112944   \n",
      "2022-12-09  2022     12    9       0.080789          5        0      0.130957   \n",
      "2022-12-10  2022     12   10       0.155699          6        1      0.092695   \n",
      "2022-12-11  2022     12   11       0.248155          0        1      0.147203   \n",
      "2022-12-12  2022     12   12       0.096529          1        0      0.214595   \n",
      "2022-12-13  2022     12   13       0.015930          2        0      0.089124   \n",
      "2022-12-14  2022     12   14       0.015238          3        0      0.050035   \n",
      "2022-12-15  2022     12   15       0.000000          4        0      0.026920   \n",
      "2022-12-16  2022     12   16       0.031291          5        0      0.000000   \n",
      "2022-12-17  2022     12   17       0.010290          6        1      0.048807   \n",
      "2022-12-18  2022     12   18       0.104305          0        1      0.018499   \n",
      "2022-12-19  2022     12   19       0.279158          1        0      0.092307   \n",
      "2022-12-20  2022     12   20       0.278630          2        0      0.219512   \n",
      "2022-12-21  2022     12   21       0.238195          3        0      0.229050   \n",
      "2022-12-22  2022     12   22       0.264366          4        0      0.227428   \n",
      "2022-12-23  2022     12   23       0.366890          5        0      0.217338   \n",
      "2022-12-24  2022     12   24       0.385359          6        1      0.298061   \n",
      "2022-12-25  2022     12   25       0.254314          0        1      0.342356   \n",
      "2022-12-26  2022     12   26       0.405280          1        0      0.250635   \n",
      "2022-12-27  2022     12   27       0.366584          2        0      0.359650   \n",
      "2022-12-28  2022     12   28       0.437322          3        0      0.309684   \n",
      "2022-12-29  2022     12   29       0.483447          4        0      0.391163   \n",
      "2022-12-30  2022     12   30       0.382118          5        0      0.476457   \n",
      "2023-01-01  2023      1    1       0.432805          0        1      0.342164   \n",
      "2023-01-02  2023      1    2       0.419496          1        0      0.400297   \n",
      "2023-01-03  2023      1    3       0.361654          2        0      0.388790   \n",
      "2023-01-04  2023      1    4       0.479975          3        0      0.372076   \n",
      "2023-01-05  2023      1    5       0.405272          4        0      0.483123   \n",
      "2023-01-06  2023      1    6       0.378532          5        0      0.356246   \n",
      "2023-01-07  2023      1    7       0.449410          6        1      0.383253   \n",
      "2023-01-08  2023      1    8       0.574815          0        1      0.454806   \n",
      "2023-01-09  2023      1    9       0.476200          1        0      0.538440   \n",
      "2023-01-10  2023      1   10       0.360953          2        0      0.482407   \n",
      "2023-01-11  2023      1   11       0.467665          3        0      0.342920   \n",
      "2023-01-12  2023      1   12       0.476958          4        0      0.483717   \n",
      "2023-01-13  2023      1   13       0.533662          5        0      0.478942   \n",
      "2023-01-14  2023      1   14       0.485822          6        1      0.518913   \n",
      "2023-01-15  2023      1   15       0.567609          0        1      0.501405   \n",
      "2023-01-16  2023      1   16       0.488716          1        0      0.513673   \n",
      "2023-01-17  2023      1   17       0.188590          2        0      0.537062   \n",
      "2023-01-18  2023      1   18       0.118528          3        0      0.251055   \n",
      "2023-01-19  2023      1   19       0.181680          4        0      0.190666   \n",
      "2023-01-20  2023      1   20       0.207983          5        0      0.231368   \n",
      "2023-01-21  2023      1   21       0.150768          6        1      0.238044   \n",
      "2023-01-22  2023      1   22       0.260762          0        1      0.269650   \n",
      "2023-01-23  2023      1   23       0.106069          1        0      0.248117   \n",
      "2023-01-24  2023      1   24       0.185663          2        0      0.148525   \n",
      "2023-01-25  2023      1   25       0.088944          3        0      0.218352   \n",
      "2023-01-26  2023      1   26       0.215701          4        0      0.161043   \n",
      "2023-01-27  2023      1   27       0.376825          5        0      0.240561   \n",
      "2023-01-28  2023      1   28       0.354258          6        1      0.324941   \n",
      "2023-01-29  2023      1   29       0.165635          0        1      0.343413   \n",
      "2023-01-30  2023      1   30       0.383463          1        0      0.231140   \n",
      "2023-01-31  2023      1   31       0.215437          2        0      0.354831   \n",
      "2023-02-01  2023      2    1       0.437150          3        0      0.215688   \n",
      "2023-02-02  2023      2    2       0.451735          4        0      0.386630   \n",
      "2023-02-03  2023      2    3       0.458373          5        0      0.484764   \n",
      "2023-02-04  2023      2    4       0.220648          6        1      0.410873   \n",
      "2023-02-05  2023      2    5       0.468045          0        1      0.251505   \n",
      "2023-02-06  2023      2    6       0.193628          1        0      0.403397   \n",
      "2023-02-07  2023      2    7       0.083510          2        0      0.263556   \n",
      "2023-02-08  2023      2    8       0.110753          3        0      0.163950   \n",
      "2023-02-09  2023      2    9       0.135027          4        0      0.132985   \n",
      "2023-02-10  2023      2   10       0.120713          5        0      0.128720   \n",
      "2023-02-11  2023      2   11       0.238005          6        1      0.181676   \n",
      "2023-02-12  2023      2   12       0.316518          0        1      0.283314   \n",
      "2023-02-13  2023      2   13       0.098154          1        0      0.281248   \n",
      "2023-02-14  2023      2   14       0.071876          2        0      0.100780   \n",
      "2023-02-15  2023      2   15       0.113977          3        0      0.112211   \n",
      "2023-02-16  2023      2   16       0.231928          4        0      0.173751   \n",
      "2023-02-17  2023      2   17       0.464062          5        0      0.213802   \n",
      "2023-02-18  2023      2   18       0.533852          6        1      0.391250   \n",
      "2023-02-19  2023      2   19       0.435756          0        1      0.473064   \n",
      "2023-02-20  2023      2   20       0.430116          1        0      0.432393   \n",
      "2023-02-24  2023      2   24       0.492699          5        0      0.411512   \n",
      "2023-02-25  2023      2   25       0.389437          6        1      0.409438   \n",
      "2023-02-27  2023      2   27       0.421582          1        0      0.386167   \n",
      "2023-02-28  2023      2   28       0.309294          2        0      0.441503   \n",
      "2023-03-01  2023      3    1       0.333086          3        0      0.334070   \n",
      "2023-03-02  2023      3    2       0.265174          4        0      0.301936   \n",
      "2023-03-03  2023      3    3       0.341569          5        0      0.279711   \n",
      "2023-03-04  2023      3    4       0.586573          6        1      0.372301   \n",
      "2023-03-05  2023      3    5       0.470510          0        1      0.568416   \n",
      "2023-03-06  2023      3    6       0.406600          1        0      0.429704   \n",
      "2023-03-07  2023      3    7       0.446615          2        0      0.387428   \n",
      "2023-03-08  2023      3    8       0.282003          3        0      0.468527   \n",
      "2023-03-09  2023      3    9       0.220450          4        0      0.317239   \n",
      "2023-03-10  2023      3   10       0.479992          5        0      0.269798   \n",
      "2023-03-11  2023      3   11       0.401100          6        1      0.432200   \n",
      "2023-03-12  2023      3   12       0.533118          0        1      0.410755   \n",
      "2023-03-13  2023      3   13       0.420254          1        0      0.552430   \n",
      "2023-03-14  2023      3   14       0.531007          2        0      0.424092   \n",
      "2023-03-15  2023      3   15       0.459305          3        0      0.469383   \n",
      "2023-03-16  2023      3   16       0.561350          4        0      0.481143   \n",
      "2023-03-17  2023      3   17       0.480751          5        0      0.554206   \n",
      "2023-03-18  2023      3   18       0.531766          6        1      0.523997   \n",
      "2023-03-19  2023      3   19       0.461283          0        1      0.472303   \n",
      "2023-03-20  2023      3   20       0.420064          1        0      0.474216   \n",
      "2023-03-21  2023      3   21       0.419387          2        0      0.472213   \n",
      "2023-03-22  2023      3   22       0.517569          3        0      0.454274   \n",
      "2023-03-23  2023      3   23       0.622416          4        0      0.506969   \n",
      "2023-03-24  2023      3   24       0.607624          5        0      0.568136   \n",
      "2023-03-25  2023      3   25       0.653139          6        1      0.640998   \n",
      "2023-03-26  2023      3   26       0.568557          0        1      0.659828   \n",
      "2023-03-27  2023      3   27       0.616628          1        0      0.552856   \n",
      "2023-03-28  2023      3   28       0.441494          2        0      0.590491   \n",
      "2023-03-29  2023      3   29       0.401669          3        0      0.497873   \n",
      "2023-03-30  2023      3   30       0.602658          4        0      0.482391   \n",
      "2023-03-31  2023      3   31       0.577660          5        0      0.593919   \n",
      "2023-04-01  2023      4    1       0.402996          6        1      0.548383   \n",
      "2023-04-02  2023      4    2       0.448816          0        1      0.478537   \n",
      "2023-04-03  2023      4    3       0.417030          1        0      0.515568   \n",
      "2023-04-04  2023      4    4       0.489285          2        0      0.438771   \n",
      "2023-04-05  2023      4    5       0.426133          3        0      0.486228   \n",
      "2023-04-06  2023      4    6       0.431006          4        0      0.481985   \n",
      "2023-04-07  2023      4    7       0.555471          5        0      0.491474   \n",
      "2023-04-08  2023      4    8       0.526456          6        1      0.562897   \n",
      "2023-04-09  2023      4    9       0.453962          0        1      0.502185   \n",
      "2023-04-10  2023      4   10       0.575574          1        0      0.499313   \n",
      "2023-04-11  2023      4   11       0.637019          2        0      0.613674   \n",
      "2023-04-12  2023      4   12       0.647103          3        0      0.620858   \n",
      "2023-04-13  2023      4   13       0.641760          4        0      0.627959   \n",
      "2023-04-14  2023      4   14       0.484544          5        0      0.641941   \n",
      "2023-04-15  2023      4   15       0.562801          6        1      0.547829   \n",
      "2023-04-16  2023      4   16       0.481699          0        1      0.585004   \n",
      "2023-04-17  2023      4   17       0.551489          1        0      0.497645   \n",
      "2023-04-18  2023      4   18       0.465637          2        0      0.566523   \n",
      "2023-04-19  2023      4   19       0.586383          3        0      0.545632   \n",
      "2023-04-20  2023      4   20       0.633795          4        0      0.590446   \n",
      "2023-04-21  2023      4   21       0.529556          5        0      0.636936   \n",
      "2023-04-22  2023      4   22       0.204438          6        1      0.540064   \n",
      "2023-04-23  2023      4   23       0.559264          0        1      0.336271   \n",
      "2023-04-24  2023      4   24       0.680448          1        0      0.571455   \n",
      "2023-04-25  2023      4   25       0.659966          2        0      0.650179   \n",
      "2023-04-26  2023      4   26       0.512042          3        0      0.666851   \n",
      "2023-04-27  2023      4   27       0.601786          4        0      0.587570   \n",
      "2023-04-28  2023      4   28       0.324294          5        0      0.589323   \n",
      "2023-04-29  2023      4   29       0.636260          6        1      0.385832   \n",
      "2023-04-30  2023      4   30       0.634834          0        1      0.631269   \n",
      "2023-05-01  2023      5    1       0.541248          1        0      0.694261   \n",
      "2023-05-02  2023      5    2       0.560212          2        0      0.553852   \n",
      "2023-05-03  2023      5    3       0.592683          3        0      0.581148   \n",
      "2023-05-04  2023      5    4       0.598521          4        0      0.582727   \n",
      "2023-05-05  2023      5    5       0.529111          5        0      0.646536   \n",
      "2023-05-06  2023      5    6       0.472365          6        1      0.606743   \n",
      "2023-05-07  2023      5    7       0.333965          0        1      0.467610   \n",
      "2023-05-08  2023      5    8       0.283520          1        0      0.405624   \n",
      "2023-05-09  2023      5    9       0.283182          2        0      0.361889   \n",
      "2023-05-10  2023      5   10       0.366395          3        0      0.393976   \n",
      "2023-05-11  2023      5   11       0.443356          4        0      0.405852   \n",
      "2023-05-12  2023      5   12       0.359370          5        0      0.428600   \n",
      "2023-05-13  2023      5   13       0.682344          6        1      0.438041   \n",
      "2023-05-14  2023      5   14       0.619002          0        1      0.665173   \n",
      "2023-05-15  2023      5   15       0.491354          1        0      0.629662   \n",
      "2023-05-16  2023      5   16       0.549023          2        0      0.474871   \n",
      "2023-05-17  2023      5   17       0.533283          3        0      0.571232   \n",
      "2023-05-18  2023      5   18       0.616537          4        0      0.565062   \n",
      "2023-05-19  2023      5   19       0.658185          5        0      0.619277   \n",
      "2023-05-20  2023      5   20       0.692775          6        1      0.662683   \n",
      "2023-05-21  2023      5   21       0.605158          0        1      0.646586   \n",
      "2023-05-22  2023      5   22       0.518672          1        0      0.660999   \n",
      "2023-05-23  2023      5   23       0.631709          2        0      0.553363   \n",
      "2023-05-24  2023      5   24       0.523628          3        0      0.628459   \n",
      "2023-05-25  2023      5   25       0.613462          4        0      0.561850   \n",
      "2023-05-26  2023      5   26       0.680637          5        0      0.618691   \n",
      "2023-05-27  2023      5   27       0.750427          6        1      0.737156   \n",
      "2023-05-28  2023      5   28       0.740310          0        1      0.701986   \n",
      "2023-05-29  2023      5   29       0.668690          1        0      0.750581   \n",
      "2023-05-30  2023      5   30       0.659776          2        0      0.694923   \n",
      "2023-05-31  2023      5   31       0.655019          3        0      0.682360   \n",
      "2023-06-01  2023      6    1       0.609141          4        0      0.704164   \n",
      "2023-06-02  2023      6    2       0.721601          5        0      0.603239   \n",
      "2023-06-03  2023      6    3       0.712407          6        1      0.766906   \n",
      "2023-06-04  2023      6    4       0.751185          0        1      0.738567   \n",
      "2023-06-05  2023      6    5       0.676465          1        0      0.754909   \n",
      "2023-06-06  2023      6    6       0.738529          2        0      0.726478   \n",
      "2023-06-07  2023      6    7       0.698464          3        0      0.717127   \n",
      "2023-06-08  2023      6    8       0.783235          4        0      0.781115   \n",
      "2023-06-09  2023      6    9       0.904446          5        0      0.781009   \n",
      "2023-06-10  2023      6   10       0.979708          6        1      0.896895   \n",
      "2023-06-11  2023      6   11       0.877679          0        1      0.969189   \n",
      "2023-06-12  2023      6   12       0.900403          1        0      0.883634   \n",
      "2023-06-13  2023      6   13       1.000000          2        0      0.950126   \n",
      "2023-06-14  2023      6   14       0.960743          3        0      0.959366   \n",
      "2023-06-15  2023      6   15       0.837078          4        0      0.979016   \n",
      "2023-06-16  2023      6   16       0.979898          5        0      0.906614   \n",
      "2023-06-17  2023      6   17       0.966622          6        1      0.983869   \n",
      "2023-06-18  2023      6   18       0.881801          0        1      1.000000   \n",
      "2023-06-19  2023      6   19       0.657798          1        0      0.899118   \n",
      "2023-06-20  2023      6   20       0.604161          2        0      0.795278   \n",
      "2023-06-21  2023      6   21       0.558385          3        0      0.691094   \n",
      "2023-06-22  2023      6   22       0.450358          4        0      0.644550   \n",
      "2023-06-23  2023      6   23       0.599411          5        0      0.582761   \n",
      "2023-06-24  2023      6   24       0.627908          6        1      0.681105   \n",
      "2023-06-25  2023      6   25       0.861559          0        1      0.727021   \n",
      "2023-06-26  2023      6   26       0.642708          1        0      0.842330   \n",
      "2023-06-27  2023      6   27       0.554490          2        0      0.732188   \n",
      "2023-06-28  2023      6   28       0.462166          3        0      0.635715   \n",
      "2023-06-29  2023      6   29       0.451546          4        0      0.568566   \n",
      "2023-06-30  2023      6   30       0.528764          5        0      0.522385   \n",
      "2023-07-01  2023      7    1       0.355775          6        1      0.598303   \n",
      "2023-07-02  2023      7    2       0.632657          0        1      0.490782   \n",
      "2023-07-03  2023      7    3       0.561416          1        0      0.650620   \n",
      "2023-07-04  2023      7    4       0.518474          2        0      0.619951   \n",
      "2023-07-05  2023      7    5       0.521714          3        0      0.548126   \n",
      "2023-07-06  2023      7    6       0.560823          4        0      0.623419   \n",
      "2023-07-07  2023      7    7       0.677413          5        0      0.583257   \n",
      "2023-07-08  2023      7    8       0.710980          6        1      0.682569   \n",
      "2023-07-09  2023      7    9       0.606140          0        1      0.743802   \n",
      "2023-07-10  2023      7   10       0.596814          1        0      0.635365   \n",
      "2023-07-11  2023      7   11       0.513180          2        0      0.666136   \n",
      "2023-07-12  2023      7   12       0.513329          3        0      0.527552   \n",
      "2023-07-13  2023      7   13       0.527593          4        0      0.569399   \n",
      "2023-07-14  2023      7   14       0.637588          5        0      0.612391   \n",
      "2023-07-15  2023      7   15       0.474542          6        1      0.639298   \n",
      "2023-07-16  2023      7   16       0.457994          0        1      0.554049   \n",
      "2023-07-17  2023      7   17       0.482458          1        0      0.476990   \n",
      "2023-07-18  2023      7   18       0.546772          2        0      0.564354   \n",
      "2023-07-19  2023      7   19       0.457425          3        0      0.586008   \n",
      "2023-07-20  2023      7   20       0.389911          4        0      0.500079   \n",
      "2023-07-21  2023      7   21       0.421903          5        0      0.462367   \n",
      "2023-07-22  2023      7   22       0.511853          6        1      0.449173   \n",
      "2023-07-23  2023      7   23       0.406410          0        1      0.572587   \n",
      "2023-07-24  2023      7   24       0.383908          1        0      0.459486   \n",
      "2023-07-25  2023      7   25       0.448891          2        0      0.424881   \n",
      "2023-07-26  2023      7   26       0.531955          3        0      0.489619   \n",
      "2023-07-27  2023      7   27       0.296836          4        0      0.530722   \n",
      "2023-07-28  2023      7   28       0.285606          5        0      0.411402   \n",
      "2023-07-29  2023      7   29       0.393135          6        1      0.324842   \n",
      "2023-07-30  2023      7   30       0.464054          0        1      0.412268   \n",
      "2023-07-31  2023      7   31       0.332448          1        0      0.486680   \n",
      "2023-08-01  2023      8    1       0.448891          2        0      0.406907   \n",
      "2023-08-02  2023      8    2       0.430215          3        0      0.481596   \n",
      "2023-08-03  2023      8    3       0.426702          4        0      0.405275   \n",
      "2023-08-04  2023      8    4       0.396548          5        0      0.450346   \n",
      "2023-08-05  2023      8    5       0.391997          6        1      0.471527   \n",
      "2023-08-06  2023      8    6       0.491957          0        1      0.410775   \n",
      "2023-08-07  2023      8    7       0.476768          1        0      0.482667   \n",
      "2023-08-08  2023      8    8       0.384411          2        0      0.464502   \n",
      "2023-08-09  2023      8    9       0.471574          3        0      0.455950   \n",
      "2023-08-10  2023      8   10       0.534041          4        0      0.505031   \n",
      "2023-08-11  2023      8   11       0.544472          5        0      0.485851   \n",
      "2023-08-12  2023      8   12       0.447233          6        1      0.544454   \n",
      "2023-08-13  2023      8   13       0.483785          0        1      0.496462   \n",
      "2023-08-14  2023      8   14       0.525507          1        0      0.517747   \n",
      "2023-08-15  2023      8   15       0.528368          2        0      0.510231   \n",
      "2023-08-16  2023      8   16       0.559264          3        0      0.501911   \n",
      "2023-08-17  2023      8   17       0.424616          4        0      0.611529   \n",
      "2023-08-18  2023      8   18       0.461283          5        0      0.473991   \n",
      "2023-08-19  2023      8   19       0.515266          6        1      0.461779   \n",
      "2023-08-20  2023      8   20       0.474113          0        1      0.509276   \n",
      "2023-08-21  2023      8   21       0.479885          1        0      0.501891   \n",
      "2023-08-22  2023      8   22       0.423668          2        0      0.564312   \n",
      "2023-08-23  2023      8   23       0.510525          3        0      0.423916   \n",
      "2023-08-24  2023      8   24       0.410623          4        0      0.486823   \n",
      "2023-08-25  2023      8   25       0.324863          5        0      0.474790   \n",
      "2023-08-26  2023      8   26       0.460080          6        1      0.397242   \n",
      "2023-08-27  2023      8   27       0.455149          0        1      0.501875   \n",
      "2023-08-28  2023      8   28       0.421771          1        0      0.408292   \n",
      "2023-08-29  2023      8   29       0.378532          2        0      0.466123   \n",
      "2023-08-30  2023      8   30       0.419331          3        0      0.472752   \n",
      "2023-08-31  2023      8   31       0.421202          4        0      0.416289   \n",
      "2023-09-01  2023      9    1       0.277072          5        0      0.435614   \n",
      "2023-09-02  2023      9    2       0.295253          6        1      0.300704   \n",
      "2023-09-03  2023      9    3       0.468424          0        1      0.396672   \n",
      "2023-09-04  2023      9    4       0.512991          1        0      0.485569   \n",
      "2023-09-05  2023      9    5       0.523025          2        0      0.454646   \n",
      "2023-09-06  2023      9    6       0.602693          3        0      0.546065   \n",
      "2023-09-07  2023      9    7       0.623554          4        0      0.593501   \n",
      "2023-09-08  2023      9    8       0.669663          5        0      0.635752   \n",
      "2023-09-09  2023      9    9       0.701119          6        1      0.620744   \n",
      "2023-09-10  2023      9   10       0.730324          0        1      0.654193   \n",
      "2023-09-11  2023      9   11       0.637415          1        0      0.755523   \n",
      "2023-09-12  2023      9   12       0.412479          2        0      0.644232   \n",
      "2023-09-13  2023      9   13       0.428409          3        0      0.461509   \n",
      "2023-09-14  2023      9   14       0.372431          4        0      0.441124   \n",
      "2023-09-15  2023      9   15       0.421392          5        0      0.442215   \n",
      "2023-09-16  2023      9   16       0.448511          6        1      0.507082   \n",
      "2023-09-17  2023      9   17       0.359378          0        1      0.472783   \n",
      "2023-09-18  2023      9   18       0.470189          1        0      0.382923   \n",
      "2023-09-19  2023      9   19       0.404476          2        0      0.494550   \n",
      "2023-09-20  2023      9   20       0.574729          3        0      0.479540   \n",
      "2023-09-21  2023      9   21       0.390480          4        0      0.578539   \n",
      "2023-09-22  2023      9   22       0.385739          5        0      0.416587   \n",
      "2023-09-23  2023      9   23       0.304950          6        1      0.396852   \n",
      "2023-09-24  2023      9   24       0.407738          0        1      0.407202   \n",
      "2023-09-25  2023      9   25       0.430305          1        0      0.428357   \n",
      "2023-09-26  2023      9   26       0.293670          2        0      0.454504   \n",
      "2023-09-27  2023      9   27       0.385739          3        0      0.324383   \n",
      "2023-09-28  2023      9   28       0.433340          4        0      0.423127   \n",
      "2023-09-29  2023      9   29       0.315240          5        0      0.481689   \n",
      "2023-09-30  2023      9   30       0.322587          6        1      0.324186   \n",
      "2023-10-01  2023     10    1       0.486061          0        1      0.372022   \n",
      "2023-10-02  2023     10    2       0.488197          1        0      0.469716   \n",
      "2023-10-03  2023     10    3       0.557747          2        0      0.509581   \n",
      "2023-10-04  2023     10    4       0.378153          3        0      0.567512   \n",
      "2023-10-05  2023     10    5       0.346705          4        0      0.376712   \n",
      "2023-10-06  2023     10    6       0.432985          5        0      0.382196   \n",
      "2023-10-07  2023     10    7       0.518111          6        1      0.454616   \n",
      "2023-10-08  2023     10    8       0.374409          0        1      0.525121   \n",
      "2023-10-09  2023     10    9       0.246374          1        0      0.421333   \n",
      "\n",
      "            day_lag1  day_lag7   day_lag30  day_lag365  \n",
      "Date                                                    \n",
      "2022-01-01       NaN       NaN         NaN         NaN  \n",
      "2022-01-02  0.298815       NaN         NaN         NaN  \n",
      "2022-01-03  0.388855       NaN         NaN         NaN  \n",
      "2022-01-04  0.517163       NaN         NaN         NaN  \n",
      "2022-01-05  0.460649       NaN         NaN         NaN  \n",
      "2022-01-06  0.301981       NaN         NaN         NaN  \n",
      "2022-01-07  0.270624       NaN         NaN         NaN  \n",
      "2022-01-08  0.387445  0.298815         NaN         NaN  \n",
      "2022-01-09  0.416362  0.388855         NaN         NaN  \n",
      "2022-01-10  0.386118  0.517163         NaN         NaN  \n",
      "2022-01-11  0.064100  0.460649         NaN         NaN  \n",
      "2022-01-12  0.125067  0.301981         NaN         NaN  \n",
      "2022-01-13  0.029774  0.270624         NaN         NaN  \n",
      "2022-01-14  0.006258  0.387445         NaN         NaN  \n",
      "2022-01-15  0.020779  0.416362         NaN         NaN  \n",
      "2022-01-16  0.054049  0.386118         NaN         NaN  \n",
      "2022-01-17  0.088944  0.064100         NaN         NaN  \n",
      "2022-01-18  0.109434  0.125067         NaN         NaN  \n",
      "2022-01-19  0.096909  0.029774         NaN         NaN  \n",
      "2022-01-20  0.120614  0.006258         NaN         NaN  \n",
      "2022-01-21  0.479687  0.020779         NaN         NaN  \n",
      "2022-01-22  0.278020  0.054049         NaN         NaN  \n",
      "2022-01-23  0.274417  0.088944         NaN         NaN  \n",
      "2022-01-24  0.294857  0.109434         NaN         NaN  \n",
      "2022-01-25  0.237815  0.096909         NaN         NaN  \n",
      "2022-01-26  0.024464  0.120614         NaN         NaN  \n",
      "2022-01-27  0.095581  0.479687         NaN         NaN  \n",
      "2022-01-28  0.225109  0.278020         NaN         NaN  \n",
      "2022-01-29  0.097288  0.274417         NaN         NaN  \n",
      "2022-01-30  0.391824  0.294857         NaN         NaN  \n",
      "2022-01-31  0.392187  0.237815   34.826087         NaN  \n",
      "2022-02-01  0.596435  0.024464   44.717391         NaN  \n",
      "2022-02-02  0.369462  0.095581   58.812500         NaN  \n",
      "2022-02-03  0.357482  0.225109   52.604167         NaN  \n",
      "2022-02-04  0.350654  0.097288   35.173913         NaN  \n",
      "2022-02-05  0.435953  0.391824   31.729167         NaN  \n",
      "2022-02-06  0.434098  0.392187   44.562500         NaN  \n",
      "2022-02-07  0.557368  0.596435   47.739130         NaN  \n",
      "2022-02-08  0.463493  0.369462   44.416667         NaN  \n",
      "2022-02-09  0.457128  0.357482    9.041667         NaN  \n",
      "2022-02-10  0.374739  0.350654   15.739130         NaN  \n",
      "2022-02-11  0.255263  0.435953    5.270833         NaN  \n",
      "2022-02-12  0.289118  0.434098    2.687500         NaN  \n",
      "2022-02-13  0.334345  0.557368    4.282609         NaN  \n",
      "2022-02-14  0.526266  0.463493    7.937500         NaN  \n",
      "2022-02-15  0.534701  0.457128   11.770833         NaN  \n",
      "2022-02-16  0.427271  0.374739   14.021739         NaN  \n",
      "2022-02-17  0.489475  0.255263   12.645833         NaN  \n",
      "2022-02-18  0.622367  0.289118   15.250000         NaN  \n",
      "2022-02-19  0.556040  0.334345   54.695652         NaN  \n",
      "2022-02-20  0.574246  0.526266   32.541667         NaN  \n",
      "2022-02-21  0.581205  0.534701   32.145833         NaN  \n",
      "2022-02-22  0.604779  0.427271   34.391304         NaN  \n",
      "2022-02-23  0.345534  0.489475   28.125000         NaN  \n",
      "2022-02-24  0.380346  0.622367    4.687500         NaN  \n",
      "2022-02-25  0.489475  0.556040   12.500000         NaN  \n",
      "2022-02-26  0.444149  0.574246   26.729167         NaN  \n",
      "2022-02-27  0.287140  0.581205   12.687500         NaN  \n",
      "2022-02-28  0.419685  0.604779   45.043478         NaN  \n",
      "2022-03-01  0.347620  0.345534   45.083333         NaN  \n",
      "2022-03-02  0.158115  0.380346   67.520833         NaN  \n",
      "2022-03-03  0.157216  0.489475   42.586957         NaN  \n",
      "2022-03-04  0.200834  0.444149   41.270833         NaN  \n",
      "2022-03-05  0.267944  0.287140   40.520833         NaN  \n",
      "2022-03-06  0.206524  0.419685   49.891304         NaN  \n",
      "2022-03-07  0.357984  0.347620   49.687500         NaN  \n",
      "2022-03-08  0.416082  0.158115   63.229167         NaN  \n",
      "2022-03-09  0.379860  0.157216   52.916667         NaN  \n",
      "2022-03-10  0.426455  0.200834   52.217391         NaN  \n",
      "2022-03-11  0.562299  0.267944   43.166667         NaN  \n",
      "2022-03-12  0.573298  0.206524   30.041667         NaN  \n",
      "2022-03-13  0.656206  0.357984   33.760870         NaN  \n",
      "2022-03-14  0.725014  0.416082   38.729167         NaN  \n",
      "2022-03-15  0.449080  0.379860   59.812500         NaN  \n",
      "2022-03-16  0.292433  0.426455   60.739130         NaN  \n",
      "2022-03-17  0.202640  0.562299   48.937500         NaN  \n",
      "2022-03-18  0.419216  0.573298   55.770833         NaN  \n",
      "2022-03-19  0.343410  0.656206   70.369565         NaN  \n",
      "2022-03-20  0.561614  0.725014   63.083333         NaN  \n",
      "2022-03-21  0.493078  0.449080   65.083333         NaN  \n",
      "2022-03-22  0.356006  0.292433   65.847826         NaN  \n",
      "2022-03-23  0.439219  0.202640   68.437500         NaN  \n",
      "2022-03-24  0.464062  0.419216   39.958333         NaN  \n",
      "2022-03-25  0.445848  0.343410   43.782609         NaN  \n",
      "2022-03-26  0.540869  0.561614   55.770833         NaN  \n",
      "2022-03-27  0.615210  0.493078   50.791667         NaN  \n",
      "2022-03-30       NaN  0.464062   40.187500         NaN  \n",
      "2022-03-31  0.391428  0.445848   19.369565         NaN  \n",
      "2022-04-01  0.432185  0.540869   19.270833         NaN  \n",
      "2022-04-02  0.482268  0.615210   24.062500         NaN  \n",
      "2022-04-03  0.611087  0.307106   31.434783         NaN  \n",
      "2022-04-04  0.505784       NaN   24.687500         NaN  \n",
      "2022-04-05  0.423882       NaN   41.326087         NaN  \n",
      "2022-04-06  0.321087  0.391428   47.708333         NaN  \n",
      "2022-04-07  0.468045  0.432185   43.729167         NaN  \n",
      "2022-04-08  0.577091  0.482268   48.847826         NaN  \n",
      "2022-04-09  0.431600  0.611087   63.770833         NaN  \n",
      "2022-04-10  0.509008  0.505784   64.979167         NaN  \n",
      "2022-04-11  0.484734  0.423882   74.086957         NaN  \n",
      "2022-04-12  0.550540  0.321087   81.645833         NaN  \n",
      "2022-04-13  0.494727  0.468045   51.333333         NaN  \n",
      "2022-04-14  0.159492  0.577091   34.125000         NaN  \n",
      "2022-04-15  0.284658  0.431600   24.260870         NaN  \n",
      "2022-04-16  0.331863  0.509008   48.052632         NaN  \n",
      "2022-04-17  0.478096  0.484734   39.725000         NaN  \n",
      "2022-04-18  0.517732  0.550540   63.695652         NaN  \n",
      "2022-04-19  0.556469  0.494727   56.166667         NaN  \n",
      "2022-04-20  0.497440  0.159492   41.108696         NaN  \n",
      "2022-04-21  0.560781  0.284658   50.250000         NaN  \n",
      "2022-04-22  0.569728  0.331863   52.979167         NaN  \n",
      "2022-04-23  0.458752  0.478096   50.978261         NaN  \n",
      "2022-04-24  0.601176  0.517732   61.416667         NaN  \n",
      "2022-04-25  0.694597  0.556469   69.583333         NaN  \n",
      "2022-04-26  0.398635  0.497440   35.736842         NaN  \n",
      "2022-04-27  0.518490  0.560781         NaN         NaN  \n",
      "2022-04-28  0.592881  0.569728         NaN         NaN  \n",
      "2022-04-29  0.587521  0.458752   45.000000         NaN  \n",
      "2022-04-30  0.384601  0.601176   49.477273         NaN  \n",
      "2022-05-01  0.583778  0.694597   54.979167         NaN  \n",
      "2022-05-02  0.517542  0.398635   69.130435         NaN  \n",
      "2022-05-03  0.532335  0.518490   57.562500         NaN  \n",
      "2022-05-04  0.528368  0.592881   48.565217         NaN  \n",
      "2022-05-05  0.456476  0.587521   37.272727         NaN  \n",
      "2022-05-06  0.318035  0.384601   53.416667         NaN  \n",
      "2022-05-07  0.409040  0.583778   65.395833         NaN  \n",
      "2022-05-08  0.392187  0.517542   49.413043         NaN  \n",
      "2022-05-09  0.543713  0.532335   57.916667         NaN  \n",
      "2022-05-10  0.573290  0.528368   55.250000         NaN  \n",
      "2022-05-11  0.528921  0.456476   62.479167         NaN  \n",
      "2022-05-12  0.585625  0.318035   56.347826         NaN  \n",
      "2022-05-13  0.498685  0.409040   19.520833         NaN  \n",
      "2022-05-14  0.535559  0.392187   33.270833         NaN  \n",
      "2022-05-15  0.652001  0.543713   38.456522         NaN  \n",
      "2022-05-16  0.733779  0.573290   54.520833         NaN  \n",
      "2022-05-17  0.543144  0.528921   58.875000         NaN  \n",
      "2022-05-18  0.516594  0.585625   63.130435         NaN  \n",
      "2022-05-19  0.673225  0.498685   56.645833         NaN  \n",
      "2022-05-20  0.515835  0.535559   63.604167         NaN  \n",
      "2022-05-21  0.422254  0.652001   64.586957         NaN  \n",
      "2022-05-22  0.592287  0.733779   52.395833         NaN  \n",
      "2022-05-23  0.653518  0.543144   68.041667         NaN  \n",
      "2022-05-24  0.437339  0.516594   78.304348         NaN  \n",
      "2022-05-25  0.486416  0.673225   45.791667         NaN  \n",
      "2022-05-26  0.489664  0.515835   58.958333         NaN  \n",
      "2022-05-27  0.498957  0.422254   67.130435         NaN  \n",
      "2022-05-28  0.550928  0.592287   66.541667         NaN  \n",
      "2022-05-29  0.527973  0.653518   44.250000         NaN  \n",
      "2022-05-30  0.502181  0.437339   66.130435         NaN  \n",
      "2022-05-31  0.457326  0.486416   58.854167         NaN  \n",
      "2022-06-01  0.461218  0.489664   60.479167         NaN  \n",
      "2022-06-02  0.526266  0.498957   60.043478         NaN  \n",
      "2022-06-03  0.664897  0.550928   52.145833         NaN  \n",
      "2022-06-04  0.777315  0.527973   36.937500         NaN  \n",
      "2022-06-05  0.801631  0.502181   46.934783         NaN  \n",
      "2022-06-06  0.415513  0.457326   45.083333         NaN  \n",
      "2022-06-07  0.507788  0.461218   61.729167         NaN  \n",
      "2022-06-08  0.357671  0.526266   64.978261         NaN  \n",
      "2022-06-09  0.271383  0.664897   60.104167         NaN  \n",
      "2022-06-10  0.422299  0.777315   66.333333         NaN  \n",
      "2022-06-11  0.410203  0.801631   56.782609         NaN  \n",
      "2022-06-12  0.478855  0.415513   60.833333         NaN  \n",
      "2022-06-13  0.549543  0.507788   73.625000         NaN  \n",
      "2022-06-14  0.547696  0.357671   82.608696         NaN  \n",
      "2022-06-15  0.646880  0.271383   61.666667         NaN  \n",
      "2022-06-16  0.851326  0.422299   58.750000         NaN  \n",
      "2022-06-17  0.801890  0.410203   75.956522         NaN  \n",
      "2022-06-18  0.830944  0.478855   58.666667         NaN  \n",
      "2022-06-19  0.935826  0.549543   48.386364         NaN  \n",
      "2022-06-20  0.520956  0.547696   67.065217         NaN  \n",
      "2022-06-21  0.530059  0.646880   73.791667         NaN  \n",
      "2022-06-22  0.441494  0.851326   50.043478         NaN  \n",
      "2022-06-23  0.699033  0.801890   55.434783         NaN  \n",
      "2022-06-24  0.655604  0.830944   55.791667         NaN  \n",
      "2022-06-25  0.487801  0.935826   56.812500         NaN  \n",
      "2022-06-26  0.384032  0.520956   62.521739         NaN  \n",
      "2022-06-27  0.393324  0.530059   60.000000         NaN  \n",
      "2022-06-28  0.272496  0.441494   57.166667         NaN  \n",
      "2022-06-29  0.494216  0.699033   52.239130         NaN  \n",
      "2022-06-30  0.602883  0.655604   52.666667         NaN  \n",
      "2022-07-01  0.319989  0.487801   59.812500         NaN  \n",
      "2022-07-02  0.366016  0.384032   75.041667         NaN  \n",
      "2022-07-03  0.512611  0.393324   87.391304         NaN  \n",
      "2022-07-04  0.482656  0.272496   90.062500         NaN  \n",
      "2022-07-05  0.461597  0.494216   47.645833         NaN  \n",
      "2022-07-06  0.491940  0.602883   57.782609         NaN  \n",
      "2022-07-07  0.543606  0.319989   41.291667         NaN  \n",
      "2022-07-08  0.411910  0.366016   31.812500         NaN  \n",
      "2022-07-09  0.515835  0.512611   48.391304         NaN  \n",
      "2022-07-10  0.534701  0.482656   47.062500         NaN  \n",
      "2022-07-11  0.441874  0.461597   54.604167         NaN  \n",
      "2022-07-12  0.453063  0.491940   62.369565         NaN  \n",
      "2022-07-13  0.500862  0.543606   62.166667         NaN  \n",
      "2022-07-14  0.681775  0.411910   73.062500         NaN  \n",
      "2022-07-15  0.499716  0.515835   95.521739         NaN  \n",
      "2022-07-16  0.476521  0.534701   90.090909         NaN  \n",
      "2022-07-17  0.537076  0.441874   93.282609         NaN  \n",
      "2022-07-18  0.608762  0.453063  104.804348         NaN  \n",
      "2022-07-19  0.851749  0.500862   59.229167         NaN  \n",
      "2022-07-20  0.984259  0.681775   60.229167         NaN  \n",
      "2022-07-21  0.715342  0.499716   50.500000         NaN  \n",
      "2022-07-22  0.433777  0.476521   78.791667         NaN  \n",
      "2022-07-23  0.438839  0.537076   74.020833         NaN  \n",
      "2022-07-24  0.609141  0.608762   55.586957         NaN  \n",
      "2022-07-25  0.702314  0.851749   44.187500         NaN  \n",
      "2022-07-26  0.495543  0.984259   45.208333         NaN  \n",
      "2022-07-27  0.451166  0.715342   31.934783         NaN  \n",
      "2022-07-28  0.500070  0.433777   56.291667         NaN  \n",
      "2022-07-29  0.620140  0.438839   68.229167         NaN  \n",
      "2022-07-30  0.772046  0.609141   37.152174         NaN  \n",
      "2022-07-31  0.674214  0.702314   42.208333         NaN  \n",
      "2022-08-01  0.411720  0.495543   58.312500         NaN  \n",
      "2022-08-02  0.506353  0.451166   55.021739         NaN  \n",
      "2022-08-03  0.486811  0.500070   52.708333         NaN  \n",
      "2022-08-04  0.418737  0.620140   56.041667         NaN  \n",
      "2022-08-05  0.351982  0.772046   61.717391         NaN  \n",
      "2022-08-06  0.494250  0.674214   47.250000         NaN  \n",
      "2022-08-07  0.486630  0.411720   58.666667         NaN  \n",
      "2022-08-08  0.648777  0.506353   60.739130         NaN  \n",
      "2022-08-09  0.622795  0.486811   50.541667         NaN  \n",
      "2022-08-10  0.619398  0.418737   51.770833         NaN  \n",
      "2022-08-11  0.811682  0.351982   57.021739         NaN  \n",
      "2022-08-12  0.924142  0.494250   76.895833         NaN  \n",
      "2022-08-13  0.948689  0.486630   56.895833         NaN  \n",
      "2022-08-14  0.867438  0.648777   54.347826         NaN  \n",
      "2022-08-15  0.898540  0.622795   61.000000         NaN  \n",
      "2022-08-16  0.821247  0.619398   68.875000         NaN  \n",
      "2022-08-17  0.915608  0.811682   95.568182         NaN  \n",
      "2022-08-18  0.622795  0.924142  110.125000         NaN  \n",
      "2022-08-19  0.715177  0.948689   80.583333         NaN  \n",
      "2022-08-20  0.345344  0.867438   49.652174         NaN  \n",
      "2022-08-21  0.438270  0.898540   50.208333         NaN  \n",
      "2022-08-22  0.416006  0.821247   68.916667         NaN  \n",
      "2022-08-23  0.869748  0.915608   79.152174         NaN  \n",
      "2022-08-24  0.464252  0.622795   56.437500         NaN  \n",
      "2022-08-25  0.660914  0.715177   51.562500         NaN  \n",
      "2022-08-26  0.799166  0.345344   56.934783         NaN  \n",
      "2022-08-27  0.569926  0.438270   70.125000         NaN  \n",
      "2022-08-28  0.515266  0.416006   86.812500         NaN  \n",
      "2022-08-29  0.610468  0.869748   76.065217         NaN  \n",
      "2022-08-30  0.568145  0.464252   47.229167         NaN  \n",
      "2022-08-31  0.585815  0.660914   57.625000         NaN  \n",
      "2022-09-01  0.637398  0.799166   55.478261         NaN  \n",
      "2022-09-02  0.658185  0.569926   48.000000         NaN  \n",
      "2022-09-03  0.610279  0.515266   40.666667         NaN  \n",
      "2022-09-04  0.628295  0.610468   56.295455         NaN  \n",
      "2022-09-05  0.565333  0.568145   55.458333         NaN  \n",
      "2022-09-06  0.672235  0.585815   73.270833         NaN  \n",
      "2022-09-07  0.520939  0.637398   70.416667         NaN  \n",
      "2022-09-08  0.504457  0.658185   70.043478         NaN  \n",
      "2022-09-09  0.413196  0.610279   91.166667         NaN  \n",
      "2022-09-10  0.422340  0.628295  103.520833         NaN  \n",
      "2022-09-11  0.414565  0.565333  106.217391         NaN  \n",
      "2022-09-12  0.432391  0.672235   97.291667         NaN  \n",
      "2022-09-13  0.399393  0.520939  100.708333         NaN  \n",
      "2022-09-14  0.294519  0.504457   92.217391         NaN  \n",
      "2022-09-15  0.211347  0.413196  102.583333         NaN  \n",
      "2022-09-16  0.282761  0.422340   70.416667         NaN  \n",
      "2022-09-17  0.374739  0.414565   80.565217         NaN  \n",
      "2022-09-18  0.301981  0.432391   39.937500         NaN  \n",
      "2022-09-19  0.324483  0.399393   50.145833         NaN  \n",
      "2022-09-20  0.311018  0.294519   47.700000         NaN  \n",
      "2022-09-21  0.286942  0.211347   97.545455         NaN  \n",
      "2022-09-22  0.230988  0.282761   53.000000         NaN  \n",
      "2022-09-23  0.280106  0.374739   74.604167         NaN  \n",
      "2022-09-24  0.280807  0.301981   89.791667         NaN  \n",
      "2022-09-25  0.394083  0.324483   64.608696         NaN  \n",
      "2022-09-26  0.342310  0.311018   58.604167         NaN  \n",
      "2022-09-27  0.314844  0.286942   69.062500         NaN  \n",
      "2022-09-28  0.312536  0.230988   64.413043         NaN  \n",
      "2022-09-29  0.251280  0.280106   66.354167         NaN  \n",
      "2022-09-30  0.189184  0.280807   72.020833         NaN  \n",
      "2022-10-01  0.266831  0.394083   74.304348         NaN  \n",
      "2022-10-02  0.412289  0.342310   69.041667         NaN  \n",
      "2022-10-03  0.331665  0.314844   71.020833         NaN  \n",
      "2022-10-04  0.149630  0.312536   64.104167         NaN  \n",
      "2022-10-05  0.257159  0.251280   75.847826         NaN  \n",
      "2022-10-06  0.411585  0.189184   59.227273         NaN  \n",
      "2022-10-07  0.350085  0.266831   57.416667         NaN  \n",
      "2022-10-08  0.285606  0.412289   47.391304         NaN  \n",
      "2022-10-09  0.358484  0.331665   48.395833         NaN  \n",
      "2022-10-10  0.045515  0.149630   47.541667         NaN  \n",
      "2022-10-11  0.359568  0.257159   49.500000         NaN  \n",
      "2022-10-12  0.034895  0.411585   45.875000         NaN  \n",
      "2022-10-13  0.149992  0.350085   34.354167         NaN  \n",
      "2022-10-14  0.179405  0.285606   25.217391         NaN  \n",
      "2022-10-15  0.194725  0.358484   33.062500         NaN  \n",
      "2022-10-16  0.320121  0.045515   43.166667         NaN  \n",
      "2022-10-17  0.325242  0.359568   35.173913         NaN  \n",
      "2022-10-18  0.177508  0.034895   37.645833         NaN  \n",
      "2022-10-19  0.225109  0.149992   36.166667         NaN  \n",
      "2022-10-20  0.190594  0.179405   33.521739         NaN  \n",
      "2022-10-21  0.169395  0.194725   27.375000         NaN  \n",
      "2022-10-22  0.356913  0.320121   32.770833         NaN  \n",
      "2022-10-23  0.333965  0.325242   32.847826         NaN  \n",
      "2022-10-24  0.321639  0.177508   45.291667         NaN  \n",
      "2022-10-25  0.452548  0.225109   39.604167         NaN  \n",
      "2022-11-07       NaN       NaN   41.380952         NaN  \n",
      "2022-11-08  0.458790       NaN    7.000000         NaN  \n",
      "2022-11-09  0.416461       NaN   41.500000         NaN  \n",
      "2022-11-10  0.404893       NaN    5.833333         NaN  \n",
      "2022-11-11  0.283493       NaN   18.477273         NaN  \n",
      "2022-11-12  0.246918       NaN   21.708333         NaN  \n",
      "2022-11-13  0.055187       NaN   23.391304         NaN  \n",
      "2022-11-14  0.043239  0.458790   37.166667         NaN  \n",
      "2022-11-15  0.032652  0.416461   37.729167         NaN  \n",
      "2022-11-16  0.296226  0.404893   21.500000         NaN  \n",
      "2022-11-17  0.331500  0.283493   26.729167         NaN  \n",
      "2022-11-18  0.469001  0.246918   22.937500         NaN  \n",
      "2022-11-19  0.253935  0.055187   20.608696         NaN  \n",
      "2022-11-20  0.038498  0.043239   41.208333         NaN  \n",
      "2022-11-21  0.018206  0.032652   38.687500         NaN  \n",
      "2022-11-22  0.315803  0.296226   37.333333         NaN  \n",
      "2022-11-23  0.389342  0.331500   51.714286         NaN  \n",
      "2022-11-24  0.317593  0.469001   41.000000         NaN  \n",
      "2022-11-25  0.391668  0.253935         NaN         NaN  \n",
      "2022-11-26  0.239712  0.038498         NaN         NaN  \n",
      "2022-11-27  0.177904  0.018206         NaN         NaN  \n",
      "2022-11-28  0.275934  0.315803         NaN         NaN  \n",
      "2022-11-29  0.135976  0.389342         NaN         NaN  \n",
      "2022-12-01       NaN  0.391668         NaN         NaN  \n",
      "2022-12-02  0.061970  0.239712         NaN         NaN  \n",
      "2022-12-03  0.095581  0.177904         NaN         NaN  \n",
      "2022-12-04  0.076237  0.275934         NaN         NaN  \n",
      "2022-12-05  0.043998  0.135976         NaN         NaN  \n",
      "2022-12-06  0.002968  0.041874         NaN         NaN  \n",
      "2022-12-07  0.068083       NaN   52.400000         NaN  \n",
      "2022-12-08  0.134496  0.061970   47.750000         NaN  \n",
      "2022-12-09  0.135555  0.095581   46.479167         NaN  \n",
      "2022-12-10  0.080789  0.076237   33.142857         NaN  \n",
      "2022-12-11  0.155699  0.043998   29.125000         NaN  \n",
      "2022-12-12  0.248155  0.002968    8.062500         NaN  \n",
      "2022-12-13  0.096529  0.068083    6.750000         NaN  \n",
      "2022-12-14  0.015930  0.134496    5.586957         NaN  \n",
      "2022-12-15  0.015238  0.135555   34.541667         NaN  \n",
      "2022-12-16  0.000000  0.080789   38.416667         NaN  \n",
      "2022-12-17  0.031291  0.155699   53.521739         NaN  \n",
      "2022-12-18  0.010290  0.248155   29.895833         NaN  \n",
      "2022-12-19  0.104305  0.096529    6.229167         NaN  \n",
      "2022-12-20  0.279158  0.015930    4.000000         NaN  \n",
      "2022-12-21  0.278630  0.015238   36.692308         NaN  \n",
      "2022-12-22  0.238195  0.000000   44.770833         NaN  \n",
      "2022-12-23  0.264366  0.031291   36.888889         NaN  \n",
      "2022-12-24  0.366890  0.010290   45.026316         NaN  \n",
      "2022-12-25  0.385359  0.104305   28.333333         NaN  \n",
      "2022-12-26  0.254314  0.279158   21.543478         NaN  \n",
      "2022-12-27  0.405280  0.278630   32.312500         NaN  \n",
      "2022-12-28  0.366584  0.238195   16.937500         NaN  \n",
      "2022-12-29  0.437322  0.264366    6.600000         NaN  \n",
      "2022-12-30  0.483447  0.366890         NaN         NaN  \n",
      "2023-01-01       NaN  0.254314   12.500000   34.826087  \n",
      "2023-01-02  0.432805  0.405280   10.375000   44.717391  \n",
      "2023-01-03  0.419496  0.366584    6.833333   58.812500  \n",
      "2023-01-04  0.361654  0.437322    2.326087   52.604167  \n",
      "2023-01-05  0.479975  0.483447    9.479167   35.173913  \n",
      "2023-01-06  0.405272  0.382118   16.775000   31.729167  \n",
      "2023-01-07  0.378532       NaN   16.891304   44.562500  \n",
      "2023-01-08  0.449410  0.432805   10.875000   47.739130  \n",
      "2023-01-09  0.574815  0.419496   19.104167   44.416667  \n",
      "2023-01-10  0.476200  0.361654   29.260870    9.041667  \n",
      "2023-01-11  0.360953  0.479975   12.604167   15.739130  \n",
      "2023-01-12  0.467665  0.405272    3.750000    5.270833  \n",
      "2023-01-13  0.476958  0.378532    3.673913    2.687500  \n",
      "2023-01-14  0.533662  0.449410    2.000000    4.282609  \n",
      "2023-01-15  0.485822  0.574815    5.437500    7.937500  \n",
      "2023-01-16  0.567609  0.476200    3.130435   11.770833  \n",
      "2023-01-17  0.488716  0.360953   13.458333   14.021739  \n",
      "2023-01-18  0.188590  0.467665   32.666667   12.645833  \n",
      "2023-01-19  0.118528  0.476958   32.608696   15.250000  \n",
      "2023-01-20  0.181680  0.533662   28.166667   54.695652  \n",
      "2023-01-21  0.207983  0.485822   31.041667   32.541667  \n",
      "2023-01-22  0.150768  0.567609   42.304348   32.145833  \n",
      "2023-01-23  0.260762  0.488716   44.333333   34.391304  \n",
      "2023-01-24  0.106069  0.188590   29.937500   28.125000  \n",
      "2023-01-25  0.185663  0.118528   46.521739    4.687500  \n",
      "2023-01-26  0.088944  0.181680   42.270833   12.500000  \n",
      "2023-01-27  0.215701  0.207983   50.041667   26.729167  \n",
      "2023-01-28  0.376825  0.150768   55.108696   12.687500  \n",
      "2023-01-29  0.354258  0.260762   43.977273   45.043478  \n",
      "2023-01-30  0.165635  0.106069         NaN   45.083333  \n",
      "2023-01-31  0.383463  0.185663   49.545455   67.520833  \n",
      "2023-02-01  0.215437  0.088944   48.083333   42.586957  \n",
      "2023-02-02  0.437150  0.215701   41.729167   41.270833  \n",
      "2023-02-03  0.451735  0.376825   54.727273   40.520833  \n",
      "2023-02-04  0.458373  0.354258   46.520833   49.891304  \n",
      "2023-02-05  0.220648  0.165635   43.583333   49.687500  \n",
      "2023-02-06  0.468045  0.383463   51.369565   63.229167  \n",
      "2023-02-07  0.193628  0.215437   65.145833   52.916667  \n",
      "2023-02-08  0.083510  0.437150   54.312500   52.217391  \n",
      "2023-02-09  0.110753  0.451735   41.652174   43.166667  \n",
      "2023-02-10  0.135027  0.458373   53.375000   30.041667  \n",
      "2023-02-11  0.120713  0.220648   54.395833   33.760870  \n",
      "2023-02-12  0.238005  0.468045   60.625000   38.729167  \n",
      "2023-02-13  0.316518  0.193628   55.369565   59.812500  \n",
      "2023-02-14  0.098154  0.083510   64.354167   60.739130  \n",
      "2023-02-15  0.071876  0.110753   55.687500   48.937500  \n",
      "2023-02-16  0.113977  0.135027   22.717391   55.770833  \n",
      "2023-02-17  0.231928  0.120713   15.020833   70.369565  \n",
      "2023-02-18  0.464062  0.238005   21.958333   63.083333  \n",
      "2023-02-19  0.533852  0.316518   24.847826   65.083333  \n",
      "2023-02-20  0.435756  0.098154   18.562500   65.847826  \n",
      "2023-02-24       NaN  0.464062   11.770833   55.770833  \n",
      "2023-02-25  0.492699  0.533852   25.695652   50.791667  \n",
      "2023-02-27       NaN  0.430116   40.916667   48.104167  \n",
      "2023-02-28  0.421582       NaN   20.195652   40.187500  \n",
      "2023-03-01  0.309294       NaN   44.125000   19.369565  \n",
      "2023-03-02  0.333086       NaN   25.666667   19.270833  \n",
      "2023-03-03  0.265174  0.492699   50.022727   24.062500  \n",
      "2023-03-04  0.341569  0.389437   51.625000   31.434783  \n",
      "2023-03-05  0.586573       NaN   52.354167   24.687500  \n",
      "2023-03-06  0.470510  0.421582   26.239130   41.326087  \n",
      "2023-03-07  0.406600  0.309294   53.416667   47.708333  \n",
      "2023-03-08  0.446615  0.333086   23.270833   43.729167  \n",
      "2023-03-09  0.282003  0.265174   11.173913   48.847826  \n",
      "2023-03-10  0.220450  0.341569   14.166667   63.770833  \n",
      "2023-03-11  0.479992  0.586573   16.833333   64.979167  \n",
      "2023-03-12  0.401100  0.470510   15.260870   74.086957  \n",
      "2023-03-13  0.533118  0.406600   28.145833   81.645833  \n",
      "2023-03-14  0.420254  0.446615   36.770833   51.333333  \n",
      "2023-03-15  0.531007  0.282003   12.782609   34.125000  \n",
      "2023-03-16  0.459305  0.220450    9.895833   24.260870  \n",
      "2023-03-17  0.561350  0.479992   14.520833   48.052632  \n",
      "2023-03-18  0.480751  0.401100   27.478261   39.725000  \n",
      "2023-03-19  0.531766  0.533118   52.979167   63.695652  \n",
      "2023-03-20  0.461283  0.420254   60.645833   56.166667  \n",
      "2023-03-21  0.420064  0.531007   49.869565   41.108696  \n",
      "2023-03-22  0.419387  0.459305   49.250000   50.250000  \n",
      "2023-03-23  0.517569  0.561350         NaN   52.979167  \n",
      "2023-03-24  0.622416  0.480751         NaN   50.978261  \n",
      "2023-03-25  0.607624  0.531766         NaN   61.416667  \n",
      "2023-03-26  0.653139  0.461283   56.125000   69.583333  \n",
      "2023-03-27  0.568557  0.420064   44.781250   35.736842  \n",
      "2023-03-28  0.616628  0.419387         NaN         NaN  \n",
      "2023-03-29  0.441494  0.517569   48.312500         NaN  \n",
      "2023-03-30  0.401669  0.622416   35.977273   45.000000  \n",
      "2023-03-31  0.602658  0.607624   38.590909   49.477273  \n",
      "2023-04-01  0.577660  0.653139   31.130435   54.979167  \n",
      "2023-04-02  0.402996  0.568557   39.522727   69.130435  \n",
      "2023-04-03  0.448816  0.616628   66.437500   57.562500  \n",
      "2023-04-04  0.417030  0.441494   53.687500   48.565217  \n",
      "2023-04-05  0.489285  0.401669   46.666667   37.272727  \n",
      "2023-04-06  0.426133  0.602658   51.062500   53.416667  \n",
      "2023-04-07  0.431006  0.577660   32.979167   65.395833  \n",
      "2023-04-08  0.555471  0.402996   26.217391   49.413043  \n",
      "2023-04-09  0.526456  0.448816   54.729167   57.916667  \n",
      "2023-04-10  0.453962  0.417030   46.062500   55.250000  \n",
      "2023-04-11  0.575574  0.489285   60.565217   62.479167  \n",
      "2023-04-12  0.637019  0.426133   48.166667   56.347826  \n",
      "2023-04-13  0.647103  0.431006   60.333333   19.520833  \n",
      "2023-04-14  0.641760  0.555471   52.456522   33.270833  \n",
      "2023-04-15  0.484544  0.526456   63.666667   38.456522  \n",
      "2023-04-16  0.562801  0.453962   54.812500   54.520833  \n",
      "2023-04-17  0.481699  0.575574   60.416667   58.875000  \n",
      "2023-04-18  0.551489  0.637019   52.673913   63.130435  \n",
      "2023-04-19  0.465637  0.647103   48.145833   56.645833  \n",
      "2023-04-20  0.586383  0.641760   48.071429   63.604167  \n",
      "2023-04-21  0.633795  0.484544   58.857143   64.586957  \n",
      "2023-04-22  0.529556  0.562801   70.375000   52.395833  \n",
      "2023-04-23  0.204438  0.481699   68.750000   68.041667  \n",
      "2023-04-24  0.559264  0.551489   73.750000   78.304348  \n",
      "2023-04-25  0.680448  0.465637   64.458333   45.791667  \n",
      "2023-04-26  0.659966  0.586383   69.739130   58.958333  \n",
      "2023-04-27  0.512042  0.633795   50.500000   67.130435  \n",
      "2023-04-28  0.601786  0.529556   46.125000   66.541667  \n",
      "2023-04-29  0.324294  0.204438   68.204545   44.250000  \n",
      "2023-04-30  0.636260  0.559264   65.458333   66.130435  \n",
      "2023-05-01  0.634834  0.680448   46.270833   58.854167  \n",
      "2023-05-02  0.541248  0.659966   51.304348   60.479167  \n",
      "2023-05-03  0.560212  0.512042   47.812500   60.043478  \n",
      "2023-05-04  0.592683  0.601786   55.750000   52.145833  \n",
      "2023-05-05  0.598521  0.324294   48.812500   36.937500  \n",
      "2023-05-06  0.529111  0.636260   49.347826   46.934783  \n",
      "2023-05-07  0.472365  0.634834   63.020833   45.083333  \n",
      "2023-05-08  0.333965  0.541248   59.833333   61.729167  \n",
      "2023-05-09  0.283520  0.560212   51.869565   64.978261  \n",
      "2023-05-10  0.283182  0.592683   65.229167   60.104167  \n",
      "2023-05-11  0.366395  0.598521   71.979167   66.333333  \n",
      "2023-05-12  0.443356  0.529111   73.086957   56.782609  \n",
      "2023-05-13  0.359370  0.472365   72.500000   60.833333  \n",
      "2023-05-14  0.682344  0.333965   55.229167   73.625000  \n",
      "2023-05-15  0.619002  0.283520   63.826087   82.608696  \n",
      "2023-05-16  0.491354  0.283182   54.916667   61.666667  \n",
      "2023-05-17  0.549023  0.366395   62.583333   58.750000  \n",
      "2023-05-18  0.533283  0.443356   53.152174   75.956522  \n",
      "2023-05-19  0.616537  0.359370   66.416667   58.666667  \n",
      "2023-05-20  0.658185  0.682344   71.625000   48.386364  \n",
      "2023-05-21  0.692775  0.619002   60.173913   67.065217  \n",
      "2023-05-22  0.605158  0.491354   24.458333   73.791667  \n",
      "2023-05-23  0.518672  0.549023   63.437500   50.043478  \n",
      "2023-05-24  0.631709  0.533283   76.750000   55.434783  \n",
      "2023-05-25  0.523628  0.616537   74.500000   55.791667  \n",
      "2023-05-26  0.613462  0.658185   58.250000   56.812500  \n",
      "2023-05-27  0.680637  0.692775   68.108696   62.521739  \n",
      "2023-05-28  0.750427  0.605158   37.625000   60.000000  \n",
      "2023-05-29  0.740310  0.518672   71.895833   57.166667  \n",
      "2023-05-30  0.668690  0.631709   71.739130   52.239130  \n",
      "2023-05-31  0.659776  0.523628   61.458333   52.666667  \n",
      "2023-06-01  0.655019  0.613462   63.541667   59.812500  \n",
      "2023-06-02  0.609141  0.680637   67.108696   75.041667  \n",
      "2023-06-03  0.721601  0.750427   67.750000   87.391304  \n",
      "2023-06-04  0.712407  0.740310   60.125000   90.062500  \n",
      "2023-06-05  0.751185  0.668690   53.891304   47.645833  \n",
      "2023-06-06  0.676465  0.659776   38.687500   57.782609  \n",
      "2023-06-07  0.738529  0.655019   33.145833   41.291667  \n",
      "2023-06-08  0.698464  0.609141   33.108696   31.812500  \n",
      "2023-06-09  0.783235  0.721601   42.250000   48.391304  \n",
      "2023-06-10  0.904446  0.712407   50.704545   47.062500  \n",
      "2023-06-11  0.979708  0.751185   41.478261   54.604167  \n",
      "2023-06-12  0.877679  0.676465   76.958333   62.369565  \n",
      "2023-06-13  0.900403  0.738529   70.000000   62.166667  \n",
      "2023-06-14  1.000000  0.698464   55.977273   73.062500  \n",
      "2023-06-15  0.960743  0.783235   62.312500   95.521739  \n",
      "2023-06-16  0.837078  0.904446   60.583333   90.090909  \n",
      "2023-06-17  0.979898  0.979708   69.729167   93.282609  \n",
      "2023-06-18  0.966622  0.877679   74.304348  104.804348  \n",
      "2023-06-19  0.881801  0.900403   78.104167   59.229167  \n",
      "2023-06-20  0.657798  1.000000   68.479167   60.229167  \n",
      "2023-06-21  0.604161  0.960743   58.978261   50.500000  \n",
      "2023-06-22  0.558385  0.837078   71.395833   78.791667  \n",
      "2023-06-23  0.450358  0.979898   59.522727   74.020833  \n",
      "2023-06-24  0.599411  0.966622   69.391304   55.586957  \n",
      "2023-06-25  0.627908  0.881801   76.770833   44.187500  \n",
      "2023-06-26  0.861559  0.657798   84.437500   45.208333  \n",
      "2023-06-27  0.642708  0.604161   83.326087   31.934783  \n",
      "2023-06-28  0.554490  0.558385   75.458333   56.291667  \n",
      "2023-06-29  0.462166  0.450358   74.479167   68.229167  \n",
      "2023-06-30  0.451546  0.599411   73.956522   37.152174  \n",
      "2023-07-01  0.528764  0.627908   68.916667   42.208333  \n",
      "2023-07-02  0.355775  0.861559   81.270833   58.312500  \n",
      "2023-07-03  0.632657  0.642708   80.260870   55.021739  \n",
      "2023-07-04  0.561416  0.554490   84.520833   52.708333  \n",
      "2023-07-05  0.518474  0.462166   76.312500   56.041667  \n",
      "2023-07-06  0.521714  0.451546   83.130435   61.717391  \n",
      "2023-07-07  0.560823  0.528764   78.729167   47.250000  \n",
      "2023-07-08  0.677413  0.355775   88.041667   58.666667  \n",
      "2023-07-09  0.710980  0.632657  101.357143   60.739130  \n",
      "2023-07-10  0.606140  0.561416  109.625000   50.541667  \n",
      "2023-07-11  0.596814  0.518474   98.416667   51.770833  \n",
      "2023-07-12  0.513180  0.521714  100.913043   57.021739  \n",
      "2023-07-13  0.513329  0.560823  111.854167   76.895833  \n",
      "2023-07-14  0.527593  0.677413  107.541667   56.895833  \n",
      "2023-07-15  0.637588  0.710980   93.956522   54.347826  \n",
      "2023-07-16  0.474542  0.606140  109.645833   61.000000  \n",
      "2023-07-17  0.457994  0.596814  108.187500   68.875000  \n",
      "2023-07-18  0.482458  0.513180   98.869565   95.568182  \n",
      "2023-07-19  0.546772  0.513329   74.261905  110.125000  \n",
      "2023-07-20  0.457425  0.527593   68.369565   80.583333  \n",
      "2023-07-21  0.389911  0.637588   63.340909   49.652174  \n",
      "2023-07-22  0.421903  0.474542   51.473684   50.208333  \n",
      "2023-07-23  0.511853  0.457994   67.847826   68.916667  \n",
      "2023-07-24  0.406410  0.482458   70.978261   79.152174  \n",
      "2023-07-25  0.383908  0.546772   96.645833   56.437500  \n",
      "2023-07-26  0.448891  0.457425   72.604167   51.562500  \n",
      "2023-07-27  0.531955  0.389911   62.913043   56.934783  \n",
      "2023-07-28  0.296836  0.421903   52.770833   70.125000  \n",
      "2023-07-29  0.285606  0.511853   51.604167   86.812500  \n",
      "2023-07-30  0.393135  0.406410   60.086957   76.065217  \n",
      "2023-07-31  0.464054  0.383908   41.083333   47.229167  \n",
      "2023-08-01  0.332448  0.448891   71.500000   57.625000  \n",
      "2023-08-02  0.448891  0.531955   63.673913   55.478261  \n",
      "2023-08-03  0.430215  0.296836   58.956522   48.000000  \n",
      "2023-08-04  0.426702  0.285606   59.312500   40.666667  \n",
      "2023-08-05  0.396548  0.393135   63.608696   56.295455  \n",
      "2023-08-06  0.391997  0.464054   76.416667   55.458333  \n",
      "2023-08-07  0.491957  0.332448   80.104167   73.270833  \n",
      "2023-08-08  0.476768  0.448891   68.586957   70.416667  \n",
      "2023-08-09  0.384411  0.430215   67.562500   70.043478  \n",
      "2023-08-10  0.471574  0.426702   58.375000   91.166667  \n",
      "2023-08-11  0.534041  0.396548   58.391304  103.520833  \n",
      "2023-08-12  0.544472  0.391997   59.958333  106.217391  \n",
      "2023-08-13  0.447233  0.491957   72.041667   97.291667  \n",
      "2023-08-14  0.483785  0.476768   54.130435  100.708333  \n",
      "2023-08-15  0.525507  0.384411   52.312500   92.217391  \n",
      "2023-08-16  0.528368  0.471574   55.000000  102.583333  \n",
      "2023-08-17  0.559264  0.534041   62.065217   70.416667  \n",
      "2023-08-18  0.424616  0.544472   52.250000   80.565217  \n",
      "2023-08-19  0.461283  0.447233   44.833333   39.937500  \n",
      "2023-08-20  0.515266  0.483785   48.347826   50.145833  \n",
      "2023-08-21  0.474113  0.525507   58.229167   47.700000  \n",
      "2023-08-22  0.479885  0.528368   46.645833   97.545455  \n",
      "2023-08-23  0.423668  0.559264   44.173913   53.000000  \n",
      "2023-08-24  0.510525  0.424616   51.312500   74.604167  \n",
      "2023-08-25  0.410623  0.461283   60.437500   89.791667  \n",
      "2023-08-26  0.324863  0.515266   34.608696   64.608696  \n",
      "2023-08-27  0.460080  0.474113   33.375000   58.604167  \n",
      "2023-08-28  0.455149  0.479885   45.187500   69.062500  \n",
      "2023-08-29  0.421771  0.423668   52.978261   64.413043  \n",
      "2023-08-30  0.378532  0.510525   38.520833   66.354167  \n",
      "2023-08-31  0.419331  0.410623   51.312500   72.020833  \n",
      "2023-09-01  0.421202  0.324863   49.260870   74.304348  \n",
      "2023-09-02  0.277072  0.460080   48.875000   69.041667  \n",
      "2023-09-03  0.295253  0.455149   45.562500   71.020833  \n",
      "2023-09-04  0.468424  0.421771   45.062500   64.104167  \n",
      "2023-09-05  0.512991  0.378532   56.043478   75.847826  \n",
      "2023-09-06  0.523025  0.419331   54.375000   59.227273  \n",
      "2023-09-07  0.602693  0.421202   44.229167   57.416667  \n",
      "2023-09-08  0.623554  0.277072   53.804348   47.391304  \n",
      "2023-09-09  0.669663  0.295253   60.666667   48.395833  \n",
      "2023-09-10  0.701119  0.468424   61.812500   47.541667  \n",
      "2023-09-11  0.730324  0.512991   51.130435   49.500000  \n",
      "2023-09-12  0.637415  0.523025   55.145833   45.875000  \n",
      "2023-09-13  0.412479  0.602693   59.729167   34.354167  \n",
      "2023-09-14  0.428409  0.623554   60.043478   25.217391  \n",
      "2023-09-15  0.372431  0.669663   63.437500   33.062500  \n",
      "2023-09-16  0.421392  0.701119   48.645833   43.166667  \n",
      "2023-09-17  0.448511  0.730324   52.673913   35.173913  \n",
      "2023-09-18  0.359378  0.637415   58.604167   37.645833  \n",
      "2023-09-19  0.470189  0.412479   54.083333   36.166667  \n",
      "2023-09-20  0.404476  0.428409   54.717391   33.521739  \n",
      "2023-09-21  0.574729  0.372431   48.541667   27.375000  \n",
      "2023-09-22  0.390480  0.421392   58.083333   32.770833  \n",
      "2023-09-23  0.385739  0.448511   47.108696   32.847826  \n",
      "2023-09-24  0.304950  0.359378   37.687500   45.291667  \n",
      "2023-09-25  0.407738  0.470189   52.541667   39.604167  \n",
      "2023-09-26  0.430305  0.404476   52.000000   36.586957  \n",
      "2023-09-27  0.293670  0.574729   48.333333   36.333333  \n",
      "2023-09-28  0.385739  0.390480   43.583333   29.604167  \n",
      "2023-09-29  0.433340  0.385739   48.065217   22.782609  \n",
      "2023-09-30  0.315240  0.304950   48.270833   31.312500  \n",
      "2023-10-01  0.322587  0.407738   32.437500   47.291667  \n",
      "2023-10-02  0.486061  0.430305   34.434783   38.434783  \n",
      "2023-10-03  0.488197  0.293670   53.458333   18.437500  \n",
      "2023-10-04  0.557747  0.385739   58.354167   30.250000  \n",
      "2023-10-05  0.378153  0.433340   59.456522   47.214286  \n",
      "2023-10-06  0.346705  0.315240   68.208333   40.458333  \n",
      "2023-10-07  0.432985  0.322587   70.500000   33.375000  \n",
      "2023-10-08  0.518111  0.486061   75.565217   41.380952  \n",
      "2023-10-09  0.374409  0.488197   79.020833    7.000000  \n"
     ]
    }
   ],
   "source": [
    "# Remove rows with null values in the 'Concentration' column in-place\n",
    "data_normalized.dropna(subset=['Concentration'], inplace=True)\n",
    "\n",
    "# Display the modified data\n",
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81eee8",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "e1129ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
      "0    2022      1    1       0.298815          6        1      0.466547   \n",
      "1    2022      1    2       0.388855          0        1      0.327173   \n",
      "2    2022      1    3       0.517163          1        0      0.396925   \n",
      "3    2022      1    4       0.460649          2        0      0.505970   \n",
      "4    2022      1    5       0.301981          3        0      0.466815   \n",
      "5    2022      1    6       0.270624          4        0      0.343341   \n",
      "6    2022      1    7       0.387445          5        0      0.304628   \n",
      "7    2022      1    8       0.416362          6        1      0.388693   \n",
      "8    2022      1    9       0.386118          0        1      0.428560   \n",
      "9    2022      1   10       0.064100          1        0      0.408978   \n",
      "10   2022      1   11       0.125067          2        0      0.147431   \n",
      "11   2022      1   12       0.029774          3        0      0.160503   \n",
      "12   2022      1   13       0.006258          4        0      0.106219   \n",
      "13   2022      1   14       0.020779          5        0      0.071960   \n",
      "14   2022      1   15       0.054049          6        1      0.100682   \n",
      "15   2022      1   16       0.088944          0        1      0.066488   \n",
      "16   2022      1   17       0.109434          1        0      0.110738   \n",
      "17   2022      1   18       0.096909          2        0      0.146506   \n",
      "18   2022      1   19       0.120614          3        0      0.113443   \n",
      "19   2022      1   20       0.479687          4        0      0.134075   \n",
      "20   2022      1   21       0.278020          5        0      0.381509   \n",
      "21   2022      1   22       0.274417          6        1      0.284489   \n",
      "22   2022      1   23       0.294857          0        1      0.269091   \n",
      "23   2022      1   24       0.237815          1        0      0.277497   \n",
      "24   2022      1   25       0.024464          2        0      0.196586   \n",
      "25   2022      1   26       0.095581          3        0      0.088783   \n",
      "26   2022      1   27       0.225109          4        0      0.138901   \n",
      "27   2022      1   28       0.097288          5        0      0.200195   \n",
      "28   2022      1   29       0.391824          6        1      0.102719   \n",
      "29   2022      1   30       0.392187          0        1      0.346674   \n",
      "30   2022      1   31       0.596435          1        0      0.384829   \n",
      "31   2022      2    1       0.369462          2        0      0.492721   \n",
      "32   2022      2    2       0.357482          3        0      0.359827   \n",
      "33   2022      2    3       0.350654          4        0      0.312919   \n",
      "34   2022      2    4       0.435953          5        0      0.376209   \n",
      "35   2022      2    5       0.434098          6        1      0.396489   \n",
      "36   2022      2    6       0.557368          0        1      0.407478   \n",
      "37   2022      2    7       0.463493          1        0      0.519806   \n",
      "38   2022      2    8       0.457128          2        0      0.439747   \n",
      "39   2022      2    9       0.374739          3        0      0.464669   \n",
      "40   2022      2   10       0.255263          4        0      0.369381   \n",
      "41   2022      2   11       0.289118          5        0      0.277285   \n",
      "42   2022      2   12       0.334345          6        1      0.334044   \n",
      "43   2022      2   13       0.526266          0        1      0.339135   \n",
      "44   2022      2   14       0.534701          1        0      0.507016   \n",
      "45   2022      2   15       0.427271          2        0      0.505986   \n",
      "46   2022      2   16       0.489475          3        0      0.426891   \n",
      "47   2022      2   17       0.622367          4        0      0.501522   \n",
      "48   2022      2   18       0.556040          5        0      0.562843   \n",
      "49   2022      2   19       0.574246          6        1      0.555912   \n",
      "50   2022      2   20       0.581205          0        1      0.569380   \n",
      "51   2022      2   21       0.604779          1        0      0.568624   \n",
      "52   2022      2   22       0.345534          2        0      0.590364   \n",
      "53   2022      2   23       0.380346          3        0      0.389898   \n",
      "54   2022      2   24       0.489475          4        0      0.429659   \n",
      "55   2022      2   25       0.444149          5        0      0.503496   \n",
      "56   2022      2   26       0.287140          6        1      0.449600   \n",
      "57   2022      2   27       0.419685          0        1      0.369219   \n",
      "58   2022      2   28       0.347620          1        0      0.432865   \n",
      "59   2022      3    1       0.158115          2        0      0.385504   \n",
      "60   2022      3    2       0.157216          3        0      0.230122   \n",
      "61   2022      3    3       0.200834          4        0      0.234262   \n",
      "62   2022      3    4       0.267944          5        0      0.253007   \n",
      "63   2022      3    5       0.206524          6        1      0.285923   \n",
      "64   2022      3    6       0.357984          0        1      0.270896   \n",
      "65   2022      3    7       0.416082          1        0      0.355737   \n",
      "66   2022      3    8       0.379860          2        0      0.416586   \n",
      "67   2022      3    9       0.426455          3        0      0.373618   \n",
      "68   2022      3   10       0.562299          4        0      0.431001   \n",
      "69   2022      3   11       0.573298          5        0      0.536255   \n",
      "70   2022      3   12       0.656206          6        1      0.532195   \n",
      "71   2022      3   13       0.725014          0        1      0.629487   \n",
      "72   2022      3   14       0.449080          1        0      0.675264   \n",
      "73   2022      3   15       0.292433          2        0      0.471538   \n",
      "74   2022      3   16       0.202640          3        0      0.345560   \n",
      "75   2022      3   17       0.419216          4        0      0.258792   \n",
      "76   2022      3   18       0.343410          5        0      0.432793   \n",
      "77   2022      3   19       0.561614          6        1      0.398846   \n",
      "78   2022      3   20       0.493078          0        1      0.538941   \n",
      "79   2022      3   21       0.356006          1        0      0.506768   \n",
      "80   2022      3   22       0.439219          2        0      0.356591   \n",
      "81   2022      3   23       0.464062          3        0      0.486151   \n",
      "82   2022      3   24       0.445848          4        0      0.466931   \n",
      "83   2022      3   25       0.540869          5        0      0.451391   \n",
      "84   2022      3   26       0.615210          6        1      0.554560   \n",
      "85   2022      3   27       0.307106          0        1      0.571035   \n",
      "86   2022      3   30       0.391428          3        0      0.395153   \n",
      "87   2022      3   31       0.432185          4        0      0.401784   \n",
      "88   2022      4    1       0.482268          5        0      0.447654   \n",
      "89   2022      4    2       0.611087          6        1      0.492731   \n",
      "90   2022      4    3       0.505784          0        1      0.613934   \n",
      "91   2022      4    4       0.423882          1        0      0.527159   \n",
      "92   2022      4    5       0.321087          2        0      0.420639   \n",
      "93   2022      4    6       0.468045          3        0      0.383949   \n",
      "94   2022      4    7       0.577091          4        0      0.478888   \n",
      "95   2022      4    8       0.431600          5        0      0.594612   \n",
      "96   2022      4    9       0.509008          6        1      0.450480   \n",
      "97   2022      4   10       0.484734          0        1      0.503039   \n",
      "98   2022      4   11       0.550540          1        0      0.518701   \n",
      "99   2022      4   12       0.494727          2        0      0.541125   \n",
      "100  2022      4   13       0.159492          3        0      0.547964   \n",
      "101  2022      4   14       0.284658          4        0      0.216143   \n",
      "102  2022      4   15       0.331863          5        0      0.333106   \n",
      "103  2022      4   16       0.478096          6        1      0.390919   \n",
      "104  2022      4   17       0.517732          0        1      0.466760   \n",
      "105  2022      4   18       0.556469          1        0      0.570456   \n",
      "106  2022      4   19       0.497440          2        0      0.489860   \n",
      "107  2022      4   20       0.560781          3        0      0.528059   \n",
      "108  2022      4   21       0.569728          4        0      0.568729   \n",
      "109  2022      4   22       0.458752          5        0      0.559387   \n",
      "110  2022      4   23       0.601176          6        1      0.506502   \n",
      "111  2022      4   24       0.694597          0        1      0.549245   \n",
      "112  2022      4   25       0.398635          1        0      0.712422   \n",
      "113  2022      4   26       0.518490          2        0      0.447841   \n",
      "114  2022      4   27       0.592881          3        0      0.529915   \n",
      "115  2022      4   28       0.587521          4        0      0.598992   \n",
      "116  2022      4   29       0.384601          5        0      0.557278   \n",
      "117  2022      4   30       0.583778          6        1      0.522334   \n",
      "118  2022      5    1       0.517542          0        1      0.543888   \n",
      "119  2022      5    2       0.532335          1        0      0.531479   \n",
      "120  2022      5    3       0.528368          2        0      0.558914   \n",
      "121  2022      5    4       0.456476          3        0      0.573200   \n",
      "122  2022      5    5       0.318035          4        0      0.516359   \n",
      "123  2022      5    6       0.409040          5        0      0.326798   \n",
      "124  2022      5    7       0.392187          6        1      0.464434   \n",
      "125  2022      5    8       0.543713          0        1      0.459690   \n",
      "126  2022      5    9       0.573290          1        0      0.556216   \n",
      "127  2022      5   10       0.528921          2        0      0.581269   \n",
      "128  2022      5   11       0.585625          3        0      0.493264   \n",
      "129  2022      5   12       0.498685          4        0      0.645864   \n",
      "130  2022      5   13       0.535559          5        0      0.526214   \n",
      "131  2022      5   14       0.652001          6        1      0.532064   \n",
      "132  2022      5   15       0.733779          0        1      0.651456   \n",
      "133  2022      5   16       0.543144          1        0      0.693219   \n",
      "134  2022      5   17       0.516594          2        0      0.641480   \n",
      "135  2022      5   18       0.673225          3        0      0.510713   \n",
      "136  2022      5   19       0.515835          4        0      0.646901   \n",
      "137  2022      5   20       0.422254          5        0      0.572802   \n",
      "138  2022      5   21       0.592287          6        1      0.494739   \n",
      "139  2022      5   22       0.653518          0        1      0.640648   \n",
      "140  2022      5   23       0.437339          1        0      0.578709   \n",
      "141  2022      5   24       0.486416          2        0      0.524911   \n",
      "142  2022      5   25       0.489664          3        0      0.568844   \n",
      "143  2022      5   26       0.498957          4        0      0.505108   \n",
      "144  2022      5   27       0.550928          5        0      0.518500   \n",
      "145  2022      5   28       0.527973          6        1      0.556883   \n",
      "146  2022      5   29       0.502181          0        1      0.612422   \n",
      "147  2022      5   30       0.457326          1        0      0.537375   \n",
      "148  2022      5   31       0.461218          2        0      0.456005   \n",
      "149  2022      6    1       0.526266          3        0      0.502611   \n",
      "150  2022      6    2       0.664897          4        0      0.572065   \n",
      "151  2022      6    3       0.777315          5        0      0.694799   \n",
      "152  2022      6    4       0.801631          6        1      0.718812   \n",
      "153  2022      6    5       0.415513          0        1      0.758420   \n",
      "154  2022      6    6       0.507788          1        0      0.522465   \n",
      "155  2022      6    7       0.357671          2        0      0.549040   \n",
      "156  2022      6    8       0.271383          3        0      0.427439   \n",
      "157  2022      6    9       0.422299          4        0      0.304690   \n",
      "158  2022      6   10       0.410203          5        0      0.525334   \n",
      "159  2022      6   11       0.478855          6        1      0.464583   \n",
      "160  2022      6   12       0.549543          0        1      0.486417   \n",
      "161  2022      6   13       0.547696          1        0      0.565368   \n",
      "162  2022      6   14       0.646880          2        0      0.536200   \n",
      "163  2022      6   15       0.851326          3        0      0.710619   \n",
      "164  2022      6   16       0.801890          4        0      0.777583   \n",
      "165  2022      6   17       0.830944          5        0      0.756309   \n",
      "166  2022      6   18       0.935826          6        1      0.832344   \n",
      "167  2022      6   19       0.520956          0        1      0.897166   \n",
      "168  2022      6   20       0.530059          1        0      0.609831   \n",
      "169  2022      6   21       0.441494          2        0      0.534725   \n",
      "170  2022      6   22       0.699033          3        0      0.524000   \n",
      "171  2022      6   23       0.655604          4        0      0.715756   \n",
      "172  2022      6   24       0.487801          5        0      0.721601   \n",
      "173  2022      6   25       0.384032          6        1      0.527797   \n",
      "174  2022      6   26       0.393324          0        1      0.436919   \n",
      "175  2022      6   27       0.272496          1        0      0.474541   \n",
      "176  2022      6   28       0.494216          2        0      0.384282   \n",
      "177  2022      6   29       0.602883          3        0      0.546647   \n",
      "178  2022      6   30       0.319989          4        0      0.584725   \n",
      "179  2022      7    1       0.366016          5        0      0.388647   \n",
      "180  2022      7    2       0.512611          6        1      0.465493   \n",
      "181  2022      7    3       0.482656          0        1      0.521199   \n",
      "182  2022      7    4       0.461597          1        0      0.493089   \n",
      "183  2022      7    5       0.491940          2        0      0.509657   \n",
      "184  2022      7    6       0.543606          3        0      0.527720   \n",
      "185  2022      7    7       0.411910          4        0      0.564480   \n",
      "186  2022      7    8       0.515835          5        0      0.435411   \n",
      "187  2022      7    9       0.534701          6        1      0.534163   \n",
      "188  2022      7   10       0.441874          0        1      0.576936   \n",
      "189  2022      7   11       0.453063          1        0      0.467706   \n",
      "190  2022      7   12       0.500862          2        0      0.493521   \n",
      "191  2022      7   13       0.681775          3        0      0.498020   \n",
      "192  2022      7   14       0.499716          4        0      0.680732   \n",
      "193  2022      7   15       0.476521          5        0      0.560744   \n",
      "194  2022      7   16       0.537076          6        1      0.475975   \n",
      "195  2022      7   17       0.608762          0        1      0.562733   \n",
      "196  2022      7   18       0.851749          1        0      0.587716   \n",
      "197  2022      7   19       0.984259          2        0      0.859029   \n",
      "198  2022      7   20       0.715342          3        0      0.929823   \n",
      "199  2022      7   21       0.433777          4        0      0.681507   \n",
      "200  2022      7   22       0.438839          5        0      0.524680   \n",
      "201  2022      7   23       0.609141          6        1      0.482341   \n",
      "202  2022      7   24       0.702314          0        1      0.659996   \n",
      "203  2022      7   25       0.495543          1        0      0.707888   \n",
      "204  2022      7   26       0.451166          2        0      0.540182   \n",
      "205  2022      7   27       0.500070          3        0      0.528331   \n",
      "206  2022      7   28       0.620140          4        0      0.518908   \n",
      "207  2022      7   29       0.772046          5        0      0.654986   \n",
      "208  2022      7   30       0.674214          6        1      0.775612   \n",
      "209  2022      7   31       0.411720          0        1      0.684770   \n",
      "210  2022      8    1       0.506353          1        0      0.488877   \n",
      "211  2022      8    2       0.486811          2        0      0.525895   \n",
      "212  2022      8    3       0.418737          3        0      0.555880   \n",
      "213  2022      8    4       0.351982          4        0      0.489551   \n",
      "214  2022      8    5       0.494250          5        0      0.432003   \n",
      "215  2022      8    6       0.486630          6        1      0.504427   \n",
      "216  2022      8    7       0.648777          0        1      0.520875   \n",
      "217  2022      8    8       0.622795          1        0      0.682397   \n",
      "218  2022      8    9       0.619398          2        0      0.640903   \n",
      "219  2022      8   10       0.811682          3        0      0.603950   \n",
      "220  2022      8   11       0.924142          4        0      0.785350   \n",
      "221  2022      8   12       0.948689          5        0      0.896142   \n",
      "222  2022      8   13       0.867438          6        1      0.942876   \n",
      "223  2022      8   14       0.898540          0        1      0.844639   \n",
      "224  2022      8   15       0.821247          1        0      0.851581   \n",
      "225  2022      8   16       0.915608          2        0      0.861745   \n",
      "226  2022      8   17       0.622795          3        0      0.928715   \n",
      "227  2022      8   18       0.715177          4        0      0.704819   \n",
      "228  2022      8   19       0.345344          5        0      0.709246   \n",
      "229  2022      8   20       0.438270          6        1      0.483520   \n",
      "230  2022      8   21       0.416006          0        1      0.539112   \n",
      "231  2022      8   22       0.869748          1        0      0.539574   \n",
      "232  2022      8   23       0.464252          2        0      0.805224   \n",
      "233  2022      8   24       0.660914          3        0      0.574237   \n",
      "234  2022      8   25       0.799166          4        0      0.695110   \n",
      "235  2022      8   26       0.569926          5        0      0.831559   \n",
      "236  2022      8   27       0.515266          6        1      0.577054   \n",
      "237  2022      8   28       0.610468          0        1      0.604599   \n",
      "238  2022      8   29       0.568145          1        0      0.671386   \n",
      "239  2022      8   30       0.585815          2        0      0.594098   \n",
      "240  2022      8   31       0.637398          3        0      0.661215   \n",
      "241  2022      9    1       0.658185          4        0      0.637972   \n",
      "242  2022      9    2       0.610279          5        0      0.713475   \n",
      "243  2022      9    3       0.628295          6        1      0.661230   \n",
      "244  2022      9    4       0.565333          0        1      0.638976   \n",
      "245  2022      9    5       0.672235          1        0      0.638234   \n",
      "246  2022      9    6       0.520939          2        0      0.671074   \n",
      "247  2022      9    7       0.504457          3        0      0.620464   \n",
      "248  2022      9    8       0.413196          4        0      0.544060   \n",
      "249  2022      9    9       0.422340          5        0      0.480774   \n",
      "250  2022      9   10       0.414565          6        1      0.496127   \n",
      "251  2022      9   11       0.432391          0        1      0.482318   \n",
      "252  2022      9   12       0.399393          1        0      0.509366   \n",
      "253  2022      9   13       0.294519          2        0      0.435886   \n",
      "254  2022      9   14       0.211347          3        0      0.373043   \n",
      "255  2022      9   15       0.282761          4        0      0.313115   \n",
      "256  2022      9   16       0.374739          5        0      0.342517   \n",
      "257  2022      9   17       0.301981          6        1      0.420071   \n",
      "258  2022      9   18       0.324483          0        1      0.342536   \n",
      "259  2022      9   19       0.311018          1        0      0.385490   \n",
      "260  2022      9   20       0.286942          2        0      0.355364   \n",
      "261  2022      9   21       0.230988          3        0      0.311634   \n",
      "262  2022      9   22       0.280106          4        0      0.301578   \n",
      "263  2022      9   23       0.280807          5        0      0.306080   \n",
      "264  2022      9   24       0.394083          6        1      0.330317   \n",
      "265  2022      9   25       0.342310          0        1      0.390082   \n",
      "266  2022      9   26       0.314844          1        0      0.361444   \n",
      "267  2022      9   27       0.312536          2        0      0.349734   \n",
      "268  2022      9   28       0.251280          3        0      0.328361   \n",
      "269  2022      9   29       0.189184          4        0      0.283878   \n",
      "270  2022      9   30       0.266831          5        0      0.229932   \n",
      "271  2022     10    1       0.412289          6        1      0.296030   \n",
      "272  2022     10    2       0.331665          0        1      0.405728   \n",
      "273  2022     10    3       0.149630          1        0      0.339249   \n",
      "274  2022     10    4       0.257159          2        0      0.204381   \n",
      "275  2022     10    5       0.411585          3        0      0.267312   \n",
      "276  2022     10    6       0.350085          4        0      0.392919   \n",
      "277  2022     10    7       0.285606          5        0      0.365086   \n",
      "278  2022     10    8       0.358484          6        1      0.315100   \n",
      "279  2022     10    9       0.045515          0        1      0.342639   \n",
      "280  2022     10   10       0.359568          1        0      0.096538   \n",
      "281  2022     10   11       0.034895          2        0      0.360458   \n",
      "282  2022     10   12       0.149992          3        0      0.130982   \n",
      "283  2022     10   13       0.179405          4        0      0.138448   \n",
      "284  2022     10   14       0.194725          5        0      0.231479   \n",
      "285  2022     10   15       0.320121          6        1      0.161289   \n",
      "286  2022     10   16       0.325242          0        1      0.371259   \n",
      "287  2022     10   17       0.177508          1        0      0.302338   \n",
      "288  2022     10   18       0.225109          2        0      0.156816   \n",
      "289  2022     10   19       0.190594          3        0      0.270665   \n",
      "290  2022     10   20       0.169395          4        0      0.172306   \n",
      "291  2022     10   21       0.356913          5        0      0.234601   \n",
      "292  2022     10   22       0.333965          6        1      0.305642   \n",
      "293  2022     10   23       0.321639          0        1      0.293959   \n",
      "294  2022     10   24       0.452548          1        0      0.357166   \n",
      "295  2022     10   25       0.355016          2        0      0.394539   \n",
      "296  2022     11    7       0.458790          1        0      0.358060   \n",
      "297  2022     11    8       0.416461          2        0      0.397774   \n",
      "298  2022     11    9       0.404893          3        0      0.417848   \n",
      "299  2022     11   10       0.283493          4        0      0.412450   \n",
      "300  2022     11   11       0.246918          5        0      0.283279   \n",
      "301  2022     11   12       0.055187          6        1      0.262579   \n",
      "302  2022     11   13       0.043239          0        1      0.112646   \n",
      "303  2022     11   14       0.032652          1        0      0.117939   \n",
      "304  2022     11   15       0.296226          2        0      0.091609   \n",
      "305  2022     11   16       0.331500          3        0      0.250625   \n",
      "306  2022     11   17       0.469001          4        0      0.346229   \n",
      "307  2022     11   18       0.253935          5        0      0.426100   \n",
      "308  2022     11   19       0.038498          6        1      0.284872   \n",
      "309  2022     11   20       0.018206          0        1      0.050636   \n",
      "310  2022     11   21       0.315803          1        0      0.061931   \n",
      "311  2022     11   22       0.389342          2        0      0.318607   \n",
      "312  2022     11   23       0.317593          3        0      0.371202   \n",
      "313  2022     11   24       0.391668          4        0      0.314759   \n",
      "314  2022     11   25       0.239712          5        0      0.330450   \n",
      "315  2022     11   26       0.177904          6        1      0.250787   \n",
      "316  2022     11   27       0.275934          0        1      0.224054   \n",
      "317  2022     11   28       0.135976          1        0      0.280065   \n",
      "318  2022     11   29       0.041874          2        0      0.140084   \n",
      "319  2022     12    1       0.061970          4        0      0.078178   \n",
      "320  2022     12    2       0.095581          5        0      0.124956   \n",
      "321  2022     12    3       0.076237          6        1      0.112610   \n",
      "322  2022     12    4       0.043998          0        1      0.096438   \n",
      "323  2022     12    5       0.002968          1        0      0.059070   \n",
      "324  2022     12    6       0.068083          2        0      0.042643   \n",
      "325  2022     12    7       0.134496          3        0      0.094772   \n",
      "326  2022     12    8       0.135555          4        0      0.112944   \n",
      "327  2022     12    9       0.080789          5        0      0.130957   \n",
      "328  2022     12   10       0.155699          6        1      0.092695   \n",
      "329  2022     12   11       0.248155          0        1      0.147203   \n",
      "330  2022     12   12       0.096529          1        0      0.214595   \n",
      "331  2022     12   13       0.015930          2        0      0.089124   \n",
      "332  2022     12   14       0.015238          3        0      0.050035   \n",
      "333  2022     12   15       0.000000          4        0      0.026920   \n",
      "334  2022     12   16       0.031291          5        0      0.000000   \n",
      "335  2022     12   17       0.010290          6        1      0.048807   \n",
      "336  2022     12   18       0.104305          0        1      0.018499   \n",
      "337  2022     12   19       0.279158          1        0      0.092307   \n",
      "338  2022     12   20       0.278630          2        0      0.219512   \n",
      "339  2022     12   21       0.238195          3        0      0.229050   \n",
      "340  2022     12   22       0.264366          4        0      0.227428   \n",
      "341  2022     12   23       0.366890          5        0      0.217338   \n",
      "342  2022     12   24       0.385359          6        1      0.298061   \n",
      "343  2022     12   25       0.254314          0        1      0.342356   \n",
      "344  2022     12   26       0.405280          1        0      0.250635   \n",
      "345  2022     12   27       0.366584          2        0      0.359650   \n",
      "346  2022     12   28       0.437322          3        0      0.309684   \n",
      "347  2022     12   29       0.483447          4        0      0.391163   \n",
      "348  2022     12   30       0.382118          5        0      0.476457   \n",
      "349  2023      1    1       0.432805          0        1      0.342164   \n",
      "350  2023      1    2       0.419496          1        0      0.400297   \n",
      "351  2023      1    3       0.361654          2        0      0.388790   \n",
      "352  2023      1    4       0.479975          3        0      0.372076   \n",
      "353  2023      1    5       0.405272          4        0      0.483123   \n",
      "354  2023      1    6       0.378532          5        0      0.356246   \n",
      "355  2023      1    7       0.449410          6        1      0.383253   \n",
      "356  2023      1    8       0.574815          0        1      0.454806   \n",
      "357  2023      1    9       0.476200          1        0      0.538440   \n",
      "358  2023      1   10       0.360953          2        0      0.482407   \n",
      "359  2023      1   11       0.467665          3        0      0.342920   \n",
      "360  2023      1   12       0.476958          4        0      0.483717   \n",
      "361  2023      1   13       0.533662          5        0      0.478942   \n",
      "362  2023      1   14       0.485822          6        1      0.518913   \n",
      "363  2023      1   15       0.567609          0        1      0.501405   \n",
      "364  2023      1   16       0.488716          1        0      0.513673   \n",
      "365  2023      1   17       0.188590          2        0      0.537062   \n",
      "366  2023      1   18       0.118528          3        0      0.251055   \n",
      "367  2023      1   19       0.181680          4        0      0.190666   \n",
      "368  2023      1   20       0.207983          5        0      0.231368   \n",
      "369  2023      1   21       0.150768          6        1      0.238044   \n",
      "370  2023      1   22       0.260762          0        1      0.269650   \n",
      "371  2023      1   23       0.106069          1        0      0.248117   \n",
      "372  2023      1   24       0.185663          2        0      0.148525   \n",
      "373  2023      1   25       0.088944          3        0      0.218352   \n",
      "374  2023      1   26       0.215701          4        0      0.161043   \n",
      "375  2023      1   27       0.376825          5        0      0.240561   \n",
      "376  2023      1   28       0.354258          6        1      0.324941   \n",
      "377  2023      1   29       0.165635          0        1      0.343413   \n",
      "378  2023      1   30       0.383463          1        0      0.231140   \n",
      "379  2023      1   31       0.215437          2        0      0.354831   \n",
      "380  2023      2    1       0.437150          3        0      0.215688   \n",
      "381  2023      2    2       0.451735          4        0      0.386630   \n",
      "382  2023      2    3       0.458373          5        0      0.484764   \n",
      "383  2023      2    4       0.220648          6        1      0.410873   \n",
      "384  2023      2    5       0.468045          0        1      0.251505   \n",
      "385  2023      2    6       0.193628          1        0      0.403397   \n",
      "386  2023      2    7       0.083510          2        0      0.263556   \n",
      "387  2023      2    8       0.110753          3        0      0.163950   \n",
      "388  2023      2    9       0.135027          4        0      0.132985   \n",
      "389  2023      2   10       0.120713          5        0      0.128720   \n",
      "390  2023      2   11       0.238005          6        1      0.181676   \n",
      "391  2023      2   12       0.316518          0        1      0.283314   \n",
      "392  2023      2   13       0.098154          1        0      0.281248   \n",
      "393  2023      2   14       0.071876          2        0      0.100780   \n",
      "394  2023      2   15       0.113977          3        0      0.112211   \n",
      "395  2023      2   16       0.231928          4        0      0.173751   \n",
      "396  2023      2   17       0.464062          5        0      0.213802   \n",
      "397  2023      2   18       0.533852          6        1      0.391250   \n",
      "398  2023      2   19       0.435756          0        1      0.473064   \n",
      "399  2023      2   20       0.430116          1        0      0.432393   \n",
      "400  2023      2   24       0.492699          5        0      0.411512   \n",
      "401  2023      2   25       0.389437          6        1      0.409438   \n",
      "402  2023      2   27       0.421582          1        0      0.386167   \n",
      "403  2023      2   28       0.309294          2        0      0.441503   \n",
      "404  2023      3    1       0.333086          3        0      0.334070   \n",
      "405  2023      3    2       0.265174          4        0      0.301936   \n",
      "406  2023      3    3       0.341569          5        0      0.279711   \n",
      "407  2023      3    4       0.586573          6        1      0.372301   \n",
      "408  2023      3    5       0.470510          0        1      0.568416   \n",
      "409  2023      3    6       0.406600          1        0      0.429704   \n",
      "410  2023      3    7       0.446615          2        0      0.387428   \n",
      "411  2023      3    8       0.282003          3        0      0.468527   \n",
      "412  2023      3    9       0.220450          4        0      0.317239   \n",
      "413  2023      3   10       0.479992          5        0      0.269798   \n",
      "414  2023      3   11       0.401100          6        1      0.432200   \n",
      "415  2023      3   12       0.533118          0        1      0.410755   \n",
      "416  2023      3   13       0.420254          1        0      0.552430   \n",
      "417  2023      3   14       0.531007          2        0      0.424092   \n",
      "418  2023      3   15       0.459305          3        0      0.469383   \n",
      "419  2023      3   16       0.561350          4        0      0.481143   \n",
      "420  2023      3   17       0.480751          5        0      0.554206   \n",
      "421  2023      3   18       0.531766          6        1      0.523997   \n",
      "422  2023      3   19       0.461283          0        1      0.472303   \n",
      "423  2023      3   20       0.420064          1        0      0.474216   \n",
      "424  2023      3   21       0.419387          2        0      0.472213   \n",
      "425  2023      3   22       0.517569          3        0      0.454274   \n",
      "426  2023      3   23       0.622416          4        0      0.506969   \n",
      "427  2023      3   24       0.607624          5        0      0.568136   \n",
      "428  2023      3   25       0.653139          6        1      0.640998   \n",
      "429  2023      3   26       0.568557          0        1      0.659828   \n",
      "430  2023      3   27       0.616628          1        0      0.552856   \n",
      "431  2023      3   28       0.441494          2        0      0.590491   \n",
      "432  2023      3   29       0.401669          3        0      0.497873   \n",
      "433  2023      3   30       0.602658          4        0      0.482391   \n",
      "434  2023      3   31       0.577660          5        0      0.593919   \n",
      "435  2023      4    1       0.402996          6        1      0.548383   \n",
      "436  2023      4    2       0.448816          0        1      0.478537   \n",
      "437  2023      4    3       0.417030          1        0      0.515568   \n",
      "438  2023      4    4       0.489285          2        0      0.438771   \n",
      "439  2023      4    5       0.426133          3        0      0.486228   \n",
      "440  2023      4    6       0.431006          4        0      0.481985   \n",
      "441  2023      4    7       0.555471          5        0      0.491474   \n",
      "442  2023      4    8       0.526456          6        1      0.562897   \n",
      "443  2023      4    9       0.453962          0        1      0.502185   \n",
      "444  2023      4   10       0.575574          1        0      0.499313   \n",
      "445  2023      4   11       0.637019          2        0      0.613674   \n",
      "446  2023      4   12       0.647103          3        0      0.620858   \n",
      "447  2023      4   13       0.641760          4        0      0.627959   \n",
      "448  2023      4   14       0.484544          5        0      0.641941   \n",
      "449  2023      4   15       0.562801          6        1      0.547829   \n",
      "450  2023      4   16       0.481699          0        1      0.585004   \n",
      "451  2023      4   17       0.551489          1        0      0.497645   \n",
      "452  2023      4   18       0.465637          2        0      0.566523   \n",
      "453  2023      4   19       0.586383          3        0      0.545632   \n",
      "454  2023      4   20       0.633795          4        0      0.590446   \n",
      "455  2023      4   21       0.529556          5        0      0.636936   \n",
      "456  2023      4   22       0.204438          6        1      0.540064   \n",
      "457  2023      4   23       0.559264          0        1      0.336271   \n",
      "458  2023      4   24       0.680448          1        0      0.571455   \n",
      "459  2023      4   25       0.659966          2        0      0.650179   \n",
      "460  2023      4   26       0.512042          3        0      0.666851   \n",
      "461  2023      4   27       0.601786          4        0      0.587570   \n",
      "462  2023      4   28       0.324294          5        0      0.589323   \n",
      "463  2023      4   29       0.636260          6        1      0.385832   \n",
      "464  2023      4   30       0.634834          0        1      0.631269   \n",
      "465  2023      5    1       0.541248          1        0      0.694261   \n",
      "466  2023      5    2       0.560212          2        0      0.553852   \n",
      "467  2023      5    3       0.592683          3        0      0.581148   \n",
      "468  2023      5    4       0.598521          4        0      0.582727   \n",
      "469  2023      5    5       0.529111          5        0      0.646536   \n",
      "470  2023      5    6       0.472365          6        1      0.606743   \n",
      "471  2023      5    7       0.333965          0        1      0.467610   \n",
      "472  2023      5    8       0.283520          1        0      0.405624   \n",
      "473  2023      5    9       0.283182          2        0      0.361889   \n",
      "474  2023      5   10       0.366395          3        0      0.393976   \n",
      "475  2023      5   11       0.443356          4        0      0.405852   \n",
      "476  2023      5   12       0.359370          5        0      0.428600   \n",
      "477  2023      5   13       0.682344          6        1      0.438041   \n",
      "478  2023      5   14       0.619002          0        1      0.665173   \n",
      "479  2023      5   15       0.491354          1        0      0.629662   \n",
      "480  2023      5   16       0.549023          2        0      0.474871   \n",
      "481  2023      5   17       0.533283          3        0      0.571232   \n",
      "482  2023      5   18       0.616537          4        0      0.565062   \n",
      "483  2023      5   19       0.658185          5        0      0.619277   \n",
      "484  2023      5   20       0.692775          6        1      0.662683   \n",
      "485  2023      5   21       0.605158          0        1      0.646586   \n",
      "486  2023      5   22       0.518672          1        0      0.660999   \n",
      "487  2023      5   23       0.631709          2        0      0.553363   \n",
      "488  2023      5   24       0.523628          3        0      0.628459   \n",
      "489  2023      5   25       0.613462          4        0      0.561850   \n",
      "490  2023      5   26       0.680637          5        0      0.618691   \n",
      "491  2023      5   27       0.750427          6        1      0.737156   \n",
      "492  2023      5   28       0.740310          0        1      0.701986   \n",
      "493  2023      5   29       0.668690          1        0      0.750581   \n",
      "494  2023      5   30       0.659776          2        0      0.694923   \n",
      "495  2023      5   31       0.655019          3        0      0.682360   \n",
      "496  2023      6    1       0.609141          4        0      0.704164   \n",
      "497  2023      6    2       0.721601          5        0      0.603239   \n",
      "498  2023      6    3       0.712407          6        1      0.766906   \n",
      "499  2023      6    4       0.751185          0        1      0.738567   \n",
      "500  2023      6    5       0.676465          1        0      0.754909   \n",
      "501  2023      6    6       0.738529          2        0      0.726478   \n",
      "502  2023      6    7       0.698464          3        0      0.717127   \n",
      "503  2023      6    8       0.783235          4        0      0.781115   \n",
      "504  2023      6    9       0.904446          5        0      0.781009   \n",
      "505  2023      6   10       0.979708          6        1      0.896895   \n",
      "506  2023      6   11       0.877679          0        1      0.969189   \n",
      "507  2023      6   12       0.900403          1        0      0.883634   \n",
      "508  2023      6   13       1.000000          2        0      0.950126   \n",
      "509  2023      6   14       0.960743          3        0      0.959366   \n",
      "510  2023      6   15       0.837078          4        0      0.979016   \n",
      "511  2023      6   16       0.979898          5        0      0.906614   \n",
      "512  2023      6   17       0.966622          6        1      0.983869   \n",
      "513  2023      6   18       0.881801          0        1      1.000000   \n",
      "514  2023      6   19       0.657798          1        0      0.899118   \n",
      "515  2023      6   20       0.604161          2        0      0.795278   \n",
      "516  2023      6   21       0.558385          3        0      0.691094   \n",
      "517  2023      6   22       0.450358          4        0      0.644550   \n",
      "518  2023      6   23       0.599411          5        0      0.582761   \n",
      "519  2023      6   24       0.627908          6        1      0.681105   \n",
      "520  2023      6   25       0.861559          0        1      0.727021   \n",
      "521  2023      6   26       0.642708          1        0      0.842330   \n",
      "522  2023      6   27       0.554490          2        0      0.732188   \n",
      "523  2023      6   28       0.462166          3        0      0.635715   \n",
      "524  2023      6   29       0.451546          4        0      0.568566   \n",
      "525  2023      6   30       0.528764          5        0      0.522385   \n",
      "526  2023      7    1       0.355775          6        1      0.598303   \n",
      "527  2023      7    2       0.632657          0        1      0.490782   \n",
      "528  2023      7    3       0.561416          1        0      0.650620   \n",
      "529  2023      7    4       0.518474          2        0      0.619951   \n",
      "530  2023      7    5       0.521714          3        0      0.548126   \n",
      "531  2023      7    6       0.560823          4        0      0.623419   \n",
      "532  2023      7    7       0.677413          5        0      0.583257   \n",
      "533  2023      7    8       0.710980          6        1      0.682569   \n",
      "534  2023      7    9       0.606140          0        1      0.743802   \n",
      "535  2023      7   10       0.596814          1        0      0.635365   \n",
      "536  2023      7   11       0.513180          2        0      0.666136   \n",
      "537  2023      7   12       0.513329          3        0      0.527552   \n",
      "538  2023      7   13       0.527593          4        0      0.569399   \n",
      "539  2023      7   14       0.637588          5        0      0.612391   \n",
      "540  2023      7   15       0.474542          6        1      0.639298   \n",
      "541  2023      7   16       0.457994          0        1      0.554049   \n",
      "542  2023      7   17       0.482458          1        0      0.476990   \n",
      "543  2023      7   18       0.546772          2        0      0.564354   \n",
      "544  2023      7   19       0.457425          3        0      0.586008   \n",
      "545  2023      7   20       0.389911          4        0      0.500079   \n",
      "546  2023      7   21       0.421903          5        0      0.462367   \n",
      "547  2023      7   22       0.511853          6        1      0.449173   \n",
      "548  2023      7   23       0.406410          0        1      0.572587   \n",
      "549  2023      7   24       0.383908          1        0      0.459486   \n",
      "550  2023      7   25       0.448891          2        0      0.424881   \n",
      "551  2023      7   26       0.531955          3        0      0.489619   \n",
      "552  2023      7   27       0.296836          4        0      0.530722   \n",
      "553  2023      7   28       0.285606          5        0      0.411402   \n",
      "554  2023      7   29       0.393135          6        1      0.324842   \n",
      "555  2023      7   30       0.464054          0        1      0.412268   \n",
      "556  2023      7   31       0.332448          1        0      0.486680   \n",
      "557  2023      8    1       0.448891          2        0      0.406907   \n",
      "558  2023      8    2       0.430215          3        0      0.481596   \n",
      "559  2023      8    3       0.426702          4        0      0.405275   \n",
      "560  2023      8    4       0.396548          5        0      0.450346   \n",
      "561  2023      8    5       0.391997          6        1      0.471527   \n",
      "562  2023      8    6       0.491957          0        1      0.410775   \n",
      "563  2023      8    7       0.476768          1        0      0.482667   \n",
      "564  2023      8    8       0.384411          2        0      0.464502   \n",
      "565  2023      8    9       0.471574          3        0      0.455950   \n",
      "566  2023      8   10       0.534041          4        0      0.505031   \n",
      "567  2023      8   11       0.544472          5        0      0.485851   \n",
      "568  2023      8   12       0.447233          6        1      0.544454   \n",
      "569  2023      8   13       0.483785          0        1      0.496462   \n",
      "570  2023      8   14       0.525507          1        0      0.517747   \n",
      "571  2023      8   15       0.528368          2        0      0.510231   \n",
      "572  2023      8   16       0.559264          3        0      0.501911   \n",
      "573  2023      8   17       0.424616          4        0      0.611529   \n",
      "574  2023      8   18       0.461283          5        0      0.473991   \n",
      "575  2023      8   19       0.515266          6        1      0.461779   \n",
      "576  2023      8   20       0.474113          0        1      0.509276   \n",
      "577  2023      8   21       0.479885          1        0      0.501891   \n",
      "578  2023      8   22       0.423668          2        0      0.564312   \n",
      "579  2023      8   23       0.510525          3        0      0.423916   \n",
      "580  2023      8   24       0.410623          4        0      0.486823   \n",
      "581  2023      8   25       0.324863          5        0      0.474790   \n",
      "582  2023      8   26       0.460080          6        1      0.397242   \n",
      "583  2023      8   27       0.455149          0        1      0.501875   \n",
      "584  2023      8   28       0.421771          1        0      0.408292   \n",
      "585  2023      8   29       0.378532          2        0      0.466123   \n",
      "586  2023      8   30       0.419331          3        0      0.472752   \n",
      "587  2023      8   31       0.421202          4        0      0.416289   \n",
      "588  2023      9    1       0.277072          5        0      0.435614   \n",
      "589  2023      9    2       0.295253          6        1      0.300704   \n",
      "590  2023      9    3       0.468424          0        1      0.396672   \n",
      "591  2023      9    4       0.512991          1        0      0.485569   \n",
      "592  2023      9    5       0.523025          2        0      0.454646   \n",
      "593  2023      9    6       0.602693          3        0      0.546065   \n",
      "594  2023      9    7       0.623554          4        0      0.593501   \n",
      "595  2023      9    8       0.669663          5        0      0.635752   \n",
      "596  2023      9    9       0.701119          6        1      0.620744   \n",
      "597  2023      9   10       0.730324          0        1      0.654193   \n",
      "598  2023      9   11       0.637415          1        0      0.755523   \n",
      "599  2023      9   12       0.412479          2        0      0.644232   \n",
      "600  2023      9   13       0.428409          3        0      0.461509   \n",
      "601  2023      9   14       0.372431          4        0      0.441124   \n",
      "602  2023      9   15       0.421392          5        0      0.442215   \n",
      "603  2023      9   16       0.448511          6        1      0.507082   \n",
      "604  2023      9   17       0.359378          0        1      0.472783   \n",
      "605  2023      9   18       0.470189          1        0      0.382923   \n",
      "606  2023      9   19       0.404476          2        0      0.494550   \n",
      "607  2023      9   20       0.574729          3        0      0.479540   \n",
      "608  2023      9   21       0.390480          4        0      0.578539   \n",
      "609  2023      9   22       0.385739          5        0      0.416587   \n",
      "610  2023      9   23       0.304950          6        1      0.396852   \n",
      "611  2023      9   24       0.407738          0        1      0.407202   \n",
      "612  2023      9   25       0.430305          1        0      0.428357   \n",
      "613  2023      9   26       0.293670          2        0      0.454504   \n",
      "614  2023      9   27       0.385739          3        0      0.324383   \n",
      "615  2023      9   28       0.433340          4        0      0.423127   \n",
      "616  2023      9   29       0.315240          5        0      0.481689   \n",
      "617  2023      9   30       0.322587          6        1      0.324186   \n",
      "618  2023     10    1       0.486061          0        1      0.372022   \n",
      "619  2023     10    2       0.488197          1        0      0.469716   \n",
      "620  2023     10    3       0.557747          2        0      0.509581   \n",
      "621  2023     10    4       0.378153          3        0      0.567512   \n",
      "622  2023     10    5       0.346705          4        0      0.376712   \n",
      "623  2023     10    6       0.432985          5        0      0.382196   \n",
      "624  2023     10    7       0.518111          6        1      0.454616   \n",
      "625  2023     10    8       0.374409          0        1      0.525121   \n",
      "626  2023     10    9       0.246374          1        0      0.421333   \n",
      "\n",
      "     day_lag1  day_lag7   day_lag30  day_lag365  \n",
      "0         NaN       NaN         NaN         NaN  \n",
      "1    0.298815       NaN         NaN         NaN  \n",
      "2    0.388855       NaN         NaN         NaN  \n",
      "3    0.517163       NaN         NaN         NaN  \n",
      "4    0.460649       NaN         NaN         NaN  \n",
      "5    0.301981       NaN         NaN         NaN  \n",
      "6    0.270624       NaN         NaN         NaN  \n",
      "7    0.387445  0.298815         NaN         NaN  \n",
      "8    0.416362  0.388855         NaN         NaN  \n",
      "9    0.386118  0.517163         NaN         NaN  \n",
      "10   0.064100  0.460649         NaN         NaN  \n",
      "11   0.125067  0.301981         NaN         NaN  \n",
      "12   0.029774  0.270624         NaN         NaN  \n",
      "13   0.006258  0.387445         NaN         NaN  \n",
      "14   0.020779  0.416362         NaN         NaN  \n",
      "15   0.054049  0.386118         NaN         NaN  \n",
      "16   0.088944  0.064100         NaN         NaN  \n",
      "17   0.109434  0.125067         NaN         NaN  \n",
      "18   0.096909  0.029774         NaN         NaN  \n",
      "19   0.120614  0.006258         NaN         NaN  \n",
      "20   0.479687  0.020779         NaN         NaN  \n",
      "21   0.278020  0.054049         NaN         NaN  \n",
      "22   0.274417  0.088944         NaN         NaN  \n",
      "23   0.294857  0.109434         NaN         NaN  \n",
      "24   0.237815  0.096909         NaN         NaN  \n",
      "25   0.024464  0.120614         NaN         NaN  \n",
      "26   0.095581  0.479687         NaN         NaN  \n",
      "27   0.225109  0.278020         NaN         NaN  \n",
      "28   0.097288  0.274417         NaN         NaN  \n",
      "29   0.391824  0.294857         NaN         NaN  \n",
      "30   0.392187  0.237815   34.826087         NaN  \n",
      "31   0.596435  0.024464   44.717391         NaN  \n",
      "32   0.369462  0.095581   58.812500         NaN  \n",
      "33   0.357482  0.225109   52.604167         NaN  \n",
      "34   0.350654  0.097288   35.173913         NaN  \n",
      "35   0.435953  0.391824   31.729167         NaN  \n",
      "36   0.434098  0.392187   44.562500         NaN  \n",
      "37   0.557368  0.596435   47.739130         NaN  \n",
      "38   0.463493  0.369462   44.416667         NaN  \n",
      "39   0.457128  0.357482    9.041667         NaN  \n",
      "40   0.374739  0.350654   15.739130         NaN  \n",
      "41   0.255263  0.435953    5.270833         NaN  \n",
      "42   0.289118  0.434098    2.687500         NaN  \n",
      "43   0.334345  0.557368    4.282609         NaN  \n",
      "44   0.526266  0.463493    7.937500         NaN  \n",
      "45   0.534701  0.457128   11.770833         NaN  \n",
      "46   0.427271  0.374739   14.021739         NaN  \n",
      "47   0.489475  0.255263   12.645833         NaN  \n",
      "48   0.622367  0.289118   15.250000         NaN  \n",
      "49   0.556040  0.334345   54.695652         NaN  \n",
      "50   0.574246  0.526266   32.541667         NaN  \n",
      "51   0.581205  0.534701   32.145833         NaN  \n",
      "52   0.604779  0.427271   34.391304         NaN  \n",
      "53   0.345534  0.489475   28.125000         NaN  \n",
      "54   0.380346  0.622367    4.687500         NaN  \n",
      "55   0.489475  0.556040   12.500000         NaN  \n",
      "56   0.444149  0.574246   26.729167         NaN  \n",
      "57   0.287140  0.581205   12.687500         NaN  \n",
      "58   0.419685  0.604779   45.043478         NaN  \n",
      "59   0.347620  0.345534   45.083333         NaN  \n",
      "60   0.158115  0.380346   67.520833         NaN  \n",
      "61   0.157216  0.489475   42.586957         NaN  \n",
      "62   0.200834  0.444149   41.270833         NaN  \n",
      "63   0.267944  0.287140   40.520833         NaN  \n",
      "64   0.206524  0.419685   49.891304         NaN  \n",
      "65   0.357984  0.347620   49.687500         NaN  \n",
      "66   0.416082  0.158115   63.229167         NaN  \n",
      "67   0.379860  0.157216   52.916667         NaN  \n",
      "68   0.426455  0.200834   52.217391         NaN  \n",
      "69   0.562299  0.267944   43.166667         NaN  \n",
      "70   0.573298  0.206524   30.041667         NaN  \n",
      "71   0.656206  0.357984   33.760870         NaN  \n",
      "72   0.725014  0.416082   38.729167         NaN  \n",
      "73   0.449080  0.379860   59.812500         NaN  \n",
      "74   0.292433  0.426455   60.739130         NaN  \n",
      "75   0.202640  0.562299   48.937500         NaN  \n",
      "76   0.419216  0.573298   55.770833         NaN  \n",
      "77   0.343410  0.656206   70.369565         NaN  \n",
      "78   0.561614  0.725014   63.083333         NaN  \n",
      "79   0.493078  0.449080   65.083333         NaN  \n",
      "80   0.356006  0.292433   65.847826         NaN  \n",
      "81   0.439219  0.202640   68.437500         NaN  \n",
      "82   0.464062  0.419216   39.958333         NaN  \n",
      "83   0.445848  0.343410   43.782609         NaN  \n",
      "84   0.540869  0.561614   55.770833         NaN  \n",
      "85   0.615210  0.493078   50.791667         NaN  \n",
      "86        NaN  0.464062   40.187500         NaN  \n",
      "87   0.391428  0.445848   19.369565         NaN  \n",
      "88   0.432185  0.540869   19.270833         NaN  \n",
      "89   0.482268  0.615210   24.062500         NaN  \n",
      "90   0.611087  0.307106   31.434783         NaN  \n",
      "91   0.505784       NaN   24.687500         NaN  \n",
      "92   0.423882       NaN   41.326087         NaN  \n",
      "93   0.321087  0.391428   47.708333         NaN  \n",
      "94   0.468045  0.432185   43.729167         NaN  \n",
      "95   0.577091  0.482268   48.847826         NaN  \n",
      "96   0.431600  0.611087   63.770833         NaN  \n",
      "97   0.509008  0.505784   64.979167         NaN  \n",
      "98   0.484734  0.423882   74.086957         NaN  \n",
      "99   0.550540  0.321087   81.645833         NaN  \n",
      "100  0.494727  0.468045   51.333333         NaN  \n",
      "101  0.159492  0.577091   34.125000         NaN  \n",
      "102  0.284658  0.431600   24.260870         NaN  \n",
      "103  0.331863  0.509008   48.052632         NaN  \n",
      "104  0.478096  0.484734   39.725000         NaN  \n",
      "105  0.517732  0.550540   63.695652         NaN  \n",
      "106  0.556469  0.494727   56.166667         NaN  \n",
      "107  0.497440  0.159492   41.108696         NaN  \n",
      "108  0.560781  0.284658   50.250000         NaN  \n",
      "109  0.569728  0.331863   52.979167         NaN  \n",
      "110  0.458752  0.478096   50.978261         NaN  \n",
      "111  0.601176  0.517732   61.416667         NaN  \n",
      "112  0.694597  0.556469   69.583333         NaN  \n",
      "113  0.398635  0.497440   35.736842         NaN  \n",
      "114  0.518490  0.560781         NaN         NaN  \n",
      "115  0.592881  0.569728         NaN         NaN  \n",
      "116  0.587521  0.458752   45.000000         NaN  \n",
      "117  0.384601  0.601176   49.477273         NaN  \n",
      "118  0.583778  0.694597   54.979167         NaN  \n",
      "119  0.517542  0.398635   69.130435         NaN  \n",
      "120  0.532335  0.518490   57.562500         NaN  \n",
      "121  0.528368  0.592881   48.565217         NaN  \n",
      "122  0.456476  0.587521   37.272727         NaN  \n",
      "123  0.318035  0.384601   53.416667         NaN  \n",
      "124  0.409040  0.583778   65.395833         NaN  \n",
      "125  0.392187  0.517542   49.413043         NaN  \n",
      "126  0.543713  0.532335   57.916667         NaN  \n",
      "127  0.573290  0.528368   55.250000         NaN  \n",
      "128  0.528921  0.456476   62.479167         NaN  \n",
      "129  0.585625  0.318035   56.347826         NaN  \n",
      "130  0.498685  0.409040   19.520833         NaN  \n",
      "131  0.535559  0.392187   33.270833         NaN  \n",
      "132  0.652001  0.543713   38.456522         NaN  \n",
      "133  0.733779  0.573290   54.520833         NaN  \n",
      "134  0.543144  0.528921   58.875000         NaN  \n",
      "135  0.516594  0.585625   63.130435         NaN  \n",
      "136  0.673225  0.498685   56.645833         NaN  \n",
      "137  0.515835  0.535559   63.604167         NaN  \n",
      "138  0.422254  0.652001   64.586957         NaN  \n",
      "139  0.592287  0.733779   52.395833         NaN  \n",
      "140  0.653518  0.543144   68.041667         NaN  \n",
      "141  0.437339  0.516594   78.304348         NaN  \n",
      "142  0.486416  0.673225   45.791667         NaN  \n",
      "143  0.489664  0.515835   58.958333         NaN  \n",
      "144  0.498957  0.422254   67.130435         NaN  \n",
      "145  0.550928  0.592287   66.541667         NaN  \n",
      "146  0.527973  0.653518   44.250000         NaN  \n",
      "147  0.502181  0.437339   66.130435         NaN  \n",
      "148  0.457326  0.486416   58.854167         NaN  \n",
      "149  0.461218  0.489664   60.479167         NaN  \n",
      "150  0.526266  0.498957   60.043478         NaN  \n",
      "151  0.664897  0.550928   52.145833         NaN  \n",
      "152  0.777315  0.527973   36.937500         NaN  \n",
      "153  0.801631  0.502181   46.934783         NaN  \n",
      "154  0.415513  0.457326   45.083333         NaN  \n",
      "155  0.507788  0.461218   61.729167         NaN  \n",
      "156  0.357671  0.526266   64.978261         NaN  \n",
      "157  0.271383  0.664897   60.104167         NaN  \n",
      "158  0.422299  0.777315   66.333333         NaN  \n",
      "159  0.410203  0.801631   56.782609         NaN  \n",
      "160  0.478855  0.415513   60.833333         NaN  \n",
      "161  0.549543  0.507788   73.625000         NaN  \n",
      "162  0.547696  0.357671   82.608696         NaN  \n",
      "163  0.646880  0.271383   61.666667         NaN  \n",
      "164  0.851326  0.422299   58.750000         NaN  \n",
      "165  0.801890  0.410203   75.956522         NaN  \n",
      "166  0.830944  0.478855   58.666667         NaN  \n",
      "167  0.935826  0.549543   48.386364         NaN  \n",
      "168  0.520956  0.547696   67.065217         NaN  \n",
      "169  0.530059  0.646880   73.791667         NaN  \n",
      "170  0.441494  0.851326   50.043478         NaN  \n",
      "171  0.699033  0.801890   55.434783         NaN  \n",
      "172  0.655604  0.830944   55.791667         NaN  \n",
      "173  0.487801  0.935826   56.812500         NaN  \n",
      "174  0.384032  0.520956   62.521739         NaN  \n",
      "175  0.393324  0.530059   60.000000         NaN  \n",
      "176  0.272496  0.441494   57.166667         NaN  \n",
      "177  0.494216  0.699033   52.239130         NaN  \n",
      "178  0.602883  0.655604   52.666667         NaN  \n",
      "179  0.319989  0.487801   59.812500         NaN  \n",
      "180  0.366016  0.384032   75.041667         NaN  \n",
      "181  0.512611  0.393324   87.391304         NaN  \n",
      "182  0.482656  0.272496   90.062500         NaN  \n",
      "183  0.461597  0.494216   47.645833         NaN  \n",
      "184  0.491940  0.602883   57.782609         NaN  \n",
      "185  0.543606  0.319989   41.291667         NaN  \n",
      "186  0.411910  0.366016   31.812500         NaN  \n",
      "187  0.515835  0.512611   48.391304         NaN  \n",
      "188  0.534701  0.482656   47.062500         NaN  \n",
      "189  0.441874  0.461597   54.604167         NaN  \n",
      "190  0.453063  0.491940   62.369565         NaN  \n",
      "191  0.500862  0.543606   62.166667         NaN  \n",
      "192  0.681775  0.411910   73.062500         NaN  \n",
      "193  0.499716  0.515835   95.521739         NaN  \n",
      "194  0.476521  0.534701   90.090909         NaN  \n",
      "195  0.537076  0.441874   93.282609         NaN  \n",
      "196  0.608762  0.453063  104.804348         NaN  \n",
      "197  0.851749  0.500862   59.229167         NaN  \n",
      "198  0.984259  0.681775   60.229167         NaN  \n",
      "199  0.715342  0.499716   50.500000         NaN  \n",
      "200  0.433777  0.476521   78.791667         NaN  \n",
      "201  0.438839  0.537076   74.020833         NaN  \n",
      "202  0.609141  0.608762   55.586957         NaN  \n",
      "203  0.702314  0.851749   44.187500         NaN  \n",
      "204  0.495543  0.984259   45.208333         NaN  \n",
      "205  0.451166  0.715342   31.934783         NaN  \n",
      "206  0.500070  0.433777   56.291667         NaN  \n",
      "207  0.620140  0.438839   68.229167         NaN  \n",
      "208  0.772046  0.609141   37.152174         NaN  \n",
      "209  0.674214  0.702314   42.208333         NaN  \n",
      "210  0.411720  0.495543   58.312500         NaN  \n",
      "211  0.506353  0.451166   55.021739         NaN  \n",
      "212  0.486811  0.500070   52.708333         NaN  \n",
      "213  0.418737  0.620140   56.041667         NaN  \n",
      "214  0.351982  0.772046   61.717391         NaN  \n",
      "215  0.494250  0.674214   47.250000         NaN  \n",
      "216  0.486630  0.411720   58.666667         NaN  \n",
      "217  0.648777  0.506353   60.739130         NaN  \n",
      "218  0.622795  0.486811   50.541667         NaN  \n",
      "219  0.619398  0.418737   51.770833         NaN  \n",
      "220  0.811682  0.351982   57.021739         NaN  \n",
      "221  0.924142  0.494250   76.895833         NaN  \n",
      "222  0.948689  0.486630   56.895833         NaN  \n",
      "223  0.867438  0.648777   54.347826         NaN  \n",
      "224  0.898540  0.622795   61.000000         NaN  \n",
      "225  0.821247  0.619398   68.875000         NaN  \n",
      "226  0.915608  0.811682   95.568182         NaN  \n",
      "227  0.622795  0.924142  110.125000         NaN  \n",
      "228  0.715177  0.948689   80.583333         NaN  \n",
      "229  0.345344  0.867438   49.652174         NaN  \n",
      "230  0.438270  0.898540   50.208333         NaN  \n",
      "231  0.416006  0.821247   68.916667         NaN  \n",
      "232  0.869748  0.915608   79.152174         NaN  \n",
      "233  0.464252  0.622795   56.437500         NaN  \n",
      "234  0.660914  0.715177   51.562500         NaN  \n",
      "235  0.799166  0.345344   56.934783         NaN  \n",
      "236  0.569926  0.438270   70.125000         NaN  \n",
      "237  0.515266  0.416006   86.812500         NaN  \n",
      "238  0.610468  0.869748   76.065217         NaN  \n",
      "239  0.568145  0.464252   47.229167         NaN  \n",
      "240  0.585815  0.660914   57.625000         NaN  \n",
      "241  0.637398  0.799166   55.478261         NaN  \n",
      "242  0.658185  0.569926   48.000000         NaN  \n",
      "243  0.610279  0.515266   40.666667         NaN  \n",
      "244  0.628295  0.610468   56.295455         NaN  \n",
      "245  0.565333  0.568145   55.458333         NaN  \n",
      "246  0.672235  0.585815   73.270833         NaN  \n",
      "247  0.520939  0.637398   70.416667         NaN  \n",
      "248  0.504457  0.658185   70.043478         NaN  \n",
      "249  0.413196  0.610279   91.166667         NaN  \n",
      "250  0.422340  0.628295  103.520833         NaN  \n",
      "251  0.414565  0.565333  106.217391         NaN  \n",
      "252  0.432391  0.672235   97.291667         NaN  \n",
      "253  0.399393  0.520939  100.708333         NaN  \n",
      "254  0.294519  0.504457   92.217391         NaN  \n",
      "255  0.211347  0.413196  102.583333         NaN  \n",
      "256  0.282761  0.422340   70.416667         NaN  \n",
      "257  0.374739  0.414565   80.565217         NaN  \n",
      "258  0.301981  0.432391   39.937500         NaN  \n",
      "259  0.324483  0.399393   50.145833         NaN  \n",
      "260  0.311018  0.294519   47.700000         NaN  \n",
      "261  0.286942  0.211347   97.545455         NaN  \n",
      "262  0.230988  0.282761   53.000000         NaN  \n",
      "263  0.280106  0.374739   74.604167         NaN  \n",
      "264  0.280807  0.301981   89.791667         NaN  \n",
      "265  0.394083  0.324483   64.608696         NaN  \n",
      "266  0.342310  0.311018   58.604167         NaN  \n",
      "267  0.314844  0.286942   69.062500         NaN  \n",
      "268  0.312536  0.230988   64.413043         NaN  \n",
      "269  0.251280  0.280106   66.354167         NaN  \n",
      "270  0.189184  0.280807   72.020833         NaN  \n",
      "271  0.266831  0.394083   74.304348         NaN  \n",
      "272  0.412289  0.342310   69.041667         NaN  \n",
      "273  0.331665  0.314844   71.020833         NaN  \n",
      "274  0.149630  0.312536   64.104167         NaN  \n",
      "275  0.257159  0.251280   75.847826         NaN  \n",
      "276  0.411585  0.189184   59.227273         NaN  \n",
      "277  0.350085  0.266831   57.416667         NaN  \n",
      "278  0.285606  0.412289   47.391304         NaN  \n",
      "279  0.358484  0.331665   48.395833         NaN  \n",
      "280  0.045515  0.149630   47.541667         NaN  \n",
      "281  0.359568  0.257159   49.500000         NaN  \n",
      "282  0.034895  0.411585   45.875000         NaN  \n",
      "283  0.149992  0.350085   34.354167         NaN  \n",
      "284  0.179405  0.285606   25.217391         NaN  \n",
      "285  0.194725  0.358484   33.062500         NaN  \n",
      "286  0.320121  0.045515   43.166667         NaN  \n",
      "287  0.325242  0.359568   35.173913         NaN  \n",
      "288  0.177508  0.034895   37.645833         NaN  \n",
      "289  0.225109  0.149992   36.166667         NaN  \n",
      "290  0.190594  0.179405   33.521739         NaN  \n",
      "291  0.169395  0.194725   27.375000         NaN  \n",
      "292  0.356913  0.320121   32.770833         NaN  \n",
      "293  0.333965  0.325242   32.847826         NaN  \n",
      "294  0.321639  0.177508   45.291667         NaN  \n",
      "295  0.452548  0.225109   39.604167         NaN  \n",
      "296       NaN       NaN   41.380952         NaN  \n",
      "297  0.458790       NaN    7.000000         NaN  \n",
      "298  0.416461       NaN   41.500000         NaN  \n",
      "299  0.404893       NaN    5.833333         NaN  \n",
      "300  0.283493       NaN   18.477273         NaN  \n",
      "301  0.246918       NaN   21.708333         NaN  \n",
      "302  0.055187       NaN   23.391304         NaN  \n",
      "303  0.043239  0.458790   37.166667         NaN  \n",
      "304  0.032652  0.416461   37.729167         NaN  \n",
      "305  0.296226  0.404893   21.500000         NaN  \n",
      "306  0.331500  0.283493   26.729167         NaN  \n",
      "307  0.469001  0.246918   22.937500         NaN  \n",
      "308  0.253935  0.055187   20.608696         NaN  \n",
      "309  0.038498  0.043239   41.208333         NaN  \n",
      "310  0.018206  0.032652   38.687500         NaN  \n",
      "311  0.315803  0.296226   37.333333         NaN  \n",
      "312  0.389342  0.331500   51.714286         NaN  \n",
      "313  0.317593  0.469001   41.000000         NaN  \n",
      "314  0.391668  0.253935         NaN         NaN  \n",
      "315  0.239712  0.038498         NaN         NaN  \n",
      "316  0.177904  0.018206         NaN         NaN  \n",
      "317  0.275934  0.315803         NaN         NaN  \n",
      "318  0.135976  0.389342         NaN         NaN  \n",
      "319       NaN  0.391668         NaN         NaN  \n",
      "320  0.061970  0.239712         NaN         NaN  \n",
      "321  0.095581  0.177904         NaN         NaN  \n",
      "322  0.076237  0.275934         NaN         NaN  \n",
      "323  0.043998  0.135976         NaN         NaN  \n",
      "324  0.002968  0.041874         NaN         NaN  \n",
      "325  0.068083       NaN   52.400000         NaN  \n",
      "326  0.134496  0.061970   47.750000         NaN  \n",
      "327  0.135555  0.095581   46.479167         NaN  \n",
      "328  0.080789  0.076237   33.142857         NaN  \n",
      "329  0.155699  0.043998   29.125000         NaN  \n",
      "330  0.248155  0.002968    8.062500         NaN  \n",
      "331  0.096529  0.068083    6.750000         NaN  \n",
      "332  0.015930  0.134496    5.586957         NaN  \n",
      "333  0.015238  0.135555   34.541667         NaN  \n",
      "334  0.000000  0.080789   38.416667         NaN  \n",
      "335  0.031291  0.155699   53.521739         NaN  \n",
      "336  0.010290  0.248155   29.895833         NaN  \n",
      "337  0.104305  0.096529    6.229167         NaN  \n",
      "338  0.279158  0.015930    4.000000         NaN  \n",
      "339  0.278630  0.015238   36.692308         NaN  \n",
      "340  0.238195  0.000000   44.770833         NaN  \n",
      "341  0.264366  0.031291   36.888889         NaN  \n",
      "342  0.366890  0.010290   45.026316         NaN  \n",
      "343  0.385359  0.104305   28.333333         NaN  \n",
      "344  0.254314  0.279158   21.543478         NaN  \n",
      "345  0.405280  0.278630   32.312500         NaN  \n",
      "346  0.366584  0.238195   16.937500         NaN  \n",
      "347  0.437322  0.264366    6.600000         NaN  \n",
      "348  0.483447  0.366890         NaN         NaN  \n",
      "349       NaN  0.254314   12.500000   34.826087  \n",
      "350  0.432805  0.405280   10.375000   44.717391  \n",
      "351  0.419496  0.366584    6.833333   58.812500  \n",
      "352  0.361654  0.437322    2.326087   52.604167  \n",
      "353  0.479975  0.483447    9.479167   35.173913  \n",
      "354  0.405272  0.382118   16.775000   31.729167  \n",
      "355  0.378532       NaN   16.891304   44.562500  \n",
      "356  0.449410  0.432805   10.875000   47.739130  \n",
      "357  0.574815  0.419496   19.104167   44.416667  \n",
      "358  0.476200  0.361654   29.260870    9.041667  \n",
      "359  0.360953  0.479975   12.604167   15.739130  \n",
      "360  0.467665  0.405272    3.750000    5.270833  \n",
      "361  0.476958  0.378532    3.673913    2.687500  \n",
      "362  0.533662  0.449410    2.000000    4.282609  \n",
      "363  0.485822  0.574815    5.437500    7.937500  \n",
      "364  0.567609  0.476200    3.130435   11.770833  \n",
      "365  0.488716  0.360953   13.458333   14.021739  \n",
      "366  0.188590  0.467665   32.666667   12.645833  \n",
      "367  0.118528  0.476958   32.608696   15.250000  \n",
      "368  0.181680  0.533662   28.166667   54.695652  \n",
      "369  0.207983  0.485822   31.041667   32.541667  \n",
      "370  0.150768  0.567609   42.304348   32.145833  \n",
      "371  0.260762  0.488716   44.333333   34.391304  \n",
      "372  0.106069  0.188590   29.937500   28.125000  \n",
      "373  0.185663  0.118528   46.521739    4.687500  \n",
      "374  0.088944  0.181680   42.270833   12.500000  \n",
      "375  0.215701  0.207983   50.041667   26.729167  \n",
      "376  0.376825  0.150768   55.108696   12.687500  \n",
      "377  0.354258  0.260762   43.977273   45.043478  \n",
      "378  0.165635  0.106069         NaN   45.083333  \n",
      "379  0.383463  0.185663   49.545455   67.520833  \n",
      "380  0.215437  0.088944   48.083333   42.586957  \n",
      "381  0.437150  0.215701   41.729167   41.270833  \n",
      "382  0.451735  0.376825   54.727273   40.520833  \n",
      "383  0.458373  0.354258   46.520833   49.891304  \n",
      "384  0.220648  0.165635   43.583333   49.687500  \n",
      "385  0.468045  0.383463   51.369565   63.229167  \n",
      "386  0.193628  0.215437   65.145833   52.916667  \n",
      "387  0.083510  0.437150   54.312500   52.217391  \n",
      "388  0.110753  0.451735   41.652174   43.166667  \n",
      "389  0.135027  0.458373   53.375000   30.041667  \n",
      "390  0.120713  0.220648   54.395833   33.760870  \n",
      "391  0.238005  0.468045   60.625000   38.729167  \n",
      "392  0.316518  0.193628   55.369565   59.812500  \n",
      "393  0.098154  0.083510   64.354167   60.739130  \n",
      "394  0.071876  0.110753   55.687500   48.937500  \n",
      "395  0.113977  0.135027   22.717391   55.770833  \n",
      "396  0.231928  0.120713   15.020833   70.369565  \n",
      "397  0.464062  0.238005   21.958333   63.083333  \n",
      "398  0.533852  0.316518   24.847826   65.083333  \n",
      "399  0.435756  0.098154   18.562500   65.847826  \n",
      "400       NaN  0.464062   11.770833   55.770833  \n",
      "401  0.492699  0.533852   25.695652   50.791667  \n",
      "402       NaN  0.430116   40.916667   48.104167  \n",
      "403  0.421582       NaN   20.195652   40.187500  \n",
      "404  0.309294       NaN   44.125000   19.369565  \n",
      "405  0.333086       NaN   25.666667   19.270833  \n",
      "406  0.265174  0.492699   50.022727   24.062500  \n",
      "407  0.341569  0.389437   51.625000   31.434783  \n",
      "408  0.586573       NaN   52.354167   24.687500  \n",
      "409  0.470510  0.421582   26.239130   41.326087  \n",
      "410  0.406600  0.309294   53.416667   47.708333  \n",
      "411  0.446615  0.333086   23.270833   43.729167  \n",
      "412  0.282003  0.265174   11.173913   48.847826  \n",
      "413  0.220450  0.341569   14.166667   63.770833  \n",
      "414  0.479992  0.586573   16.833333   64.979167  \n",
      "415  0.401100  0.470510   15.260870   74.086957  \n",
      "416  0.533118  0.406600   28.145833   81.645833  \n",
      "417  0.420254  0.446615   36.770833   51.333333  \n",
      "418  0.531007  0.282003   12.782609   34.125000  \n",
      "419  0.459305  0.220450    9.895833   24.260870  \n",
      "420  0.561350  0.479992   14.520833   48.052632  \n",
      "421  0.480751  0.401100   27.478261   39.725000  \n",
      "422  0.531766  0.533118   52.979167   63.695652  \n",
      "423  0.461283  0.420254   60.645833   56.166667  \n",
      "424  0.420064  0.531007   49.869565   41.108696  \n",
      "425  0.419387  0.459305   49.250000   50.250000  \n",
      "426  0.517569  0.561350         NaN   52.979167  \n",
      "427  0.622416  0.480751         NaN   50.978261  \n",
      "428  0.607624  0.531766         NaN   61.416667  \n",
      "429  0.653139  0.461283   56.125000   69.583333  \n",
      "430  0.568557  0.420064   44.781250   35.736842  \n",
      "431  0.616628  0.419387         NaN         NaN  \n",
      "432  0.441494  0.517569   48.312500         NaN  \n",
      "433  0.401669  0.622416   35.977273   45.000000  \n",
      "434  0.602658  0.607624   38.590909   49.477273  \n",
      "435  0.577660  0.653139   31.130435   54.979167  \n",
      "436  0.402996  0.568557   39.522727   69.130435  \n",
      "437  0.448816  0.616628   66.437500   57.562500  \n",
      "438  0.417030  0.441494   53.687500   48.565217  \n",
      "439  0.489285  0.401669   46.666667   37.272727  \n",
      "440  0.426133  0.602658   51.062500   53.416667  \n",
      "441  0.431006  0.577660   32.979167   65.395833  \n",
      "442  0.555471  0.402996   26.217391   49.413043  \n",
      "443  0.526456  0.448816   54.729167   57.916667  \n",
      "444  0.453962  0.417030   46.062500   55.250000  \n",
      "445  0.575574  0.489285   60.565217   62.479167  \n",
      "446  0.637019  0.426133   48.166667   56.347826  \n",
      "447  0.647103  0.431006   60.333333   19.520833  \n",
      "448  0.641760  0.555471   52.456522   33.270833  \n",
      "449  0.484544  0.526456   63.666667   38.456522  \n",
      "450  0.562801  0.453962   54.812500   54.520833  \n",
      "451  0.481699  0.575574   60.416667   58.875000  \n",
      "452  0.551489  0.637019   52.673913   63.130435  \n",
      "453  0.465637  0.647103   48.145833   56.645833  \n",
      "454  0.586383  0.641760   48.071429   63.604167  \n",
      "455  0.633795  0.484544   58.857143   64.586957  \n",
      "456  0.529556  0.562801   70.375000   52.395833  \n",
      "457  0.204438  0.481699   68.750000   68.041667  \n",
      "458  0.559264  0.551489   73.750000   78.304348  \n",
      "459  0.680448  0.465637   64.458333   45.791667  \n",
      "460  0.659966  0.586383   69.739130   58.958333  \n",
      "461  0.512042  0.633795   50.500000   67.130435  \n",
      "462  0.601786  0.529556   46.125000   66.541667  \n",
      "463  0.324294  0.204438   68.204545   44.250000  \n",
      "464  0.636260  0.559264   65.458333   66.130435  \n",
      "465  0.634834  0.680448   46.270833   58.854167  \n",
      "466  0.541248  0.659966   51.304348   60.479167  \n",
      "467  0.560212  0.512042   47.812500   60.043478  \n",
      "468  0.592683  0.601786   55.750000   52.145833  \n",
      "469  0.598521  0.324294   48.812500   36.937500  \n",
      "470  0.529111  0.636260   49.347826   46.934783  \n",
      "471  0.472365  0.634834   63.020833   45.083333  \n",
      "472  0.333965  0.541248   59.833333   61.729167  \n",
      "473  0.283520  0.560212   51.869565   64.978261  \n",
      "474  0.283182  0.592683   65.229167   60.104167  \n",
      "475  0.366395  0.598521   71.979167   66.333333  \n",
      "476  0.443356  0.529111   73.086957   56.782609  \n",
      "477  0.359370  0.472365   72.500000   60.833333  \n",
      "478  0.682344  0.333965   55.229167   73.625000  \n",
      "479  0.619002  0.283520   63.826087   82.608696  \n",
      "480  0.491354  0.283182   54.916667   61.666667  \n",
      "481  0.549023  0.366395   62.583333   58.750000  \n",
      "482  0.533283  0.443356   53.152174   75.956522  \n",
      "483  0.616537  0.359370   66.416667   58.666667  \n",
      "484  0.658185  0.682344   71.625000   48.386364  \n",
      "485  0.692775  0.619002   60.173913   67.065217  \n",
      "486  0.605158  0.491354   24.458333   73.791667  \n",
      "487  0.518672  0.549023   63.437500   50.043478  \n",
      "488  0.631709  0.533283   76.750000   55.434783  \n",
      "489  0.523628  0.616537   74.500000   55.791667  \n",
      "490  0.613462  0.658185   58.250000   56.812500  \n",
      "491  0.680637  0.692775   68.108696   62.521739  \n",
      "492  0.750427  0.605158   37.625000   60.000000  \n",
      "493  0.740310  0.518672   71.895833   57.166667  \n",
      "494  0.668690  0.631709   71.739130   52.239130  \n",
      "495  0.659776  0.523628   61.458333   52.666667  \n",
      "496  0.655019  0.613462   63.541667   59.812500  \n",
      "497  0.609141  0.680637   67.108696   75.041667  \n",
      "498  0.721601  0.750427   67.750000   87.391304  \n",
      "499  0.712407  0.740310   60.125000   90.062500  \n",
      "500  0.751185  0.668690   53.891304   47.645833  \n",
      "501  0.676465  0.659776   38.687500   57.782609  \n",
      "502  0.738529  0.655019   33.145833   41.291667  \n",
      "503  0.698464  0.609141   33.108696   31.812500  \n",
      "504  0.783235  0.721601   42.250000   48.391304  \n",
      "505  0.904446  0.712407   50.704545   47.062500  \n",
      "506  0.979708  0.751185   41.478261   54.604167  \n",
      "507  0.877679  0.676465   76.958333   62.369565  \n",
      "508  0.900403  0.738529   70.000000   62.166667  \n",
      "509  1.000000  0.698464   55.977273   73.062500  \n",
      "510  0.960743  0.783235   62.312500   95.521739  \n",
      "511  0.837078  0.904446   60.583333   90.090909  \n",
      "512  0.979898  0.979708   69.729167   93.282609  \n",
      "513  0.966622  0.877679   74.304348  104.804348  \n",
      "514  0.881801  0.900403   78.104167   59.229167  \n",
      "515  0.657798  1.000000   68.479167   60.229167  \n",
      "516  0.604161  0.960743   58.978261   50.500000  \n",
      "517  0.558385  0.837078   71.395833   78.791667  \n",
      "518  0.450358  0.979898   59.522727   74.020833  \n",
      "519  0.599411  0.966622   69.391304   55.586957  \n",
      "520  0.627908  0.881801   76.770833   44.187500  \n",
      "521  0.861559  0.657798   84.437500   45.208333  \n",
      "522  0.642708  0.604161   83.326087   31.934783  \n",
      "523  0.554490  0.558385   75.458333   56.291667  \n",
      "524  0.462166  0.450358   74.479167   68.229167  \n",
      "525  0.451546  0.599411   73.956522   37.152174  \n",
      "526  0.528764  0.627908   68.916667   42.208333  \n",
      "527  0.355775  0.861559   81.270833   58.312500  \n",
      "528  0.632657  0.642708   80.260870   55.021739  \n",
      "529  0.561416  0.554490   84.520833   52.708333  \n",
      "530  0.518474  0.462166   76.312500   56.041667  \n",
      "531  0.521714  0.451546   83.130435   61.717391  \n",
      "532  0.560823  0.528764   78.729167   47.250000  \n",
      "533  0.677413  0.355775   88.041667   58.666667  \n",
      "534  0.710980  0.632657  101.357143   60.739130  \n",
      "535  0.606140  0.561416  109.625000   50.541667  \n",
      "536  0.596814  0.518474   98.416667   51.770833  \n",
      "537  0.513180  0.521714  100.913043   57.021739  \n",
      "538  0.513329  0.560823  111.854167   76.895833  \n",
      "539  0.527593  0.677413  107.541667   56.895833  \n",
      "540  0.637588  0.710980   93.956522   54.347826  \n",
      "541  0.474542  0.606140  109.645833   61.000000  \n",
      "542  0.457994  0.596814  108.187500   68.875000  \n",
      "543  0.482458  0.513180   98.869565   95.568182  \n",
      "544  0.546772  0.513329   74.261905  110.125000  \n",
      "545  0.457425  0.527593   68.369565   80.583333  \n",
      "546  0.389911  0.637588   63.340909   49.652174  \n",
      "547  0.421903  0.474542   51.473684   50.208333  \n",
      "548  0.511853  0.457994   67.847826   68.916667  \n",
      "549  0.406410  0.482458   70.978261   79.152174  \n",
      "550  0.383908  0.546772   96.645833   56.437500  \n",
      "551  0.448891  0.457425   72.604167   51.562500  \n",
      "552  0.531955  0.389911   62.913043   56.934783  \n",
      "553  0.296836  0.421903   52.770833   70.125000  \n",
      "554  0.285606  0.511853   51.604167   86.812500  \n",
      "555  0.393135  0.406410   60.086957   76.065217  \n",
      "556  0.464054  0.383908   41.083333   47.229167  \n",
      "557  0.332448  0.448891   71.500000   57.625000  \n",
      "558  0.448891  0.531955   63.673913   55.478261  \n",
      "559  0.430215  0.296836   58.956522   48.000000  \n",
      "560  0.426702  0.285606   59.312500   40.666667  \n",
      "561  0.396548  0.393135   63.608696   56.295455  \n",
      "562  0.391997  0.464054   76.416667   55.458333  \n",
      "563  0.491957  0.332448   80.104167   73.270833  \n",
      "564  0.476768  0.448891   68.586957   70.416667  \n",
      "565  0.384411  0.430215   67.562500   70.043478  \n",
      "566  0.471574  0.426702   58.375000   91.166667  \n",
      "567  0.534041  0.396548   58.391304  103.520833  \n",
      "568  0.544472  0.391997   59.958333  106.217391  \n",
      "569  0.447233  0.491957   72.041667   97.291667  \n",
      "570  0.483785  0.476768   54.130435  100.708333  \n",
      "571  0.525507  0.384411   52.312500   92.217391  \n",
      "572  0.528368  0.471574   55.000000  102.583333  \n",
      "573  0.559264  0.534041   62.065217   70.416667  \n",
      "574  0.424616  0.544472   52.250000   80.565217  \n",
      "575  0.461283  0.447233   44.833333   39.937500  \n",
      "576  0.515266  0.483785   48.347826   50.145833  \n",
      "577  0.474113  0.525507   58.229167   47.700000  \n",
      "578  0.479885  0.528368   46.645833   97.545455  \n",
      "579  0.423668  0.559264   44.173913   53.000000  \n",
      "580  0.510525  0.424616   51.312500   74.604167  \n",
      "581  0.410623  0.461283   60.437500   89.791667  \n",
      "582  0.324863  0.515266   34.608696   64.608696  \n",
      "583  0.460080  0.474113   33.375000   58.604167  \n",
      "584  0.455149  0.479885   45.187500   69.062500  \n",
      "585  0.421771  0.423668   52.978261   64.413043  \n",
      "586  0.378532  0.510525   38.520833   66.354167  \n",
      "587  0.419331  0.410623   51.312500   72.020833  \n",
      "588  0.421202  0.324863   49.260870   74.304348  \n",
      "589  0.277072  0.460080   48.875000   69.041667  \n",
      "590  0.295253  0.455149   45.562500   71.020833  \n",
      "591  0.468424  0.421771   45.062500   64.104167  \n",
      "592  0.512991  0.378532   56.043478   75.847826  \n",
      "593  0.523025  0.419331   54.375000   59.227273  \n",
      "594  0.602693  0.421202   44.229167   57.416667  \n",
      "595  0.623554  0.277072   53.804348   47.391304  \n",
      "596  0.669663  0.295253   60.666667   48.395833  \n",
      "597  0.701119  0.468424   61.812500   47.541667  \n",
      "598  0.730324  0.512991   51.130435   49.500000  \n",
      "599  0.637415  0.523025   55.145833   45.875000  \n",
      "600  0.412479  0.602693   59.729167   34.354167  \n",
      "601  0.428409  0.623554   60.043478   25.217391  \n",
      "602  0.372431  0.669663   63.437500   33.062500  \n",
      "603  0.421392  0.701119   48.645833   43.166667  \n",
      "604  0.448511  0.730324   52.673913   35.173913  \n",
      "605  0.359378  0.637415   58.604167   37.645833  \n",
      "606  0.470189  0.412479   54.083333   36.166667  \n",
      "607  0.404476  0.428409   54.717391   33.521739  \n",
      "608  0.574729  0.372431   48.541667   27.375000  \n",
      "609  0.390480  0.421392   58.083333   32.770833  \n",
      "610  0.385739  0.448511   47.108696   32.847826  \n",
      "611  0.304950  0.359378   37.687500   45.291667  \n",
      "612  0.407738  0.470189   52.541667   39.604167  \n",
      "613  0.430305  0.404476   52.000000   36.586957  \n",
      "614  0.293670  0.574729   48.333333   36.333333  \n",
      "615  0.385739  0.390480   43.583333   29.604167  \n",
      "616  0.433340  0.385739   48.065217   22.782609  \n",
      "617  0.315240  0.304950   48.270833   31.312500  \n",
      "618  0.322587  0.407738   32.437500   47.291667  \n",
      "619  0.486061  0.430305   34.434783   38.434783  \n",
      "620  0.488197  0.293670   53.458333   18.437500  \n",
      "621  0.557747  0.385739   58.354167   30.250000  \n",
      "622  0.378153  0.433340   59.456522   47.214286  \n",
      "623  0.346705  0.315240   68.208333   40.458333  \n",
      "624  0.432985  0.322587   70.500000   33.375000  \n",
      "625  0.518111  0.486061   75.565217   41.380952  \n",
      "626  0.374409  0.488197   79.020833    7.000000  \n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Date' is the index in data_normalized\n",
    "data_normalized.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the DataFrame after resetting the index\n",
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "579b3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized.drop(['day_lag30', 'day_lag365'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "0e5bd462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month  Day  Concentration  DayOfWeek  Weekend  FittedValues  \\\n",
      "7    2022      1    8       0.416362          6        1      0.388693   \n",
      "8    2022      1    9       0.386118          0        1      0.428560   \n",
      "9    2022      1   10       0.064100          1        0      0.408978   \n",
      "10   2022      1   11       0.125067          2        0      0.147431   \n",
      "11   2022      1   12       0.029774          3        0      0.160503   \n",
      "12   2022      1   13       0.006258          4        0      0.106219   \n",
      "13   2022      1   14       0.020779          5        0      0.071960   \n",
      "14   2022      1   15       0.054049          6        1      0.100682   \n",
      "15   2022      1   16       0.088944          0        1      0.066488   \n",
      "16   2022      1   17       0.109434          1        0      0.110738   \n",
      "17   2022      1   18       0.096909          2        0      0.146506   \n",
      "18   2022      1   19       0.120614          3        0      0.113443   \n",
      "19   2022      1   20       0.479687          4        0      0.134075   \n",
      "20   2022      1   21       0.278020          5        0      0.381509   \n",
      "21   2022      1   22       0.274417          6        1      0.284489   \n",
      "22   2022      1   23       0.294857          0        1      0.269091   \n",
      "23   2022      1   24       0.237815          1        0      0.277497   \n",
      "24   2022      1   25       0.024464          2        0      0.196586   \n",
      "25   2022      1   26       0.095581          3        0      0.088783   \n",
      "26   2022      1   27       0.225109          4        0      0.138901   \n",
      "27   2022      1   28       0.097288          5        0      0.200195   \n",
      "28   2022      1   29       0.391824          6        1      0.102719   \n",
      "29   2022      1   30       0.392187          0        1      0.346674   \n",
      "30   2022      1   31       0.596435          1        0      0.384829   \n",
      "31   2022      2    1       0.369462          2        0      0.492721   \n",
      "32   2022      2    2       0.357482          3        0      0.359827   \n",
      "33   2022      2    3       0.350654          4        0      0.312919   \n",
      "34   2022      2    4       0.435953          5        0      0.376209   \n",
      "35   2022      2    5       0.434098          6        1      0.396489   \n",
      "36   2022      2    6       0.557368          0        1      0.407478   \n",
      "37   2022      2    7       0.463493          1        0      0.519806   \n",
      "38   2022      2    8       0.457128          2        0      0.439747   \n",
      "39   2022      2    9       0.374739          3        0      0.464669   \n",
      "40   2022      2   10       0.255263          4        0      0.369381   \n",
      "41   2022      2   11       0.289118          5        0      0.277285   \n",
      "42   2022      2   12       0.334345          6        1      0.334044   \n",
      "43   2022      2   13       0.526266          0        1      0.339135   \n",
      "44   2022      2   14       0.534701          1        0      0.507016   \n",
      "45   2022      2   15       0.427271          2        0      0.505986   \n",
      "46   2022      2   16       0.489475          3        0      0.426891   \n",
      "47   2022      2   17       0.622367          4        0      0.501522   \n",
      "48   2022      2   18       0.556040          5        0      0.562843   \n",
      "49   2022      2   19       0.574246          6        1      0.555912   \n",
      "50   2022      2   20       0.581205          0        1      0.569380   \n",
      "51   2022      2   21       0.604779          1        0      0.568624   \n",
      "52   2022      2   22       0.345534          2        0      0.590364   \n",
      "53   2022      2   23       0.380346          3        0      0.389898   \n",
      "54   2022      2   24       0.489475          4        0      0.429659   \n",
      "55   2022      2   25       0.444149          5        0      0.503496   \n",
      "56   2022      2   26       0.287140          6        1      0.449600   \n",
      "57   2022      2   27       0.419685          0        1      0.369219   \n",
      "58   2022      2   28       0.347620          1        0      0.432865   \n",
      "59   2022      3    1       0.158115          2        0      0.385504   \n",
      "60   2022      3    2       0.157216          3        0      0.230122   \n",
      "61   2022      3    3       0.200834          4        0      0.234262   \n",
      "62   2022      3    4       0.267944          5        0      0.253007   \n",
      "63   2022      3    5       0.206524          6        1      0.285923   \n",
      "64   2022      3    6       0.357984          0        1      0.270896   \n",
      "65   2022      3    7       0.416082          1        0      0.355737   \n",
      "66   2022      3    8       0.379860          2        0      0.416586   \n",
      "67   2022      3    9       0.426455          3        0      0.373618   \n",
      "68   2022      3   10       0.562299          4        0      0.431001   \n",
      "69   2022      3   11       0.573298          5        0      0.536255   \n",
      "70   2022      3   12       0.656206          6        1      0.532195   \n",
      "71   2022      3   13       0.725014          0        1      0.629487   \n",
      "72   2022      3   14       0.449080          1        0      0.675264   \n",
      "73   2022      3   15       0.292433          2        0      0.471538   \n",
      "74   2022      3   16       0.202640          3        0      0.345560   \n",
      "75   2022      3   17       0.419216          4        0      0.258792   \n",
      "76   2022      3   18       0.343410          5        0      0.432793   \n",
      "77   2022      3   19       0.561614          6        1      0.398846   \n",
      "78   2022      3   20       0.493078          0        1      0.538941   \n",
      "79   2022      3   21       0.356006          1        0      0.506768   \n",
      "80   2022      3   22       0.439219          2        0      0.356591   \n",
      "81   2022      3   23       0.464062          3        0      0.486151   \n",
      "82   2022      3   24       0.445848          4        0      0.466931   \n",
      "83   2022      3   25       0.540869          5        0      0.451391   \n",
      "84   2022      3   26       0.615210          6        1      0.554560   \n",
      "85   2022      3   27       0.307106          0        1      0.571035   \n",
      "87   2022      3   31       0.432185          4        0      0.401784   \n",
      "88   2022      4    1       0.482268          5        0      0.447654   \n",
      "89   2022      4    2       0.611087          6        1      0.492731   \n",
      "90   2022      4    3       0.505784          0        1      0.613934   \n",
      "93   2022      4    6       0.468045          3        0      0.383949   \n",
      "94   2022      4    7       0.577091          4        0      0.478888   \n",
      "95   2022      4    8       0.431600          5        0      0.594612   \n",
      "96   2022      4    9       0.509008          6        1      0.450480   \n",
      "97   2022      4   10       0.484734          0        1      0.503039   \n",
      "98   2022      4   11       0.550540          1        0      0.518701   \n",
      "99   2022      4   12       0.494727          2        0      0.541125   \n",
      "100  2022      4   13       0.159492          3        0      0.547964   \n",
      "101  2022      4   14       0.284658          4        0      0.216143   \n",
      "102  2022      4   15       0.331863          5        0      0.333106   \n",
      "103  2022      4   16       0.478096          6        1      0.390919   \n",
      "104  2022      4   17       0.517732          0        1      0.466760   \n",
      "105  2022      4   18       0.556469          1        0      0.570456   \n",
      "106  2022      4   19       0.497440          2        0      0.489860   \n",
      "107  2022      4   20       0.560781          3        0      0.528059   \n",
      "108  2022      4   21       0.569728          4        0      0.568729   \n",
      "109  2022      4   22       0.458752          5        0      0.559387   \n",
      "110  2022      4   23       0.601176          6        1      0.506502   \n",
      "111  2022      4   24       0.694597          0        1      0.549245   \n",
      "112  2022      4   25       0.398635          1        0      0.712422   \n",
      "113  2022      4   26       0.518490          2        0      0.447841   \n",
      "114  2022      4   27       0.592881          3        0      0.529915   \n",
      "115  2022      4   28       0.587521          4        0      0.598992   \n",
      "116  2022      4   29       0.384601          5        0      0.557278   \n",
      "117  2022      4   30       0.583778          6        1      0.522334   \n",
      "118  2022      5    1       0.517542          0        1      0.543888   \n",
      "119  2022      5    2       0.532335          1        0      0.531479   \n",
      "120  2022      5    3       0.528368          2        0      0.558914   \n",
      "121  2022      5    4       0.456476          3        0      0.573200   \n",
      "122  2022      5    5       0.318035          4        0      0.516359   \n",
      "123  2022      5    6       0.409040          5        0      0.326798   \n",
      "124  2022      5    7       0.392187          6        1      0.464434   \n",
      "125  2022      5    8       0.543713          0        1      0.459690   \n",
      "126  2022      5    9       0.573290          1        0      0.556216   \n",
      "127  2022      5   10       0.528921          2        0      0.581269   \n",
      "128  2022      5   11       0.585625          3        0      0.493264   \n",
      "129  2022      5   12       0.498685          4        0      0.645864   \n",
      "130  2022      5   13       0.535559          5        0      0.526214   \n",
      "131  2022      5   14       0.652001          6        1      0.532064   \n",
      "132  2022      5   15       0.733779          0        1      0.651456   \n",
      "133  2022      5   16       0.543144          1        0      0.693219   \n",
      "134  2022      5   17       0.516594          2        0      0.641480   \n",
      "135  2022      5   18       0.673225          3        0      0.510713   \n",
      "136  2022      5   19       0.515835          4        0      0.646901   \n",
      "137  2022      5   20       0.422254          5        0      0.572802   \n",
      "138  2022      5   21       0.592287          6        1      0.494739   \n",
      "139  2022      5   22       0.653518          0        1      0.640648   \n",
      "140  2022      5   23       0.437339          1        0      0.578709   \n",
      "141  2022      5   24       0.486416          2        0      0.524911   \n",
      "142  2022      5   25       0.489664          3        0      0.568844   \n",
      "143  2022      5   26       0.498957          4        0      0.505108   \n",
      "144  2022      5   27       0.550928          5        0      0.518500   \n",
      "145  2022      5   28       0.527973          6        1      0.556883   \n",
      "146  2022      5   29       0.502181          0        1      0.612422   \n",
      "147  2022      5   30       0.457326          1        0      0.537375   \n",
      "148  2022      5   31       0.461218          2        0      0.456005   \n",
      "149  2022      6    1       0.526266          3        0      0.502611   \n",
      "150  2022      6    2       0.664897          4        0      0.572065   \n",
      "151  2022      6    3       0.777315          5        0      0.694799   \n",
      "152  2022      6    4       0.801631          6        1      0.718812   \n",
      "153  2022      6    5       0.415513          0        1      0.758420   \n",
      "154  2022      6    6       0.507788          1        0      0.522465   \n",
      "155  2022      6    7       0.357671          2        0      0.549040   \n",
      "156  2022      6    8       0.271383          3        0      0.427439   \n",
      "157  2022      6    9       0.422299          4        0      0.304690   \n",
      "158  2022      6   10       0.410203          5        0      0.525334   \n",
      "159  2022      6   11       0.478855          6        1      0.464583   \n",
      "160  2022      6   12       0.549543          0        1      0.486417   \n",
      "161  2022      6   13       0.547696          1        0      0.565368   \n",
      "162  2022      6   14       0.646880          2        0      0.536200   \n",
      "163  2022      6   15       0.851326          3        0      0.710619   \n",
      "164  2022      6   16       0.801890          4        0      0.777583   \n",
      "165  2022      6   17       0.830944          5        0      0.756309   \n",
      "166  2022      6   18       0.935826          6        1      0.832344   \n",
      "167  2022      6   19       0.520956          0        1      0.897166   \n",
      "168  2022      6   20       0.530059          1        0      0.609831   \n",
      "169  2022      6   21       0.441494          2        0      0.534725   \n",
      "170  2022      6   22       0.699033          3        0      0.524000   \n",
      "171  2022      6   23       0.655604          4        0      0.715756   \n",
      "172  2022      6   24       0.487801          5        0      0.721601   \n",
      "173  2022      6   25       0.384032          6        1      0.527797   \n",
      "174  2022      6   26       0.393324          0        1      0.436919   \n",
      "175  2022      6   27       0.272496          1        0      0.474541   \n",
      "176  2022      6   28       0.494216          2        0      0.384282   \n",
      "177  2022      6   29       0.602883          3        0      0.546647   \n",
      "178  2022      6   30       0.319989          4        0      0.584725   \n",
      "179  2022      7    1       0.366016          5        0      0.388647   \n",
      "180  2022      7    2       0.512611          6        1      0.465493   \n",
      "181  2022      7    3       0.482656          0        1      0.521199   \n",
      "182  2022      7    4       0.461597          1        0      0.493089   \n",
      "183  2022      7    5       0.491940          2        0      0.509657   \n",
      "184  2022      7    6       0.543606          3        0      0.527720   \n",
      "185  2022      7    7       0.411910          4        0      0.564480   \n",
      "186  2022      7    8       0.515835          5        0      0.435411   \n",
      "187  2022      7    9       0.534701          6        1      0.534163   \n",
      "188  2022      7   10       0.441874          0        1      0.576936   \n",
      "189  2022      7   11       0.453063          1        0      0.467706   \n",
      "190  2022      7   12       0.500862          2        0      0.493521   \n",
      "191  2022      7   13       0.681775          3        0      0.498020   \n",
      "192  2022      7   14       0.499716          4        0      0.680732   \n",
      "193  2022      7   15       0.476521          5        0      0.560744   \n",
      "194  2022      7   16       0.537076          6        1      0.475975   \n",
      "195  2022      7   17       0.608762          0        1      0.562733   \n",
      "196  2022      7   18       0.851749          1        0      0.587716   \n",
      "197  2022      7   19       0.984259          2        0      0.859029   \n",
      "198  2022      7   20       0.715342          3        0      0.929823   \n",
      "199  2022      7   21       0.433777          4        0      0.681507   \n",
      "200  2022      7   22       0.438839          5        0      0.524680   \n",
      "201  2022      7   23       0.609141          6        1      0.482341   \n",
      "202  2022      7   24       0.702314          0        1      0.659996   \n",
      "203  2022      7   25       0.495543          1        0      0.707888   \n",
      "204  2022      7   26       0.451166          2        0      0.540182   \n",
      "205  2022      7   27       0.500070          3        0      0.528331   \n",
      "206  2022      7   28       0.620140          4        0      0.518908   \n",
      "207  2022      7   29       0.772046          5        0      0.654986   \n",
      "208  2022      7   30       0.674214          6        1      0.775612   \n",
      "209  2022      7   31       0.411720          0        1      0.684770   \n",
      "210  2022      8    1       0.506353          1        0      0.488877   \n",
      "211  2022      8    2       0.486811          2        0      0.525895   \n",
      "212  2022      8    3       0.418737          3        0      0.555880   \n",
      "213  2022      8    4       0.351982          4        0      0.489551   \n",
      "214  2022      8    5       0.494250          5        0      0.432003   \n",
      "215  2022      8    6       0.486630          6        1      0.504427   \n",
      "216  2022      8    7       0.648777          0        1      0.520875   \n",
      "217  2022      8    8       0.622795          1        0      0.682397   \n",
      "218  2022      8    9       0.619398          2        0      0.640903   \n",
      "219  2022      8   10       0.811682          3        0      0.603950   \n",
      "220  2022      8   11       0.924142          4        0      0.785350   \n",
      "221  2022      8   12       0.948689          5        0      0.896142   \n",
      "222  2022      8   13       0.867438          6        1      0.942876   \n",
      "223  2022      8   14       0.898540          0        1      0.844639   \n",
      "224  2022      8   15       0.821247          1        0      0.851581   \n",
      "225  2022      8   16       0.915608          2        0      0.861745   \n",
      "226  2022      8   17       0.622795          3        0      0.928715   \n",
      "227  2022      8   18       0.715177          4        0      0.704819   \n",
      "228  2022      8   19       0.345344          5        0      0.709246   \n",
      "229  2022      8   20       0.438270          6        1      0.483520   \n",
      "230  2022      8   21       0.416006          0        1      0.539112   \n",
      "231  2022      8   22       0.869748          1        0      0.539574   \n",
      "232  2022      8   23       0.464252          2        0      0.805224   \n",
      "233  2022      8   24       0.660914          3        0      0.574237   \n",
      "234  2022      8   25       0.799166          4        0      0.695110   \n",
      "235  2022      8   26       0.569926          5        0      0.831559   \n",
      "236  2022      8   27       0.515266          6        1      0.577054   \n",
      "237  2022      8   28       0.610468          0        1      0.604599   \n",
      "238  2022      8   29       0.568145          1        0      0.671386   \n",
      "239  2022      8   30       0.585815          2        0      0.594098   \n",
      "240  2022      8   31       0.637398          3        0      0.661215   \n",
      "241  2022      9    1       0.658185          4        0      0.637972   \n",
      "242  2022      9    2       0.610279          5        0      0.713475   \n",
      "243  2022      9    3       0.628295          6        1      0.661230   \n",
      "244  2022      9    4       0.565333          0        1      0.638976   \n",
      "245  2022      9    5       0.672235          1        0      0.638234   \n",
      "246  2022      9    6       0.520939          2        0      0.671074   \n",
      "247  2022      9    7       0.504457          3        0      0.620464   \n",
      "248  2022      9    8       0.413196          4        0      0.544060   \n",
      "249  2022      9    9       0.422340          5        0      0.480774   \n",
      "250  2022      9   10       0.414565          6        1      0.496127   \n",
      "251  2022      9   11       0.432391          0        1      0.482318   \n",
      "252  2022      9   12       0.399393          1        0      0.509366   \n",
      "253  2022      9   13       0.294519          2        0      0.435886   \n",
      "254  2022      9   14       0.211347          3        0      0.373043   \n",
      "255  2022      9   15       0.282761          4        0      0.313115   \n",
      "256  2022      9   16       0.374739          5        0      0.342517   \n",
      "257  2022      9   17       0.301981          6        1      0.420071   \n",
      "258  2022      9   18       0.324483          0        1      0.342536   \n",
      "259  2022      9   19       0.311018          1        0      0.385490   \n",
      "260  2022      9   20       0.286942          2        0      0.355364   \n",
      "261  2022      9   21       0.230988          3        0      0.311634   \n",
      "262  2022      9   22       0.280106          4        0      0.301578   \n",
      "263  2022      9   23       0.280807          5        0      0.306080   \n",
      "264  2022      9   24       0.394083          6        1      0.330317   \n",
      "265  2022      9   25       0.342310          0        1      0.390082   \n",
      "266  2022      9   26       0.314844          1        0      0.361444   \n",
      "267  2022      9   27       0.312536          2        0      0.349734   \n",
      "268  2022      9   28       0.251280          3        0      0.328361   \n",
      "269  2022      9   29       0.189184          4        0      0.283878   \n",
      "270  2022      9   30       0.266831          5        0      0.229932   \n",
      "271  2022     10    1       0.412289          6        1      0.296030   \n",
      "272  2022     10    2       0.331665          0        1      0.405728   \n",
      "273  2022     10    3       0.149630          1        0      0.339249   \n",
      "274  2022     10    4       0.257159          2        0      0.204381   \n",
      "275  2022     10    5       0.411585          3        0      0.267312   \n",
      "276  2022     10    6       0.350085          4        0      0.392919   \n",
      "277  2022     10    7       0.285606          5        0      0.365086   \n",
      "278  2022     10    8       0.358484          6        1      0.315100   \n",
      "279  2022     10    9       0.045515          0        1      0.342639   \n",
      "280  2022     10   10       0.359568          1        0      0.096538   \n",
      "281  2022     10   11       0.034895          2        0      0.360458   \n",
      "282  2022     10   12       0.149992          3        0      0.130982   \n",
      "283  2022     10   13       0.179405          4        0      0.138448   \n",
      "284  2022     10   14       0.194725          5        0      0.231479   \n",
      "285  2022     10   15       0.320121          6        1      0.161289   \n",
      "286  2022     10   16       0.325242          0        1      0.371259   \n",
      "287  2022     10   17       0.177508          1        0      0.302338   \n",
      "288  2022     10   18       0.225109          2        0      0.156816   \n",
      "289  2022     10   19       0.190594          3        0      0.270665   \n",
      "290  2022     10   20       0.169395          4        0      0.172306   \n",
      "291  2022     10   21       0.356913          5        0      0.234601   \n",
      "292  2022     10   22       0.333965          6        1      0.305642   \n",
      "293  2022     10   23       0.321639          0        1      0.293959   \n",
      "294  2022     10   24       0.452548          1        0      0.357166   \n",
      "295  2022     10   25       0.355016          2        0      0.394539   \n",
      "303  2022     11   14       0.032652          1        0      0.117939   \n",
      "304  2022     11   15       0.296226          2        0      0.091609   \n",
      "305  2022     11   16       0.331500          3        0      0.250625   \n",
      "306  2022     11   17       0.469001          4        0      0.346229   \n",
      "307  2022     11   18       0.253935          5        0      0.426100   \n",
      "308  2022     11   19       0.038498          6        1      0.284872   \n",
      "309  2022     11   20       0.018206          0        1      0.050636   \n",
      "310  2022     11   21       0.315803          1        0      0.061931   \n",
      "311  2022     11   22       0.389342          2        0      0.318607   \n",
      "312  2022     11   23       0.317593          3        0      0.371202   \n",
      "313  2022     11   24       0.391668          4        0      0.314759   \n",
      "314  2022     11   25       0.239712          5        0      0.330450   \n",
      "315  2022     11   26       0.177904          6        1      0.250787   \n",
      "316  2022     11   27       0.275934          0        1      0.224054   \n",
      "317  2022     11   28       0.135976          1        0      0.280065   \n",
      "318  2022     11   29       0.041874          2        0      0.140084   \n",
      "320  2022     12    2       0.095581          5        0      0.124956   \n",
      "321  2022     12    3       0.076237          6        1      0.112610   \n",
      "322  2022     12    4       0.043998          0        1      0.096438   \n",
      "323  2022     12    5       0.002968          1        0      0.059070   \n",
      "324  2022     12    6       0.068083          2        0      0.042643   \n",
      "326  2022     12    8       0.135555          4        0      0.112944   \n",
      "327  2022     12    9       0.080789          5        0      0.130957   \n",
      "328  2022     12   10       0.155699          6        1      0.092695   \n",
      "329  2022     12   11       0.248155          0        1      0.147203   \n",
      "330  2022     12   12       0.096529          1        0      0.214595   \n",
      "331  2022     12   13       0.015930          2        0      0.089124   \n",
      "332  2022     12   14       0.015238          3        0      0.050035   \n",
      "333  2022     12   15       0.000000          4        0      0.026920   \n",
      "334  2022     12   16       0.031291          5        0      0.000000   \n",
      "335  2022     12   17       0.010290          6        1      0.048807   \n",
      "336  2022     12   18       0.104305          0        1      0.018499   \n",
      "337  2022     12   19       0.279158          1        0      0.092307   \n",
      "338  2022     12   20       0.278630          2        0      0.219512   \n",
      "339  2022     12   21       0.238195          3        0      0.229050   \n",
      "340  2022     12   22       0.264366          4        0      0.227428   \n",
      "341  2022     12   23       0.366890          5        0      0.217338   \n",
      "342  2022     12   24       0.385359          6        1      0.298061   \n",
      "343  2022     12   25       0.254314          0        1      0.342356   \n",
      "344  2022     12   26       0.405280          1        0      0.250635   \n",
      "345  2022     12   27       0.366584          2        0      0.359650   \n",
      "346  2022     12   28       0.437322          3        0      0.309684   \n",
      "347  2022     12   29       0.483447          4        0      0.391163   \n",
      "348  2022     12   30       0.382118          5        0      0.476457   \n",
      "350  2023      1    2       0.419496          1        0      0.400297   \n",
      "351  2023      1    3       0.361654          2        0      0.388790   \n",
      "352  2023      1    4       0.479975          3        0      0.372076   \n",
      "353  2023      1    5       0.405272          4        0      0.483123   \n",
      "354  2023      1    6       0.378532          5        0      0.356246   \n",
      "356  2023      1    8       0.574815          0        1      0.454806   \n",
      "357  2023      1    9       0.476200          1        0      0.538440   \n",
      "358  2023      1   10       0.360953          2        0      0.482407   \n",
      "359  2023      1   11       0.467665          3        0      0.342920   \n",
      "360  2023      1   12       0.476958          4        0      0.483717   \n",
      "361  2023      1   13       0.533662          5        0      0.478942   \n",
      "362  2023      1   14       0.485822          6        1      0.518913   \n",
      "363  2023      1   15       0.567609          0        1      0.501405   \n",
      "364  2023      1   16       0.488716          1        0      0.513673   \n",
      "365  2023      1   17       0.188590          2        0      0.537062   \n",
      "366  2023      1   18       0.118528          3        0      0.251055   \n",
      "367  2023      1   19       0.181680          4        0      0.190666   \n",
      "368  2023      1   20       0.207983          5        0      0.231368   \n",
      "369  2023      1   21       0.150768          6        1      0.238044   \n",
      "370  2023      1   22       0.260762          0        1      0.269650   \n",
      "371  2023      1   23       0.106069          1        0      0.248117   \n",
      "372  2023      1   24       0.185663          2        0      0.148525   \n",
      "373  2023      1   25       0.088944          3        0      0.218352   \n",
      "374  2023      1   26       0.215701          4        0      0.161043   \n",
      "375  2023      1   27       0.376825          5        0      0.240561   \n",
      "376  2023      1   28       0.354258          6        1      0.324941   \n",
      "377  2023      1   29       0.165635          0        1      0.343413   \n",
      "378  2023      1   30       0.383463          1        0      0.231140   \n",
      "379  2023      1   31       0.215437          2        0      0.354831   \n",
      "380  2023      2    1       0.437150          3        0      0.215688   \n",
      "381  2023      2    2       0.451735          4        0      0.386630   \n",
      "382  2023      2    3       0.458373          5        0      0.484764   \n",
      "383  2023      2    4       0.220648          6        1      0.410873   \n",
      "384  2023      2    5       0.468045          0        1      0.251505   \n",
      "385  2023      2    6       0.193628          1        0      0.403397   \n",
      "386  2023      2    7       0.083510          2        0      0.263556   \n",
      "387  2023      2    8       0.110753          3        0      0.163950   \n",
      "388  2023      2    9       0.135027          4        0      0.132985   \n",
      "389  2023      2   10       0.120713          5        0      0.128720   \n",
      "390  2023      2   11       0.238005          6        1      0.181676   \n",
      "391  2023      2   12       0.316518          0        1      0.283314   \n",
      "392  2023      2   13       0.098154          1        0      0.281248   \n",
      "393  2023      2   14       0.071876          2        0      0.100780   \n",
      "394  2023      2   15       0.113977          3        0      0.112211   \n",
      "395  2023      2   16       0.231928          4        0      0.173751   \n",
      "396  2023      2   17       0.464062          5        0      0.213802   \n",
      "397  2023      2   18       0.533852          6        1      0.391250   \n",
      "398  2023      2   19       0.435756          0        1      0.473064   \n",
      "399  2023      2   20       0.430116          1        0      0.432393   \n",
      "401  2023      2   25       0.389437          6        1      0.409438   \n",
      "406  2023      3    3       0.341569          5        0      0.279711   \n",
      "407  2023      3    4       0.586573          6        1      0.372301   \n",
      "409  2023      3    6       0.406600          1        0      0.429704   \n",
      "410  2023      3    7       0.446615          2        0      0.387428   \n",
      "411  2023      3    8       0.282003          3        0      0.468527   \n",
      "412  2023      3    9       0.220450          4        0      0.317239   \n",
      "413  2023      3   10       0.479992          5        0      0.269798   \n",
      "414  2023      3   11       0.401100          6        1      0.432200   \n",
      "415  2023      3   12       0.533118          0        1      0.410755   \n",
      "416  2023      3   13       0.420254          1        0      0.552430   \n",
      "417  2023      3   14       0.531007          2        0      0.424092   \n",
      "418  2023      3   15       0.459305          3        0      0.469383   \n",
      "419  2023      3   16       0.561350          4        0      0.481143   \n",
      "420  2023      3   17       0.480751          5        0      0.554206   \n",
      "421  2023      3   18       0.531766          6        1      0.523997   \n",
      "422  2023      3   19       0.461283          0        1      0.472303   \n",
      "423  2023      3   20       0.420064          1        0      0.474216   \n",
      "424  2023      3   21       0.419387          2        0      0.472213   \n",
      "425  2023      3   22       0.517569          3        0      0.454274   \n",
      "426  2023      3   23       0.622416          4        0      0.506969   \n",
      "427  2023      3   24       0.607624          5        0      0.568136   \n",
      "428  2023      3   25       0.653139          6        1      0.640998   \n",
      "429  2023      3   26       0.568557          0        1      0.659828   \n",
      "430  2023      3   27       0.616628          1        0      0.552856   \n",
      "431  2023      3   28       0.441494          2        0      0.590491   \n",
      "432  2023      3   29       0.401669          3        0      0.497873   \n",
      "433  2023      3   30       0.602658          4        0      0.482391   \n",
      "434  2023      3   31       0.577660          5        0      0.593919   \n",
      "435  2023      4    1       0.402996          6        1      0.548383   \n",
      "436  2023      4    2       0.448816          0        1      0.478537   \n",
      "437  2023      4    3       0.417030          1        0      0.515568   \n",
      "438  2023      4    4       0.489285          2        0      0.438771   \n",
      "439  2023      4    5       0.426133          3        0      0.486228   \n",
      "440  2023      4    6       0.431006          4        0      0.481985   \n",
      "441  2023      4    7       0.555471          5        0      0.491474   \n",
      "442  2023      4    8       0.526456          6        1      0.562897   \n",
      "443  2023      4    9       0.453962          0        1      0.502185   \n",
      "444  2023      4   10       0.575574          1        0      0.499313   \n",
      "445  2023      4   11       0.637019          2        0      0.613674   \n",
      "446  2023      4   12       0.647103          3        0      0.620858   \n",
      "447  2023      4   13       0.641760          4        0      0.627959   \n",
      "448  2023      4   14       0.484544          5        0      0.641941   \n",
      "449  2023      4   15       0.562801          6        1      0.547829   \n",
      "450  2023      4   16       0.481699          0        1      0.585004   \n",
      "451  2023      4   17       0.551489          1        0      0.497645   \n",
      "452  2023      4   18       0.465637          2        0      0.566523   \n",
      "453  2023      4   19       0.586383          3        0      0.545632   \n",
      "454  2023      4   20       0.633795          4        0      0.590446   \n",
      "455  2023      4   21       0.529556          5        0      0.636936   \n",
      "456  2023      4   22       0.204438          6        1      0.540064   \n",
      "457  2023      4   23       0.559264          0        1      0.336271   \n",
      "458  2023      4   24       0.680448          1        0      0.571455   \n",
      "459  2023      4   25       0.659966          2        0      0.650179   \n",
      "460  2023      4   26       0.512042          3        0      0.666851   \n",
      "461  2023      4   27       0.601786          4        0      0.587570   \n",
      "462  2023      4   28       0.324294          5        0      0.589323   \n",
      "463  2023      4   29       0.636260          6        1      0.385832   \n",
      "464  2023      4   30       0.634834          0        1      0.631269   \n",
      "465  2023      5    1       0.541248          1        0      0.694261   \n",
      "466  2023      5    2       0.560212          2        0      0.553852   \n",
      "467  2023      5    3       0.592683          3        0      0.581148   \n",
      "468  2023      5    4       0.598521          4        0      0.582727   \n",
      "469  2023      5    5       0.529111          5        0      0.646536   \n",
      "470  2023      5    6       0.472365          6        1      0.606743   \n",
      "471  2023      5    7       0.333965          0        1      0.467610   \n",
      "472  2023      5    8       0.283520          1        0      0.405624   \n",
      "473  2023      5    9       0.283182          2        0      0.361889   \n",
      "474  2023      5   10       0.366395          3        0      0.393976   \n",
      "475  2023      5   11       0.443356          4        0      0.405852   \n",
      "476  2023      5   12       0.359370          5        0      0.428600   \n",
      "477  2023      5   13       0.682344          6        1      0.438041   \n",
      "478  2023      5   14       0.619002          0        1      0.665173   \n",
      "479  2023      5   15       0.491354          1        0      0.629662   \n",
      "480  2023      5   16       0.549023          2        0      0.474871   \n",
      "481  2023      5   17       0.533283          3        0      0.571232   \n",
      "482  2023      5   18       0.616537          4        0      0.565062   \n",
      "483  2023      5   19       0.658185          5        0      0.619277   \n",
      "484  2023      5   20       0.692775          6        1      0.662683   \n",
      "485  2023      5   21       0.605158          0        1      0.646586   \n",
      "486  2023      5   22       0.518672          1        0      0.660999   \n",
      "487  2023      5   23       0.631709          2        0      0.553363   \n",
      "488  2023      5   24       0.523628          3        0      0.628459   \n",
      "489  2023      5   25       0.613462          4        0      0.561850   \n",
      "490  2023      5   26       0.680637          5        0      0.618691   \n",
      "491  2023      5   27       0.750427          6        1      0.737156   \n",
      "492  2023      5   28       0.740310          0        1      0.701986   \n",
      "493  2023      5   29       0.668690          1        0      0.750581   \n",
      "494  2023      5   30       0.659776          2        0      0.694923   \n",
      "495  2023      5   31       0.655019          3        0      0.682360   \n",
      "496  2023      6    1       0.609141          4        0      0.704164   \n",
      "497  2023      6    2       0.721601          5        0      0.603239   \n",
      "498  2023      6    3       0.712407          6        1      0.766906   \n",
      "499  2023      6    4       0.751185          0        1      0.738567   \n",
      "500  2023      6    5       0.676465          1        0      0.754909   \n",
      "501  2023      6    6       0.738529          2        0      0.726478   \n",
      "502  2023      6    7       0.698464          3        0      0.717127   \n",
      "503  2023      6    8       0.783235          4        0      0.781115   \n",
      "504  2023      6    9       0.904446          5        0      0.781009   \n",
      "505  2023      6   10       0.979708          6        1      0.896895   \n",
      "506  2023      6   11       0.877679          0        1      0.969189   \n",
      "507  2023      6   12       0.900403          1        0      0.883634   \n",
      "508  2023      6   13       1.000000          2        0      0.950126   \n",
      "509  2023      6   14       0.960743          3        0      0.959366   \n",
      "510  2023      6   15       0.837078          4        0      0.979016   \n",
      "511  2023      6   16       0.979898          5        0      0.906614   \n",
      "512  2023      6   17       0.966622          6        1      0.983869   \n",
      "513  2023      6   18       0.881801          0        1      1.000000   \n",
      "514  2023      6   19       0.657798          1        0      0.899118   \n",
      "515  2023      6   20       0.604161          2        0      0.795278   \n",
      "516  2023      6   21       0.558385          3        0      0.691094   \n",
      "517  2023      6   22       0.450358          4        0      0.644550   \n",
      "518  2023      6   23       0.599411          5        0      0.582761   \n",
      "519  2023      6   24       0.627908          6        1      0.681105   \n",
      "520  2023      6   25       0.861559          0        1      0.727021   \n",
      "521  2023      6   26       0.642708          1        0      0.842330   \n",
      "522  2023      6   27       0.554490          2        0      0.732188   \n",
      "523  2023      6   28       0.462166          3        0      0.635715   \n",
      "524  2023      6   29       0.451546          4        0      0.568566   \n",
      "525  2023      6   30       0.528764          5        0      0.522385   \n",
      "526  2023      7    1       0.355775          6        1      0.598303   \n",
      "527  2023      7    2       0.632657          0        1      0.490782   \n",
      "528  2023      7    3       0.561416          1        0      0.650620   \n",
      "529  2023      7    4       0.518474          2        0      0.619951   \n",
      "530  2023      7    5       0.521714          3        0      0.548126   \n",
      "531  2023      7    6       0.560823          4        0      0.623419   \n",
      "532  2023      7    7       0.677413          5        0      0.583257   \n",
      "533  2023      7    8       0.710980          6        1      0.682569   \n",
      "534  2023      7    9       0.606140          0        1      0.743802   \n",
      "535  2023      7   10       0.596814          1        0      0.635365   \n",
      "536  2023      7   11       0.513180          2        0      0.666136   \n",
      "537  2023      7   12       0.513329          3        0      0.527552   \n",
      "538  2023      7   13       0.527593          4        0      0.569399   \n",
      "539  2023      7   14       0.637588          5        0      0.612391   \n",
      "540  2023      7   15       0.474542          6        1      0.639298   \n",
      "541  2023      7   16       0.457994          0        1      0.554049   \n",
      "542  2023      7   17       0.482458          1        0      0.476990   \n",
      "543  2023      7   18       0.546772          2        0      0.564354   \n",
      "544  2023      7   19       0.457425          3        0      0.586008   \n",
      "545  2023      7   20       0.389911          4        0      0.500079   \n",
      "546  2023      7   21       0.421903          5        0      0.462367   \n",
      "547  2023      7   22       0.511853          6        1      0.449173   \n",
      "548  2023      7   23       0.406410          0        1      0.572587   \n",
      "549  2023      7   24       0.383908          1        0      0.459486   \n",
      "550  2023      7   25       0.448891          2        0      0.424881   \n",
      "551  2023      7   26       0.531955          3        0      0.489619   \n",
      "552  2023      7   27       0.296836          4        0      0.530722   \n",
      "553  2023      7   28       0.285606          5        0      0.411402   \n",
      "554  2023      7   29       0.393135          6        1      0.324842   \n",
      "555  2023      7   30       0.464054          0        1      0.412268   \n",
      "556  2023      7   31       0.332448          1        0      0.486680   \n",
      "557  2023      8    1       0.448891          2        0      0.406907   \n",
      "558  2023      8    2       0.430215          3        0      0.481596   \n",
      "559  2023      8    3       0.426702          4        0      0.405275   \n",
      "560  2023      8    4       0.396548          5        0      0.450346   \n",
      "561  2023      8    5       0.391997          6        1      0.471527   \n",
      "562  2023      8    6       0.491957          0        1      0.410775   \n",
      "563  2023      8    7       0.476768          1        0      0.482667   \n",
      "564  2023      8    8       0.384411          2        0      0.464502   \n",
      "565  2023      8    9       0.471574          3        0      0.455950   \n",
      "566  2023      8   10       0.534041          4        0      0.505031   \n",
      "567  2023      8   11       0.544472          5        0      0.485851   \n",
      "568  2023      8   12       0.447233          6        1      0.544454   \n",
      "569  2023      8   13       0.483785          0        1      0.496462   \n",
      "570  2023      8   14       0.525507          1        0      0.517747   \n",
      "571  2023      8   15       0.528368          2        0      0.510231   \n",
      "572  2023      8   16       0.559264          3        0      0.501911   \n",
      "573  2023      8   17       0.424616          4        0      0.611529   \n",
      "574  2023      8   18       0.461283          5        0      0.473991   \n",
      "575  2023      8   19       0.515266          6        1      0.461779   \n",
      "576  2023      8   20       0.474113          0        1      0.509276   \n",
      "577  2023      8   21       0.479885          1        0      0.501891   \n",
      "578  2023      8   22       0.423668          2        0      0.564312   \n",
      "579  2023      8   23       0.510525          3        0      0.423916   \n",
      "580  2023      8   24       0.410623          4        0      0.486823   \n",
      "581  2023      8   25       0.324863          5        0      0.474790   \n",
      "582  2023      8   26       0.460080          6        1      0.397242   \n",
      "583  2023      8   27       0.455149          0        1      0.501875   \n",
      "584  2023      8   28       0.421771          1        0      0.408292   \n",
      "585  2023      8   29       0.378532          2        0      0.466123   \n",
      "586  2023      8   30       0.419331          3        0      0.472752   \n",
      "587  2023      8   31       0.421202          4        0      0.416289   \n",
      "588  2023      9    1       0.277072          5        0      0.435614   \n",
      "589  2023      9    2       0.295253          6        1      0.300704   \n",
      "590  2023      9    3       0.468424          0        1      0.396672   \n",
      "591  2023      9    4       0.512991          1        0      0.485569   \n",
      "592  2023      9    5       0.523025          2        0      0.454646   \n",
      "593  2023      9    6       0.602693          3        0      0.546065   \n",
      "594  2023      9    7       0.623554          4        0      0.593501   \n",
      "595  2023      9    8       0.669663          5        0      0.635752   \n",
      "596  2023      9    9       0.701119          6        1      0.620744   \n",
      "597  2023      9   10       0.730324          0        1      0.654193   \n",
      "598  2023      9   11       0.637415          1        0      0.755523   \n",
      "599  2023      9   12       0.412479          2        0      0.644232   \n",
      "600  2023      9   13       0.428409          3        0      0.461509   \n",
      "601  2023      9   14       0.372431          4        0      0.441124   \n",
      "602  2023      9   15       0.421392          5        0      0.442215   \n",
      "603  2023      9   16       0.448511          6        1      0.507082   \n",
      "604  2023      9   17       0.359378          0        1      0.472783   \n",
      "605  2023      9   18       0.470189          1        0      0.382923   \n",
      "606  2023      9   19       0.404476          2        0      0.494550   \n",
      "607  2023      9   20       0.574729          3        0      0.479540   \n",
      "608  2023      9   21       0.390480          4        0      0.578539   \n",
      "609  2023      9   22       0.385739          5        0      0.416587   \n",
      "610  2023      9   23       0.304950          6        1      0.396852   \n",
      "611  2023      9   24       0.407738          0        1      0.407202   \n",
      "612  2023      9   25       0.430305          1        0      0.428357   \n",
      "613  2023      9   26       0.293670          2        0      0.454504   \n",
      "614  2023      9   27       0.385739          3        0      0.324383   \n",
      "615  2023      9   28       0.433340          4        0      0.423127   \n",
      "616  2023      9   29       0.315240          5        0      0.481689   \n",
      "617  2023      9   30       0.322587          6        1      0.324186   \n",
      "618  2023     10    1       0.486061          0        1      0.372022   \n",
      "619  2023     10    2       0.488197          1        0      0.469716   \n",
      "620  2023     10    3       0.557747          2        0      0.509581   \n",
      "621  2023     10    4       0.378153          3        0      0.567512   \n",
      "622  2023     10    5       0.346705          4        0      0.376712   \n",
      "623  2023     10    6       0.432985          5        0      0.382196   \n",
      "624  2023     10    7       0.518111          6        1      0.454616   \n",
      "625  2023     10    8       0.374409          0        1      0.525121   \n",
      "626  2023     10    9       0.246374          1        0      0.421333   \n",
      "\n",
      "     day_lag1  day_lag7  \n",
      "7    0.387445  0.298815  \n",
      "8    0.416362  0.388855  \n",
      "9    0.386118  0.517163  \n",
      "10   0.064100  0.460649  \n",
      "11   0.125067  0.301981  \n",
      "12   0.029774  0.270624  \n",
      "13   0.006258  0.387445  \n",
      "14   0.020779  0.416362  \n",
      "15   0.054049  0.386118  \n",
      "16   0.088944  0.064100  \n",
      "17   0.109434  0.125067  \n",
      "18   0.096909  0.029774  \n",
      "19   0.120614  0.006258  \n",
      "20   0.479687  0.020779  \n",
      "21   0.278020  0.054049  \n",
      "22   0.274417  0.088944  \n",
      "23   0.294857  0.109434  \n",
      "24   0.237815  0.096909  \n",
      "25   0.024464  0.120614  \n",
      "26   0.095581  0.479687  \n",
      "27   0.225109  0.278020  \n",
      "28   0.097288  0.274417  \n",
      "29   0.391824  0.294857  \n",
      "30   0.392187  0.237815  \n",
      "31   0.596435  0.024464  \n",
      "32   0.369462  0.095581  \n",
      "33   0.357482  0.225109  \n",
      "34   0.350654  0.097288  \n",
      "35   0.435953  0.391824  \n",
      "36   0.434098  0.392187  \n",
      "37   0.557368  0.596435  \n",
      "38   0.463493  0.369462  \n",
      "39   0.457128  0.357482  \n",
      "40   0.374739  0.350654  \n",
      "41   0.255263  0.435953  \n",
      "42   0.289118  0.434098  \n",
      "43   0.334345  0.557368  \n",
      "44   0.526266  0.463493  \n",
      "45   0.534701  0.457128  \n",
      "46   0.427271  0.374739  \n",
      "47   0.489475  0.255263  \n",
      "48   0.622367  0.289118  \n",
      "49   0.556040  0.334345  \n",
      "50   0.574246  0.526266  \n",
      "51   0.581205  0.534701  \n",
      "52   0.604779  0.427271  \n",
      "53   0.345534  0.489475  \n",
      "54   0.380346  0.622367  \n",
      "55   0.489475  0.556040  \n",
      "56   0.444149  0.574246  \n",
      "57   0.287140  0.581205  \n",
      "58   0.419685  0.604779  \n",
      "59   0.347620  0.345534  \n",
      "60   0.158115  0.380346  \n",
      "61   0.157216  0.489475  \n",
      "62   0.200834  0.444149  \n",
      "63   0.267944  0.287140  \n",
      "64   0.206524  0.419685  \n",
      "65   0.357984  0.347620  \n",
      "66   0.416082  0.158115  \n",
      "67   0.379860  0.157216  \n",
      "68   0.426455  0.200834  \n",
      "69   0.562299  0.267944  \n",
      "70   0.573298  0.206524  \n",
      "71   0.656206  0.357984  \n",
      "72   0.725014  0.416082  \n",
      "73   0.449080  0.379860  \n",
      "74   0.292433  0.426455  \n",
      "75   0.202640  0.562299  \n",
      "76   0.419216  0.573298  \n",
      "77   0.343410  0.656206  \n",
      "78   0.561614  0.725014  \n",
      "79   0.493078  0.449080  \n",
      "80   0.356006  0.292433  \n",
      "81   0.439219  0.202640  \n",
      "82   0.464062  0.419216  \n",
      "83   0.445848  0.343410  \n",
      "84   0.540869  0.561614  \n",
      "85   0.615210  0.493078  \n",
      "87   0.391428  0.445848  \n",
      "88   0.432185  0.540869  \n",
      "89   0.482268  0.615210  \n",
      "90   0.611087  0.307106  \n",
      "93   0.321087  0.391428  \n",
      "94   0.468045  0.432185  \n",
      "95   0.577091  0.482268  \n",
      "96   0.431600  0.611087  \n",
      "97   0.509008  0.505784  \n",
      "98   0.484734  0.423882  \n",
      "99   0.550540  0.321087  \n",
      "100  0.494727  0.468045  \n",
      "101  0.159492  0.577091  \n",
      "102  0.284658  0.431600  \n",
      "103  0.331863  0.509008  \n",
      "104  0.478096  0.484734  \n",
      "105  0.517732  0.550540  \n",
      "106  0.556469  0.494727  \n",
      "107  0.497440  0.159492  \n",
      "108  0.560781  0.284658  \n",
      "109  0.569728  0.331863  \n",
      "110  0.458752  0.478096  \n",
      "111  0.601176  0.517732  \n",
      "112  0.694597  0.556469  \n",
      "113  0.398635  0.497440  \n",
      "114  0.518490  0.560781  \n",
      "115  0.592881  0.569728  \n",
      "116  0.587521  0.458752  \n",
      "117  0.384601  0.601176  \n",
      "118  0.583778  0.694597  \n",
      "119  0.517542  0.398635  \n",
      "120  0.532335  0.518490  \n",
      "121  0.528368  0.592881  \n",
      "122  0.456476  0.587521  \n",
      "123  0.318035  0.384601  \n",
      "124  0.409040  0.583778  \n",
      "125  0.392187  0.517542  \n",
      "126  0.543713  0.532335  \n",
      "127  0.573290  0.528368  \n",
      "128  0.528921  0.456476  \n",
      "129  0.585625  0.318035  \n",
      "130  0.498685  0.409040  \n",
      "131  0.535559  0.392187  \n",
      "132  0.652001  0.543713  \n",
      "133  0.733779  0.573290  \n",
      "134  0.543144  0.528921  \n",
      "135  0.516594  0.585625  \n",
      "136  0.673225  0.498685  \n",
      "137  0.515835  0.535559  \n",
      "138  0.422254  0.652001  \n",
      "139  0.592287  0.733779  \n",
      "140  0.653518  0.543144  \n",
      "141  0.437339  0.516594  \n",
      "142  0.486416  0.673225  \n",
      "143  0.489664  0.515835  \n",
      "144  0.498957  0.422254  \n",
      "145  0.550928  0.592287  \n",
      "146  0.527973  0.653518  \n",
      "147  0.502181  0.437339  \n",
      "148  0.457326  0.486416  \n",
      "149  0.461218  0.489664  \n",
      "150  0.526266  0.498957  \n",
      "151  0.664897  0.550928  \n",
      "152  0.777315  0.527973  \n",
      "153  0.801631  0.502181  \n",
      "154  0.415513  0.457326  \n",
      "155  0.507788  0.461218  \n",
      "156  0.357671  0.526266  \n",
      "157  0.271383  0.664897  \n",
      "158  0.422299  0.777315  \n",
      "159  0.410203  0.801631  \n",
      "160  0.478855  0.415513  \n",
      "161  0.549543  0.507788  \n",
      "162  0.547696  0.357671  \n",
      "163  0.646880  0.271383  \n",
      "164  0.851326  0.422299  \n",
      "165  0.801890  0.410203  \n",
      "166  0.830944  0.478855  \n",
      "167  0.935826  0.549543  \n",
      "168  0.520956  0.547696  \n",
      "169  0.530059  0.646880  \n",
      "170  0.441494  0.851326  \n",
      "171  0.699033  0.801890  \n",
      "172  0.655604  0.830944  \n",
      "173  0.487801  0.935826  \n",
      "174  0.384032  0.520956  \n",
      "175  0.393324  0.530059  \n",
      "176  0.272496  0.441494  \n",
      "177  0.494216  0.699033  \n",
      "178  0.602883  0.655604  \n",
      "179  0.319989  0.487801  \n",
      "180  0.366016  0.384032  \n",
      "181  0.512611  0.393324  \n",
      "182  0.482656  0.272496  \n",
      "183  0.461597  0.494216  \n",
      "184  0.491940  0.602883  \n",
      "185  0.543606  0.319989  \n",
      "186  0.411910  0.366016  \n",
      "187  0.515835  0.512611  \n",
      "188  0.534701  0.482656  \n",
      "189  0.441874  0.461597  \n",
      "190  0.453063  0.491940  \n",
      "191  0.500862  0.543606  \n",
      "192  0.681775  0.411910  \n",
      "193  0.499716  0.515835  \n",
      "194  0.476521  0.534701  \n",
      "195  0.537076  0.441874  \n",
      "196  0.608762  0.453063  \n",
      "197  0.851749  0.500862  \n",
      "198  0.984259  0.681775  \n",
      "199  0.715342  0.499716  \n",
      "200  0.433777  0.476521  \n",
      "201  0.438839  0.537076  \n",
      "202  0.609141  0.608762  \n",
      "203  0.702314  0.851749  \n",
      "204  0.495543  0.984259  \n",
      "205  0.451166  0.715342  \n",
      "206  0.500070  0.433777  \n",
      "207  0.620140  0.438839  \n",
      "208  0.772046  0.609141  \n",
      "209  0.674214  0.702314  \n",
      "210  0.411720  0.495543  \n",
      "211  0.506353  0.451166  \n",
      "212  0.486811  0.500070  \n",
      "213  0.418737  0.620140  \n",
      "214  0.351982  0.772046  \n",
      "215  0.494250  0.674214  \n",
      "216  0.486630  0.411720  \n",
      "217  0.648777  0.506353  \n",
      "218  0.622795  0.486811  \n",
      "219  0.619398  0.418737  \n",
      "220  0.811682  0.351982  \n",
      "221  0.924142  0.494250  \n",
      "222  0.948689  0.486630  \n",
      "223  0.867438  0.648777  \n",
      "224  0.898540  0.622795  \n",
      "225  0.821247  0.619398  \n",
      "226  0.915608  0.811682  \n",
      "227  0.622795  0.924142  \n",
      "228  0.715177  0.948689  \n",
      "229  0.345344  0.867438  \n",
      "230  0.438270  0.898540  \n",
      "231  0.416006  0.821247  \n",
      "232  0.869748  0.915608  \n",
      "233  0.464252  0.622795  \n",
      "234  0.660914  0.715177  \n",
      "235  0.799166  0.345344  \n",
      "236  0.569926  0.438270  \n",
      "237  0.515266  0.416006  \n",
      "238  0.610468  0.869748  \n",
      "239  0.568145  0.464252  \n",
      "240  0.585815  0.660914  \n",
      "241  0.637398  0.799166  \n",
      "242  0.658185  0.569926  \n",
      "243  0.610279  0.515266  \n",
      "244  0.628295  0.610468  \n",
      "245  0.565333  0.568145  \n",
      "246  0.672235  0.585815  \n",
      "247  0.520939  0.637398  \n",
      "248  0.504457  0.658185  \n",
      "249  0.413196  0.610279  \n",
      "250  0.422340  0.628295  \n",
      "251  0.414565  0.565333  \n",
      "252  0.432391  0.672235  \n",
      "253  0.399393  0.520939  \n",
      "254  0.294519  0.504457  \n",
      "255  0.211347  0.413196  \n",
      "256  0.282761  0.422340  \n",
      "257  0.374739  0.414565  \n",
      "258  0.301981  0.432391  \n",
      "259  0.324483  0.399393  \n",
      "260  0.311018  0.294519  \n",
      "261  0.286942  0.211347  \n",
      "262  0.230988  0.282761  \n",
      "263  0.280106  0.374739  \n",
      "264  0.280807  0.301981  \n",
      "265  0.394083  0.324483  \n",
      "266  0.342310  0.311018  \n",
      "267  0.314844  0.286942  \n",
      "268  0.312536  0.230988  \n",
      "269  0.251280  0.280106  \n",
      "270  0.189184  0.280807  \n",
      "271  0.266831  0.394083  \n",
      "272  0.412289  0.342310  \n",
      "273  0.331665  0.314844  \n",
      "274  0.149630  0.312536  \n",
      "275  0.257159  0.251280  \n",
      "276  0.411585  0.189184  \n",
      "277  0.350085  0.266831  \n",
      "278  0.285606  0.412289  \n",
      "279  0.358484  0.331665  \n",
      "280  0.045515  0.149630  \n",
      "281  0.359568  0.257159  \n",
      "282  0.034895  0.411585  \n",
      "283  0.149992  0.350085  \n",
      "284  0.179405  0.285606  \n",
      "285  0.194725  0.358484  \n",
      "286  0.320121  0.045515  \n",
      "287  0.325242  0.359568  \n",
      "288  0.177508  0.034895  \n",
      "289  0.225109  0.149992  \n",
      "290  0.190594  0.179405  \n",
      "291  0.169395  0.194725  \n",
      "292  0.356913  0.320121  \n",
      "293  0.333965  0.325242  \n",
      "294  0.321639  0.177508  \n",
      "295  0.452548  0.225109  \n",
      "303  0.043239  0.458790  \n",
      "304  0.032652  0.416461  \n",
      "305  0.296226  0.404893  \n",
      "306  0.331500  0.283493  \n",
      "307  0.469001  0.246918  \n",
      "308  0.253935  0.055187  \n",
      "309  0.038498  0.043239  \n",
      "310  0.018206  0.032652  \n",
      "311  0.315803  0.296226  \n",
      "312  0.389342  0.331500  \n",
      "313  0.317593  0.469001  \n",
      "314  0.391668  0.253935  \n",
      "315  0.239712  0.038498  \n",
      "316  0.177904  0.018206  \n",
      "317  0.275934  0.315803  \n",
      "318  0.135976  0.389342  \n",
      "320  0.061970  0.239712  \n",
      "321  0.095581  0.177904  \n",
      "322  0.076237  0.275934  \n",
      "323  0.043998  0.135976  \n",
      "324  0.002968  0.041874  \n",
      "326  0.134496  0.061970  \n",
      "327  0.135555  0.095581  \n",
      "328  0.080789  0.076237  \n",
      "329  0.155699  0.043998  \n",
      "330  0.248155  0.002968  \n",
      "331  0.096529  0.068083  \n",
      "332  0.015930  0.134496  \n",
      "333  0.015238  0.135555  \n",
      "334  0.000000  0.080789  \n",
      "335  0.031291  0.155699  \n",
      "336  0.010290  0.248155  \n",
      "337  0.104305  0.096529  \n",
      "338  0.279158  0.015930  \n",
      "339  0.278630  0.015238  \n",
      "340  0.238195  0.000000  \n",
      "341  0.264366  0.031291  \n",
      "342  0.366890  0.010290  \n",
      "343  0.385359  0.104305  \n",
      "344  0.254314  0.279158  \n",
      "345  0.405280  0.278630  \n",
      "346  0.366584  0.238195  \n",
      "347  0.437322  0.264366  \n",
      "348  0.483447  0.366890  \n",
      "350  0.432805  0.405280  \n",
      "351  0.419496  0.366584  \n",
      "352  0.361654  0.437322  \n",
      "353  0.479975  0.483447  \n",
      "354  0.405272  0.382118  \n",
      "356  0.449410  0.432805  \n",
      "357  0.574815  0.419496  \n",
      "358  0.476200  0.361654  \n",
      "359  0.360953  0.479975  \n",
      "360  0.467665  0.405272  \n",
      "361  0.476958  0.378532  \n",
      "362  0.533662  0.449410  \n",
      "363  0.485822  0.574815  \n",
      "364  0.567609  0.476200  \n",
      "365  0.488716  0.360953  \n",
      "366  0.188590  0.467665  \n",
      "367  0.118528  0.476958  \n",
      "368  0.181680  0.533662  \n",
      "369  0.207983  0.485822  \n",
      "370  0.150768  0.567609  \n",
      "371  0.260762  0.488716  \n",
      "372  0.106069  0.188590  \n",
      "373  0.185663  0.118528  \n",
      "374  0.088944  0.181680  \n",
      "375  0.215701  0.207983  \n",
      "376  0.376825  0.150768  \n",
      "377  0.354258  0.260762  \n",
      "378  0.165635  0.106069  \n",
      "379  0.383463  0.185663  \n",
      "380  0.215437  0.088944  \n",
      "381  0.437150  0.215701  \n",
      "382  0.451735  0.376825  \n",
      "383  0.458373  0.354258  \n",
      "384  0.220648  0.165635  \n",
      "385  0.468045  0.383463  \n",
      "386  0.193628  0.215437  \n",
      "387  0.083510  0.437150  \n",
      "388  0.110753  0.451735  \n",
      "389  0.135027  0.458373  \n",
      "390  0.120713  0.220648  \n",
      "391  0.238005  0.468045  \n",
      "392  0.316518  0.193628  \n",
      "393  0.098154  0.083510  \n",
      "394  0.071876  0.110753  \n",
      "395  0.113977  0.135027  \n",
      "396  0.231928  0.120713  \n",
      "397  0.464062  0.238005  \n",
      "398  0.533852  0.316518  \n",
      "399  0.435756  0.098154  \n",
      "401  0.492699  0.533852  \n",
      "406  0.265174  0.492699  \n",
      "407  0.341569  0.389437  \n",
      "409  0.470510  0.421582  \n",
      "410  0.406600  0.309294  \n",
      "411  0.446615  0.333086  \n",
      "412  0.282003  0.265174  \n",
      "413  0.220450  0.341569  \n",
      "414  0.479992  0.586573  \n",
      "415  0.401100  0.470510  \n",
      "416  0.533118  0.406600  \n",
      "417  0.420254  0.446615  \n",
      "418  0.531007  0.282003  \n",
      "419  0.459305  0.220450  \n",
      "420  0.561350  0.479992  \n",
      "421  0.480751  0.401100  \n",
      "422  0.531766  0.533118  \n",
      "423  0.461283  0.420254  \n",
      "424  0.420064  0.531007  \n",
      "425  0.419387  0.459305  \n",
      "426  0.517569  0.561350  \n",
      "427  0.622416  0.480751  \n",
      "428  0.607624  0.531766  \n",
      "429  0.653139  0.461283  \n",
      "430  0.568557  0.420064  \n",
      "431  0.616628  0.419387  \n",
      "432  0.441494  0.517569  \n",
      "433  0.401669  0.622416  \n",
      "434  0.602658  0.607624  \n",
      "435  0.577660  0.653139  \n",
      "436  0.402996  0.568557  \n",
      "437  0.448816  0.616628  \n",
      "438  0.417030  0.441494  \n",
      "439  0.489285  0.401669  \n",
      "440  0.426133  0.602658  \n",
      "441  0.431006  0.577660  \n",
      "442  0.555471  0.402996  \n",
      "443  0.526456  0.448816  \n",
      "444  0.453962  0.417030  \n",
      "445  0.575574  0.489285  \n",
      "446  0.637019  0.426133  \n",
      "447  0.647103  0.431006  \n",
      "448  0.641760  0.555471  \n",
      "449  0.484544  0.526456  \n",
      "450  0.562801  0.453962  \n",
      "451  0.481699  0.575574  \n",
      "452  0.551489  0.637019  \n",
      "453  0.465637  0.647103  \n",
      "454  0.586383  0.641760  \n",
      "455  0.633795  0.484544  \n",
      "456  0.529556  0.562801  \n",
      "457  0.204438  0.481699  \n",
      "458  0.559264  0.551489  \n",
      "459  0.680448  0.465637  \n",
      "460  0.659966  0.586383  \n",
      "461  0.512042  0.633795  \n",
      "462  0.601786  0.529556  \n",
      "463  0.324294  0.204438  \n",
      "464  0.636260  0.559264  \n",
      "465  0.634834  0.680448  \n",
      "466  0.541248  0.659966  \n",
      "467  0.560212  0.512042  \n",
      "468  0.592683  0.601786  \n",
      "469  0.598521  0.324294  \n",
      "470  0.529111  0.636260  \n",
      "471  0.472365  0.634834  \n",
      "472  0.333965  0.541248  \n",
      "473  0.283520  0.560212  \n",
      "474  0.283182  0.592683  \n",
      "475  0.366395  0.598521  \n",
      "476  0.443356  0.529111  \n",
      "477  0.359370  0.472365  \n",
      "478  0.682344  0.333965  \n",
      "479  0.619002  0.283520  \n",
      "480  0.491354  0.283182  \n",
      "481  0.549023  0.366395  \n",
      "482  0.533283  0.443356  \n",
      "483  0.616537  0.359370  \n",
      "484  0.658185  0.682344  \n",
      "485  0.692775  0.619002  \n",
      "486  0.605158  0.491354  \n",
      "487  0.518672  0.549023  \n",
      "488  0.631709  0.533283  \n",
      "489  0.523628  0.616537  \n",
      "490  0.613462  0.658185  \n",
      "491  0.680637  0.692775  \n",
      "492  0.750427  0.605158  \n",
      "493  0.740310  0.518672  \n",
      "494  0.668690  0.631709  \n",
      "495  0.659776  0.523628  \n",
      "496  0.655019  0.613462  \n",
      "497  0.609141  0.680637  \n",
      "498  0.721601  0.750427  \n",
      "499  0.712407  0.740310  \n",
      "500  0.751185  0.668690  \n",
      "501  0.676465  0.659776  \n",
      "502  0.738529  0.655019  \n",
      "503  0.698464  0.609141  \n",
      "504  0.783235  0.721601  \n",
      "505  0.904446  0.712407  \n",
      "506  0.979708  0.751185  \n",
      "507  0.877679  0.676465  \n",
      "508  0.900403  0.738529  \n",
      "509  1.000000  0.698464  \n",
      "510  0.960743  0.783235  \n",
      "511  0.837078  0.904446  \n",
      "512  0.979898  0.979708  \n",
      "513  0.966622  0.877679  \n",
      "514  0.881801  0.900403  \n",
      "515  0.657798  1.000000  \n",
      "516  0.604161  0.960743  \n",
      "517  0.558385  0.837078  \n",
      "518  0.450358  0.979898  \n",
      "519  0.599411  0.966622  \n",
      "520  0.627908  0.881801  \n",
      "521  0.861559  0.657798  \n",
      "522  0.642708  0.604161  \n",
      "523  0.554490  0.558385  \n",
      "524  0.462166  0.450358  \n",
      "525  0.451546  0.599411  \n",
      "526  0.528764  0.627908  \n",
      "527  0.355775  0.861559  \n",
      "528  0.632657  0.642708  \n",
      "529  0.561416  0.554490  \n",
      "530  0.518474  0.462166  \n",
      "531  0.521714  0.451546  \n",
      "532  0.560823  0.528764  \n",
      "533  0.677413  0.355775  \n",
      "534  0.710980  0.632657  \n",
      "535  0.606140  0.561416  \n",
      "536  0.596814  0.518474  \n",
      "537  0.513180  0.521714  \n",
      "538  0.513329  0.560823  \n",
      "539  0.527593  0.677413  \n",
      "540  0.637588  0.710980  \n",
      "541  0.474542  0.606140  \n",
      "542  0.457994  0.596814  \n",
      "543  0.482458  0.513180  \n",
      "544  0.546772  0.513329  \n",
      "545  0.457425  0.527593  \n",
      "546  0.389911  0.637588  \n",
      "547  0.421903  0.474542  \n",
      "548  0.511853  0.457994  \n",
      "549  0.406410  0.482458  \n",
      "550  0.383908  0.546772  \n",
      "551  0.448891  0.457425  \n",
      "552  0.531955  0.389911  \n",
      "553  0.296836  0.421903  \n",
      "554  0.285606  0.511853  \n",
      "555  0.393135  0.406410  \n",
      "556  0.464054  0.383908  \n",
      "557  0.332448  0.448891  \n",
      "558  0.448891  0.531955  \n",
      "559  0.430215  0.296836  \n",
      "560  0.426702  0.285606  \n",
      "561  0.396548  0.393135  \n",
      "562  0.391997  0.464054  \n",
      "563  0.491957  0.332448  \n",
      "564  0.476768  0.448891  \n",
      "565  0.384411  0.430215  \n",
      "566  0.471574  0.426702  \n",
      "567  0.534041  0.396548  \n",
      "568  0.544472  0.391997  \n",
      "569  0.447233  0.491957  \n",
      "570  0.483785  0.476768  \n",
      "571  0.525507  0.384411  \n",
      "572  0.528368  0.471574  \n",
      "573  0.559264  0.534041  \n",
      "574  0.424616  0.544472  \n",
      "575  0.461283  0.447233  \n",
      "576  0.515266  0.483785  \n",
      "577  0.474113  0.525507  \n",
      "578  0.479885  0.528368  \n",
      "579  0.423668  0.559264  \n",
      "580  0.510525  0.424616  \n",
      "581  0.410623  0.461283  \n",
      "582  0.324863  0.515266  \n",
      "583  0.460080  0.474113  \n",
      "584  0.455149  0.479885  \n",
      "585  0.421771  0.423668  \n",
      "586  0.378532  0.510525  \n",
      "587  0.419331  0.410623  \n",
      "588  0.421202  0.324863  \n",
      "589  0.277072  0.460080  \n",
      "590  0.295253  0.455149  \n",
      "591  0.468424  0.421771  \n",
      "592  0.512991  0.378532  \n",
      "593  0.523025  0.419331  \n",
      "594  0.602693  0.421202  \n",
      "595  0.623554  0.277072  \n",
      "596  0.669663  0.295253  \n",
      "597  0.701119  0.468424  \n",
      "598  0.730324  0.512991  \n",
      "599  0.637415  0.523025  \n",
      "600  0.412479  0.602693  \n",
      "601  0.428409  0.623554  \n",
      "602  0.372431  0.669663  \n",
      "603  0.421392  0.701119  \n",
      "604  0.448511  0.730324  \n",
      "605  0.359378  0.637415  \n",
      "606  0.470189  0.412479  \n",
      "607  0.404476  0.428409  \n",
      "608  0.574729  0.372431  \n",
      "609  0.390480  0.421392  \n",
      "610  0.385739  0.448511  \n",
      "611  0.304950  0.359378  \n",
      "612  0.407738  0.470189  \n",
      "613  0.430305  0.404476  \n",
      "614  0.293670  0.574729  \n",
      "615  0.385739  0.390480  \n",
      "616  0.433340  0.385739  \n",
      "617  0.315240  0.304950  \n",
      "618  0.322587  0.407738  \n",
      "619  0.486061  0.430305  \n",
      "620  0.488197  0.293670  \n",
      "621  0.557747  0.385739  \n",
      "622  0.378153  0.433340  \n",
      "623  0.346705  0.315240  \n",
      "624  0.432985  0.322587  \n",
      "625  0.518111  0.486061  \n",
      "626  0.374409  0.488197  \n"
     ]
    }
   ],
   "source": [
    "# Remove rows with null values in the 'day_lag1' column in-place\n",
    "data_normalized.dropna(subset=['day_lag1'], inplace=True)\n",
    "\n",
    "# Remove rows with null values in the 'day_lag7' column in-place\n",
    "data_normalized.dropna(subset=['day_lag7'], inplace=True)\n",
    "\n",
    "# Display the modified data\n",
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d816d462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year             0\n",
       "Month            0\n",
       "Day              0\n",
       "Concentration    0\n",
       "DayOfWeek        0\n",
       "Weekend          0\n",
       "FittedValues     0\n",
       "day_lag1         0\n",
       "day_lag7         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "537f2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##if we want the excel file\n",
    "#data.to_excel(\"output.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "81ffa581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = data_normalized.drop(columns=['Concentration'])\n",
    "y = data_normalized['Concentration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "73d0be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "6a97b043",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15000\n",
      "13/13 [==============================] - 1s 11ms/step - loss: 717.4595 - mse: 717.4595 - val_loss: 299.8949 - val_mse: 299.8949\n",
      "Epoch 2/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 130.5160 - mse: 130.5160 - val_loss: 15.5767 - val_mse: 15.5767\n",
      "Epoch 3/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.9438 - mse: 3.9438 - val_loss: 5.8433 - val_mse: 5.8433\n",
      "Epoch 4/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 7.7959 - mse: 7.7959 - val_loss: 5.5170 - val_mse: 5.5170\n",
      "Epoch 5/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.4949 - mse: 2.4949 - val_loss: 0.1764 - val_mse: 0.1764\n",
      "Epoch 6/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1781 - mse: 0.1781 - val_loss: 0.3965 - val_mse: 0.3965\n",
      "Epoch 7/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2774 - mse: 0.2774 - val_loss: 0.1635 - val_mse: 0.1635\n",
      "Epoch 8/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0940 - val_loss: 0.0842 - val_mse: 0.0842\n",
      "Epoch 9/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Epoch 10/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0794 - mse: 0.0794 - val_loss: 0.0853 - val_mse: 0.0853\n",
      "Epoch 11/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0784 - mse: 0.0784 - val_loss: 0.0854 - val_mse: 0.0854\n",
      "Epoch 12/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0778 - mse: 0.0778 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 13/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0777 - mse: 0.0777 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 14/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0776 - mse: 0.0776 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 15/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0775 - mse: 0.0775 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Epoch 16/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 17/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0772 - mse: 0.0772 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 18/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0771 - mse: 0.0771 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 19/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0770 - mse: 0.0770 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 20/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 21/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 22/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0814 - val_mse: 0.0814\n",
      "Epoch 23/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 24/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 25/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0803 - val_mse: 0.0803\n",
      "Epoch 26/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0749 - mse: 0.0749 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 27/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0806 - val_mse: 0.0806\n",
      "Epoch 28/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0740 - mse: 0.0740 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 29/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0732 - mse: 0.0732 - val_loss: 0.0789 - val_mse: 0.0789\n",
      "Epoch 30/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0730 - mse: 0.0730 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 31/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0726 - mse: 0.0726 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 32/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0774 - val_mse: 0.0774\n",
      "Epoch 33/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0761 - val_mse: 0.0761\n",
      "Epoch 34/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 35/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711 - val_loss: 0.0761 - val_mse: 0.0761\n",
      "Epoch 36/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 37/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0768 - val_mse: 0.0768\n",
      "Epoch 38/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 39/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 40/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 41/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 42/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 43/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 44/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 45/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 46/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 47/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 48/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 49/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 50/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 51/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 52/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 53/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 54/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 55/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 56/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 57/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 58/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 59/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704 - val_loss: 0.0766 - val_mse: 0.0766\n",
      "Epoch 60/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 61/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 62/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 63/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 64/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0716 - mse: 0.0716 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 65/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 66/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0721 - mse: 0.0721 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 67/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0768 - val_mse: 0.0768\n",
      "Epoch 68/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0750 - val_mse: 0.0750\n",
      "Epoch 69/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 70/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 71/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697 - val_loss: 0.0761 - val_mse: 0.0761\n",
      "Epoch 72/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0761 - val_mse: 0.0761\n",
      "Epoch 73/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697 - val_loss: 0.0750 - val_mse: 0.0750\n",
      "Epoch 74/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 75/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 76/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 77/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 78/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 79/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0761 - val_mse: 0.0761\n",
      "Epoch 80/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 81/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 82/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 83/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 84/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0719 - mse: 0.0719 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 85/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 86/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 87/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 88/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 89/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 90/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 91/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 92/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0780 - val_mse: 0.0780\n",
      "Epoch 93/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0739 - val_mse: 0.0739\n",
      "Epoch 94/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 95/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0705 - mse: 0.0705 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 96/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 97/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 98/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 99/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0750 - val_mse: 0.0750\n",
      "Epoch 101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "Epoch 102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0742 - val_mse: 0.0742\n",
      "Epoch 103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0739 - val_mse: 0.0739\n",
      "Epoch 105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704 - val_loss: 0.0734 - val_mse: 0.0734\n",
      "Epoch 110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 0.0739 - val_mse: 0.0739\n",
      "Epoch 111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0710 - mse: 0.0710 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0733 - val_mse: 0.0733\n",
      "Epoch 117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0711 - mse: 0.0711 - val_loss: 0.0735 - val_mse: 0.0735\n",
      "Epoch 120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0763 - val_mse: 0.0763\n",
      "Epoch 122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0729 - val_mse: 0.0729\n",
      "Epoch 125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0734 - val_mse: 0.0734\n",
      "Epoch 130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "Epoch 132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0704 - mse: 0.0704 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0761 - val_mse: 0.0761\n",
      "Epoch 141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0793 - val_mse: 0.0793\n",
      "Epoch 147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0729 - mse: 0.0729 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0729 - val_mse: 0.0729\n",
      "Epoch 163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0739 - val_mse: 0.0739\n",
      "Epoch 165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0729 - val_mse: 0.0729\n",
      "Epoch 166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675 - val_loss: 0.0731 - val_mse: 0.0731\n",
      "Epoch 167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0768 - val_mse: 0.0768\n",
      "Epoch 168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0735 - val_mse: 0.0735\n",
      "Epoch 169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0768 - val_mse: 0.0768\n",
      "Epoch 175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0689 - mse: 0.0689 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0729 - val_mse: 0.0729\n",
      "Epoch 183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0853 - val_mse: 0.0853\n",
      "Epoch 184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0721 - val_mse: 0.0721\n",
      "Epoch 186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0731 - val_mse: 0.0731\n",
      "Epoch 189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0774 - val_mse: 0.0774\n",
      "Epoch 193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0839 - val_mse: 0.0839\n",
      "Epoch 194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0735 - val_mse: 0.0735\n",
      "Epoch 197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0763 - val_mse: 0.0763\n",
      "Epoch 199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0729 - val_mse: 0.0729\n",
      "Epoch 208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0741 - val_mse: 0.0741\n",
      "Epoch 212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0721 - val_mse: 0.0721\n",
      "Epoch 213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 0.0747 - val_mse: 0.0747\n",
      "Epoch 221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0734 - val_mse: 0.0734\n",
      "Epoch 222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "Epoch 225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0725 - mse: 0.0725 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0711 - val_mse: 0.0711\n",
      "Epoch 234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0711 - val_mse: 0.0711\n",
      "Epoch 235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 0.0710 - val_mse: 0.0710\n",
      "Epoch 236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 0.0714 - val_mse: 0.0714\n",
      "Epoch 237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0753 - val_mse: 0.0753\n",
      "Epoch 239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0711 - val_mse: 0.0711\n",
      "Epoch 240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0673 - mse: 0.0673 - val_loss: 0.0860 - val_mse: 0.0860\n",
      "Epoch 244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0915 - val_mse: 0.0915\n",
      "Epoch 245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0738 - mse: 0.0738 - val_loss: 0.0913 - val_mse: 0.0913\n",
      "Epoch 246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0729 - val_mse: 0.0729\n",
      "Epoch 248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0742 - val_mse: 0.0742\n",
      "Epoch 251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0717 - mse: 0.0717 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0705 - mse: 0.0705 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0731 - val_mse: 0.0731\n",
      "Epoch 263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0653 - mse: 0.0653 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 0.0702 - val_mse: 0.0702\n",
      "Epoch 267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0734 - val_mse: 0.0734\n",
      "Epoch 268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0780 - val_mse: 0.0780\n",
      "Epoch 269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0889 - val_mse: 0.0889\n",
      "Epoch 276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0733 - val_mse: 0.0733\n",
      "Epoch 280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0709 - val_mse: 0.0709\n",
      "Epoch 282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0777 - val_mse: 0.0777\n",
      "Epoch 283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0725 - mse: 0.0725 - val_loss: 0.0697 - val_mse: 0.0697\n",
      "Epoch 284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 0.0700 - val_mse: 0.0700\n",
      "Epoch 285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0695 - val_mse: 0.0695\n",
      "Epoch 290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.0811 - val_mse: 0.0811\n",
      "Epoch 291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0697 - mse: 0.0697 - val_loss: 0.0772 - val_mse: 0.0772\n",
      "Epoch 292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0860 - val_mse: 0.0860\n",
      "Epoch 295/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0706 - val_mse: 0.0706\n",
      "Epoch 298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0735 - mse: 0.0735 - val_loss: 0.0695 - val_mse: 0.0695\n",
      "Epoch 301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0709 - val_mse: 0.0709\n",
      "Epoch 302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.0693 - val_mse: 0.0693\n",
      "Epoch 304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0807 - val_mse: 0.0807\n",
      "Epoch 307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0709 - val_mse: 0.0709\n",
      "Epoch 308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0694 - val_mse: 0.0694\n",
      "Epoch 313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0648 - mse: 0.0648 - val_loss: 0.0729 - val_mse: 0.0729\n",
      "Epoch 317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.0866 - val_mse: 0.0866\n",
      "Epoch 318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 0.0691 - val_mse: 0.0691\n",
      "Epoch 319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0695 - val_mse: 0.0695\n",
      "Epoch 321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0778 - val_mse: 0.0778\n",
      "Epoch 322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0706 - val_mse: 0.0706\n",
      "Epoch 323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 324/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0639 - mse: 0.0639 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641 - val_loss: 0.0703 - val_mse: 0.0703\n",
      "Epoch 326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.1005 - val_mse: 0.1005\n",
      "Epoch 327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0785 - val_mse: 0.0785\n",
      "Epoch 331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 0.0714 - val_mse: 0.0714\n",
      "Epoch 333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.0705 - val_mse: 0.0705\n",
      "Epoch 334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0691 - val_mse: 0.0691\n",
      "Epoch 335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0624 - mse: 0.0624 - val_loss: 0.0678 - val_mse: 0.0678\n",
      "Epoch 339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0681 - val_mse: 0.0681\n",
      "Epoch 340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0655 - mse: 0.0655 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 0.0716 - val_mse: 0.0716\n",
      "Epoch 342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0768 - val_mse: 0.0768\n",
      "Epoch 344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.1225 - val_mse: 0.1225\n",
      "Epoch 346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0913 - val_mse: 0.0913\n",
      "Epoch 351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0734 - mse: 0.0734 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0671 - val_mse: 0.0671\n",
      "Epoch 356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.0673 - val_mse: 0.0673\n",
      "Epoch 358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0653 - mse: 0.0653 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.1127 - val_mse: 0.1127\n",
      "Epoch 360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.0696 - val_mse: 0.0696\n",
      "Epoch 361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.0705 - val_mse: 0.0705\n",
      "Epoch 362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "Epoch 363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0684 - val_mse: 0.0684\n",
      "Epoch 364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0616 - mse: 0.0616 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0660 - mse: 0.0660 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 0.0669 - val_mse: 0.0669\n",
      "Epoch 370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 373/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 374/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 375/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0636 - mse: 0.0636 - val_loss: 0.0742 - val_mse: 0.0742\n",
      "Epoch 376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0731 - val_mse: 0.0731\n",
      "Epoch 378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 0.0700 - val_mse: 0.0700\n",
      "Epoch 379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0614 - mse: 0.0614 - val_loss: 0.0666 - val_mse: 0.0666\n",
      "Epoch 380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0673 - val_mse: 0.0673\n",
      "Epoch 381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.0666 - val_mse: 0.0666\n",
      "Epoch 382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0699 - val_mse: 0.0699\n",
      "Epoch 383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0668 - val_mse: 0.0668\n",
      "Epoch 384/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0660 - val_mse: 0.0660\n",
      "Epoch 385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0627 - mse: 0.0627 - val_loss: 0.0673 - val_mse: 0.0673\n",
      "Epoch 386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0657 - val_mse: 0.0657\n",
      "Epoch 387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.0662 - val_mse: 0.0662\n",
      "Epoch 389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0660 - val_mse: 0.0660\n",
      "Epoch 390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0661 - val_mse: 0.0661\n",
      "Epoch 391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0710 - val_mse: 0.0710\n",
      "Epoch 392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0624 - mse: 0.0624 - val_loss: 0.0656 - val_mse: 0.0656\n",
      "Epoch 393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0648 - mse: 0.0648 - val_loss: 0.0659 - val_mse: 0.0659\n",
      "Epoch 395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0614 - mse: 0.0614 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0660 - val_mse: 0.0660\n",
      "Epoch 400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0654 - val_mse: 0.0654\n",
      "Epoch 401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 402/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0658 - val_mse: 0.0658\n",
      "Epoch 404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0750 - val_mse: 0.0750\n",
      "Epoch 407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0697 - val_mse: 0.0697\n",
      "Epoch 408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0748 - mse: 0.0748 - val_loss: 0.0695 - val_mse: 0.0695\n",
      "Epoch 412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.1338 - val_mse: 0.1338\n",
      "Epoch 414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599 - val_loss: 0.0974 - val_mse: 0.0974\n",
      "Epoch 420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - mse: 0.0699 - val_loss: 0.0677 - val_mse: 0.0677\n",
      "Epoch 421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0605 - mse: 0.0605 - val_loss: 0.0814 - val_mse: 0.0814\n",
      "Epoch 422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0614 - mse: 0.0614 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0656 - val_mse: 0.0656\n",
      "Epoch 426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0884 - val_mse: 0.0884\n",
      "Epoch 427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0670 - val_mse: 0.0670\n",
      "Epoch 428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618 - val_loss: 0.0659 - val_mse: 0.0659\n",
      "Epoch 429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 431/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 432/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0634 - val_mse: 0.0634\n",
      "Epoch 433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0977 - val_mse: 0.0977\n",
      "Epoch 434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0719 - mse: 0.0719 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0632 - val_mse: 0.0632\n",
      "Epoch 436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 437/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0640 - val_mse: 0.0640\n",
      "Epoch 438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0706 - val_mse: 0.0706\n",
      "Epoch 439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0630 - val_mse: 0.0630\n",
      "Epoch 440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0673 - val_mse: 0.0673\n",
      "Epoch 443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0640 - val_mse: 0.0640\n",
      "Epoch 444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.0812 - val_mse: 0.0812\n",
      "Epoch 445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0631 - mse: 0.0631 - val_loss: 0.0654 - val_mse: 0.0654\n",
      "Epoch 446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661 - val_loss: 0.1009 - val_mse: 0.1009\n",
      "Epoch 447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.0932 - val_mse: 0.0932\n",
      "Epoch 448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0630 - val_mse: 0.0630\n",
      "Epoch 449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0900 - val_mse: 0.0900\n",
      "Epoch 454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0636 - val_mse: 0.0636\n",
      "Epoch 455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 457/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0630 - val_mse: 0.0630\n",
      "Epoch 458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0630 - val_mse: 0.0630\n",
      "Epoch 460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0633 - val_mse: 0.0633\n",
      "Epoch 461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0970 - val_mse: 0.0970\n",
      "Epoch 462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0624 - mse: 0.0624 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Epoch 463/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0618 - val_mse: 0.0618\n",
      "Epoch 465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0631 - val_mse: 0.0631\n",
      "Epoch 467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0656 - val_mse: 0.0656\n",
      "Epoch 468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0650 - val_mse: 0.0650\n",
      "Epoch 469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0631 - val_mse: 0.0631\n",
      "Epoch 471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0995 - val_mse: 0.0995\n",
      "Epoch 472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 0.1461 - val_mse: 0.1461\n",
      "Epoch 473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0612 - val_mse: 0.0612\n",
      "Epoch 476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0700 - val_mse: 0.0700\n",
      "Epoch 477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0613 - val_mse: 0.0613\n",
      "Epoch 479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0741 - val_mse: 0.0741\n",
      "Epoch 480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0690 - mse: 0.0690 - val_loss: 0.1083 - val_mse: 0.1083\n",
      "Epoch 481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599 - val_loss: 0.0839 - val_mse: 0.0839\n",
      "Epoch 483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0706 - val_mse: 0.0706\n",
      "Epoch 485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0637 - val_mse: 0.0637\n",
      "Epoch 488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0647 - mse: 0.0647 - val_loss: 0.0963 - val_mse: 0.0963\n",
      "Epoch 489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0648 - mse: 0.0648 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.0678 - val_mse: 0.0678\n",
      "Epoch 492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0804 - mse: 0.0804 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0617 - val_mse: 0.0617\n",
      "Epoch 495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613 - val_loss: 0.0822 - val_mse: 0.0822\n",
      "Epoch 497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599 - val_loss: 0.0664 - val_mse: 0.0664\n",
      "Epoch 499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0623 - mse: 0.0623 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0711 - val_mse: 0.0711\n",
      "Epoch 503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0618 - val_mse: 0.0618\n",
      "Epoch 504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0738 - val_mse: 0.0738\n",
      "Epoch 506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0837 - val_mse: 0.0837\n",
      "Epoch 507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0778 - mse: 0.0778 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0810 - mse: 0.0810 - val_loss: 0.1122 - val_mse: 0.1122\n",
      "Epoch 509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0873 - mse: 0.0873 - val_loss: 0.0860 - val_mse: 0.0860\n",
      "Epoch 510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0753 - mse: 0.0753 - val_loss: 0.0961 - val_mse: 0.0961\n",
      "Epoch 511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0657 - val_mse: 0.0657\n",
      "Epoch 514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0681 - val_mse: 0.0681\n",
      "Epoch 515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 0.0637 - val_mse: 0.0637\n",
      "Epoch 517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0618 - mse: 0.0618 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0599 - val_mse: 0.0599\n",
      "Epoch 520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0636 - val_mse: 0.0636\n",
      "Epoch 523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0610 - mse: 0.0610 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0695 - val_mse: 0.0695\n",
      "Epoch 527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.1357 - val_mse: 0.1357\n",
      "Epoch 530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0731 - val_loss: 0.1094 - val_mse: 0.1094\n",
      "Epoch 531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0648 - mse: 0.0648 - val_loss: 0.0817 - val_mse: 0.0817\n",
      "Epoch 533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0583 - val_mse: 0.0583\n",
      "Epoch 534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0620 - val_mse: 0.0620\n",
      "Epoch 536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0654 - val_mse: 0.0654\n",
      "Epoch 541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 0.0700 - val_mse: 0.0700\n",
      "Epoch 543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0583 - val_mse: 0.0583\n",
      "Epoch 547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0585 - val_mse: 0.0585\n",
      "Epoch 549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0634 - val_mse: 0.0634\n",
      "Epoch 550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0576 - val_mse: 0.0576\n",
      "Epoch 551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0618 - val_mse: 0.0618\n",
      "Epoch 553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0576 - val_mse: 0.0576\n",
      "Epoch 556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0573 - val_mse: 0.0573\n",
      "Epoch 560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.1106 - val_mse: 0.1106\n",
      "Epoch 561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0576 - mse: 0.0576 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0878 - val_mse: 0.0878\n",
      "Epoch 563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "Epoch 564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0695 - val_mse: 0.0695\n",
      "Epoch 565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574 - val_loss: 0.0671 - val_mse: 0.0671\n",
      "Epoch 566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0566 - val_mse: 0.0566\n",
      "Epoch 568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0741 - val_mse: 0.0741\n",
      "Epoch 571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0565 - val_mse: 0.0565\n",
      "Epoch 572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0583 - val_mse: 0.0583\n",
      "Epoch 573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520 - val_loss: 0.0681 - val_mse: 0.0681\n",
      "Epoch 575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0575 - val_mse: 0.0575\n",
      "Epoch 576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0565 - val_mse: 0.0565\n",
      "Epoch 580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0663 - mse: 0.0663 - val_loss: 0.0641 - val_mse: 0.0641\n",
      "Epoch 589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0593 - val_mse: 0.0593\n",
      "Epoch 591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0769 - val_mse: 0.0769\n",
      "Epoch 593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0594 - val_mse: 0.0594\n",
      "Epoch 596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0650 - val_mse: 0.0650\n",
      "Epoch 597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.1036 - val_mse: 0.1036\n",
      "Epoch 599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0563 - val_mse: 0.0563\n",
      "Epoch 602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0903 - val_mse: 0.0903\n",
      "Epoch 603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0632 - mse: 0.0632 - val_loss: 0.0560 - val_mse: 0.0560\n",
      "Epoch 605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0668 - val_mse: 0.0668\n",
      "Epoch 606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0927 - val_mse: 0.0927\n",
      "Epoch 609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0873 - mse: 0.0873 - val_loss: 0.1086 - val_mse: 0.1086\n",
      "Epoch 612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0617 - mse: 0.0617 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0766 - val_mse: 0.0766\n",
      "Epoch 615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597 - val_loss: 0.0739 - val_mse: 0.0739\n",
      "Epoch 616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0754 - mse: 0.0754 - val_loss: 0.1253 - val_mse: 0.1253\n",
      "Epoch 617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0892 - mse: 0.0892 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0738 - mse: 0.0738 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0719 - mse: 0.0719 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0554 - val_mse: 0.0554\n",
      "Epoch 623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0619 - val_mse: 0.0619\n",
      "Epoch 626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579 - val_loss: 0.0541 - val_mse: 0.0541\n",
      "Epoch 628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0579 - mse: 0.0579 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0575 - val_mse: 0.0575\n",
      "Epoch 636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0586 - val_mse: 0.0586\n",
      "Epoch 640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0541 - val_mse: 0.0541\n",
      "Epoch 645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0560 - val_mse: 0.0560\n",
      "Epoch 646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0575 - val_mse: 0.0575\n",
      "Epoch 649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0821 - val_mse: 0.0821\n",
      "Epoch 650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0694 - val_mse: 0.0694\n",
      "Epoch 653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0888 - val_mse: 0.0888\n",
      "Epoch 654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0888 - val_mse: 0.0888\n",
      "Epoch 657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.1645 - val_mse: 0.1645\n",
      "Epoch 661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0540 - val_mse: 0.0540\n",
      "Epoch 664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0731 - val_mse: 0.0731\n",
      "Epoch 665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0566 - val_mse: 0.0566\n",
      "Epoch 667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0586 - val_mse: 0.0586\n",
      "Epoch 668/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0582 - val_mse: 0.0582\n",
      "Epoch 676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0528 - val_mse: 0.0528\n",
      "Epoch 677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0892 - val_mse: 0.0892\n",
      "Epoch 678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0530 - val_mse: 0.0530\n",
      "Epoch 681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0632 - val_mse: 0.0632\n",
      "Epoch 683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0844 - val_mse: 0.0844\n",
      "Epoch 684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0576 - val_mse: 0.0576\n",
      "Epoch 686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0843 - val_mse: 0.0843\n",
      "Epoch 689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0550 - val_mse: 0.0550\n",
      "Epoch 694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0614 - val_mse: 0.0614\n",
      "Epoch 697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.1052 - val_mse: 0.1052\n",
      "Epoch 698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0764 - mse: 0.0764 - val_loss: 0.1419 - val_mse: 0.1419\n",
      "Epoch 699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 0.0908 - val_mse: 0.0908\n",
      "Epoch 700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.1196 - val_mse: 0.1196\n",
      "Epoch 705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0666 - val_mse: 0.0666\n",
      "Epoch 708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0831 - val_mse: 0.0831\n",
      "Epoch 709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 717/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0942 - val_mse: 0.0942\n",
      "Epoch 722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0856 - mse: 0.0856 - val_loss: 0.0656 - val_mse: 0.0656\n",
      "Epoch 724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0731 - mse: 0.0731 - val_loss: 0.0867 - val_mse: 0.0867\n",
      "Epoch 728/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0555 - val_mse: 0.0555\n",
      "Epoch 731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0522 - val_mse: 0.0522\n",
      "Epoch 734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0632 - val_mse: 0.0632\n",
      "Epoch 737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0506 - val_mse: 0.0506\n",
      "Epoch 740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0637 - val_mse: 0.0637\n",
      "Epoch 741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0907 - val_mse: 0.0907\n",
      "Epoch 744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0522 - val_mse: 0.0522\n",
      "Epoch 748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0594 - val_mse: 0.0594\n",
      "Epoch 750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0650 - val_mse: 0.0650\n",
      "Epoch 759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.0576 - val_mse: 0.0576\n",
      "Epoch 765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0506 - val_mse: 0.0506\n",
      "Epoch 766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0701 - val_mse: 0.0701\n",
      "Epoch 769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587 - val_loss: 0.1034 - val_mse: 0.1034\n",
      "Epoch 770/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0803 - mse: 0.0803 - val_loss: 0.1135 - val_mse: 0.1135\n",
      "Epoch 771/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0549 - val_mse: 0.0549\n",
      "Epoch 772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0646 - mse: 0.0646 - val_loss: 0.0983 - val_mse: 0.0983\n",
      "Epoch 774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0538 - val_mse: 0.0538\n",
      "Epoch 777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0673 - val_mse: 0.0673\n",
      "Epoch 778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0636 - val_mse: 0.0636\n",
      "Epoch 780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.1131 - val_mse: 0.1131\n",
      "Epoch 784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1081 - mse: 0.1081 - val_loss: 0.0677 - val_mse: 0.0677\n",
      "Epoch 785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0649 - mse: 0.0649 - val_loss: 0.0506 - val_mse: 0.0506\n",
      "Epoch 786/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0577 - val_mse: 0.0577\n",
      "Epoch 793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 794/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0583 - val_mse: 0.0583\n",
      "Epoch 795/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0661 - mse: 0.0661 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0510 - val_mse: 0.0510\n",
      "Epoch 800/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0644 - val_mse: 0.0644\n",
      "Epoch 801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 803/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0541 - val_mse: 0.0541\n",
      "Epoch 804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0651 - val_mse: 0.0651\n",
      "Epoch 810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0646 - val_mse: 0.0646\n",
      "Epoch 812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0669 - val_mse: 0.0669\n",
      "Epoch 817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0528 - val_mse: 0.0528\n",
      "Epoch 822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0601 - mse: 0.0601 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 824/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 827/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0700 - val_mse: 0.0700\n",
      "Epoch 834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0609 - mse: 0.0609 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0882 - val_mse: 0.0882\n",
      "Epoch 837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0587 - val_mse: 0.0587\n",
      "Epoch 840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0612 - val_mse: 0.0612\n",
      "Epoch 841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0640 - val_mse: 0.0640\n",
      "Epoch 842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0651 - val_mse: 0.0651\n",
      "Epoch 844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0726 - val_mse: 0.0726\n",
      "Epoch 845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0641 - mse: 0.0641 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 849/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0921 - val_mse: 0.0921\n",
      "Epoch 850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0651 - val_mse: 0.0651\n",
      "Epoch 852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0627 - val_mse: 0.0627\n",
      "Epoch 856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0586 - val_mse: 0.0586\n",
      "Epoch 857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0684 - mse: 0.0684 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0636 - mse: 0.0636 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0972 - val_mse: 0.0972\n",
      "Epoch 870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.0833 - val_mse: 0.0833\n",
      "Epoch 871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0679 - val_mse: 0.0679\n",
      "Epoch 872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0528 - val_mse: 0.0528\n",
      "Epoch 874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0630 - val_mse: 0.0630\n",
      "Epoch 877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0587 - mse: 0.0587 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0540 - val_mse: 0.0540\n",
      "Epoch 879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0650 - val_mse: 0.0650\n",
      "Epoch 881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0881 - val_mse: 0.0881\n",
      "Epoch 891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0823 - val_mse: 0.0823\n",
      "Epoch 892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0577 - val_mse: 0.0577\n",
      "Epoch 898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0716 - val_mse: 0.0716\n",
      "Epoch 906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0723 - val_mse: 0.0723\n",
      "Epoch 907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0992 - val_mse: 0.0992\n",
      "Epoch 915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0591 - val_mse: 0.0591\n",
      "Epoch 919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0602 - val_mse: 0.0602\n",
      "Epoch 922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0541 - val_mse: 0.0541\n",
      "Epoch 924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0613 - mse: 0.0613 - val_loss: 0.1364 - val_mse: 0.1364\n",
      "Epoch 928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0599 - mse: 0.0599 - val_loss: 0.1086 - val_mse: 0.1086\n",
      "Epoch 931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0597 - mse: 0.0597 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0889 - val_mse: 0.0889\n",
      "Epoch 934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0866 - val_mse: 0.0866\n",
      "Epoch 937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0801 - val_mse: 0.0801\n",
      "Epoch 938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0554 - val_mse: 0.0554\n",
      "Epoch 941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0710 - val_mse: 0.0710\n",
      "Epoch 944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0580 - val_mse: 0.0580\n",
      "Epoch 949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0475 - val_mse: 0.0475\n",
      "Epoch 959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0939 - val_mse: 0.0939\n",
      "Epoch 962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0745 - mse: 0.0745 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0629 - val_mse: 0.0629\n",
      "Epoch 970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0802 - val_mse: 0.0802\n",
      "Epoch 974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0747 - val_mse: 0.0747\n",
      "Epoch 983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.1309 - val_mse: 0.1309\n",
      "Epoch 989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 1000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 1001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 1002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 1003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 1004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 1005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 1006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0559 - val_mse: 0.0559\n",
      "Epoch 1007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 1008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 1009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 1010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0598 - mse: 0.0598 - val_loss: 0.0580 - val_mse: 0.0580\n",
      "Epoch 1011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 1012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0620 - val_mse: 0.0620\n",
      "Epoch 1013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 1014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 1015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 1016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 1017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 1018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 1019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 1020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0674 - val_mse: 0.0674\n",
      "Epoch 1021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 1022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 1023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 1024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 1026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 1027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 1028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 1029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 1030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 1033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 1034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 1035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 1036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 1037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 1038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0627 - val_mse: 0.0627\n",
      "Epoch 1039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 1040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 1041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 1042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 1043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 1044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 1045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 1046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 1047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0633 - mse: 0.0633 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 1048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 1049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 1050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 1051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0530 - val_mse: 0.0530\n",
      "Epoch 1052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 1053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 1054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 1055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 1056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 1057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 1058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 1059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 1060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 1061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 1062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 1063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 1065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 1066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 1067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 1068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 1069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 1070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 1071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 1072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 1073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 1074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 1075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 1076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 1077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 1078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 1079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0856 - val_mse: 0.0856\n",
      "Epoch 1080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0632 - val_mse: 0.0632\n",
      "Epoch 1082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 1083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 1084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 1085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 1086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 1087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 1088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 1089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 1090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0554 - val_mse: 0.0554\n",
      "Epoch 1091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 1092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 1093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0713 - mse: 0.0713 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 1094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0812 - val_mse: 0.0812\n",
      "Epoch 1095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 1096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 1097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 1098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 1099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 1100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0907 - val_mse: 0.0907\n",
      "Epoch 1101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0636 - mse: 0.0636 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 1102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.1204 - val_mse: 0.1204\n",
      "Epoch 1103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 1104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0781 - val_mse: 0.0781\n",
      "Epoch 1105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 1106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.1239 - val_mse: 0.1239\n",
      "Epoch 1107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0727 - val_mse: 0.0727\n",
      "Epoch 1108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 1109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 1110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 1111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 1112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 1113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 1114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 1115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 1116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0661 - val_mse: 0.0661\n",
      "Epoch 1117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 1119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 1120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 1121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0547 - mse: 0.0547 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 1125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 1126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0630 - val_mse: 0.0630\n",
      "Epoch 1127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 1128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 1129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 1130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 1131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 1132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 1133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 1134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 1135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 1136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 1137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 1138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 1139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 1140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 1141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 1142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 1143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0866 - val_mse: 0.0866\n",
      "Epoch 1144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 1145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 1146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 1147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 1148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0585 - val_mse: 0.0585\n",
      "Epoch 1149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 1150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 1151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 1152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 1153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 1154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 1155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 1156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 1157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 1158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 1159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 1160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 1161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 1162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 1163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 1164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0641 - val_mse: 0.0641\n",
      "Epoch 1165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 1166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 1167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 1168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.1013 - val_mse: 0.1013\n",
      "Epoch 1169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 1170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0617 - val_mse: 0.0617\n",
      "Epoch 1171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 1172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 1173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 1175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 1176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0965 - val_mse: 0.0965\n",
      "Epoch 1178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0882 - val_mse: 0.0882\n",
      "Epoch 1179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0953 - val_mse: 0.0953\n",
      "Epoch 1180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 1181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0563 - val_mse: 0.0563\n",
      "Epoch 1182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 1183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 1184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0671 - val_mse: 0.0671\n",
      "Epoch 1185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0807 - val_mse: 0.0807\n",
      "Epoch 1186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 1187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 1189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 1190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 1191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 1193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 1194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0627 - val_mse: 0.0627\n",
      "Epoch 1195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 1196/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 1197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 1198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 1199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.1074 - val_mse: 0.1074\n",
      "Epoch 1200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0634 - val_mse: 0.0634\n",
      "Epoch 1202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 1204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 1205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 1206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 1207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 1208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 1209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0622 - val_mse: 0.0622\n",
      "Epoch 1211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 1212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 1213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 1214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 1215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 1216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 1217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0704 - val_mse: 0.0704\n",
      "Epoch 1218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 1219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 1220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 1221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 1222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 1223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 1224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0580 - val_mse: 0.0580\n",
      "Epoch 1225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0584 - val_mse: 0.0584\n",
      "Epoch 1226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 1227/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 1228/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0540 - val_mse: 0.0540\n",
      "Epoch 1229/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0496 - val_mse: 0.0496\n",
      "Epoch 1230/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 1231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0658 - val_mse: 0.0658\n",
      "Epoch 1232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 1233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 1234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.1045 - val_mse: 0.1045\n",
      "Epoch 1235/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 1236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 1237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 1238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 1239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 1240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 1241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 1242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 1243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 1244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 1245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.1129 - val_mse: 0.1129\n",
      "Epoch 1246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0653 - mse: 0.0653 - val_loss: 0.0676 - val_mse: 0.0676\n",
      "Epoch 1247/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 1248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 1249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 1250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 1251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 1252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 1253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 1254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 1255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 1256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 1257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 1258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 1259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 1260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 1261/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 1262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 1263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 1264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 1265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 1266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0697 - val_mse: 0.0697\n",
      "Epoch 1267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 1268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 1269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0522 - val_mse: 0.0522\n",
      "Epoch 1270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0631 - val_mse: 0.0631\n",
      "Epoch 1271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 1272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0612 - val_mse: 0.0612\n",
      "Epoch 1273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 1274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 1275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 1276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 1277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 1278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 1280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 1281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0496 - val_mse: 0.0496\n",
      "Epoch 1282/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 1283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 1284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 1285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 1286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 1287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 1288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0538 - val_mse: 0.0538\n",
      "Epoch 1289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.1100 - val_mse: 0.1100\n",
      "Epoch 1290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 0.1139 - val_mse: 0.1139\n",
      "Epoch 1291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 1292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 1293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 1294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 1296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 1298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 1299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 1300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 1302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 1303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 1304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0859 - val_mse: 0.0859\n",
      "Epoch 1305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0540 - mse: 0.0540 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 1307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.1142 - val_mse: 0.1142\n",
      "Epoch 1308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 1309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1310/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 1311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 1312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 1313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 1315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 1317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0510 - val_mse: 0.0510\n",
      "Epoch 1318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 1319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 1320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0510 - val_mse: 0.0510\n",
      "Epoch 1321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 1322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 1323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0698 - val_mse: 0.0698\n",
      "Epoch 1324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 1325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 1326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 1327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 1328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 1329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 1330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 1331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 1332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 1333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 1334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 1335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 1336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 1337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 1338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 1339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 1340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 1341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0661 - val_mse: 0.0661\n",
      "Epoch 1342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 1343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0577 - val_mse: 0.0577\n",
      "Epoch 1345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 1346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0620 - val_mse: 0.0620\n",
      "Epoch 1348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 1349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 1350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 1351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 1352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 1354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 1355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 1356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 1357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 1358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 1359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 1360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0566 - val_mse: 0.0566\n",
      "Epoch 1361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 1362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 1363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 1364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 1365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 1366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 1367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 1368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 1369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 1370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 1371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 1372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 1373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 1374/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 1375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 1376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 1377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 1378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 1379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 1380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0983 - val_mse: 0.0983\n",
      "Epoch 1381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0565 - val_mse: 0.0565\n",
      "Epoch 1382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 1383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0517 - mse: 0.0517 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 1384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 1385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 1386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 1387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 1388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 1389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 1390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 1392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 1393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0641 - val_mse: 0.0641\n",
      "Epoch 1394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 1395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 1396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 1397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 1398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 1399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 1401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 1402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 1403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 1404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 1405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 1406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 1407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 1408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 1411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 1413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 1414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 1415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0919 - val_mse: 0.0919\n",
      "Epoch 1419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 1420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0648 - val_mse: 0.0648\n",
      "Epoch 1421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 1422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 1423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 1424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 1425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 1426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 1427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 1428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 1430/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0699 - val_mse: 0.0699\n",
      "Epoch 1431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 1432/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 1433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 1434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 1435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 1436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 1437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 1439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 1441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 1442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 1443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 1444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 1445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0699 - val_mse: 0.0699\n",
      "Epoch 1446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 1447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 1448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.1008 - val_mse: 0.1008\n",
      "Epoch 1449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 1450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 1451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 1453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0613 - val_mse: 0.0613\n",
      "Epoch 1454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 1455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 1457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 1458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 1460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 1462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 1464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 1465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 1466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 1467/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 1468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 1469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 1470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 1471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 1472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 1473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0469 - val_mse: 0.0469\n",
      "Epoch 1474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 1475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 1476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 1477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 1478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 1480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 1481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0573 - val_mse: 0.0573\n",
      "Epoch 1482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 1483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 1484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 1485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0915 - val_mse: 0.0915\n",
      "Epoch 1486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0622 - val_mse: 0.0622\n",
      "Epoch 1487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 1488/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 1489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 1491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 1493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 1494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 1495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 1496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 1500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 1501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0617 - val_mse: 0.0617\n",
      "Epoch 1502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 1503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 1504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 1506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 1507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0503 - mse: 0.0503 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 1509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 1510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 1511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 1512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 1513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0709 - val_mse: 0.0709\n",
      "Epoch 1516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 1517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 1519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 1520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 1522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 1523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 1524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 1525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 1526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0918 - val_mse: 0.0918\n",
      "Epoch 1527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 1528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0663 - val_mse: 0.0663\n",
      "Epoch 1529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 1530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 1532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0593 - val_mse: 0.0593\n",
      "Epoch 1533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 1534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0475 - val_mse: 0.0475\n",
      "Epoch 1535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 1536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 1537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 1539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 1540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 1542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 1545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 1546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 1548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 1549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 1550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 1552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 1553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 1555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 1556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 1557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 1558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 1559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 1560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 1562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 1563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 1564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 1565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 1566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 1568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 1569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 1570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0688 - val_mse: 0.0688\n",
      "Epoch 1571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 1574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 1575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 1577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 1578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 1579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 1580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 1581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 1582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 1583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 1585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 1587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 1588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 1590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "Epoch 1591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 1592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 1593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 1594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 1595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 1596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 1597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0725 - val_mse: 0.0725\n",
      "Epoch 1598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0522 - val_mse: 0.0522\n",
      "Epoch 1599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 1601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 1602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 1603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 1604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 1605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 1606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 1607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 1608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 1609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 1610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 1611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 1612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 1613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0661 - val_mse: 0.0661\n",
      "Epoch 1614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 1615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 1616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 1618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 1619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 1620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 1621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 1622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 1624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0555 - val_mse: 0.0555\n",
      "Epoch 1625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 1626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 1627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0567 - mse: 0.0567 - val_loss: 0.0824 - val_mse: 0.0824\n",
      "Epoch 1628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 1629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 1630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 1632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 1633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 1634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 1635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 1636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 1638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 1639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 1640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 1641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 1642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 1643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 1644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 1645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 1647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 1648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 1649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0587 - val_mse: 0.0587\n",
      "Epoch 1650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 1651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 1652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 1653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 1654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0538 - val_mse: 0.0538\n",
      "Epoch 1655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 1656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0674 - val_mse: 0.0674\n",
      "Epoch 1657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 1658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 1659/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 1660/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 1661/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 1662/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 1663/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 1664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 1665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0773 - val_mse: 0.0773\n",
      "Epoch 1666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 1667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 1669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 1670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 1672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 1673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 1674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 1675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 1676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 1677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 1678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 1679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 1680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 1681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 1682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0475 - val_mse: 0.0475\n",
      "Epoch 1683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 1684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 1685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 1686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 1687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 1688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 1689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 1690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 1691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 1692/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0741 - val_mse: 0.0741\n",
      "Epoch 1693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 1694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 1695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 1696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 1697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 1698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 1699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 1701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 1702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 1703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 1704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 1705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 1706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 1707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 1708/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 1709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 1710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 1711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0543 - val_mse: 0.0543\n",
      "Epoch 1712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 1713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 1715/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 1716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 1717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 1718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 1719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0693 - val_mse: 0.0693\n",
      "Epoch 1720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 1721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 1723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 1724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 1725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 1726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 1728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 1729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 1730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 1731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 1732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 1733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 1734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 1735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 1736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 1737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 1738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0575 - val_mse: 0.0575\n",
      "Epoch 1739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 1740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 1741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 1742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 1743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 1744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 1745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 1746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 1747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 1749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 1750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 1751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 1752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 1753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 1754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 1755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 1756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 1757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 1758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 1759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 1760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 1761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 1762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 1763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 1764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 1765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 1766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 1767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 1768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 1769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 1770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 1771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 1772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 1773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 1774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 1775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 1776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 1778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 1781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0618 - val_mse: 0.0618\n",
      "Epoch 1782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 1783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 1784/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 1785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 1786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 1787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 1789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 1790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 1791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0630 - val_mse: 0.0630\n",
      "Epoch 1792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 1793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 1794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0620 - val_mse: 0.0620\n",
      "Epoch 1795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0626 - val_mse: 0.0626\n",
      "Epoch 1796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 1797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 1798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 1799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 1800/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 1801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 1802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 1803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 1804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 1805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 1806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 1807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0735 - val_mse: 0.0735\n",
      "Epoch 1808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 1809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 1810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 1811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0559 - val_mse: 0.0559\n",
      "Epoch 1812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 1813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 1814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 1816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 1817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 1818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 1819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 1820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 1821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 1822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0626 - val_mse: 0.0626\n",
      "Epoch 1823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 1824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 1825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 1826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 1827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 1828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 1829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 1830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 1831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 1832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 1833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 1834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 1835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 1836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 1837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 1838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 1839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - mse: 0.0675 - val_loss: 0.0575 - val_mse: 0.0575\n",
      "Epoch 1840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 1841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 1842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 1843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0710 - val_mse: 0.0710\n",
      "Epoch 1844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 1845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 1848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0939 - val_mse: 0.0939\n",
      "Epoch 1849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 1850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 1851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 1852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 1853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 1854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 1855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 1856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 1857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 1858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 1859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 1860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 1861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 1862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 1863/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 1865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 1866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 1867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 1869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 1870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 1871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 1872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 1873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 1874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 1875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 1876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 1877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 1878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 1879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0575 - val_mse: 0.0575\n",
      "Epoch 1880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 1881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 1882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 1883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 1884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 1885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 1887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 1888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 1889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 1890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0684 - val_mse: 0.0684\n",
      "Epoch 1891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 1892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0647 - val_mse: 0.0647\n",
      "Epoch 1893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 1894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 1895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 1896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 1897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 1898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 1899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 1900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0522 - val_mse: 0.0522\n",
      "Epoch 1901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 1903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 1904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 1905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 1906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0905 - val_mse: 0.0905\n",
      "Epoch 1907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 1908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 1909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 1910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 1911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 1912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0743 - val_mse: 0.0743\n",
      "Epoch 1913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 1914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 1915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 1916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 1917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 1918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 1919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 1920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 1921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 1922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 1923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0594 - val_mse: 0.0594\n",
      "Epoch 1924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 1925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0623 - val_mse: 0.0623\n",
      "Epoch 1926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 1927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 1928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 1929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 1930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 1931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0719 - val_mse: 0.0719\n",
      "Epoch 1932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 1933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 1934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 1935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 1936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 1937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 1938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 1939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 1940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 1941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 1942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 1943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 1944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 1945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 1946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 1947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 1948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 1950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 1951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 1952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 1953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 1954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 1955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0622 - val_mse: 0.0622\n",
      "Epoch 1956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.1041 - val_mse: 0.1041\n",
      "Epoch 1957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 1958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 1959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 1961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 1962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 1963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 1964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 1965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 1966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 1967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 1968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 1969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 1970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 1971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 1972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 1973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 1974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 1975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 1976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 1977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 1978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 1979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 1980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 1981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 1982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 1983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 1984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 1985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "Epoch 1986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 1987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 1988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 1989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 1990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 1991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 1992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 1993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 1994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 1995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 1996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 1997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 1998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 1999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 2000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 2001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 2002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 2003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 2004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 2005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 2006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 2008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 2009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 2011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 2012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 2013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 2017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0639 - val_mse: 0.0639\n",
      "Epoch 2018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 2019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 2020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 2021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 2022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 2023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 2024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 2025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 2026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 2028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 2029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0837 - val_mse: 0.0837\n",
      "Epoch 2030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 2031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 2032/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 2033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0804 - val_mse: 0.0804\n",
      "Epoch 2034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 2035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 2036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 2037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 2038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 2039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 2040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 2041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 2042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 2043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 2044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 2045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 2046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 2047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 2049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 2050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 2051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 2052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 2054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 2055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 2058/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 2059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 2060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 2061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 2062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 2063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 2064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 2065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 2066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 2068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 2069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 2070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 2071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 2073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 2075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 2076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0959 - val_mse: 0.0959\n",
      "Epoch 2077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 2078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 2079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 2080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 2081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 2082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0882 - val_mse: 0.0882\n",
      "Epoch 2084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 2085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 2086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 2087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 2088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 2089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 2090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 2091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 2092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 2093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 2094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0550 - val_mse: 0.0550\n",
      "Epoch 2095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 2096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 2097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 2099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 2100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0613 - val_mse: 0.0613\n",
      "Epoch 2101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 2102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 2103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 2104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 2106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 2107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 2109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 2111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 2112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 2115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 2116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 2117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 2118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 2119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 2121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 2124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 2125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 2126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 2127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 2133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 2136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 2137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 2138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0660 - val_mse: 0.0660\n",
      "Epoch 2140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 2141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 2142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 2143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0677 - val_mse: 0.0677\n",
      "Epoch 2144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 2145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 2146/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 2148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 2149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 2150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 2151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 2152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 2153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0716 - val_mse: 0.0716\n",
      "Epoch 2154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 2155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 2156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0544 - val_mse: 0.0544\n",
      "Epoch 2157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 2158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 2159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 2160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0560 - val_mse: 0.0560\n",
      "Epoch 2162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 2164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 2165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 2167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 2168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 2169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 2171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 2172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 2173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 2175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 2176/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2177/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0593 - val_mse: 0.0593\n",
      "Epoch 2178/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0591 - val_mse: 0.0591\n",
      "Epoch 2179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 2180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 2181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 2182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 2183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0844 - val_mse: 0.0844\n",
      "Epoch 2185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 2186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 2187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 2191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 2192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 2194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 2195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 2196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 2197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 2199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 2200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 2201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 2202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 2203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 2204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 2205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 2206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 2207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 2211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.1324 - val_mse: 0.1324\n",
      "Epoch 2212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 2213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 2214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 2215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 2216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 2218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 2220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 2221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 2222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0504 - val_mse: 0.0504\n",
      "Epoch 2223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 2227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 2231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 2234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 2241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 2243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 2244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 2245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 2247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 2248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 2249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0525 - val_mse: 0.0525\n",
      "Epoch 2250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 2251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 2252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 2253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 2255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 2256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 2258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 2261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 2262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 2263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 2265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0898 - val_mse: 0.0898\n",
      "Epoch 2266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 2269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 2270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 2272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 2275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 2277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 2278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 2279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0710 - val_mse: 0.0710\n",
      "Epoch 2280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 2281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 2282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 2284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 2285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 2286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 2290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0510 - val_mse: 0.0510\n",
      "Epoch 2291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 2292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 2293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 2294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 2296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 2297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 2298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0744 - val_mse: 0.0744\n",
      "Epoch 2299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 2300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 2303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 2304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 2305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 2306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 2309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 2311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 2312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 2313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 2314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 2315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 2318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 2320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 2323/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 2324/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 2327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0675 - val_mse: 0.0675\n",
      "Epoch 2328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 2329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 2331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 2332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 2333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 2334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 2335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 2336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 2337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 2338/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 2339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0787 - val_mse: 0.0787\n",
      "Epoch 2340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 2341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 2342/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 2343/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2344/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 2345/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 2346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0810 - val_mse: 0.0810\n",
      "Epoch 2347/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 2349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0568 - mse: 0.0568 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 2350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 2351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 2353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 2354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 2355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 2356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 2358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 2359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 2360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 2364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 2366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0634 - val_mse: 0.0634\n",
      "Epoch 2367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 2368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 2369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 2370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 2371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 2372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 2373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 2375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 2378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 2380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 2383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 2386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 2387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 2388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 2390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 2391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 2392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2393/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 2394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0629 - val_mse: 0.0629\n",
      "Epoch 2395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 2398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 2399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 2402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 2403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 2404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 2406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 2407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 2408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 2409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 2410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 2412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 2413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 2414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 2415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 2416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 2417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 2418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 2419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 2420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 2421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 2422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 2425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 2426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 2427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 2428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 2429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 2430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 2431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 2432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 2433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 2434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 2435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 2436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 2438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 2439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 2441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 2443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 2444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 2445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 2446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 2449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 2450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 2451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 2452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0541 - val_mse: 0.0541\n",
      "Epoch 2453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 2455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 2458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 2459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 2460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 2461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 2462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 2463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 2464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 2465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0622 - val_mse: 0.0622\n",
      "Epoch 2466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 2469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 2470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 2471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 2473/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 2474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 2475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2478/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 2480/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 2481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 2482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 2483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 2484/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 2486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 2487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 2488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 2489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 2490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 2491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 2493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 2494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 2497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 2498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 2501/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 2502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 2503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 2505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 2507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 2509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 2511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 2513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 2514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 2515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 2517/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 2518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 2519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 2520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 2522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 2524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 2525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 2526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 2528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0694 - val_mse: 0.0694\n",
      "Epoch 2530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 2531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 2532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 2533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 2539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 2540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 2541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 2543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 2544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 2546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 2547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 2548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2551/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 2558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 2559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 2560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 2562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 2564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 2566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 2567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 2568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 2569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 2570/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 2571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 2572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 2573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 2574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0606 - val_mse: 0.0606\n",
      "Epoch 2577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 2578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 2580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 2582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 2583/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0664 - val_mse: 0.0664\n",
      "Epoch 2584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0563 - val_mse: 0.0563\n",
      "Epoch 2585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0530 - val_mse: 0.0530\n",
      "Epoch 2586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 2587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 2588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 2590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 2592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 2594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 2595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 2596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 2597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 2598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 2599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 2600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 2601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0862 - val_mse: 0.0862\n",
      "Epoch 2602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 2603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 2606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 2608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 2609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 2610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 2611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 2612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 2615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 2617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 2618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 2619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 2622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 2623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 2624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 2626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 2627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 2629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 2630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 2632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 2635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 2637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 2638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 2640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 2641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 2642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 2643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 2644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 2646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 2648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 2650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 2651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 2652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 2653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 2654/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 2655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 2656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 2657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 2658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 2659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 2660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 2661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0434 - mse: 0.0434 - val_loss: 0.0786 - val_mse: 0.0786\n",
      "Epoch 2667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 2668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 2669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 2670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 2671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 2672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 2674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 2675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 2677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 2678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 2679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 2680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 2681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 2683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 2684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 2685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 2686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 2687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 2689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 2692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 2693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 2695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 2698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 2699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 2700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 2705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 2706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 2708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 2709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 2710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 2714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 2716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 2718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 2720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 2721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 2722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 2724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 2726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 2727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 2728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 2729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 2730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 2731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 2732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 2733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 2735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 2736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 2737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 2739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 2740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 2742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 2743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 2744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 2745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 2746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 2747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 2748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 2749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0623 - val_mse: 0.0623\n",
      "Epoch 2750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 2751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 2752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 2754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 2755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 2756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 2757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 2758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 2760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 2762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 2764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 2765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 2766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 2767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 2769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 2771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 2773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 2775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 2779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 2780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 2781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 2782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 2784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 2785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 2786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 2789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 2791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 2792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0665 - val_mse: 0.0665\n",
      "Epoch 2793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 2794/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 2795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 2796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 2799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2800/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 2801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 2802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 2803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 2804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 2810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 2811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 2812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 2813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 2814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 2815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 2816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 2817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 2818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 2820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 2821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2822/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 2823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 2824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 2826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2827/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2828/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 2829/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2830/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2831/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 2832/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2833/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 2834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 2835/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 2836/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 2837/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2838/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 2839/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 2840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 2841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 2845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 2846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 2850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 2851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 2852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 2853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 2854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 2857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 2860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 2861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 2864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 2865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0612 - val_mse: 0.0612\n",
      "Epoch 2866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 2867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 2868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 2869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 2870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 2871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 2872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 2873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0584 - val_mse: 0.0584\n",
      "Epoch 2874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 2875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 2876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 2877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 2879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 2880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 2882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 2883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 2884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 2885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 2886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 2887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 2890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 2892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 2894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0780 - val_mse: 0.0780\n",
      "Epoch 2895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 2896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 2897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 2898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 2899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 2900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 2901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 2903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 2904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 2905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 2907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 2909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 2910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 2911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 2912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 2913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 2914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 2915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 2916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 2917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 2918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 2919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 2920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 2923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 2925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 2926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 2927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 2929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 2930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 2931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 2932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 2934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 2935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 2936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 2937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 2939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 2940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 2941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 2942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 2943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 2944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 2945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 2946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 2947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 2948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 2949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 2950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 2951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 2952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 2953/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 2954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 2955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 2956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 2957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 2958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 2959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 2960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 2961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 2962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 2963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 2964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 2965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 2966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 2967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 2968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 2970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 2971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 2972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 2973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 2975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 2976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 2977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 2978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 2979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 2980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 2981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 2982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 2983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 2984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 2985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 2986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 2987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 2988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 2989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 2990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 2991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 2992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 2993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 2994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 2995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 2996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 2997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 2998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 2999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 3001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 3002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 3003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 3005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 3006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 3007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 3008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 3009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 3010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 3012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 3013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 3014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 3015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 3016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 3017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 3019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 3022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 3026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 3027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 3029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 3030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 3035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 3036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 3037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 3039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 3040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 3042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 3043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 3044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 3045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 3047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 3050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 3051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 3052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 3053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 3054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 3056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 3057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 3058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 3065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 3067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 3068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0671 - val_mse: 0.0671\n",
      "Epoch 3069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 3070/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 3071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3072/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 3073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 3075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 3076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 3077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 3078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 3079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 3080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 3081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 3086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 3087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 3088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 3089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 3090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 3091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 3092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 3093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 3094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 3096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 3097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 3098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 3100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 3101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 3102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 3106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 3107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 3108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 3109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 3111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 3112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 3113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 3114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 3116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 3117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 3119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 3121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 3122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 3123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 3125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 3126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 3127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 3129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0582 - val_mse: 0.0582\n",
      "Epoch 3130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 3132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 3133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 3134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 3138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0594 - val_mse: 0.0594\n",
      "Epoch 3140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 3142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 3146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 3148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 3149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 3152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 3155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 3156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 3157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 3160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 3162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 3164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 3165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 3166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 3171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 3172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 3176/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 3179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 3180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 3181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0542 - val_mse: 0.0542\n",
      "Epoch 3182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 3183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 3184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 3185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 3186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 3188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 3190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 3191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 3192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 3193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 3194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 3195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 3197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 3198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 3201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 3203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 3204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 3206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 3207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 3210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 3214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 3215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0911 - val_mse: 0.0911\n",
      "Epoch 3216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0585 - val_mse: 0.0585\n",
      "Epoch 3217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 3218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 3219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 3220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 3222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 3223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 3228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 3229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 3233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 3234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 3236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 3237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 3238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 3239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3240/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 3241/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3242/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 3245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 3248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 3249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 3251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 3252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 3256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 3258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 3261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 3262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 3263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 3264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 3265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 3266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 3267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 3269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 3270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3273/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 3275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 3276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3277/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 3278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 3279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 3280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 3284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 3286/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 3288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 3289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 3291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3292/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 3294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 3296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 3298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 3299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 3300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 3301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 3302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 3304/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 3307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 3308/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 3310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 3312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 3315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 3317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 3318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 3319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 3322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3324/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3325/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 3330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 3331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 3332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 3333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 3334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 3335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 3337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 3339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 3342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3345/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 3346/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 3347/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 3348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 3349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3350/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 3351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 3352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 3353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 3354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 3357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 3358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 3359/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 3360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 3361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 3364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 3366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 3367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 3369/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 3370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 3374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 3375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 3377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 3378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 3381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 3383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 3384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 3385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 3386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 3389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 3393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 3395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 3396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 3397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 3399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 3400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 3402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 3405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 3406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 3407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 3408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 3409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 3413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 3414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 3415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 3416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 3417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 3419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 3421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 3423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 3426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 3427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 3434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 3437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 3440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 3441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 3442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 3443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 3444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 3445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 3446/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 3447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 3449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 3454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 3455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 3457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 3460/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3461/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 3465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 3466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 3467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 3469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 3470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 3472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 3474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 3477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 3478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 3479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 3480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 3481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 3488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 3490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 3492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 3493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 3495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 3497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 3498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 3499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 3500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 3507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 3508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 3509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 3510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 3511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 3514/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 3515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 3518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 3522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 3525/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 3526/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 3528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 3529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3531/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3532/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 3533/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3534/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3535/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3536/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3537/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3538/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 3539/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 3540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 3544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 3545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 3546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 3548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 3549/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3550/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3551/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 3552/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3553/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 3554/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 3555/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3556/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 3557/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 3558/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3559/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3560/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3561/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3562/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "Epoch 3563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3564/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3565/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3566/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 3567/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 3568/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3569/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 3570/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 3571/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 3572/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3573/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 3574/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 3575/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 3576/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 3577/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3578/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 3579/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 3580/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3581/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 3582/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3583/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 3584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 3586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3588/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3591/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 3593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 3596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 3598/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 3599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 3600/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 3602/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3603/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 3604/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 3605/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 3606/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3607/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 3608/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3609/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3611/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 3613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 3615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0622 - val_mse: 0.0622\n",
      "Epoch 3620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 3621/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 3623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 3625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3626/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 3629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 3630/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3631/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3632/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 3633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3634/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 3635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 3636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3638/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 3639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3644/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3645/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3646/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3647/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3648/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3649/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 3650/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3651/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3652/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 3653/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 3654/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3655/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 3656/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 3657/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 3658/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3659/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3660/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 3661/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3663/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3664/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 3665/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 3666/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3667/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3668/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 3669/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3670/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 3671/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 3672/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3673/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 3674/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3675/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3676/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3677/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3678/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3679/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 3680/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 3681/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3682/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0562 - val_mse: 0.0562\n",
      "Epoch 3683/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3684/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3685/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3686/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3687/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 3688/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3689/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3690/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 3691/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3692/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 3693/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3694/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3695/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 3696/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 3697/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3698/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 3699/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3700/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3701/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3702/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 3703/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3704/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 3705/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 3706/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 3707/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 3708/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3709/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 3710/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 3711/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 3712/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3713/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 3714/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 3715/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 3716/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 3717/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 3718/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 3719/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3720/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3721/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3722/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3723/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3724/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3725/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 3726/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 3727/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3728/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3729/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3730/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 3731/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 3732/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 3733/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 3734/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 3735/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3736/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3737/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3738/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 3739/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3740/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 3741/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3743/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 3744/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3745/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3746/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 3747/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3748/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3749/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3750/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3751/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 3753/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3754/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3755/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 3756/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 3757/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 3758/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 3759/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 3760/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3761/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 3762/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3763/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3764/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3765/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 3766/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3767/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 3768/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 3769/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 3770/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3772/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3773/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 3774/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 3775/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 3776/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3777/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3778/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3779/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 3780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 3783/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 3784/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 3785/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 3786/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 3787/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 3791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3792/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3793/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3794/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 3795/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 3796/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3797/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3798/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 3799/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3800/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3801/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 3802/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 3803/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 3804/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 3805/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3806/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 3807/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3808/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 3809/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 3812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3813/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 3814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 3815/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3816/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 3818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3819/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 3821/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 3822/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 3823/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3824/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3825/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 3826/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3827/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 3828/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3829/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 3830/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 3832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 3833/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 3835/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 3836/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 3838/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 3839/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3840/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 3841/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0542 - val_mse: 0.0542\n",
      "Epoch 3842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 3843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 3844/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 3845/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3846/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3847/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3848/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 3849/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 3850/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3851/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 3852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 3853/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3854/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 3855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3856/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 3857/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 3858/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3859/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 3860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 3861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 3862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 3863/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 3864/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3865/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 3866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 3867/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 3868/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3869/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3870/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0804 - val_mse: 0.0804\n",
      "Epoch 3871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 3872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 3873/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 3874/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 3875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 3876/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 3877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3878/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3879/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 3880/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 3881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3882/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 3883/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 3884/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 3885/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 3886/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 3887/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 3888/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3890/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 3891/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 3892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 3893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 3894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 3895/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3896/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 3897/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 3898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 3899/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3900/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 3901/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 3902/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 3903/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 3904/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3905/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 3906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 3908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 3909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 3910/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3911/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 3912/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 3913/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 3914/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3915/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3916/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 3917/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 3918/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 3919/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 3920/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 3921/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 3922/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0528 - val_mse: 0.0528\n",
      "Epoch 3923/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 3924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 3925/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 3926/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 3927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 3929/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 3930/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 3931/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 3932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 3934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 3935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 3936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 3938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 3941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 3942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3944/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 3945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 3946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 3948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 3950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 3951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 3952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 3954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 3955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 3956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 3957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 3958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 3960/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0503 - val_mse: 0.0503\n",
      "Epoch 3961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 3962/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 3963/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 3964/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 3965/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 3966/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 3967/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 3968/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3969/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 3970/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 3971/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 3972/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 3973/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 3974/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 3975/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 3976/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3977/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 3978/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 3979/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3980/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3981/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3982/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 3983/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 3984/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 3985/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0633 - val_mse: 0.0633\n",
      "Epoch 3986/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 3987/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 3988/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 3989/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 3990/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 3991/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 3992/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 3993/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 3994/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 3995/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 3996/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 3997/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 3998/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 3999/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 4000/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 4001/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4002/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 4003/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4004/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 4005/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 4006/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4007/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4008/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 4009/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4010/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 4011/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4012/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 4013/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4014/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4015/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4016/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4017/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 4018/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4019/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 4020/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 4021/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 4022/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 4023/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 4024/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4025/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 4026/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 4027/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 4028/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 4029/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4030/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 4031/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4032/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4033/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 4034/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4035/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 4036/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4037/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4038/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0688 - val_mse: 0.0688\n",
      "Epoch 4039/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 4040/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4041/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4042/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4043/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4044/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4045/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 4046/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 4047/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4048/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4049/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 4050/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4051/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 4052/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 4053/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4054/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4056/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 4057/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 4058/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 4059/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4060/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 4061/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 4062/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 4063/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 4064/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 4065/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4066/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 4067/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4068/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4069/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4070/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 4071/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4072/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0530 - val_mse: 0.0530\n",
      "Epoch 4073/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4074/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 4075/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4076/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4077/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 4078/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 4079/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 4080/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 4081/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4082/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 4083/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4084/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4085/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 4086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 4087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 4088/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4089/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 4090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 4091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 4092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 4095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 4096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4097/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4098/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4100/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 4102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 4103/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4104/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 4105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 4106/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 4107/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4108/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 4109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 4111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 4112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 4114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 4117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 4118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 4119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 4121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0746 - val_mse: 0.0746\n",
      "Epoch 4122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 4126/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 4127/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4129/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 4130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 4131/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 4132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 4133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0994 - val_mse: 0.0994\n",
      "Epoch 4134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 4135/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 4137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 4139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4140/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 4143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 4144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 4149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 4150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 4151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 4152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 4154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 4157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 4162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 4163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 4165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 4166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 4167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 4168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 4169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 4170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 4171/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 4172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 4173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 4174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 4179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 4181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 4184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 4185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 4187/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 4188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 4189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 4190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 4191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 4192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 4194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 4197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 4199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 4200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 4203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 4206/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 4207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 4209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 4212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 4213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 4214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 4216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 4218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 4219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 4220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 4221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 4222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 4223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 4224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4231/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4232/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4233/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 4235/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4236/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 4238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 4240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 4241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.1899 - val_mse: 0.1899\n",
      "Epoch 4242/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0750 - mse: 0.0750 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 4243/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4244/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4245/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4248/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4249/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4250/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 4251/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 4252/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4253/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4254/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 4255/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 4256/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4257/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 4258/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4259/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 4260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4261/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 4262/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4263/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 4264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 4267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4269/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 4270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 4271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0522 - val_mse: 0.0522\n",
      "Epoch 4272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4274/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 4275/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 4277/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4278/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4279/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 4280/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4281/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 4282/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 4284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 4288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 4290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 4291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 4294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 4296/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 4298/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 4299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4300/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4301/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 4302/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 4303/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4304/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4305/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4306/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 4307/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4308/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4309/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 4310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 4311/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4312/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 4315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 4316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 4317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 4318/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 4319/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4320/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 4321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 4322/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4323/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4324/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4325/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4326/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 4327/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4328/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4329/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4330/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4331/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4332/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4333/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 4334/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 4335/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 4336/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 4337/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 4338/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 4339/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4340/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 4341/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4342/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 4344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4346/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4347/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4348/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 4351/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 4352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 4353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 4354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4356/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 4357/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4358/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4359/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 4360/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4361/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4362/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4363/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4364/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 4365/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4366/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4367/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4368/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4369/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4370/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0616 - val_mse: 0.0616\n",
      "Epoch 4371/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 4372/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4373/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4374/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 4375/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4376/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4377/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4378/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4379/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4381/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 4385/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4386/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4387/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4388/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4389/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 4390/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 4391/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 4392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 4394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 4395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 4396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4397/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 4401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4402/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 4403/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 4404/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4405/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4406/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4407/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4408/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4409/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4410/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 4411/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 4412/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4413/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4414/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 4415/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 4416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 4419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4420/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 4421/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 4422/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 4423/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 4424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4430/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4431/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 4432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 4433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 4434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 4437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4438/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 4441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 4442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 4444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4445/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4446/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4447/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 4448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 4449/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4450/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4451/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 4453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 4454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 4457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 4463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 4466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 4467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 4469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 4470/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 4471/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 4474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 4477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 4478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 4479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 4480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 4482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 4483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 4485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 4487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 4488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4489/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 4491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 4492/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4493/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 4496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 4497/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 4498/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4499/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 4500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4501/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 4502/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 4504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 4505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4508/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 4509/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 4510/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4511/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 4512/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4513/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 4522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 4523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 4526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4527/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4528/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4529/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 4530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4532/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4535/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 4537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 4539/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 4540/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 4541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 4542/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4543/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4544/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4545/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 4548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 4551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4554/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4555/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0762 - val_mse: 0.0762\n",
      "Epoch 4556/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 4557/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 4558/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 4559/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 4560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 4561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 4563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0573 - val_mse: 0.0573\n",
      "Epoch 4565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 4568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 4569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 4572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 4574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 4575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 4577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 4579/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 4584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 4585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 4586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 4590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 4592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 4595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0793 - val_mse: 0.0793\n",
      "Epoch 4596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0735 - val_mse: 0.0735\n",
      "Epoch 4597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 4599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 4600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 4601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 4602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 4603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 4604/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4605/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 4606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 4607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 4609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4612/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4613/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4614/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 4615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 4616/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 4618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 4620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 4621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4623/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4624/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4625/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 4627/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 4628/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 4629/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 4630/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 4631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4632/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 4633/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 4634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 4635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 4636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 4640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 4643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 4644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4645/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 4646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4648/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4649/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4650/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 4651/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 4652/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 4653/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 4654/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 4655/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4656/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4657/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4658/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 4659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 4660/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4661/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4662/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4663/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 4664/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4665/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4666/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4667/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4668/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4669/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4670/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4671/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4672/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 4673/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4674/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4675/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4676/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4677/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4678/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 4679/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 4680/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0894 - val_mse: 0.0894\n",
      "Epoch 4681/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 4682/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4683/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4684/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4685/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 4686/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 4687/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 4688/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 4689/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4690/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4691/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4692/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 4693/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 4694/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4695/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4696/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4697/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 4698/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4699/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4700/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 4701/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4702/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 4703/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4704/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4705/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4706/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 4707/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4708/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 4709/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4710/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4711/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4712/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4713/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 4714/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 4715/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 4716/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4717/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4718/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4719/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 4720/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 4721/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4722/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 4723/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 4726/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 4727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 4729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 4731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4732/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 4733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4736/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4737/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 4738/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 4740/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4741/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 4742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4743/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4744/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 4746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4747/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4748/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4749/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4750/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4751/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4752/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4753/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4754/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 4755/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 4756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 4757/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 4759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4760/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 4767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 4769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 4770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4771/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 4772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 4773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 4774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 4775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 4776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 4778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 4779/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 4780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 4781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 4782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 4783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 4785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 4787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 4789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 4790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 4792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 4793/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 4795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 4796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 4797/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 4800/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4801/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 4802/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 4803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 4811/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 4813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 4814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 4816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 4817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 4819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 4822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 4824/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 4827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 4829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 4833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 4834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 4839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 4840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 4841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4843/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4844/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 4846/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 4847/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 4848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 4849/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 4851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4852/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4853/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4854/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 4856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 4857/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 4858/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 4860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 4864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 4865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 4866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 4867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 4868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 4869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 4870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 4871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 4873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 4874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 4876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 4878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 4881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 4884/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 4887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 4889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 4892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 4894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 4904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 4906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 4909/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4910/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 4911/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4912/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4913/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 4914/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 4915/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 4916/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 4917/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4918/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4919/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 4920/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 4921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 4922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 4923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4925/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 4926/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 4927/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4928/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 4929/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4930/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4931/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 4932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 4933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 4934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 4935/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0646 - val_mse: 0.0646\n",
      "Epoch 4936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 4938/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 4939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 4940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 4941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 4942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 4944/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 4945/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 4947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0433 - val_mse: 0.0433\n",
      "Epoch 4948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 4949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 4950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4951/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4952/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4955/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 4956/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 4957/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 4958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 4959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 4961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 4963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 4964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 4965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 4969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 4970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4973/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 4974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 4976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 4977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 4978/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4979/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 4980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 4981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 4982/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 4983/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 4984/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 4985/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 4986/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4987/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 4988/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 4989/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 4990/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 4991/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 4992/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 4993/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 4994/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4995/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4996/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 4997/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 4998/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 4999/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 5000/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5001/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 5002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 5003/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5004/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 5005/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 5006/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5007/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 5008/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 5009/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5010/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5011/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 5012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 5013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 5014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5015/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5016/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 5017/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 5018/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5019/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 5020/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 5021/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5022/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5023/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5024/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5025/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 5026/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 5027/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5028/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 5029/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5030/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5031/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5032/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5033/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5034/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 5035/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 5036/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 5037/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5038/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 5039/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 5040/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 5041/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5042/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 5043/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5044/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 5045/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 5046/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 5047/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 5048/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 5049/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 5050/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5051/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5052/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5053/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5054/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5055/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5056/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5057/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 5058/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5059/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5060/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5061/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5062/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 5063/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 5064/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 5065/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0566 - val_mse: 0.0566\n",
      "Epoch 5066/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5067/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 5068/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5069/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5070/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5071/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5072/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 5073/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5074/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5075/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5076/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5077/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5078/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 5079/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5080/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5081/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 5082/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5083/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 5084/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0639 - val_mse: 0.0639\n",
      "Epoch 5085/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5086/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 5087/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5088/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5089/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5090/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5091/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5092/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 5093/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 5094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 5095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 5096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5097/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 5098/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 5099/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 5100/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5101/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5104/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 5105/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 5106/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 5107/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 5108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 5109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 5110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 5111/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5112/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5113/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5114/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 5116/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 5117/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5118/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5119/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 5120/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 5121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 5122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 5123/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 5124/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 5126/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 5127/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 5130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5132/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 5133/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 5135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5136/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 5139/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5140/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 5141/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0670 - val_mse: 0.0670\n",
      "Epoch 5142/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 5146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 5147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5148/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 5149/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 5151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5154/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 5155/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 5156/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5157/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 5158/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 5159/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 5160/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5161/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 5164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 5165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0631 - val_mse: 0.0631\n",
      "Epoch 5166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 5167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 5169/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 5170/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 5171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 5172/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 5173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 5174/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5175/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5176/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 5177/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 5178/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 5180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 5181/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5184/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 5185/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 5186/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5188/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 5190/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 5192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 5194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 5195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5196/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 5197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 5198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5199/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 5200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 5201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 5205/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 5207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 5209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 5210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 5214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 5215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 5216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 5219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 5220/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 5222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5225/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 5226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 5227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5228/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5229/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5230/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 5231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 5232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 5238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 5240/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 5243/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 5245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 5246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5247/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 5248/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 5249/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5251/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 5253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 5254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 5255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 5256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 5257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 5258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 5259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 5261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 5262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 5264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 5265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 5266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 5267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 5269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 5274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 5275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 5276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0560 - val_mse: 0.0560\n",
      "Epoch 5277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 5278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5279/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 5280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5281/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 5282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 5284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5286/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 5292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 5293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 5294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5295/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5296/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 5297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 5301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 5302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 5309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5310/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 5311/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 5312/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 5313/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 5314/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 5315/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 5316/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5317/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 5318/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 5319/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5320/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5321/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 5322/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5323/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 5324/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5325/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5326/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5327/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5328/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5329/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5330/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5331/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 5332/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 5333/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5334/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 5335/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 5336/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 5337/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5338/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 5339/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5340/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5341/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5342/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 5343/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5344/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5345/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 5346/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 5347/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 5348/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 5349/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5350/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 5351/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 5352/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 5353/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 5354/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 5355/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5356/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5357/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5358/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5359/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5360/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 5361/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 5362/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5363/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5364/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5365/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 5366/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 5367/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5368/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 5369/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5370/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 5371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 5376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 5377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0691 - val_mse: 0.0691\n",
      "Epoch 5378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 5379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 5381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 5382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 5383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5385/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 5387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 5388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 5390/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 5392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 5394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 5397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 5399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 5402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 5404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 5405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 5407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0634 - val_mse: 0.0634\n",
      "Epoch 5408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 5412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 5413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 5414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 5416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 5418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 5419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 5422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 5430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 5431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 5432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 5435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 5436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 5437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 5438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 5440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 5442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 5443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 5444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 5448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 5450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 5453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 5455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 5456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 5459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 5460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 5461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 5464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 5465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 5466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 5467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 5468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 5473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 5476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 5482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 5486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 5487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 5488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 5490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 5491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 5495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 5497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 5499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 5500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 5502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 5503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 5504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 5510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 5512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 5515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 5518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 5519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 5520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 5522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 5523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 5525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 5526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 5527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 5530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 5531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 5532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 5533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 5534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 5535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 5541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 5543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 5544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 5545/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5546/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 5549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 5550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 5551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 5553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 5554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 5556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 5560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 5561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 5562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 5563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 5567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 5568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 5577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 5580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 5582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 5584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 5588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 5589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 5590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 5591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 5592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 5596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 5598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 5604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 5606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 5610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 5611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 5612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 5613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 5616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 5620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 5621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 5624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 5628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 5630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 5631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 5637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 5643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 5644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 5647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 5648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 5649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 5651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 5658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 5659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 5661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 5669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 5671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 5675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 5681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 5682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 5683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5684/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 5685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 5686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 5687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 5688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 5690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 5692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 5697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 5698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 5699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 5701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 5702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 5704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 5706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 5707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 5708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 5712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 5714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 5716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 5717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5718/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 5721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 5722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5728/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 5729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 5730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 5732/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 5733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 5734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 5737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 5741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 5742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 5743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5744/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 5745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5746/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 5747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 5748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 5749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 5750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 5752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 5753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5755/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 5756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 5757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 5761/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 5763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 5766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 5769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 5771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 5773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 5779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 5780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 5781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 5782/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 5784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5785/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 5786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 5788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 5791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5792/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 5793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 5795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 5800/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 5804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 5808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 5809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 5811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 5813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 5814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 5821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 5825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 5827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 5828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0588 - val_mse: 0.0588\n",
      "Epoch 5829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 5831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 5832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 5833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 5834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 5835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 5837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 5840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 5843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 5844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 5845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 5846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 5848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 5853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 5856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 5859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 5860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 5861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 5862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 5865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 5867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 5869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 5872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 5873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 5874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 5875/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 5876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 5878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 5879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 5880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 5881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 5882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 5883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 5885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 5886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 5887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 5888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 5891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 5892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 5894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 5896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 5897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 5898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 5899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 5900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 5902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 5904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 5905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 5909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 5910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 5911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 5912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 5914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 5917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 5918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 5919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 5920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 5921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 5922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 5923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 5924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 5925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 5926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 5927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 5928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 5929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 5930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 5931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 5932/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 5933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 5934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 5935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0715 - val_mse: 0.0715\n",
      "Epoch 5936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 5937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 5938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 5940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 5941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 5942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 5943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 5944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 5945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 5946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 5948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 5949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 5950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 5951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 5953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 5954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 5955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 5956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 5957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 5959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 5961/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 5962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 5963/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 5964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 5965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 5966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 5967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 5968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 5970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 5971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 5973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 5974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 5975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 5976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 5977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 5978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 5979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 5980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 5981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 5983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 5984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 5985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 5986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 5987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 5988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 5989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 5990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 5991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 5992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 5993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 5994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 5995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 5996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 5997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 5998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 5999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 6000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 6001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 6003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 6004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 6008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 6009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 6013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 6014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 6015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 6016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 6019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 6020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 6022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 6023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 6024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 6025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 6030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 6032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 6033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 6034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 6036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 6042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 6043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 6045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 6050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 6051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 6052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 6054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 6057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 6058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 6059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 6061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 6063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 6065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 6066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 6067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 6070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 6077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 6079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 6081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 6082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 6083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 6085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 6087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 6088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 6090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 6091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 6092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 6093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 6095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 6097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 6098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 6099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 6102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 6103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 6104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 6109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 6122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 6123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6124/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0629 - val_mse: 0.0629\n",
      "Epoch 6126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "Epoch 6127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6129/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 6130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 6132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 6135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 6136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 6140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 6142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6143/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 6146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 6148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 6149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 6150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 6151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 6152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 6153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0424 - val_mse: 0.0424\n",
      "Epoch 6154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 6155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 6156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 6157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 6158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 6159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 6160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 6164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 6166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6170/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 6174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 6177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 6178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 6181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 6187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 6191/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 6192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 6193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 6194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 6195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 6196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 6198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 6201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6203/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 6205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 6206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 6208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 6210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 6213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 6214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 6216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 6219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 6221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 6225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6228/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 6231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 6232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 6234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0542 - val_mse: 0.0542\n",
      "Epoch 6235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 6237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 6240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 6241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 6242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 6243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 6245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 6246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 6247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 6250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 6251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 6252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 6253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 6254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 6258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 6259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 6261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 6262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 6266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 6267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 6272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 6274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 6275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 6277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 6280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 6283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0666 - val_mse: 0.0666\n",
      "Epoch 6285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 6286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 6287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 6288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 6292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 6293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 6296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 6299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 6302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 6309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 6310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 6312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 6314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 6315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 6316/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 6317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 6322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 6323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 6327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "Epoch 6329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 6330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 6331/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 6334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 6336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 6339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 6344/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 6345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 6347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 6348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 6350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 6351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 6360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 6362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 6363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 6365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 6366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 6369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 6370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 6372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 6374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 6375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 6378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 6379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 6381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 6387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 6388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 6389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 6390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 6391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 6392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 6396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 6398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 6399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 6400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 6402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 6403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 6404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 6405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 6407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 6408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 6409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 6412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 6414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 6417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 6418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 6419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 6424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 6427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 6429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 6430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 6431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 6432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 6433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 6434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 6435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 6437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 6438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 6439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 6440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 6442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 6443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 6444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 6446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 6447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 6451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 6452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 6453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 6455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 6456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 6457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 6460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 6462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 6468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 6470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 6477/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6478/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 6480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 6481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 6482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 6492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 6495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 6496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 6497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 6498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 6499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 6500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 6502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 6503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 6504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 6505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 6506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 6507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 6510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 6511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 6512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 6513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 6514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 6517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 6522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 6525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 6531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 6533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 6534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 6537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 6538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 6540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 6542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 6545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 6548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 6550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 6551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 6553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 6554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 6555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 6556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 6558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 6561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 6563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 6564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 6565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 6567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 6569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 6570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 6579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 6580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 6581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 6583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 6584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 6585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 6586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 6587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 6590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 6592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 6593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 6594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 6596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 6597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 6598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 6600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 6601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 6603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 6608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 6610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6616/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 6620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 6621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 6624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 6625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 6631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 6633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 6636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 6637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 6638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 6639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 6640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6646/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 6647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 6650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6651/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 6653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 6657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 6661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 6662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 6663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 6666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 6667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 6668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 6669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 6670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 6671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 6674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 6676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 6679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 6681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 6682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 6683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 6684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 6685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 6688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 6690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 6691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 6692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 6694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 6697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 6698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 6699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 6700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 6701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 6703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 6704/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 6707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 6708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 6709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 6713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 6714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 6716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 6717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 6719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 6720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 6721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 6725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 6726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 6727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 6728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 6729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 6733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 6735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 6736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 6737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 6739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 6740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 6741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6743/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 6746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 6750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 6751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 6756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 6763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 6764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 6765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 6766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 6769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 6770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 6772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 6775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0563 - val_mse: 0.0563\n",
      "Epoch 6776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 6777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 6778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 6785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 6786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 6787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 6791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 6800/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 6802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 6803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6806/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 6808/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6809/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 6810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 6811/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 6812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 6813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 6815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 6816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 6817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 6818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 6821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 6822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 6826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 6828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 6830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 6831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 6832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 6834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6835/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 6836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 6840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 6841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 6842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 6846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 6847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 6849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 6850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 6851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 6856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 6858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 6859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 6861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 6864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 6867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 6875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 6876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 6877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 6879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 6880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 6883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 6884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 6885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 6886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 6888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 6891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 6892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 6893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 6895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 6896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 6897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 6898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 6899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 6904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 6905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 6906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 6907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 6911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 6912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 6914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 6915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 6916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 6917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 6921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 6922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 6923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 6924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 6926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 6927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 6933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 6936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 6938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 6939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 6940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 6941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 6942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 6945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 6946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 6947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 6949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 6952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 6953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 6954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 6955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 6956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6957/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 6960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 6961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 6963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 6964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 6965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 6966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 6967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 6969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 6970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 6971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 6972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 6973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 6974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 6975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 6976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 6977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 6978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 6980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 6981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 6984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 6985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 6986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 6987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 6989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 6990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 6991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 6992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 6993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 6994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 6996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 6997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 6998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 6999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 7000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 7001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 7005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 7007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 7012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 7013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 7014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 7015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 7016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 7017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 7021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 7023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 7025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 7027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 7029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7032/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 7033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 7034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 7035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 7036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 7039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 7040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 7042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 7043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 7044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 7045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 7048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 7049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 7050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 7051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 7052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 7053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 7054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 7055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 7057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 7058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 7059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 7064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 7065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 7066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 7071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 7072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 7075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 7076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 7077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 7078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 7079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 7084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 7086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 7088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 7094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 7095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 7096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 7098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 7101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 7105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 7106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 7107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 7108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 7109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 7119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 7120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 7126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 7129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 7134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 7136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 7137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 7139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 7140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 7141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 7143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 7144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 7145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 7150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 7151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 7152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0545 - val_mse: 0.0545\n",
      "Epoch 7153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 7154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 7155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 7156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 7157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 7159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 7160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 7162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 7163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 7164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 7168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 7170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 7171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 7172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 7174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 7177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 7179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 7180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 7181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 7183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 7184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 7185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 7186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 7187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 7190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 7192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 7193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 7196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 7197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 7201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 7203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0573 - val_mse: 0.0573\n",
      "Epoch 7204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 7206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 7207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 7208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 7209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 7211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 7212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 7214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 7215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 7218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 7219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 7223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 7224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 7225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 7226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 7227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 7228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 7229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7232/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7233/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7234/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7235/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7236/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 7237/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7238/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7239/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 7241/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 7244/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 7249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 7257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 7261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 7262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 7265/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 7266/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 7268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7269/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 7274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 7275/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 7280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 7282/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7283/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 7284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0661 - val_mse: 0.0661\n",
      "Epoch 7285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 7286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 7291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 7296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 7299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 7300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 7301/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7302/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 7303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 7305/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 7307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 7312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 7314/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 7316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 7317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 7319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 7320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 7321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 7325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 7327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 7328/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 7329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 7335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 7341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 7342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 7344/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 7345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 7346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 7351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 7352/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7356/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 7357/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 7358/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7359/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7360/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 7361/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 7362/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 7363/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7364/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 7365/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7366/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7367/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 7368/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 7369/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0497 - val_mse: 0.0497\n",
      "Epoch 7371/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 7372/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 7373/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 7374/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 7376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7377/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7378/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7379/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 7380/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7381/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7382/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7383/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 7384/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7385/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7386/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7387/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7388/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7389/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 7390/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 7391/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 7392/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7393/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7394/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 7395/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7396/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 7397/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 7398/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 7399/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7400/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 7401/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 7402/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7403/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7404/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 7405/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "Epoch 7406/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 7407/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7408/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0768 - val_mse: 0.0768\n",
      "Epoch 7409/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7410/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7411/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 7412/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7413/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7414/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7415/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 7416/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 7417/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 7418/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0799 - val_mse: 0.0799\n",
      "Epoch 7419/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 7420/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7421/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 7422/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7423/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7424/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 7425/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 7426/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7427/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7428/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7429/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 7430/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 7431/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 7432/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7433/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7434/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 7435/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 7436/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 7437/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7438/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7439/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7440/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 7441/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7442/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 7443/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7444/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7445/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7446/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 7449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 7450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7451/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 7452/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0566 - val_mse: 0.0566\n",
      "Epoch 7453/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7454/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 7455/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 7456/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7457/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 7458/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7459/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 7460/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 7461/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7462/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7463/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 7464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 7465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 7466/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 7467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 7468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 7470/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 7471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 7472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7474/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 7475/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7476/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 7477/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 7478/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7479/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 7480/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7481/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7482/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 7483/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 7484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 7485/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 7486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 7487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 7496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 7500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 7501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 7504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 7506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 7507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 7510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 7511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 7512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 7513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 7515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0612 - val_mse: 0.0612\n",
      "Epoch 7517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 7518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 7519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 7521/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 7522/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 7523/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 7526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 7527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 7528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 7529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 7531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7540/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 7541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 7543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 7544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 7546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 7551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 7552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7553/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 7554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 7557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 7558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 7560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 7564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 7566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 7569/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 7570/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 7571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 7572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 7574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 7575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 7577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 7580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 7583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 7584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 7585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 7587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 7588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 7592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 7598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 7599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 7600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 7605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 7606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 7607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 7608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 7611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 7615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 7616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 7617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 7618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 7619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 7621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 7622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 7624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 7626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 7629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 7630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7631/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 7632/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7633/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7634/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 7636/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 7637/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7638/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 7639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7644/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7645/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 7646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 7648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 7649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 7650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 7654/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 7655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 7656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 7657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 7659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 7661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7664/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 7665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7666/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 7668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 7669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 7670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7671/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 7672/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 7674/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 7675/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7676/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7677/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7678/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 7680/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 7682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 7685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 7686/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7687/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 7689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 7692/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 7694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 7695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 7698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 7699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 7700/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 7701/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7702/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 7703/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7704/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7705/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7706/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7707/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7709/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 7710/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 7711/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7712/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7713/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7714/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 7715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7716/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7717/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 7718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 7719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 7720/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 7721/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 7722/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 7723/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 7724/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7725/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 7726/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7727/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7728/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7729/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7730/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7731/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 7732/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7733/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 7734/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7735/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 7736/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7737/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7738/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7739/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7740/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 7741/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 7742/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 7743/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 7744/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 7745/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7746/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 7747/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0896 - val_mse: 0.0896\n",
      "Epoch 7748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 7749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 7751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 7752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7753/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 7754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7755/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 7760/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 7761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 7762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7763/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7764/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7765/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 7766/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7767/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7768/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7771/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 7772/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 7773/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 7774/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 7775/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7776/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7777/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 7778/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 7780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 7781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 7783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 7785/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 7786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 7787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 7788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 7789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 7791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 7796/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 7797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 7799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 7800/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 7801/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 7802/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7803/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7804/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 7805/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 7806/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7807/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7808/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7809/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 7810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 7812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 7814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 7815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7817/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 7819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 7820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7822/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 7825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 7826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 7827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 7828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 7829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 7832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 7837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 7838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 7840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 7842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 7846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 7847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 7848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 7850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 7851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 7852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 7856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 7857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 7858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 7859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 7860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 7861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 7862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 7866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 7868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 7869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 7870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 7871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 7872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 7874/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 7875/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 7876/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 7877/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 7878/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 7879/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 7880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 7882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 7884/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 7885/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 7886/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7887/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 7889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7890/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 7892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 7894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 7896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7900/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 7902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 7903/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7904/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 7906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 7907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 7908/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 7909/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 7911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0636 - val_mse: 0.0636\n",
      "Epoch 7912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7913/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 7914/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 7915/15000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 7916/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 7917/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7918/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7919/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7920/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 7921/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7922/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7923/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 7924/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7925/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7926/15000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 7927/15000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7928/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 7929/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 7930/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7931/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 7932/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7934/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7935/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7936/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 7937/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 7938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 7939/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 7941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 7942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 7943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 7945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 7948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 7949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 7950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 7952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 7953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 7955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 7956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 7957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 7958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 7959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 7961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 7962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 7963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 7965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 7967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 7968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 7969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 7970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 7972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 7974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 7975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 7976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 7977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 7979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 7980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 7981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 7982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 7983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 7985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 7986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 7987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 7988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 7989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 7990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 7991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 7992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 7993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 7994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 7995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 7996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 7997/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 7998/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 7999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 8004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 8006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 8010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 8011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0908 - val_mse: 0.0908\n",
      "Epoch 8012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 8021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 8022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 8027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 8028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 8029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 8030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 8031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 8032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 8033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 8036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 8037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 8038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 8040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 8041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 8044/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 8045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 8048/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8049/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 8050/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8051/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8052/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8053/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8054/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 8055/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8056/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 8057/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 8058/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 8059/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 8060/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8062/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 8063/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 8064/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 8066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 8068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 8069/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8070/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8071/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8072/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 8073/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 8074/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8075/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 8076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 8077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 8078/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8079/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 8081/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 8082/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8083/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8084/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8085/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 8086/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 8087/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 8088/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 8090/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 8091/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 8092/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0529 - val_mse: 0.0529\n",
      "Epoch 8093/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8095/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 8096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 8101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 8102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 8103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 8104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 8105/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8106/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 8107/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 8108/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8109/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8110/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8111/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 8112/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8113/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8114/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 8115/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8116/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8117/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8118/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 8119/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 8120/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 8121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8122/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 8123/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8124/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 8125/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 8126/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 8128/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 8133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 8136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8146/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 8148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8149/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 8150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8151/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8152/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8153/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 8154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 8155/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8156/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8157/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 8158/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 8159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8161/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 8164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 8165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 8167/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 8169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 8175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0784 - val_mse: 0.0784\n",
      "Epoch 8184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 8185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 8186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 8187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 8188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 8194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 8197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 8203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 8207/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 8211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 8215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 8216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 8217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 8224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 8225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 8226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 8227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 8228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 8229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 8230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8231/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8232/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 8234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 8235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 8236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 8237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 8238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 8240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 8241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 8242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 8243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0580 - val_mse: 0.0580\n",
      "Epoch 8245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8246/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 8247/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 8248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 8252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 8254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 8255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8256/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 8257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 8258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 8259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 8260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 8261/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 8262/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 8263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 8265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 8266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 8267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 8268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 8269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 8270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 8274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 8278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8279/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 8280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 8283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 8284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 8286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 8289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8291/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 8297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 8300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 8301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 8302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 8304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 8307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 8311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 8312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 8314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 8316/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 8317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 8318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 8320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 8321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 8322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 8323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 8327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 8328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 8329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 8330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 8331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8333/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8334/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 8335/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8336/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8337/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8338/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8339/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8340/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8341/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 8342/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8343/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 8344/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 8346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 8347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 8350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 8351/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 8352/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8353/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 8354/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8355/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8356/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 8357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 8358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 8360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 8361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 8362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 8363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 8366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 8367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 8368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 8369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 8372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 8375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 8376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 8377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 8378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8380/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 8386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 8389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 8391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 8392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 8394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 8395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0684 - val_mse: 0.0684\n",
      "Epoch 8397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 8401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 8404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 8408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 8409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 8410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8411/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8412/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8413/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 8414/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 8415/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 8416/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 8417/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8418/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8419/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 8420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 8423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 8426/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 8427/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8428/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8429/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 8430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8431/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8432/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8434/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 8435/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 8436/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8437/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 8438/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 8439/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8440/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8441/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 8442/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 8443/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 8444/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 8445/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 8446/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8447/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 8448/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8449/15000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8450/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8451/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 8452/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8453/15000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8454/15000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8455/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8456/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8457/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8458/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8459/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 8460/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8461/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8462/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 8463/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 8464/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8465/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 8469/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8470/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 8471/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8472/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 8473/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8474/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 8475/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 8476/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8477/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8478/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8479/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 8480/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8481/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8482/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8483/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 8490/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 8492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 8494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 8496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 8497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 8498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 8500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 8501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 8506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 8508/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 8509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 8511/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 8513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 8515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 8516/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 8517/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 8518/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8519/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 8520/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 8521/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 8522/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8523/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 8525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 8527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 8528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 8531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 8532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 8533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 8534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 8535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 8536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 8539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 8540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 8544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 8545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 8547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 8548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 8551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 8553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 8554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 8555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 8557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 8567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 8570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 8573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 8583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 8584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 8585/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8586/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 8588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 8589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 8591/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 8592/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8593/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 8594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 8596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 8597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 8598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 8599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 8600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 8601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 8602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 8603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 8606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 8612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 8614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 8615/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 8617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 8619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 8627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 8631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 8633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 8634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 8635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 8636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 8637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 8638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 8639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 8640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 8642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 8644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 8646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 8647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 8648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 8650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 8651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 8653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 8658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 8667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 8668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 8669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 8670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 8676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8680/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 8681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0790 - val_mse: 0.0790\n",
      "Epoch 8682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 8683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 8686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 8687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 8689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 8690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 8693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 8694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 8699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0706 - val_mse: 0.0706\n",
      "Epoch 8704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0575 - val_mse: 0.0575\n",
      "Epoch 8705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 8707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 8708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 8709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 8710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 8711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 8712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 8715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 8716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 8717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 8718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 8724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 8728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 8729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 8733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 8734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 8736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0569 - val_mse: 0.0569\n",
      "Epoch 8738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 8739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 8741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 8742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 8743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 8744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 8745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 8747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 8748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 8749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 8750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 8751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 8752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8753/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 8754/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 8756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 8757/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 8758/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8759/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8760/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 8761/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 8762/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8763/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 8764/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 8767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 8768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 8772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 8773/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8774/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8775/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8776/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 8777/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 8778/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8779/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8781/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8782/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 8784/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 8785/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8786/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8787/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 8789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 8792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 8793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 8795/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8796/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 8797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8798/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8799/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8800/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8801/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 8802/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8803/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 8805/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8806/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 8807/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 8808/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8809/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 8811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 8812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 8814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 8815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8817/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 8818/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 8819/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8820/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 8821/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8822/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 8823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0504 - val_mse: 0.0504\n",
      "Epoch 8824/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 8825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 8827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8832/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 8835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8836/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8837/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 8841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 8845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 8846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 8848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 8849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 8850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 8851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 8853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 8854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 8855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 8857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 8858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 8860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 8862/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8863/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8864/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 8865/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 8866/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8867/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8868/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8869/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8870/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 8872/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 8877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 8878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 8879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 8880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 8882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 8885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 8886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 8887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 8889/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 8890/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8891/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 8892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 8895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8896/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 8897/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 8899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 8900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 8901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 8902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 8904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 8905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 8907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 8908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 8909/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 8911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 8912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 8913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 8917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 8918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 8919/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8920/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 8923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 8925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 8926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 8928/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8929/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8930/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8931/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 8934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 8936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 8937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 8938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8939/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 8940/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 8941/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 8943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 8944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 8947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 8948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 8949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 8950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 8951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 8952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 8955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 8956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 8957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 8959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 8961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 8963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 8967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 8968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 8970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 8972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 8974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 8975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 8976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 8979/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 8981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 8983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 8984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 8985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 8987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 8988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 8989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 8990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 8991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 8992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 8993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 8994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 8995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 8996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 8997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 8999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 9001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 9002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 9004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 9008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 9010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 9011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 9017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 9019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 9023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 9024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 9025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 9029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 9032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 9037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 9040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 9043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9045/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 9048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 9049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 9051/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 9054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 9055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 9061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 9062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 9063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 9065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 9066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 9067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 9068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 9069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 9071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9072/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9073/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9074/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 9075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 9076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 9077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 9078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 9080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 9082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 9087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 9088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 9097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 9098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 9104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 9106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 9107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9109/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 9110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 9111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9113/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9114/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9116/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9118/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 9120/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 9121/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9122/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 9123/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9124/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9125/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9126/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9127/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 9128/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9129/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9130/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 9131/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 9132/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 9133/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9134/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 9135/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 9136/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9137/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9138/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9139/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 9140/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 9141/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 9142/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 9143/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9144/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9145/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9146/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9147/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9148/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9149/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 9150/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 9151/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9152/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 9153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9154/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9155/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 9156/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 9157/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9159/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 9160/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9162/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 9163/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9164/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9165/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9166/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9167/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 9168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9169/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 9172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 9173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9176/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9177/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 9178/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9180/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9181/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 9182/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9183/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9184/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 9185/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 9186/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9187/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9188/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 9189/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9190/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9191/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 9192/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 9193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 9199/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 9205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 9206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 9207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 9209/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9210/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 9211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 9213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 9214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 9217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 9221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 9222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 9223/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9224/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9225/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9226/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9227/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 9228/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9229/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 9230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 9232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 9236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 9237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 9241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 9243/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9244/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9245/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 9247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 9248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 9249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 9250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 9251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 9253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 9256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 9257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 9263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 9264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 9265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0528 - val_mse: 0.0528\n",
      "Epoch 9266/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 9267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9268/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 9272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 9273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 9274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 9276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 9278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 9279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 9280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 9281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 9283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 9284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 9286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 9295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 9299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 9300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 9305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 9306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 9307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 9308/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 9309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 9310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 9315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 9321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 9329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 9333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 9337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 9340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 9342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 9343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 9344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 9350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 9358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 9365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 9366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 9367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 9371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 9372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 9373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 9374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 9377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 9382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 9383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 9390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 9396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 9398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 9402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 9405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 9408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 9409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 9411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9412/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9413/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9414/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 9416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 9418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 9422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 9427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9428/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 9433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 9434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 9444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 9445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 9447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 9448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 9449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 9450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 9451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 9456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 9457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 9460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 9461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 9462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 9463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 9464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 9466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 9467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 9468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 9473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 9474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 9479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 9480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 9481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 9483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 9484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 9485/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 9488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9490/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9491/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9492/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9493/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9494/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 9495/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9496/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 9497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 9499/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 9500/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 9501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9503/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 9504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9505/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9506/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 9507/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 9508/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 9509/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 9510/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 9511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 9512/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 9513/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 9514/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 9515/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9516/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 9517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 9518/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 9520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 9521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 9525/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9526/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9527/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9528/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9529/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9530/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 9531/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9533/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9534/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 9535/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 9536/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9537/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 9541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 9543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 9544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9547/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 9550/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 9551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9552/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9553/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 9554/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9555/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 9556/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9558/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9560/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9561/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 9562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 9564/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9565/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 9566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9569/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 9574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 9576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 9582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 9585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 9588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 9589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 9590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 9591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9594/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 9595/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9596/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9597/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 9598/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 9599/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9600/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9601/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 9606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 9607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 9608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 9610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9614/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 9615/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 9616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9619/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 9620/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9621/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 9622/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9625/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 9626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 9627/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 9628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 9631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 9633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 9635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 9636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 9637/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 9638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9639/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 9640/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9641/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 9642/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 9643/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 9644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 9645/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 9646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 9647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 9648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 9649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 9652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 9654/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 9655/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 9657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 9658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 9660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 9661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 9663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9664/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9666/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 9667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 9669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9670/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 9671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 9672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 9673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 9675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 9677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 9680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 9682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 9684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 9688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9690/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9691/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9692/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 9693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 9694/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9695/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 9696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 9697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9698/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9699/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 9700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9703/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9704/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9705/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 9706/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9707/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 9708/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 9709/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 9710/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 9711/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9712/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 9713/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9714/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9715/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 9716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9720/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9721/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9722/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 9723/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 9724/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9725/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 9726/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 9727/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 9728/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9729/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9730/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9731/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9732/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 9733/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9734/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 9735/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9736/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 9737/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9738/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 9739/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 9740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 9741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 9742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 9749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 9750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 9751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 9752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9754/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 9756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 9758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0530 - val_mse: 0.0530\n",
      "Epoch 9759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 9760/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9761/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9762/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 9763/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9764/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9765/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9766/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9767/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9768/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9769/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 9770/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9771/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 9772/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 9773/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 9774/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 9775/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 9776/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 9778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 9781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9783/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 9784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 9785/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 9786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 9790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 9794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 9796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 9798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 9799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9800/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 9802/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 9803/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9804/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 9805/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9806/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 9807/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 9809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 9812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 9813/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 9814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 9816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 9824/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 9825/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9826/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 9830/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9831/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 9832/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9833/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9834/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 9835/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9836/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9837/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9838/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 9839/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 9840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 9842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 9843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 9844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 9846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 9847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 9849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 9850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 9851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 9852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 9854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 9858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 9860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 9861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 9867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 9868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 9869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 9875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 9876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0511 - val_mse: 0.0511\n",
      "Epoch 9877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 9879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 9880/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 9881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 9883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 9884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 9885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 9886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 9887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 9888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 9890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 9893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 9895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 9900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 9901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 9904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 9905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 9908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 9909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9911/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 9914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 9915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 9917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 9918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 9919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 9921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 9922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 9923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 9926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 9931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 9933/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9934/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9935/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9936/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 9937/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 9938/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 9939/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 9940/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9941/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9942/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 9944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 9945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 9946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 9947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 9949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 9950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 9951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 9952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 9953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 9955/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 9956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 9957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 9960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 9961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 9962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 9963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 9965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 9967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 9968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 9969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 9970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 9971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 9973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 9974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 9977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 9978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 9979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 9980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 9984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 9985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 9986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 9987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 9989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 9990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 9991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 9992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 9993/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 9994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 9995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 9996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 9997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 9998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 9999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 10000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 10003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 10007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10013/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 10016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 10017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 10018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 10019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 10021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 10022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 10025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 10026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 10027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 10030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 10031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 10032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 10034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 10040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 10043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 10047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 10048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 10050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 10052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 10056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 10058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 10059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 10060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 10063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 10064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 10065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 10066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 10069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 10070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 10071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 10072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 10074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 10080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 10081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 10082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 10087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 10089/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 10090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10091/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10092/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 10096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 10099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10100/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 10103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 10104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0617 - val_mse: 0.0617\n",
      "Epoch 10105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 10108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 10110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 10115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 10116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 10117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 10118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 10119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 10121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 10124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 10127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 10128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 10130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 10135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 10136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 10137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 10138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 10144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 10145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 10148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 10150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 10151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 10152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 10156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 10161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 10162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 10164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 10165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 10168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10170/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 10171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 10173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 10176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 10180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 10181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 10184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 10188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 10189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 10191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 10193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 10198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 10199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 10204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 10206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 10207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 10208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 10209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 10210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 10212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 10213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 10214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 10217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 10231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 10233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 10234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 10236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 10239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 10240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 10241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 10242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 10244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 10248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 10249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 10250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 10251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 10253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 10259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0538 - val_mse: 0.0538\n",
      "Epoch 10260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 10261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 10262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 10263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 10268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 10271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 10279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 10280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 10283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 10289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 10290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 10291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 10292/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 10298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 10299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 10309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 10312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 10315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 10316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 10318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 10325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 10326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 10327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 10328/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 10329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 10330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 10333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 10338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 10339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 10342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 10343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 10349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 10350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 10352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 10353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 10355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 10356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 10358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 10366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0669 - val_mse: 0.0669\n",
      "Epoch 10367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 10368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 10369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 10370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 10371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 10372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 10378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 10380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 10381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 10383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 10384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 10387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 10388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 10389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 10390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 10391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 10396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 10400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 10404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 10405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 10406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 10407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 10408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 10415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 10422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 10425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 10426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 10427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 10428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 10433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 10434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 10435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0644 - val_mse: 0.0644\n",
      "Epoch 10443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 10446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 10447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 10450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 10454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 10455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 10456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 10459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 10464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0910 - val_mse: 0.0910\n",
      "Epoch 10465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 10466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 10467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 10470/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 10479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 10480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 10482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 10483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0718 - val_mse: 0.0718\n",
      "Epoch 10484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 10490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 10491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 10493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 10494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 10495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 10496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 10498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 10499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 10500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 10501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 10502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 10504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 10506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 10508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 10511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 10512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 10513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 10515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 10516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 10518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 10522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 10523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 10524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 10525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 10527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 10528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 10531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 10536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 10539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 10541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 10544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 10546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 10547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 10552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 10554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 10558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 10564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 10565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 10566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 10568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 10574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 10575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 10576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 10580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 10582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 10583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 10584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 10585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 10587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 10589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 10597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 10599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 10601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 10602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 10603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 10607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 10617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 10618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 10619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 10624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 10626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 10627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 10628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 10630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 10633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 10634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 10638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 10640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 10641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 10642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 10645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 10647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 10652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 10653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 10657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 10658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 10662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 10665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 10666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 10671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 10672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 10673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10675/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 10677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 10678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 10679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 10683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 10690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0542 - val_mse: 0.0542\n",
      "Epoch 10691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 10692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 10694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 10695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 10696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 10698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 10699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 10702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 10707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 10710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 10712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 10713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10717/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10718/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 10720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 10726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 10728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 10729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 10731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 10732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 10734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 10742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 10745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 10747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 10748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 10750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 10752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 10753/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 10754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 10757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 10758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 10759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 10760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 10763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10765/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 10766/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 10767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 10768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 10769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 10770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 10776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 10778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 10779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 10780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 10781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 10783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 10785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 10789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 10791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 10794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 10797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 10800/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 10803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 10806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 10807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 10808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 10809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 10813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 10814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 10815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 10816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 10817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 10818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 10819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 10821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 10823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 10824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 10825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 10826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 10827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 10832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 10833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 10839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 10840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 10842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 10843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 10844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 10847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 10848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 10850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 10851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 10854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 10855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 10856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 10858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 10860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 10868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 10873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 10878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 10879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 10881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 10883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 10884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 10885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 10886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 10892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 10893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 10896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 10898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 10899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 10900/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 10901/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 10903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 10905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 10908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 10909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 10910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 10911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 10915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 10916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 10917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 10920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 10922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 10924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 10928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 10929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 10930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 10931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 10932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 10934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 10940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 10942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 10944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 10945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 10951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 10953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 10955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 10956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 10957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 10958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 10960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 10961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 10964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 10966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 10967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 10968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 10971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 10972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 10974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 10975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 10977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 10979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10980/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 10981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 10982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 10983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 10984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 10985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 10986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 10987/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 10989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 10990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 10991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0523 - val_mse: 0.0523\n",
      "Epoch 10992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 10995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 10996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 10997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 10998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 11000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 11001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 11003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 11004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 11007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 11009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 11010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 11013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 11014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0587 - val_mse: 0.0587\n",
      "Epoch 11015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 11016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 11018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 11021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 11022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 11023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 11025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 11033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 11035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 11037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 11040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 11041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 11042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 11044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 11045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 11049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 11057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 11058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 11059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 11062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 11063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 11064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 11067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 11069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 11070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 11079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 11080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 11081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 11087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 11089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 11092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 11094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 11100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 11103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 11104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 11105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 11106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 11107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 11112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 11119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 11120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 11123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 11124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 11125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 11126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 11127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 11128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 11129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 11132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 11136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 11137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 11138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 11141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 11142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 11143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 11145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 11147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 11148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 11150/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 11151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11152/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 11157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 11161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 11162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 11163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 11164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 11166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 11168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 11169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 11172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 11173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11174/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 11176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 11177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 11183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 11185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 11186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 11188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 11189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 11192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 11193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 11194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 11199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 11200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 11201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 11202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0572 - val_mse: 0.0572\n",
      "Epoch 11203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 11204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 11205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 11211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 11212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 11213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 11214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 11215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 11216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 11218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 11219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 11220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 11221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 11223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 11224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 11225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 11226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 11227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 11228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 11229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 11231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 11232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 11233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 11234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 11236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 11237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 11240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0467 - val_mse: 0.0467\n",
      "Epoch 11241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 11242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 11243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 11245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11247/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 11249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 11254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 11255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 11256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 11257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11258/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 11259/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 11260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 11261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 11262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 11263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11264/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 11267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 11269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 11276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 11280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 11281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 11285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 11288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 11289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 11290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 11292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 11293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 11297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 11298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 11299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 11300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 11302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 11307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 11308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 11309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 11312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 11313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 11317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 11320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 11322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 11327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 11329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 11331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11333/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 11334/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 11336/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11337/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11338/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 11342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 11344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 11346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 11348/15000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 11349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 11350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 11351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 11353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 11355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 11356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 11362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 11364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 11366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 11369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 11370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 11371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 11372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 11375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 11376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 11378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 11379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 11381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 11383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 11384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 11385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 11389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 11390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 11393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 11395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 11396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 11397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11399/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 11409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 11410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 11411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 11412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 11413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 11416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 11418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 11421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 11423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 11427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 11432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 11434/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 11436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 11437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 11438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11439/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 11441/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 11442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 11444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11445/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11446/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 11449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 11450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 11451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 11452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 11454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 11455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 11457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11461/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 11462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 11465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 11466/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 11467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 11469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 11471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 11472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11473/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11474/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 11477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 11478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 11480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 11482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 11487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 11490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 11491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 11494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11501/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 11502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 11506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 11507/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11508/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 11509/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 11511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11514/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 11515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 11517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 11520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 11522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11523/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 11524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 11526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 11527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 11528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 11529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 11530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 11531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 11532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 11533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 11537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11542/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 11543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11544/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 11545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11549/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 11551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 11552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 11553/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 11554/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 11555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 11561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 11562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 11563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 11565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 11567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 11568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 11569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 11573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 11574/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 11576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 11578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 11580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 11582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 11583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 11585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 11586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 11587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 11588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 11589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 11590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 11592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 11593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 11595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 11596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 11597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11601/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 11607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 11610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 11614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 11616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 11619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 11622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 11625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 11626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 11627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11629/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 11630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 11631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 11632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 11636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 11639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 11641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 11642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 11643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 11645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 11648/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11649/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 11650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 11651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 11652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 11653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 11654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 11656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 11658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 11659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 11660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 11663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 11670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 11673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 11675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 11676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 11682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11683/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 11686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 11690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 11691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 11692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 11696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 11697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 11698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 11699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 11701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 11703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 11705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 11708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 11709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 11710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 11712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 11713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11716/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11719/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 11721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 11723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 11724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 11732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 11733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 11736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 11737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 11738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 11739/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 11741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 11742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11743/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 11745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11747/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11748/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 11749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 11750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11755/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 11757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 11758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 11760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 11763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 11764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 11765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11767/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 11769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 11770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 11771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 11772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 11774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 11775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 11776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 11779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 11780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 11782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 11786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 11787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 11788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 11789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 11791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11796/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11799/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 11800/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 11804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 11805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 11806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11807/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 11808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 11809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 11810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11812/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 11813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 11814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 11819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 11827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 11828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 11830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 11831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 11836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 11841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 11842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 11844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 11850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 11854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 11855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 11856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 11857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 11858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.1235 - val_mse: 0.1235\n",
      "Epoch 11859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 11860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 11861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 11862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 11870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 11871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 11873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 11875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 11877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 11878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 11881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11883/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 11884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 11885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 11886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 11888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 11890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 11891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 11894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 11900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 11901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 11903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 11904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 11907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 11908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 11909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 11910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 11911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 11912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 11915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 11918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 11919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 11921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 11922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 11925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 11926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 11927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 11928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 11929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 11933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 11935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 11938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 11941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 11942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 11943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 11944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 11946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 11947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 11948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 11949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 11951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 11954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 11958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 11959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 11961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 11962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 11963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 11964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 11965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 11966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 11968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 11969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 11971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 11972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 11973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 11976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 11977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 11980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 11981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 11982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 11983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 11984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 11985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 11986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 11988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 11989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 11990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 11991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 11992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 11993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 11994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 11995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 11998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 11999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12000/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 12004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 12005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 12006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 12008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 12009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 12015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 12016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12020/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 12021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 12022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 12025/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 12027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 12028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12031/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 12035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 12036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 12037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 12038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 12040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 12042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 12047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 12049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 12052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 12055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 12056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 12059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 12060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 12061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 12062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12063/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12064/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 12075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 12079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 12080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 12085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 12088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 12094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 12096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 12097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 12098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 12099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 12100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 12104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 12105/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 12106/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12107/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 12108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12109/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 12110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 12116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 12117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 12118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 12124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 12125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 12126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 12127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 12128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 12129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 12130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 12131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 12132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 12133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 12135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12136/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12137/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 12138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 12147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 12148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 12149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 12150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 12151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 12152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 12153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 12154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12155/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 12161/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 12162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12163/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12165/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 12166/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 12170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12171/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 12172/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 12174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 12177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 12178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 12179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 12180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 12181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 12183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 12184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 12188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 12190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12194/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12195/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 12198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12200/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 12203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 12206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 12208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0781 - val_mse: 0.0781\n",
      "Epoch 12210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 12213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 12215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 12217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 12219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 12220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 12222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 12223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 12227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 12230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12241/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 12242/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12243/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12244/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 12245/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12246/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12247/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 12248/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12249/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 12250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 12252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 12253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 12255/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12259/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 12261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 12262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 12264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12265/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 12266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 12268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 12269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 12270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 12277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 12278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 12279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 12280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 12281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 12282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 12283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 12284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 12286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12287/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 12288/15000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 12289/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12290/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 12297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 12298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 12303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 12304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0324 - val_mse: 0.0324\n",
      "Epoch 12308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0373 - val_mse: 0.0373\n",
      "Epoch 12309/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 12310/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 12311/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 12313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12316/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 12317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 12318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 12319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 12321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 12327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 12328/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12329/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 12330/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12331/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12332/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12333/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12334/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12335/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12336/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12337/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12338/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 12339/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 12340/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12341/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12342/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 12343/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12344/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12345/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12346/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12347/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 12348/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12349/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12350/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12351/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 12352/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12353/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 12354/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 12355/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12356/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 12357/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12358/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 12359/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 12360/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 12361/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 12362/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 12363/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12364/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 12365/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12366/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12367/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 12368/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 12369/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12370/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12371/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 12372/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 12373/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 12374/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12375/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 12376/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12377/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 12378/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12379/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12380/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12381/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12382/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12383/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 12384/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 12385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 12386/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 12387/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 12389/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 12391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12392/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 12393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 12394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12395/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12396/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 12397/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12398/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12399/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 12400/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12401/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12402/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12403/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12404/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12405/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12406/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 12407/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 12408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12409/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12410/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 12411/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12413/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 12416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 12417/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 12419/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 12422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 12423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 12424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 12425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 12427/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12429/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12430/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12431/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12432/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 12433/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 12434/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12435/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12436/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12437/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12439/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 12440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12441/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 12442/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12443/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 12444/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12445/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 12446/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 12447/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 12449/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 12450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 12452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12453/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 12454/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 12455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 12456/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 12457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12459/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 12461/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 12462/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 12463/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12464/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12466/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12467/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 12468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 12469/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12470/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12471/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 12472/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12473/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12474/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12475/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12476/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 12477/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 12478/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 12481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12482/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12484/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12485/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12486/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 12487/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12488/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 12489/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12490/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12491/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12492/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12493/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 12494/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12495/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 12496/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 12497/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12498/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12499/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 12500/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 12501/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 12502/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 12503/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12504/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 12505/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 12506/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 12507/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 12508/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 12509/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 12510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 12511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12513/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12514/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 12515/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 12517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12520/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12521/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 12522/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 12523/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 12524/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 12525/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12526/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12527/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12528/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12529/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12530/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12531/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 12532/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 12533/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 12534/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12535/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 12536/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12537/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12538/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12540/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12541/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 12543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12544/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 12546/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12547/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12548/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 12549/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 12550/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 12551/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12552/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12553/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12554/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 12556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 12558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 12560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12562/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 12563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12564/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12565/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 12566/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 12567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 12568/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12571/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 12574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 12575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12579/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 12580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 12581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 12585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 12587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 12590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 12594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 12595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 12597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 12599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12600/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 12601/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 12602/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 12603/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 12606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 12612/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12613/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12614/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 12616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 12618/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 12620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 12622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 12623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 12624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 12626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12629/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 12630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 12631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 12632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12633/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 12636/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12637/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12638/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12639/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 12640/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12641/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 12642/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12643/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12644/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 12646/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12648/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12649/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 12650/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12651/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12652/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12655/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 12656/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12657/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12658/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12659/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 12660/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 12663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 12664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 12665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 12669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12670/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12671/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 12672/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 12673/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12674/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 12675/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 12676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 12678/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 12679/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 12680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 12683/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12684/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 12685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 12686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 12687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 12689/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12690/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 12691/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 12692/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 12695/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12696/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12697/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 12698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12699/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12700/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 12701/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12702/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12703/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 12707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 12709/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12710/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12711/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12712/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12714/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12715/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 12716/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 12718/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 12719/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 12720/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 12721/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12722/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 12723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 12725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12727/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12728/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 12729/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 12730/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 12731/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12732/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 12733/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12734/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12735/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12736/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12737/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12738/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 12739/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 12740/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12741/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 12742/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 12743/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12744/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12745/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 12746/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12747/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 12748/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 12749/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12750/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12751/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 12752/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 12753/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12754/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 12755/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12756/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12757/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12758/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12759/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 12760/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 12761/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12762/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 12763/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12764/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 12765/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12766/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 12767/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 12768/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12769/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12770/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12771/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12772/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12775/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12776/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12777/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12778/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12779/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12780/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0684 - val_mse: 0.0684\n",
      "Epoch 12786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 12787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 12788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 12789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12790/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12791/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 12792/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 12794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12796/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 12797/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12799/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 12800/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12801/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 12802/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12803/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0661 - val_mse: 0.0661\n",
      "Epoch 12804/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12805/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 12806/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 12807/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12808/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12809/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12810/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12811/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12812/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12813/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12814/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 12816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 12818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 12819/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 12820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 12821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 12823/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 12826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 12827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12830/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12831/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12832/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 12833/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 12834/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12835/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12837/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 12838/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 12839/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12840/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12841/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 12843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 12849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 12851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 12852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 12853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 12854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 12855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 12856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 12862/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12863/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 12864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 12867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 12869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 12872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 12873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 12874/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 12877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12879/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 12880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 12882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12883/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12884/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 12886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 12889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 12890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 12891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 12892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 12895/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 12897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 12899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 12900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 12903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 12904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 12905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 12906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 12908/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 12909/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 12910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 12912/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 12915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 12918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 12919/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 12921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 12922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 12923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 12925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 12926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 12928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 12929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12930/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 12931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 12932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 12934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 12937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 12938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 12939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 12941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 12942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 12944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 12945/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 12946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 12947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 12950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 12951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 12954/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 12955/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12956/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 12957/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 12958/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 12959/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 12960/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12961/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 12962/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 12963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 12965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 12967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 12968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 12969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 12971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 12974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 12975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 12976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 12977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 12978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 12979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 12980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 12981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 12982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 12983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 12986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 12987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 12988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 12990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 12992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 12993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 12994/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 12995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 12996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 12997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 12998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 12999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 13001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 13002/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 13004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 13006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 13008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 13009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 13010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 13011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 13013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 13017/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13018/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13019/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13020/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13021/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 13022/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 13023/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 13024/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13025/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 13030/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 13031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 13032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 13036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 13038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 13040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 13042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 13045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 13048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 13057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13058/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13062/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13063/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13064/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13065/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 13066/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 13067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 13068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 13069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13071/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 13072/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 13073/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13074/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13075/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 13076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13078/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 13080/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 13081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13082/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13083/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 13084/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13085/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 13086/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 13088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 13089/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 13090/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 13091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 13092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 13095/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13096/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13097/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 13098/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 13099/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 13100/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13101/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13102/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13103/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13104/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 13105/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13106/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 13107/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 13108/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 13109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 13111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 13112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 13113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13114/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 13115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 13116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 13117/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13118/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 13119/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13120/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13121/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13122/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 13123/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13124/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13127/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 13128/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13129/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 13130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13133/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13134/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13136/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 13137/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 13138/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13139/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 13140/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 13141/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13142/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 13146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 13150/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 13151/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 13152/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13153/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 13155/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13156/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13157/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 13160/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 13161/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13162/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13163/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13164/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13165/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13166/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13167/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 13168/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 13169/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13170/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13171/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 13172/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 13173/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13174/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13175/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 13176/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 13177/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13178/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13179/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 13180/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13181/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13182/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 13183/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 13184/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13185/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 13189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 13190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 13191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 13192/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13193/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 13195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13198/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 13199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 13200/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 13201/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13202/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 13203/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 13204/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13206/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 13207/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 13208/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13209/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 13210/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0626 - val_mse: 0.0626\n",
      "Epoch 13211/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 13212/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 13213/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13214/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13217/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0319 - val_mse: 0.0319\n",
      "Epoch 13220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 13223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 13224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 13225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 13227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 13229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 13231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 13232/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 13233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13235/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 13237/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13238/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 13239/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 13240/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 13241/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 13242/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 13243/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13244/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 13245/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13246/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 13247/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 13248/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13250/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13251/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13252/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 13253/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0577 - val_mse: 0.0577\n",
      "Epoch 13254/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 13255/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13256/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 13257/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13258/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13259/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 13260/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 13261/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13262/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13263/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 13265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 13267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13268/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 13269/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 13270/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 13271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 13272/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 13273/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13274/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 13275/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 13276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13277/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13278/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13279/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13280/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13281/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13282/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 13283/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 13284/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 13285/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 13287/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 13288/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 13290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 13291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 13292/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 13293/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13294/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13295/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13296/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13297/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13298/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 13299/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13300/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 13301/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 13302/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 13303/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13304/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13305/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 13306/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13307/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13308/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 13309/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 13310/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13311/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 13312/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 13313/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 13314/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13315/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13316/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 13317/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 13318/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13319/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13320/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 13321/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13322/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 13323/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 13324/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13325/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13326/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13327/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 13328/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13329/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13330/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13331/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 13332/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13333/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13334/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 13335/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 13336/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 13337/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13338/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13339/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 13340/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13341/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13342/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 13343/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 13344/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13345/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 13346/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13347/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 13348/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 13349/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13350/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13351/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 13352/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13353/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13354/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 13355/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 13356/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 13357/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 13358/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 13359/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13360/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13361/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 13362/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 13363/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 13364/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13365/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13366/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 13367/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 13368/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 13369/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 13370/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13371/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13372/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13373/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13374/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 13375/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 13376/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 13377/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 13378/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13379/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 13380/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13381/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 13382/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13383/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 13384/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 13385/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13386/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 13387/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13388/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 13389/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13390/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13391/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 13392/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13393/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13394/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 13395/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 13396/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13397/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 13398/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13399/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13400/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13401/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13402/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 13403/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 13404/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 13405/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13406/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13407/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13408/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 13409/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13410/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 13411/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 13412/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 13413/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13414/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13415/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 13416/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 13417/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13418/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13419/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 13420/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13421/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 13422/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13423/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 13424/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13425/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13426/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13427/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 13428/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 13429/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13430/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 13431/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13432/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13433/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13434/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 13435/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13436/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13437/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13438/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13439/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 13440/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 13441/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13442/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 13443/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 13444/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13445/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 13446/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 13447/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 13448/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 13449/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 13450/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 13451/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13452/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13453/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13454/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 13455/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13456/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 13457/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13458/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13459/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 13460/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13461/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 13462/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 13463/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 13464/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 13465/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 13466/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 13467/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 13468/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 13469/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13470/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13471/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0409 - val_mse: 0.0409\n",
      "Epoch 13472/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 13473/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 13474/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13475/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 13476/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 13477/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 13478/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13479/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 13480/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 13481/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 13482/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13483/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 13484/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13485/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13486/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13487/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 13488/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13489/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 13490/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13491/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13492/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 13493/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 13494/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 13495/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13496/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13497/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 13498/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13499/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13500/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 13501/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13502/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13503/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13504/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13505/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 13506/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 13507/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13508/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 13509/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13510/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13511/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 13512/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13513/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13514/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 13515/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 13516/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13517/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13518/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13519/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13520/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13521/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 13522/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 13523/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 13524/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 13525/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13526/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13527/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 13528/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 13529/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13530/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13531/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13532/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13533/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 13534/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 13535/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13536/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13537/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13538/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13539/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 13540/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13541/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13542/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13543/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13544/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 13545/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13546/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 13547/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 13548/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13549/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 13550/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13551/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13552/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13553/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 13554/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13555/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13556/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13557/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 13558/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13559/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13560/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 13561/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0976 - val_mse: 0.0976\n",
      "Epoch 13562/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 13563/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 13564/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13565/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 13566/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 13567/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13568/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 13569/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 13570/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13571/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13572/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 13573/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13574/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13575/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 13576/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 13577/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 13578/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13579/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13580/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13581/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13582/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 13583/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13584/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13585/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13586/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13587/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 13588/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 13589/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13590/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 13591/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 13592/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13593/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13594/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 13595/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13596/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 13597/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 13598/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13599/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13600/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0420 - val_mse: 0.0420\n",
      "Epoch 13601/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 13602/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 13603/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 13604/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 13605/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13606/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13607/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13608/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 13609/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13610/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13611/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13612/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13613/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13614/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 13615/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 13616/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13617/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13618/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13619/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13620/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13621/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 13622/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 13623/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13624/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 13625/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13626/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13627/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13628/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 13629/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13630/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13631/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13632/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13633/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 13634/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13635/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 13636/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13637/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 13638/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 13639/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13640/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13641/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 13642/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 13643/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 13644/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 13645/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 13646/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 13647/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13648/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 13649/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13650/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13651/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13652/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13653/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 13654/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 13655/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13656/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13657/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 13658/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13659/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 13660/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13661/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13662/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13663/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 13664/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13665/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 13666/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 13667/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 13668/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 13669/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 13670/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 13671/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13672/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 13673/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 13674/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0583 - val_mse: 0.0583\n",
      "Epoch 13675/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 13676/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 13677/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13678/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 13679/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13680/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 13681/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13682/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 13683/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 13684/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13685/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13686/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13687/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13688/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13689/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13690/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 13691/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13692/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13693/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13694/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13695/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13696/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13697/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 13698/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 13699/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13700/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13701/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 13702/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13703/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 13704/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 13705/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13706/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 13707/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13708/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13709/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 13710/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13711/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13712/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 13713/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 13714/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13715/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13716/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 13717/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0480 - val_mse: 0.0480\n",
      "Epoch 13718/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 13719/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 13720/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13721/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13722/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 13723/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 13724/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13725/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13726/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13727/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 13728/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 13729/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13730/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 13731/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 13732/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 13733/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0435 - val_mse: 0.0435\n",
      "Epoch 13734/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 13735/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13736/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 13737/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13738/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 13739/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13740/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13741/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13742/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13743/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 13744/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13745/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13746/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13747/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 13748/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13749/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 13750/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13751/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 13752/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 13753/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13754/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 13755/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13756/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13757/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13758/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 13760/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 13762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13763/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 13765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 13766/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13767/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13768/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 13769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 13770/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 13771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13773/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 13774/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13775/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13776/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 13777/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13778/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13779/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13780/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 13781/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13782/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 13783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 13784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 13786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 13787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 13788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 13789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13791/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13792/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13793/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 13794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13796/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13797/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 13798/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13799/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13800/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 13801/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 13802/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13803/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13804/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13805/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 13806/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 13807/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 13808/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 13809/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 13810/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 13811/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13812/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13813/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 13814/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13815/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 13816/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13817/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 13818/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13819/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 13820/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 13821/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 13822/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13823/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 13824/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 13825/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13826/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 13827/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13829/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 13830/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 13831/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13832/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13833/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13834/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13835/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13836/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13837/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 13838/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 13839/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13840/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13841/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13842/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 13845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 13846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13848/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 13850/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 13851/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 13852/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13853/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 13854/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 13860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 13862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 13864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 13865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 13866/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 13868/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 13869/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 13870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13871/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 13873/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 13874/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 13875/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13876/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13877/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13878/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 13879/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 13880/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 13881/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 13882/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 13883/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 13885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 13886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 13887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0495 - val_mse: 0.0495\n",
      "Epoch 13888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 13890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13891/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 13892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13893/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13894/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 13895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13896/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13897/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 13898/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 13899/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 13900/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 13901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 13902/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13903/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 13904/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 13906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 13908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 13909/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13910/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 13911/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 13912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 13913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 13914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 13915/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 13916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 13918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 13919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 13920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 13921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 13922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 13923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 13925/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13926/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 13927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 13928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 13930/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 13933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 13934/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 13935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 13936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13937/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 13939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 13940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 13941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 13942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 13943/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 13944/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13945/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 13946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 13947/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13950/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 13952/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 13953/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13954/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 13955/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 13956/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 13957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 13958/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 13959/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13960/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13961/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 13962/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 13963/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 13964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13965/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 13966/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 13967/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13968/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 13969/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 13970/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13971/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 13972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 13973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 13975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0322 - val_mse: 0.0322\n",
      "Epoch 13976/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 13977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 13979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13980/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 13981/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 13982/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13983/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 13984/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13985/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13986/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13987/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 13989/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 13991/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 13992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 13993/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 13994/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 13995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 13996/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 13997/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 13998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 13999/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14000/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14001/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 14002/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14003/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 14004/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 14005/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14006/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14007/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14008/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14009/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 14010/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0513 - val_mse: 0.0513\n",
      "Epoch 14011/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 14012/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14013/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14014/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 14015/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14016/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14017/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 14018/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 14019/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 14020/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14021/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14022/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14023/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14024/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 14025/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14026/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 14027/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14028/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 14029/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 14030/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 14031/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 14032/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 14033/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 14034/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14035/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14036/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14037/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 14038/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14039/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14040/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14041/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14042/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 14043/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 14044/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 14045/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14046/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 14047/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 14048/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 14049/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 14050/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0862 - val_mse: 0.0862\n",
      "Epoch 14051/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 14052/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14053/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 14054/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 14055/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14056/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14057/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14058/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 14059/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 14060/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14061/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 14062/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 14063/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14064/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14065/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 14066/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 14067/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14068/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 14069/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 14070/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14071/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 14072/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 14073/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14074/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14075/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14076/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 14077/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 14078/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14079/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 14080/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 14081/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14082/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14083/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14084/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 14085/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 14086/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14087/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14088/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14089/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14090/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 14091/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14092/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14093/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14094/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 14095/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 14096/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 14097/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 14098/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 14099/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 14100/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 14101/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 14102/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 14103/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 14104/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 14105/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 14106/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14107/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 14108/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 14109/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14110/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 14111/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 14112/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 14113/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14114/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14115/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14116/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14117/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 14118/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14119/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14120/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14121/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14122/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14123/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 14124/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14125/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14126/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 14127/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 14128/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 14129/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 14130/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 14131/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14132/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14133/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14134/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14135/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14136/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 14137/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14138/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14139/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 14140/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 14141/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14142/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14143/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 14144/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14145/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14146/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14147/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 14148/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 14149/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14150/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14151/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 14152/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 14153/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14154/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14155/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 14156/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 14157/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 14158/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 14159/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14160/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14161/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14162/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14163/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14164/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14165/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14166/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 14167/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14168/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 14169/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14170/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 14171/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14172/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14173/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14174/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14175/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 14176/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14177/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14178/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14179/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14180/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14181/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14182/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14183/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 14184/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14185/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14186/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 14187/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14188/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14189/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14190/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14191/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14192/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14193/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 14194/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 14195/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 14196/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14197/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14198/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14199/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 14200/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 14201/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 14202/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 14203/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14204/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14205/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14206/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14207/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 14208/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14209/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 14210/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 14211/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14212/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14213/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 14214/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 14215/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14216/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14217/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 14218/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14219/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14220/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 14221/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 14222/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14223/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 14224/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 14225/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 14226/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14227/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14228/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14229/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14230/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14231/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14232/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14233/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 14234/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14235/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 14236/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14237/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 14238/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14239/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14240/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 14241/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 14242/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14243/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 14244/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 14245/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 14246/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14247/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 14248/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14249/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 14250/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14251/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 14252/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 14253/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 14254/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14255/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 14256/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 14257/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 14258/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14259/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14260/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14261/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 14262/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 14263/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 14264/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14265/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 14266/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14267/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14268/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 14269/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 14270/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 14271/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 14272/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14273/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14274/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 14275/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 14276/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 14277/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14278/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14279/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 14280/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14281/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 14282/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 14283/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 14284/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14285/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14286/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 14287/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 14288/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14289/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14290/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14291/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14292/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 14293/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 14294/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 14295/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14296/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14297/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 14298/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14299/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14300/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 14301/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14302/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14303/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14304/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 14305/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14306/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14307/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14308/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14309/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 14310/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 14311/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 14312/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 14313/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 14314/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14315/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14316/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14317/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14318/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14319/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 14320/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14321/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14322/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 14323/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 14324/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14325/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14326/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14327/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 14328/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14329/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 14330/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 14331/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 14332/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14333/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 14334/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14335/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14336/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14337/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 14338/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 14339/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.1028 - val_mse: 0.1028\n",
      "Epoch 14340/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 14341/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 14342/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 14343/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14344/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 14345/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14346/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14347/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 14348/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14349/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14350/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 14351/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 14352/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14353/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 14354/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 14355/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14356/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14357/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 14358/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 14359/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14360/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14361/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14362/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14363/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 14364/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14365/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14366/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14367/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 14368/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14369/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 14370/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 14371/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 14372/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14373/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 14374/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 14375/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 14376/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 14377/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 14378/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14379/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14380/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14381/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14382/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14383/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14384/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 14385/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14386/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 14387/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 14388/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14389/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14390/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 14391/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14392/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 14393/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14394/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14395/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 14396/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 14397/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14398/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14399/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 14400/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 14401/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14402/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14403/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14404/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14405/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14406/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 14407/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14408/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 14409/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 14410/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 14411/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14412/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14413/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14414/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14415/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14416/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 14417/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 14418/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14419/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14420/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14421/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 14422/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 14423/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14424/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14425/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14426/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 14427/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14428/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 14429/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14430/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14431/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 14432/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14433/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14434/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 14435/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 14436/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 14437/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14438/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14439/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 14440/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14441/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14442/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14443/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 14444/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14445/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14446/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14447/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14448/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 14449/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 14450/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14451/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 14452/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 14453/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14454/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14455/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14456/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14457/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 14458/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14459/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14460/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14461/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 14462/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 14463/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 14464/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14465/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14466/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14467/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 14468/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14469/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14470/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14471/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 14472/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14473/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14474/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 14475/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14476/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 14477/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 14478/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14479/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14480/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 14481/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 14482/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14483/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 14484/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14485/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14486/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14487/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14488/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14489/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14490/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14491/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14492/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14493/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14494/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14495/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 14496/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 14497/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 14498/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14499/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 14500/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14501/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 14502/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 14503/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 14504/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 14505/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14506/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14507/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14508/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 14509/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 14510/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 14511/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14512/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 14513/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 14514/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 14515/15000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 14516/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14517/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 14518/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 14519/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 14520/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 14521/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 14522/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 14523/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14524/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 14525/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 14526/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14527/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 14528/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14529/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14530/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14531/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 14532/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14533/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14534/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 14535/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14536/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14537/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14538/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 14539/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14540/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 14541/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14542/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 14543/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14544/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 14545/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14546/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14547/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14548/15000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14549/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14550/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 14551/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14552/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 14553/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14554/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 14555/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 14556/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 14557/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14558/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 14559/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 14560/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14561/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 14562/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 14563/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14564/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14565/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14566/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14567/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 14568/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14569/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14570/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0670 - val_mse: 0.0670\n",
      "Epoch 14571/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14572/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14573/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14574/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14575/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 14576/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 14577/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14578/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 14579/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14580/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14581/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14582/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 14583/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 14584/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14585/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 14586/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 14587/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 14588/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14589/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 14590/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14591/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 14592/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 14593/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 14594/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14595/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14596/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14597/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 14598/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14599/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14600/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 14601/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 14602/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14603/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14604/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 14605/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 14606/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14607/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 14608/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 14609/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14610/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 14611/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14612/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14613/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14614/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14615/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14616/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14617/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14618/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 14619/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 14620/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14621/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14622/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 14623/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14624/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 14625/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14626/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 14627/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14628/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14629/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14630/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14631/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14632/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 14633/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 14634/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14635/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14636/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14637/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14638/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 14639/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 14640/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14641/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 14642/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14643/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14644/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14645/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14646/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 14647/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 14648/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 14649/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 14650/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 14651/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14652/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14653/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14654/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14655/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 14656/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14657/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 14658/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14659/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 14660/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 14661/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 14662/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14663/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14664/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14665/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14666/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 14667/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 14668/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14669/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 14670/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14671/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 14672/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14673/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14674/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 14675/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14676/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14677/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 14678/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 14679/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 14680/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 14681/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14682/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14683/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14684/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 14685/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 14686/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14687/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 14688/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14689/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14690/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14691/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14692/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14693/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14694/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 14695/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14696/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 14697/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14698/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 14699/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 14700/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14701/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14702/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14703/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14704/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 14705/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 14706/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 14707/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14708/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14709/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 14710/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 14711/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14712/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 14713/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14714/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 14715/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 14716/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 14717/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 14718/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14719/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14720/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14721/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14722/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14723/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14724/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 14725/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14726/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14727/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 14728/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14729/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14730/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14731/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14732/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 14733/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14734/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14735/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14736/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14737/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14738/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14739/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14740/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14741/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14742/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 14743/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 14744/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 14745/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14746/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14747/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14748/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 14749/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14750/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14751/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14752/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14753/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14754/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14755/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 14756/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 14757/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 14758/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 14759/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 14760/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 14761/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 14762/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14763/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14764/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14765/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14766/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14767/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 14768/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 14769/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14770/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14771/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14772/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 14773/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0527 - val_mse: 0.0527\n",
      "Epoch 14774/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 14775/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 14776/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14777/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14778/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 14779/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14780/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 14781/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 14782/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 14783/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 14784/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14785/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14786/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14787/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 14788/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14789/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 14790/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14791/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14792/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 14793/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14794/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 14795/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14796/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0313 - val_mse: 0.0313\n",
      "Epoch 14797/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 14798/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14799/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14800/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 14801/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14802/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 14803/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 14804/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14805/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14806/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 14807/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14808/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14809/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 14810/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 14811/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14812/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 14813/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14814/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14815/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 14816/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14817/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14818/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14819/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14820/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14821/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 14822/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 14823/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14824/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14825/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14826/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14827/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14828/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14829/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14830/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 14831/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14832/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14833/15000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 14834/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14835/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 14836/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 14837/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14838/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 14839/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14840/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14841/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14842/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14843/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14844/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14845/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 14846/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 14847/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14848/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14849/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14850/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 14851/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 14852/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14853/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14854/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 14855/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 14856/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 14857/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 14858/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 14859/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14860/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14861/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 14862/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14863/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14864/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 14865/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14866/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14867/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 14868/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14869/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 14870/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14871/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 14872/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 14873/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14874/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14875/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14876/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14877/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14878/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14879/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14880/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14881/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 14882/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 14883/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14884/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 14885/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14886/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 14887/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14888/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 14889/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14890/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14891/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14892/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 14893/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14894/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 14895/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 14896/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 14897/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 14898/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 14899/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 14900/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14901/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 14902/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 14903/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14904/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14905/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14906/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14907/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 14908/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14909/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 14910/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 14911/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14912/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 14913/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0351 - val_mse: 0.0351\n",
      "Epoch 14914/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14915/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14916/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14917/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14918/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 14919/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 14920/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 14921/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 14922/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 14923/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14924/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 14925/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 14926/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 14927/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 14928/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14929/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14930/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 14931/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14932/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14933/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14934/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14935/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 14936/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 14937/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14938/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 14939/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14940/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 14941/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14942/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14943/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 14944/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14945/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14946/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 14947/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 14948/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14949/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 14950/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 14951/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14952/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 14953/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 14954/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14955/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14956/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14957/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 14958/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 14959/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 14960/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 14961/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 14962/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 14963/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 14964/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 14965/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 14966/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 14967/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14968/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 14969/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 14970/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 14971/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14972/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 14973/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14974/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 14975/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 14976/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 14977/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 14978/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 14979/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 14980/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 14981/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 14982/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 14983/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 14984/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 14985/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 14986/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 14987/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 14988/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 14989/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 14990/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 14991/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 14992/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 14993/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 14994/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 14995/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 14996/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 14997/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 14998/15000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 14999/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 15000/15000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0187 - val_mse: 0.0187\n"
     ]
    }
   ],
   "source": [
    "#now we train the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "learning_rate = 0.00001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, epochs=15000, batch_size=30, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "127d7c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "a25e7ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).ravel()  # Flatten to 1D array\n",
    "y_test = y_test.ravel()  # Flatten to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "fdee38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions and actual values\n",
    "#y_test_original_scale = scaler.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "#y_pred_original_scale = scaler.inverse_transform(y_pred.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "#mse = mean_squared_error(y_test_original_scale, y_pred_original_scale)\n",
    "\n",
    "#print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "567d0728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train['Day'], y_train, label='Training Data')\n",
    "plt.scatter(X_test['Day'], y_pred, label='Model Predictions')\n",
    "plt.legend()\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Concentration')\n",
    "plt.title(\"Concentration vs. Hour_Begin\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "0f3c80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.square(y_pred - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "45922647",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(y_pred - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "e97ddc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016697352038575735"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "613759dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10037702372578078"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "03badcd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot actual vs. predicted\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Concentration')\n",
    "plt.title('Actual vs. Predicted Concentration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6617819",
   "metadata": {},
   "source": [
    "### MSE after transforming it back to normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "3f330b96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,120) (8,) (1,120) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35856\\4055916739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Inverse transform the predictions and actual values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred_original_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_test_original_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Calculate Mean Squared Error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,120) (8,) (1,120) "
     ]
    }
   ],
   "source": [
    "# Inverse transform the predictions and actual values\n",
    "y_pred_original_scale = scaler.inverse_transform(y_pred.reshape(1, -1)).ravel()\n",
    "y_test_original_scale = scaler.inverse_transform(y_test.reshape(1, -1)).ravel()\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test_original_scale, y_pred_original_scale)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7bff9367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 2054.4163\n",
      "Test MSE: 2054.416259765625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab34e963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot actual vs. predicted\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Concentration')\n",
    "plt.title('Actual vs. Predicted Concentration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e0ba5",
   "metadata": {},
   "source": [
    "# Using the full data without NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3f1abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Year_Begin'] = nona_data['DatetimeBegin'].dt.year\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Month_Begin'] = nona_data['DatetimeBegin'].dt.month\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Day_Begin'] = nona_data['DatetimeBegin'].dt.day\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Hour_Begin'] = nona_data['DatetimeBegin'].dt.hour\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Year_End'] = nona_data['DatetimeEnd'].dt.year\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Month_End'] = nona_data['DatetimeEnd'].dt.month\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Day_End'] = nona_data['DatetimeEnd'].dt.day\n",
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\4192200715.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data['Hour_End'] = nona_data['DatetimeEnd'].dt.hour\n"
     ]
    }
   ],
   "source": [
    "nona_data['Year_Begin'] = nona_data['DatetimeBegin'].dt.year\n",
    "nona_data['Month_Begin'] = nona_data['DatetimeBegin'].dt.month\n",
    "nona_data['Day_Begin'] = nona_data['DatetimeBegin'].dt.day\n",
    "nona_data['Hour_Begin'] = nona_data['DatetimeBegin'].dt.hour\n",
    "\n",
    "nona_data['Year_End'] = nona_data['DatetimeEnd'].dt.year\n",
    "nona_data['Month_End'] = nona_data['DatetimeEnd'].dt.month\n",
    "nona_data['Day_End'] = nona_data['DatetimeEnd'].dt.day\n",
    "nona_data['Hour_End'] = nona_data['DatetimeEnd'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ba104e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DatetimeBegin', 'DatetimeEnd'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22448\\1483097489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnona_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DatetimeBegin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DatetimeEnd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnona_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AirQualityStationEoICode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AirPollutant'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4955\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4956\u001b[0m         \"\"\"\n\u001b[1;32m-> 4957\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4958\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4959\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4267\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4311\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4312\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6660\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6661\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6662\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6663\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DatetimeBegin', 'DatetimeEnd'] not found in axis\""
     ]
    }
   ],
   "source": [
    "nona_data.drop(columns=['DatetimeBegin', 'DatetimeEnd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "43e9dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\AppData\\Local\\Temp\\ipykernel_22448\\1676278809.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nona_data.drop(columns=['AirQualityStationEoICode', 'AirPollutant'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "nona_data.drop(columns=['AirQualityStationEoICode', 'AirPollutant'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cef516ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = nona_data.drop(columns=['Concentration'])\n",
    "y = nona_data['Concentration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "581a614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Concentration', 'Year_Begin', 'Month_Begin', 'Day_Begin', 'Hour_Begin',\n",
       "       'Year_End', 'Month_End', 'Day_End', 'Hour_End'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nona_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "05dbdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ececda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X_train: (11521, 8)\n",
      "Dimensions of X_test: (2881, 8)\n",
      "Dimensions of y_train: (11521,)\n",
      "Dimensions of y_test: (2881,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of X_train:\", X_train.shape)\n",
    "print(\"Dimensions of X_test:\", X_test.shape)\n",
    "print(\"Dimensions of y_train:\", y_train.shape)\n",
    "print(\"Dimensions of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6d2ea5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(800, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cd243bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 8185.7500 - mse: 8185.7500 - val_loss: 4275.8496 - val_mse: 4275.8496\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 2213.9221 - mse: 2213.9221 - val_loss: 1735.2974 - val_mse: 1735.2975\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1362.8140 - mse: 1362.8140 - val_loss: 890.4460 - val_mse: 890.4460\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 984.1825 - mse: 984.1825 - val_loss: 1080.3397 - val_mse: 1080.3397\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 924.4365 - mse: 924.4365 - val_loss: 866.4568 - val_mse: 866.4568\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 839.7386 - mse: 839.7386 - val_loss: 832.9522 - val_mse: 832.9522\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 817.7286 - mse: 817.7286 - val_loss: 853.8823 - val_mse: 853.8823\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 810.4296 - mse: 810.4296 - val_loss: 839.5353 - val_mse: 839.5353\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 806.3602 - mse: 806.3602 - val_loss: 840.3098 - val_mse: 840.3098\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 805.5349 - mse: 805.5349 - val_loss: 831.8223 - val_mse: 831.8223\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 802.5091 - mse: 802.5091 - val_loss: 826.6192 - val_mse: 826.6192\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 799.7776 - mse: 799.7776 - val_loss: 827.5399 - val_mse: 827.5399\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 799.7056 - mse: 799.7056 - val_loss: 826.7935 - val_mse: 826.7935\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 806.0319 - mse: 806.0319 - val_loss: 828.3655 - val_mse: 828.3655\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 802.9395 - mse: 802.9395 - val_loss: 826.6008 - val_mse: 826.6008\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 802.0061 - mse: 802.0061 - val_loss: 827.5310 - val_mse: 827.5310\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 801.9850 - mse: 801.9850 - val_loss: 827.4418 - val_mse: 827.4418\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 799.8442 - mse: 799.8442 - val_loss: 829.0403 - val_mse: 829.0403\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 801.1108 - mse: 801.1108 - val_loss: 837.9691 - val_mse: 837.9691\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 804.0923 - mse: 804.0922 - val_loss: 835.8168 - val_mse: 835.8168\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 804.1744 - mse: 804.1744 - val_loss: 847.3604 - val_mse: 847.3604\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 806.1221 - mse: 806.1221 - val_loss: 834.1238 - val_mse: 834.1238\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 803.3812 - mse: 803.3812 - val_loss: 832.1945 - val_mse: 832.1945\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 799.6041 - mse: 799.6041 - val_loss: 827.3626 - val_mse: 827.3626\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 801.2643 - mse: 801.2643 - val_loss: 828.9036 - val_mse: 828.9036\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 805.1828 - mse: 805.1828 - val_loss: 826.7802 - val_mse: 826.7802\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 801.4275 - mse: 801.4275 - val_loss: 825.1019 - val_mse: 825.1019\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 801.2276 - mse: 801.2276 - val_loss: 825.1190 - val_mse: 825.1190\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 800.8547 - mse: 800.8547 - val_loss: 826.0343 - val_mse: 826.0343\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 801.1052 - mse: 801.1052 - val_loss: 827.7252 - val_mse: 827.7252\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 801.8672 - mse: 801.8672 - val_loss: 825.8173 - val_mse: 825.8173\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 797.2847 - mse: 797.2847 - val_loss: 825.7188 - val_mse: 825.7188\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 802.9973 - mse: 802.9973 - val_loss: 825.4336 - val_mse: 825.4336\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 799.8655 - mse: 799.8655 - val_loss: 825.6131 - val_mse: 825.6131\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 798.9768 - mse: 798.9768 - val_loss: 827.8759 - val_mse: 827.8759\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 803.3118 - mse: 803.3118 - val_loss: 825.3824 - val_mse: 825.3824\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 812.5429 - mse: 812.5429 - val_loss: 845.7935 - val_mse: 845.7935\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 811.4982 - mse: 811.4982 - val_loss: 824.5074 - val_mse: 824.5074\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 803.3527 - mse: 803.3527 - val_loss: 826.4135 - val_mse: 826.4135\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 800.1124 - mse: 800.1124 - val_loss: 829.8077 - val_mse: 829.8077\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 797.7899 - mse: 797.7899 - val_loss: 836.0718 - val_mse: 836.0718\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 803.7761 - mse: 803.7761 - val_loss: 824.4532 - val_mse: 824.4532\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 796.7432 - mse: 796.7432 - val_loss: 843.0766 - val_mse: 843.0766\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 806.5038 - mse: 806.5038 - val_loss: 823.6125 - val_mse: 823.6125\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 804.9747 - mse: 804.9747 - val_loss: 843.7743 - val_mse: 843.7743\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 808.3708 - mse: 808.3708 - val_loss: 822.4404 - val_mse: 822.4404\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 810.5383 - mse: 810.5383 - val_loss: 823.1797 - val_mse: 823.1797\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 796.7731 - mse: 796.7731 - val_loss: 822.5381 - val_mse: 822.5381\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 794.9556 - mse: 794.9556 - val_loss: 825.3207 - val_mse: 825.3207\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 797.9481 - mse: 797.9481 - val_loss: 821.6116 - val_mse: 821.6116\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 800.5089 - mse: 800.5089 - val_loss: 827.9133 - val_mse: 827.9133\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 803.2402 - mse: 803.2402 - val_loss: 824.3038 - val_mse: 824.3038\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 806.4043 - mse: 806.4043 - val_loss: 835.7211 - val_mse: 835.7211\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 800.8072 - mse: 800.8072 - val_loss: 844.4474 - val_mse: 844.4474\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 809.5803 - mse: 809.5803 - val_loss: 833.7817 - val_mse: 833.7817\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 805.5989 - mse: 805.5989 - val_loss: 826.7837 - val_mse: 826.7837\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 801.9065 - mse: 801.9065 - val_loss: 826.2614 - val_mse: 826.2614\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 806.0757 - mse: 806.0757 - val_loss: 832.7712 - val_mse: 832.7712\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 797.4581 - mse: 797.4581 - val_loss: 820.7149 - val_mse: 820.7149\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 794.4772 - mse: 794.4772 - val_loss: 829.6828 - val_mse: 829.6828\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 795.8486 - mse: 795.8486 - val_loss: 828.2357 - val_mse: 828.2357\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 800.0594 - mse: 800.0594 - val_loss: 828.6917 - val_mse: 828.6917\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 804.8911 - mse: 804.8911 - val_loss: 826.3996 - val_mse: 826.3996\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 798.2822 - mse: 798.2822 - val_loss: 831.3131 - val_mse: 831.3131\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 798.8091 - mse: 798.8091 - val_loss: 818.2600 - val_mse: 818.2600\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 797.0086 - mse: 797.0086 - val_loss: 823.5422 - val_mse: 823.5422\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 799.8517 - mse: 799.8517 - val_loss: 830.6999 - val_mse: 830.6999\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 809.1547 - mse: 809.1547 - val_loss: 816.2656 - val_mse: 816.2656\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 801.9003 - mse: 801.9003 - val_loss: 851.6554 - val_mse: 851.6554\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 808.8860 - mse: 808.8860 - val_loss: 820.2258 - val_mse: 820.2258\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 797.3751 - mse: 797.3751 - val_loss: 836.3386 - val_mse: 836.3386\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 809.0527 - mse: 809.0527 - val_loss: 815.6366 - val_mse: 815.6366\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 788.9502 - mse: 788.9502 - val_loss: 817.1843 - val_mse: 817.1843\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 787.6862 - mse: 787.6862 - val_loss: 820.7337 - val_mse: 820.7337\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 787.8539 - mse: 787.8539 - val_loss: 811.1710 - val_mse: 811.1710\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 788.2665 - mse: 788.2665 - val_loss: 815.2898 - val_mse: 815.2898\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 790.0451 - mse: 790.0451 - val_loss: 812.9011 - val_mse: 812.9011\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 784.9191 - mse: 784.9191 - val_loss: 833.2573 - val_mse: 833.2573\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 790.0842 - mse: 790.0842 - val_loss: 806.5328 - val_mse: 806.5328\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 779.3884 - mse: 779.3884 - val_loss: 806.5707 - val_mse: 806.5707\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 778.2794 - mse: 778.2794 - val_loss: 804.7276 - val_mse: 804.7276\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 776.0291 - mse: 776.0291 - val_loss: 803.9768 - val_mse: 803.9768\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 775.1953 - mse: 775.1953 - val_loss: 798.8758 - val_mse: 798.8758\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 771.8863 - mse: 771.8863 - val_loss: 810.6679 - val_mse: 810.6679\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 776.5530 - mse: 776.5530 - val_loss: 793.3300 - val_mse: 793.3300\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 765.1561 - mse: 765.1561 - val_loss: 814.8523 - val_mse: 814.8523\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 780.4518 - mse: 780.4518 - val_loss: 797.5473 - val_mse: 797.5473\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 784.8977 - mse: 784.8977 - val_loss: 798.5323 - val_mse: 798.5323\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 777.3161 - mse: 777.3161 - val_loss: 785.2211 - val_mse: 785.2211\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 766.9678 - mse: 766.9678 - val_loss: 783.2224 - val_mse: 783.2224\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 775.8694 - mse: 775.8694 - val_loss: 778.3212 - val_mse: 778.3212\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 750.4717 - mse: 750.4717 - val_loss: 781.7639 - val_mse: 781.7639\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 753.9111 - mse: 753.9111 - val_loss: 770.8544 - val_mse: 770.8544\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 750.6390 - mse: 750.6390 - val_loss: 774.8494 - val_mse: 774.8494\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 742.8752 - mse: 742.8752 - val_loss: 764.9233 - val_mse: 764.9233\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 737.6028 - mse: 737.6028 - val_loss: 770.7828 - val_mse: 770.7828\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 757.8478 - mse: 757.8478 - val_loss: 802.6860 - val_mse: 802.6860\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 808.9057 - mse: 808.9057 - val_loss: 791.9512 - val_mse: 791.9512\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 748.1931 - mse: 748.1931 - val_loss: 760.6161 - val_mse: 760.6161\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 740.0024 - mse: 740.0024 - val_loss: 757.6754 - val_mse: 757.6754\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 745.2000 - mse: 745.2000 - val_loss: 756.2048 - val_mse: 756.2048\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 731.3724 - mse: 731.3724 - val_loss: 755.6983 - val_mse: 755.6983\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 739.2499 - mse: 739.2499 - val_loss: 753.0506 - val_mse: 753.0506\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 738.1591 - mse: 738.1591 - val_loss: 767.9898 - val_mse: 767.9898\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 730.4344 - mse: 730.4344 - val_loss: 788.3130 - val_mse: 788.3130\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 773.9646 - mse: 773.9646 - val_loss: 766.4141 - val_mse: 766.4141\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 740.2281 - mse: 740.2281 - val_loss: 753.7088 - val_mse: 753.7088\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 724.3088 - mse: 724.3088 - val_loss: 752.4575 - val_mse: 752.4575\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 722.1914 - mse: 722.1914 - val_loss: 754.8390 - val_mse: 754.8390\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 721.7621 - mse: 721.7621 - val_loss: 746.1575 - val_mse: 746.1575\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 733.5912 - mse: 733.5912 - val_loss: 776.1230 - val_mse: 776.1230\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 738.3953 - mse: 738.3953 - val_loss: 765.9940 - val_mse: 765.9940\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 744.4990 - mse: 744.4990 - val_loss: 764.5432 - val_mse: 764.5432\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 726.9340 - mse: 726.9340 - val_loss: 746.7608 - val_mse: 746.7608\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 718.3239 - mse: 718.3239 - val_loss: 743.7617 - val_mse: 743.7617\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 719.6686 - mse: 719.6686 - val_loss: 743.3458 - val_mse: 743.3458\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 716.5154 - mse: 716.5154 - val_loss: 743.2175 - val_mse: 743.2175\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 717.0928 - mse: 717.0928 - val_loss: 747.4120 - val_mse: 747.4120\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 725.2688 - mse: 725.2688 - val_loss: 750.3090 - val_mse: 750.3090\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 725.4222 - mse: 725.4222 - val_loss: 767.9165 - val_mse: 767.9165\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 735.9200 - mse: 735.9200 - val_loss: 810.7108 - val_mse: 810.7108\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 752.4058 - mse: 752.4058 - val_loss: 784.4099 - val_mse: 784.4099\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 739.8441 - mse: 739.8441 - val_loss: 757.8986 - val_mse: 757.8986\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 724.2177 - mse: 724.2177 - val_loss: 748.3643 - val_mse: 748.3643\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 718.3303 - mse: 718.3303 - val_loss: 742.2938 - val_mse: 742.2938\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 722.9154 - mse: 722.9154 - val_loss: 754.5975 - val_mse: 754.5975\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 728.3863 - mse: 728.3863 - val_loss: 763.6193 - val_mse: 763.6193\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 726.0603 - mse: 726.0603 - val_loss: 740.6058 - val_mse: 740.6058\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 724.5391 - mse: 724.5391 - val_loss: 757.9440 - val_mse: 757.9440\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 734.6580 - mse: 734.6580 - val_loss: 759.6489 - val_mse: 759.6489\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 727.3151 - mse: 727.3151 - val_loss: 744.0131 - val_mse: 744.0131\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 718.3144 - mse: 718.3144 - val_loss: 752.5747 - val_mse: 752.5747\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 718.7476 - mse: 718.7476 - val_loss: 740.7767 - val_mse: 740.7767\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 714.3539 - mse: 714.3539 - val_loss: 739.6908 - val_mse: 739.6908\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 715.1714 - mse: 715.1714 - val_loss: 741.1104 - val_mse: 741.1104\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 722.4250 - mse: 722.4250 - val_loss: 745.0119 - val_mse: 745.0119\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 720.8921 - mse: 720.8921 - val_loss: 750.3013 - val_mse: 750.3013\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 724.9708 - mse: 724.9708 - val_loss: 747.6105 - val_mse: 747.6105\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 727.5762 - mse: 727.5762 - val_loss: 747.5232 - val_mse: 747.5232\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 733.5658 - mse: 733.5658 - val_loss: 806.4218 - val_mse: 806.4218\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 743.4797 - mse: 743.4797 - val_loss: 785.1457 - val_mse: 785.1457\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 733.7833 - mse: 733.7833 - val_loss: 733.6303 - val_mse: 733.6303\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 712.9134 - mse: 712.9134 - val_loss: 744.4180 - val_mse: 744.4180\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 715.8671 - mse: 715.8671 - val_loss: 732.2218 - val_mse: 732.2218\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 716.1752 - mse: 716.1752 - val_loss: 757.3536 - val_mse: 757.3536\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 719.2032 - mse: 719.2032 - val_loss: 730.9203 - val_mse: 730.9203\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 709.9536 - mse: 709.9536 - val_loss: 739.3826 - val_mse: 739.3826\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 712.0431 - mse: 712.0431 - val_loss: 739.0203 - val_mse: 739.0203\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 720.8102 - mse: 720.8102 - val_loss: 752.1520 - val_mse: 752.1520\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 720.8331 - mse: 720.8331 - val_loss: 741.0705 - val_mse: 741.0705\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 717.2233 - mse: 717.2233 - val_loss: 731.5294 - val_mse: 731.5294\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 710.8156 - mse: 710.8156 - val_loss: 728.8404 - val_mse: 728.8404\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 713.3158 - mse: 713.3158 - val_loss: 743.4839 - val_mse: 743.4839\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 711.9418 - mse: 711.9418 - val_loss: 743.2451 - val_mse: 743.2451\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 712.3735 - mse: 712.3735 - val_loss: 728.5706 - val_mse: 728.5706\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 714.1649 - mse: 714.1649 - val_loss: 760.2986 - val_mse: 760.2986\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 722.9517 - mse: 722.9517 - val_loss: 742.0707 - val_mse: 742.0707\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 714.5088 - mse: 714.5088 - val_loss: 730.5980 - val_mse: 730.5980\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 709.2532 - mse: 709.2532 - val_loss: 747.5347 - val_mse: 747.5347\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 709.6027 - mse: 709.6027 - val_loss: 733.5919 - val_mse: 733.5919\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 704.9827 - mse: 704.9827 - val_loss: 727.6718 - val_mse: 727.6718\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 703.6292 - mse: 703.6292 - val_loss: 725.6053 - val_mse: 725.6053\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 702.3813 - mse: 702.3813 - val_loss: 726.8542 - val_mse: 726.8542\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 702.5050 - mse: 702.5050 - val_loss: 726.5665 - val_mse: 726.5665\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 704.3245 - mse: 704.3245 - val_loss: 731.2664 - val_mse: 731.2664\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 704.2126 - mse: 704.2126 - val_loss: 724.3102 - val_mse: 724.3102\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 701.6595 - mse: 701.6595 - val_loss: 723.4756 - val_mse: 723.4756\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 700.6438 - mse: 700.6438 - val_loss: 728.0292 - val_mse: 728.0292\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 701.1189 - mse: 701.1189 - val_loss: 726.0110 - val_mse: 726.0110\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 700.9611 - mse: 700.9611 - val_loss: 723.1214 - val_mse: 723.1214\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 700.9542 - mse: 700.9542 - val_loss: 728.2561 - val_mse: 728.2561\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 703.2048 - mse: 703.2048 - val_loss: 722.1172 - val_mse: 722.1172\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 705.3913 - mse: 705.3913 - val_loss: 738.7817 - val_mse: 738.7817\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 710.3801 - mse: 710.3801 - val_loss: 722.7608 - val_mse: 722.7608\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 706.7379 - mse: 706.7379 - val_loss: 735.6160 - val_mse: 735.6160\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 705.2507 - mse: 705.2507 - val_loss: 726.6819 - val_mse: 726.6819\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 709.8450 - mse: 709.8450 - val_loss: 735.8994 - val_mse: 735.8994\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 703.6729 - mse: 703.6729 - val_loss: 720.8107 - val_mse: 720.8107\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 699.7013 - mse: 699.7013 - val_loss: 744.9725 - val_mse: 744.9725\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 705.5319 - mse: 705.5319 - val_loss: 723.2017 - val_mse: 723.2017\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 702.5021 - mse: 702.5021 - val_loss: 723.6567 - val_mse: 723.6567\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 701.3549 - mse: 701.3549 - val_loss: 736.8550 - val_mse: 736.8550\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 706.0686 - mse: 706.0686 - val_loss: 717.7571 - val_mse: 717.7571\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 702.0208 - mse: 702.0208 - val_loss: 748.9274 - val_mse: 748.9274\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 713.0063 - mse: 713.0063 - val_loss: 744.3904 - val_mse: 744.3904\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 707.7571 - mse: 707.7571 - val_loss: 730.5060 - val_mse: 730.5060\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 713.6298 - mse: 713.6298 - val_loss: 728.3107 - val_mse: 728.3107\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 711.1409 - mse: 711.1409 - val_loss: 734.6924 - val_mse: 734.6924\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 716.5142 - mse: 716.5142 - val_loss: 734.6245 - val_mse: 734.6245\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 700.7102 - mse: 700.7102 - val_loss: 729.5272 - val_mse: 729.5272\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 701.2858 - mse: 701.2858 - val_loss: 717.4465 - val_mse: 717.4465\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 693.1796 - mse: 693.1796 - val_loss: 710.2580 - val_mse: 710.2580\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 689.9412 - mse: 689.9412 - val_loss: 709.5355 - val_mse: 709.5355\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 689.1815 - mse: 689.1815 - val_loss: 715.5560 - val_mse: 715.5560\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 692.9855 - mse: 692.9855 - val_loss: 710.1409 - val_mse: 710.1409\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 695.9491 - mse: 695.9491 - val_loss: 704.8788 - val_mse: 704.8788\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 690.3784 - mse: 690.3784 - val_loss: 716.4142 - val_mse: 716.4142\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 695.1922 - mse: 695.1922 - val_loss: 722.3251 - val_mse: 722.3251\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 696.1556 - mse: 696.1556 - val_loss: 741.3434 - val_mse: 741.3434\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 699.2541 - mse: 699.2541 - val_loss: 706.7634 - val_mse: 706.7634\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 692.8061 - mse: 692.8061 - val_loss: 701.2036 - val_mse: 701.2036\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 694.4959 - mse: 694.4959 - val_loss: 696.6226 - val_mse: 696.6226\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 687.4500 - mse: 687.4500 - val_loss: 693.1940 - val_mse: 693.1940\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 677.6891 - mse: 677.6891 - val_loss: 690.3130 - val_mse: 690.3130\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 678.7703 - mse: 678.7703 - val_loss: 691.6248 - val_mse: 691.6248\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 678.9541 - mse: 678.9541 - val_loss: 695.6398 - val_mse: 695.6398\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 679.5858 - mse: 679.5858 - val_loss: 686.7828 - val_mse: 686.7828\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 677.6260 - mse: 677.6260 - val_loss: 706.9542 - val_mse: 706.9542\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 676.4719 - mse: 676.4719 - val_loss: 681.0502 - val_mse: 681.0502\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 669.3496 - mse: 669.3496 - val_loss: 698.6197 - val_mse: 698.6197\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 669.1825 - mse: 669.1825 - val_loss: 678.4786 - val_mse: 678.4786\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 664.0822 - mse: 664.0822 - val_loss: 682.4500 - val_mse: 682.4500\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 669.3347 - mse: 669.3347 - val_loss: 693.8730 - val_mse: 693.8730\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 680.6588 - mse: 680.6588 - val_loss: 662.1788 - val_mse: 662.1788\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 679.4946 - mse: 679.4946 - val_loss: 673.4333 - val_mse: 673.4333\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 664.7815 - mse: 664.7815 - val_loss: 683.0358 - val_mse: 683.0358\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 666.4773 - mse: 666.4773 - val_loss: 680.4120 - val_mse: 680.4120\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 681.8279 - mse: 681.8279 - val_loss: 692.4333 - val_mse: 692.4333\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 684.1646 - mse: 684.1646 - val_loss: 670.7868 - val_mse: 670.7868\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 678.9737 - mse: 678.9737 - val_loss: 664.5513 - val_mse: 664.5513\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 664.8273 - mse: 664.8273 - val_loss: 662.0357 - val_mse: 662.0357\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 661.7772 - mse: 661.7772 - val_loss: 674.7680 - val_mse: 674.7680\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 662.2095 - mse: 662.2095 - val_loss: 682.8452 - val_mse: 682.8452\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 657.2825 - mse: 657.2825 - val_loss: 651.5319 - val_mse: 651.5319\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 651.4603 - mse: 651.4603 - val_loss: 648.6208 - val_mse: 648.6208\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 650.3187 - mse: 650.3187 - val_loss: 658.6445 - val_mse: 658.6445\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 667.8635 - mse: 667.8635 - val_loss: 680.7986 - val_mse: 680.7986\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 661.7563 - mse: 661.7563 - val_loss: 652.7994 - val_mse: 652.7994\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 652.7698 - mse: 652.7698 - val_loss: 654.9495 - val_mse: 654.9495\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 653.5477 - mse: 653.5477 - val_loss: 655.3226 - val_mse: 655.3226\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 659.7652 - mse: 659.7652 - val_loss: 661.1556 - val_mse: 661.1556\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 670.5095 - mse: 670.5095 - val_loss: 698.7644 - val_mse: 698.7644\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 688.8141 - mse: 688.8141 - val_loss: 676.5958 - val_mse: 676.5958\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 673.8847 - mse: 673.8847 - val_loss: 683.9321 - val_mse: 683.9321\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 679.1924 - mse: 679.1924 - val_loss: 703.5114 - val_mse: 703.5114\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 671.3103 - mse: 671.3103 - val_loss: 655.4927 - val_mse: 655.4927\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 668.5704 - mse: 668.5704 - val_loss: 700.6434 - val_mse: 700.6434\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 662.2678 - mse: 662.2678 - val_loss: 652.8204 - val_mse: 652.8204\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 654.5115 - mse: 654.5115 - val_loss: 651.0317 - val_mse: 651.0318\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 647.5412 - mse: 647.5412 - val_loss: 654.1121 - val_mse: 654.1121\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 657.7198 - mse: 657.7198 - val_loss: 688.7847 - val_mse: 688.7847\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 657.1966 - mse: 657.1966 - val_loss: 652.7946 - val_mse: 652.7946\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 651.6372 - mse: 651.6372 - val_loss: 645.8800 - val_mse: 645.8800\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 647.4309 - mse: 647.4309 - val_loss: 648.4219 - val_mse: 648.4219\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 650.6243 - mse: 650.6243 - val_loss: 644.3456 - val_mse: 644.3456\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 648.2504 - mse: 648.2504 - val_loss: 672.0778 - val_mse: 672.0778\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 657.1966 - mse: 657.1966 - val_loss: 674.2956 - val_mse: 674.2956\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 667.4707 - mse: 667.4707 - val_loss: 672.7122 - val_mse: 672.7122\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 656.7594 - mse: 656.7594 - val_loss: 649.8566 - val_mse: 649.8566\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 646.1113 - mse: 646.1113 - val_loss: 649.8409 - val_mse: 649.8409\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 647.9850 - mse: 647.9850 - val_loss: 648.8730 - val_mse: 648.8730\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 644.5193 - mse: 644.5193 - val_loss: 651.2797 - val_mse: 651.2797\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 645.8600 - mse: 645.8600 - val_loss: 652.3717 - val_mse: 652.3717\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 652.3099 - mse: 652.3099 - val_loss: 668.2123 - val_mse: 668.2123\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 656.4730 - mse: 656.4730 - val_loss: 660.5280 - val_mse: 660.5280\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 649.1499 - mse: 649.1499 - val_loss: 653.1877 - val_mse: 653.1877\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 654.2656 - mse: 654.2656 - val_loss: 652.7108 - val_mse: 652.7108\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 644.7384 - mse: 644.7384 - val_loss: 647.5891 - val_mse: 647.5891\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 647.2908 - mse: 647.2908 - val_loss: 650.1838 - val_mse: 650.1838\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 649.9435 - mse: 649.9435 - val_loss: 652.9034 - val_mse: 652.9034\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 649.8938 - mse: 649.8938 - val_loss: 705.5211 - val_mse: 705.5211\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 668.5378 - mse: 668.5378 - val_loss: 665.0993 - val_mse: 665.0993\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 681.3953 - mse: 681.3953 - val_loss: 686.1324 - val_mse: 686.1324\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 671.8578 - mse: 671.8578 - val_loss: 675.8566 - val_mse: 675.8565\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 667.9637 - mse: 667.9637 - val_loss: 686.1575 - val_mse: 686.1575\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 670.6262 - mse: 670.6262 - val_loss: 661.6568 - val_mse: 661.6568\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 652.7888 - mse: 652.7888 - val_loss: 681.5625 - val_mse: 681.5625\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 660.1216 - mse: 660.1216 - val_loss: 654.8138 - val_mse: 654.8138\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 663.6064 - mse: 663.6064 - val_loss: 676.6169 - val_mse: 676.6169\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 658.9854 - mse: 658.9854 - val_loss: 666.6860 - val_mse: 666.6860\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 663.3741 - mse: 663.3741 - val_loss: 664.0406 - val_mse: 664.0406\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 651.5089 - mse: 651.5089 - val_loss: 661.9966 - val_mse: 661.9966\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 651.5564 - mse: 651.5564 - val_loss: 656.0127 - val_mse: 656.0127\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 659.9089 - mse: 659.9089 - val_loss: 664.0323 - val_mse: 664.0323\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 663.4103 - mse: 663.4103 - val_loss: 662.6334 - val_mse: 662.6334\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 667.5563 - mse: 667.5563 - val_loss: 651.3223 - val_mse: 651.3223\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 664.4811 - mse: 664.4811 - val_loss: 691.7054 - val_mse: 691.7054\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 663.4095 - mse: 663.4095 - val_loss: 651.8734 - val_mse: 651.8734\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 648.9515 - mse: 648.9515 - val_loss: 650.1240 - val_mse: 650.1240\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 643.0804 - mse: 643.0804 - val_loss: 648.9276 - val_mse: 648.9276\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 647.6668 - mse: 647.6668 - val_loss: 668.2067 - val_mse: 668.2067\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 657.0297 - mse: 657.0297 - val_loss: 682.9726 - val_mse: 682.9726\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 665.1915 - mse: 665.1915 - val_loss: 654.5374 - val_mse: 654.5374\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 651.2476 - mse: 651.2476 - val_loss: 653.3046 - val_mse: 653.3046\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 647.9158 - mse: 647.9158 - val_loss: 652.2066 - val_mse: 652.2066\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 645.2531 - mse: 645.2531 - val_loss: 653.0269 - val_mse: 653.0269\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 644.6592 - mse: 644.6592 - val_loss: 645.4179 - val_mse: 645.4179\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 646.5999 - mse: 646.5999 - val_loss: 648.0294 - val_mse: 648.0294\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 646.4243 - mse: 646.4243 - val_loss: 652.8618 - val_mse: 652.8618\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 652.6855 - mse: 652.6855 - val_loss: 647.0455 - val_mse: 647.0455\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 650.0509 - mse: 650.0509 - val_loss: 657.0560 - val_mse: 657.0560\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 647.3610 - mse: 647.3610 - val_loss: 647.8510 - val_mse: 647.8509\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 647.0428 - mse: 647.0428 - val_loss: 681.6234 - val_mse: 681.6234\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 664.9648 - mse: 664.9648 - val_loss: 667.5092 - val_mse: 667.5092\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 667.0298 - mse: 667.0298 - val_loss: 656.4665 - val_mse: 656.4665\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 656.4880 - mse: 656.4880 - val_loss: 675.5448 - val_mse: 675.5448\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 656.5385 - mse: 656.5385 - val_loss: 653.3170 - val_mse: 653.3170\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 647.0668 - mse: 647.0668 - val_loss: 646.3051 - val_mse: 646.3051\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 650.8480 - mse: 650.8480 - val_loss: 657.0989 - val_mse: 657.0989\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 645.3507 - mse: 645.3507 - val_loss: 647.8723 - val_mse: 647.8723\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 650.1802 - mse: 650.1802 - val_loss: 646.6790 - val_mse: 646.6790\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 657.6991 - mse: 657.6991 - val_loss: 657.1579 - val_mse: 657.1579\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 648.6149 - mse: 648.6149 - val_loss: 645.7379 - val_mse: 645.7379\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.6588 - mse: 643.6588 - val_loss: 659.4182 - val_mse: 659.4182\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 646.2455 - mse: 646.2455 - val_loss: 657.3193 - val_mse: 657.3193\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 650.8357 - mse: 650.8357 - val_loss: 648.5409 - val_mse: 648.5409\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 647.1437 - mse: 647.1437 - val_loss: 652.1103 - val_mse: 652.1103\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 650.8674 - mse: 650.8674 - val_loss: 645.7729 - val_mse: 645.7729\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 649.7506 - mse: 649.7507 - val_loss: 650.7816 - val_mse: 650.7816\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 647.2520 - mse: 647.2520 - val_loss: 658.8619 - val_mse: 658.8619\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 653.7087 - mse: 653.7087 - val_loss: 660.9548 - val_mse: 660.9548\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 661.2722 - mse: 661.2722 - val_loss: 694.5396 - val_mse: 694.5396\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 658.4883 - mse: 658.4883 - val_loss: 651.2595 - val_mse: 651.2595\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 649.1234 - mse: 649.1234 - val_loss: 659.3467 - val_mse: 659.3467\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 645.6786 - mse: 645.6786 - val_loss: 648.3948 - val_mse: 648.3948\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 642.3829 - mse: 642.3829 - val_loss: 648.8266 - val_mse: 648.8266\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 643.9285 - mse: 643.9285 - val_loss: 649.6848 - val_mse: 649.6848\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 644.2660 - mse: 644.2660 - val_loss: 646.8778 - val_mse: 646.8778\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 643.9095 - mse: 643.9095 - val_loss: 645.5333 - val_mse: 645.5333\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 643.2897 - mse: 643.2897 - val_loss: 652.2543 - val_mse: 652.2543\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 642.3471 - mse: 642.3471 - val_loss: 665.5199 - val_mse: 665.5199\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 648.3552 - mse: 648.3552 - val_loss: 645.1752 - val_mse: 645.1752\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 641.0757 - mse: 641.0757 - val_loss: 651.6266 - val_mse: 651.6266\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 644.6804 - mse: 644.6804 - val_loss: 646.3325 - val_mse: 646.3325\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 646.5192 - mse: 646.5192 - val_loss: 681.4282 - val_mse: 681.4282\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 666.3580 - mse: 666.3580 - val_loss: 654.5146 - val_mse: 654.5146\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 648.1802 - mse: 648.1802 - val_loss: 646.9836 - val_mse: 646.9836\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 645.6359 - mse: 645.6359 - val_loss: 660.0659 - val_mse: 660.0659\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 650.6405 - mse: 650.6405 - val_loss: 656.1320 - val_mse: 656.1320\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 646.0798 - mse: 646.0798 - val_loss: 644.9011 - val_mse: 644.9011\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.3522 - mse: 643.3522 - val_loss: 650.3257 - val_mse: 650.3257\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 644.8030 - mse: 644.8030 - val_loss: 655.3666 - val_mse: 655.3666\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 646.0669 - mse: 646.0669 - val_loss: 647.5255 - val_mse: 647.5255\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 645.1363 - mse: 645.1363 - val_loss: 645.4446 - val_mse: 645.4446\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 640.6191 - mse: 640.6191 - val_loss: 644.8241 - val_mse: 644.8241\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.4053 - mse: 643.4053 - val_loss: 651.9471 - val_mse: 651.9471\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 649.7430 - mse: 649.7430 - val_loss: 656.7289 - val_mse: 656.7289\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 649.9041 - mse: 649.9041 - val_loss: 650.6141 - val_mse: 650.6141\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 653.7963 - mse: 653.7963 - val_loss: 658.8531 - val_mse: 658.8531\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 661.0818 - mse: 661.0818 - val_loss: 692.5907 - val_mse: 692.5907\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 662.3859 - mse: 662.3859 - val_loss: 688.9707 - val_mse: 688.9707\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 659.5739 - mse: 659.5739 - val_loss: 670.5084 - val_mse: 670.5084\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 656.6248 - mse: 656.6248 - val_loss: 663.6646 - val_mse: 663.6646\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 653.3925 - mse: 653.3925 - val_loss: 653.1306 - val_mse: 653.1306\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 650.1013 - mse: 650.1013 - val_loss: 649.2322 - val_mse: 649.2322\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 649.1138 - mse: 649.1138 - val_loss: 649.8724 - val_mse: 649.8724\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 648.4488 - mse: 648.4488 - val_loss: 650.7546 - val_mse: 650.7546\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 647.0022 - mse: 647.0022 - val_loss: 676.0746 - val_mse: 676.0746\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 652.7646 - mse: 652.7646 - val_loss: 648.2312 - val_mse: 648.2312\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 644.7045 - mse: 644.7045 - val_loss: 652.5672 - val_mse: 652.5672\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 641.5629 - mse: 641.5629 - val_loss: 646.2564 - val_mse: 646.2564\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 642.0767 - mse: 642.0767 - val_loss: 654.8165 - val_mse: 654.8165\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 645.2094 - mse: 645.2094 - val_loss: 657.3489 - val_mse: 657.3489\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 649.7272 - mse: 649.7272 - val_loss: 645.7627 - val_mse: 645.7627\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 643.7575 - mse: 643.7575 - val_loss: 654.9501 - val_mse: 654.9501\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 644.9124 - mse: 644.9124 - val_loss: 650.5173 - val_mse: 650.5173\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 644.3743 - mse: 644.3743 - val_loss: 651.6946 - val_mse: 651.6946\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 646.2288 - mse: 646.2288 - val_loss: 655.8534 - val_mse: 655.8534\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 647.9205 - mse: 647.9205 - val_loss: 650.3470 - val_mse: 650.3470\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 642.1526 - mse: 642.1526 - val_loss: 668.3300 - val_mse: 668.3300\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 647.7525 - mse: 647.7525 - val_loss: 649.9988 - val_mse: 649.9988\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 643.1204 - mse: 643.1204 - val_loss: 652.0051 - val_mse: 652.0051\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 645.9429 - mse: 645.9429 - val_loss: 658.0030 - val_mse: 658.0030\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 646.1129 - mse: 646.1129 - val_loss: 669.4841 - val_mse: 669.4841\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 654.3610 - mse: 654.3610 - val_loss: 658.5742 - val_mse: 658.5742\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 661.2299 - mse: 661.2299 - val_loss: 660.0168 - val_mse: 660.0168\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 654.6618 - mse: 654.6618 - val_loss: 663.2985 - val_mse: 663.2985\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 650.0792 - mse: 650.0792 - val_loss: 648.6184 - val_mse: 648.6184\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 643.1140 - mse: 643.1140 - val_loss: 651.8594 - val_mse: 651.8594\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 645.4109 - mse: 645.4109 - val_loss: 647.1166 - val_mse: 647.1166\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 642.1751 - mse: 642.1751 - val_loss: 648.1393 - val_mse: 648.1393\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 651.1799 - mse: 651.1799 - val_loss: 676.2572 - val_mse: 676.2572\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 660.7912 - mse: 660.7912 - val_loss: 656.9516 - val_mse: 656.9516\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 656.8787 - mse: 656.8787 - val_loss: 651.1373 - val_mse: 651.1373\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 651.6653 - mse: 651.6653 - val_loss: 664.5840 - val_mse: 664.5840\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 655.8982 - mse: 655.8982 - val_loss: 670.2017 - val_mse: 670.2017\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 656.9617 - mse: 656.9617 - val_loss: 681.5707 - val_mse: 681.5707\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 651.9409 - mse: 651.9409 - val_loss: 663.8188 - val_mse: 663.8188\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 646.6829 - mse: 646.6829 - val_loss: 652.1019 - val_mse: 652.1019\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 650.9528 - mse: 650.9528 - val_loss: 655.3521 - val_mse: 655.3521\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 649.4917 - mse: 649.4917 - val_loss: 651.1071 - val_mse: 651.1071\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 656.2404 - mse: 656.2404 - val_loss: 666.9088 - val_mse: 666.9088\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 653.3441 - mse: 653.3441 - val_loss: 660.9486 - val_mse: 660.9486\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 652.9843 - mse: 652.9843 - val_loss: 648.4387 - val_mse: 648.4387\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 654.1323 - mse: 654.1323 - val_loss: 661.4558 - val_mse: 661.4558\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 651.1250 - mse: 651.1250 - val_loss: 658.1146 - val_mse: 658.1146\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 650.9264 - mse: 650.9264 - val_loss: 653.5450 - val_mse: 653.5450\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 641.9374 - mse: 641.9374 - val_loss: 648.1589 - val_mse: 648.1589\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 642.3098 - mse: 642.3098 - val_loss: 661.0147 - val_mse: 661.0147\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 647.2910 - mse: 647.2910 - val_loss: 654.3571 - val_mse: 654.3571\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 645.5699 - mse: 645.5699 - val_loss: 648.2689 - val_mse: 648.2689\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 642.3923 - mse: 642.3923 - val_loss: 651.6163 - val_mse: 651.6163\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 643.3478 - mse: 643.3478 - val_loss: 650.0525 - val_mse: 650.0525\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 641.9264 - mse: 641.9264 - val_loss: 651.8782 - val_mse: 651.8782\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 646.4504 - mse: 646.4504 - val_loss: 645.6051 - val_mse: 645.6051\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 645.3328 - mse: 645.3328 - val_loss: 658.4681 - val_mse: 658.4681\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 644.7087 - mse: 644.7087 - val_loss: 658.3372 - val_mse: 658.3372\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 651.4306 - mse: 651.4306 - val_loss: 665.4365 - val_mse: 665.4365\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 660.4424 - mse: 660.4424 - val_loss: 652.8974 - val_mse: 652.8974\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 658.4116 - mse: 658.4116 - val_loss: 654.7623 - val_mse: 654.7623\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 645.2184 - mse: 645.2184 - val_loss: 653.8749 - val_mse: 653.8749\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 644.2551 - mse: 644.2551 - val_loss: 655.8528 - val_mse: 655.8528\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 646.7555 - mse: 646.7555 - val_loss: 649.9147 - val_mse: 649.9147\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 642.8391 - mse: 642.8391 - val_loss: 648.1053 - val_mse: 648.1053\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 645.2927 - mse: 645.2927 - val_loss: 665.9444 - val_mse: 665.9444\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 649.9673 - mse: 649.9673 - val_loss: 649.7779 - val_mse: 649.7779\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 646.3928 - mse: 646.3928 - val_loss: 681.8608 - val_mse: 681.8608\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 662.8107 - mse: 662.8107 - val_loss: 678.5693 - val_mse: 678.5693\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 656.1506 - mse: 656.1506 - val_loss: 658.8704 - val_mse: 658.8704\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 647.6738 - mse: 647.6738 - val_loss: 654.3891 - val_mse: 654.3891\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 647.0789 - mse: 647.0789 - val_loss: 659.0980 - val_mse: 659.0980\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 654.5735 - mse: 654.5735 - val_loss: 649.2488 - val_mse: 649.2488\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 645.3750 - mse: 645.3750 - val_loss: 660.8490 - val_mse: 660.8490\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 651.6864 - mse: 651.6864 - val_loss: 653.9056 - val_mse: 653.9056\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 646.8119 - mse: 646.8119 - val_loss: 651.6967 - val_mse: 651.6967\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 644.9939 - mse: 644.9939 - val_loss: 645.5687 - val_mse: 645.5687\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 640.8394 - mse: 640.8394 - val_loss: 647.2800 - val_mse: 647.2800\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 646.1972 - mse: 646.1972 - val_loss: 681.4329 - val_mse: 681.4329\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 663.0285 - mse: 663.0285 - val_loss: 671.0250 - val_mse: 671.0250\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 651.5296 - mse: 651.5296 - val_loss: 665.1762 - val_mse: 665.1762\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 647.3491 - mse: 647.3491 - val_loss: 659.0388 - val_mse: 659.0388\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 647.5115 - mse: 647.5115 - val_loss: 657.7919 - val_mse: 657.7919\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 658.6133 - mse: 658.6133 - val_loss: 652.7673 - val_mse: 652.7673\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 655.1649 - mse: 655.1649 - val_loss: 649.7336 - val_mse: 649.7336\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 652.0896 - mse: 652.0896 - val_loss: 651.3679 - val_mse: 651.3679\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 656.0875 - mse: 656.0875 - val_loss: 647.4201 - val_mse: 647.4201\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 643.4905 - mse: 643.4905 - val_loss: 651.2449 - val_mse: 651.2449\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 648.0715 - mse: 648.0715 - val_loss: 660.0605 - val_mse: 660.0605\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 647.9620 - mse: 647.9620 - val_loss: 658.1253 - val_mse: 658.1253\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 647.2541 - mse: 647.2541 - val_loss: 656.4222 - val_mse: 656.4222\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 647.4845 - mse: 647.4845 - val_loss: 646.6901 - val_mse: 646.6901\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 645.4651 - mse: 645.4651 - val_loss: 647.2997 - val_mse: 647.2997\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 642.9233 - mse: 642.9233 - val_loss: 660.3905 - val_mse: 660.3905\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 647.1373 - mse: 647.1373 - val_loss: 662.4909 - val_mse: 662.4909\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 650.1924 - mse: 650.1924 - val_loss: 669.5955 - val_mse: 669.5955\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 650.7725 - mse: 650.7725 - val_loss: 661.3084 - val_mse: 661.3084\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 644.7322 - mse: 644.7322 - val_loss: 657.1860 - val_mse: 657.1860\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 643.2836 - mse: 643.2836 - val_loss: 647.4489 - val_mse: 647.4489\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 640.3283 - mse: 640.3283 - val_loss: 650.8290 - val_mse: 650.8290\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 644.5956 - mse: 644.5956 - val_loss: 649.8576 - val_mse: 649.8576\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 648.8492 - mse: 648.8492 - val_loss: 657.5743 - val_mse: 657.5743\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 648.1307 - mse: 648.1307 - val_loss: 651.0507 - val_mse: 651.0507\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 647.9339 - mse: 647.9339 - val_loss: 658.0923 - val_mse: 658.0923\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 648.6953 - mse: 648.6953 - val_loss: 648.7739 - val_mse: 648.7739\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 641.6707 - mse: 641.6707 - val_loss: 651.0421 - val_mse: 651.0421\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 643.6321 - mse: 643.6321 - val_loss: 647.4763 - val_mse: 647.4763\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 641.6155 - mse: 641.6155 - val_loss: 648.0620 - val_mse: 648.0620\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 644.5896 - mse: 644.5896 - val_loss: 648.5963 - val_mse: 648.5963\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 644.4560 - mse: 644.4560 - val_loss: 649.2422 - val_mse: 649.2422\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 642.5905 - mse: 642.5905 - val_loss: 650.4135 - val_mse: 650.4135\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 642.8313 - mse: 642.8313 - val_loss: 645.0034 - val_mse: 645.0034\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 642.1277 - mse: 642.1277 - val_loss: 645.9164 - val_mse: 645.9164\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 641.2945 - mse: 641.2945 - val_loss: 646.2240 - val_mse: 646.2240\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 643.1700 - mse: 643.1700 - val_loss: 650.3209 - val_mse: 650.3209\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 644.7297 - mse: 644.7297 - val_loss: 650.8248 - val_mse: 650.8248\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 644.6227 - mse: 644.6227 - val_loss: 655.9289 - val_mse: 655.9289\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 644.9958 - mse: 644.9958 - val_loss: 650.9597 - val_mse: 650.9597\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 642.5305 - mse: 642.5305 - val_loss: 648.3611 - val_mse: 648.3611\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 643.9465 - mse: 643.9465 - val_loss: 645.9633 - val_mse: 645.9633\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 641.7036 - mse: 641.7036 - val_loss: 647.3305 - val_mse: 647.3305\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 642.4666 - mse: 642.4666 - val_loss: 652.6809 - val_mse: 652.6809\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 642.9225 - mse: 642.9225 - val_loss: 656.2391 - val_mse: 656.2391\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 645.3408 - mse: 645.3408 - val_loss: 647.4647 - val_mse: 647.4647\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 642.7967 - mse: 642.7967 - val_loss: 643.6122 - val_mse: 643.6122\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 643.5739 - mse: 643.5738 - val_loss: 676.9656 - val_mse: 676.9656\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 652.1733 - mse: 652.1733 - val_loss: 648.2107 - val_mse: 648.2107\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 641.8513 - mse: 641.8513 - val_loss: 648.3156 - val_mse: 648.3156\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 642.2267 - mse: 642.2267 - val_loss: 659.1989 - val_mse: 659.1989\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 648.1819 - mse: 648.1819 - val_loss: 653.7489 - val_mse: 653.7489\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 647.8356 - mse: 647.8356 - val_loss: 648.8715 - val_mse: 648.8715\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 643.6818 - mse: 643.6818 - val_loss: 652.4376 - val_mse: 652.4376\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 642.8770 - mse: 642.8770 - val_loss: 645.9629 - val_mse: 645.9629\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 639.7375 - mse: 639.7375 - val_loss: 651.2379 - val_mse: 651.2379\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 641.6255 - mse: 641.6255 - val_loss: 649.6632 - val_mse: 649.6632\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 640.2583 - mse: 640.2583 - val_loss: 658.0372 - val_mse: 658.0372\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 653.6614 - mse: 653.6614 - val_loss: 663.0222 - val_mse: 663.0222\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 650.1187 - mse: 650.1187 - val_loss: 661.3832 - val_mse: 661.3832\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 657.0248 - mse: 657.0248 - val_loss: 662.9990 - val_mse: 662.9990\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 672.3786 - mse: 672.3786 - val_loss: 662.2993 - val_mse: 662.2993\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 661.6530 - mse: 661.6530 - val_loss: 652.1365 - val_mse: 652.1365\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 647.2648 - mse: 647.2648 - val_loss: 651.3212 - val_mse: 651.3212\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 648.2222 - mse: 648.2222 - val_loss: 648.6746 - val_mse: 648.6746\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 648.2064 - mse: 648.2064 - val_loss: 669.5670 - val_mse: 669.5670\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 651.2816 - mse: 651.2816 - val_loss: 663.9259 - val_mse: 663.9259\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 647.4318 - mse: 647.4318 - val_loss: 653.3157 - val_mse: 653.3157\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 646.4321 - mse: 646.4321 - val_loss: 660.8835 - val_mse: 660.8835\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 652.9709 - mse: 652.9709 - val_loss: 654.4683 - val_mse: 654.4683\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 647.6789 - mse: 647.6789 - val_loss: 652.8768 - val_mse: 652.8768\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 643.4064 - mse: 643.4064 - val_loss: 649.1703 - val_mse: 649.1703\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 640.4128 - mse: 640.4128 - val_loss: 653.8300 - val_mse: 653.8300\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 643.5964 - mse: 643.5964 - val_loss: 652.7427 - val_mse: 652.7427\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 647.4082 - mse: 647.4082 - val_loss: 652.3604 - val_mse: 652.3604\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 644.3887 - mse: 644.3887 - val_loss: 649.6606 - val_mse: 649.6606\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 647.4143 - mse: 647.4143 - val_loss: 651.4594 - val_mse: 651.4594\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 645.9957 - mse: 645.9957 - val_loss: 656.5538 - val_mse: 656.5538\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 644.2668 - mse: 644.2668 - val_loss: 647.9459 - val_mse: 647.9459\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 640.6726 - mse: 640.6726 - val_loss: 649.7230 - val_mse: 649.7230\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 645.0466 - mse: 645.0466 - val_loss: 654.6923 - val_mse: 654.6923\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 642.6993 - mse: 642.6993 - val_loss: 648.4935 - val_mse: 648.4935\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.0969 - mse: 643.0969 - val_loss: 652.3221 - val_mse: 652.3221\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 644.6193 - mse: 644.6193 - val_loss: 648.2872 - val_mse: 648.2872\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 646.8279 - mse: 646.8279 - val_loss: 660.7473 - val_mse: 660.7473\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 642.8895 - mse: 642.8895 - val_loss: 651.3654 - val_mse: 651.3654\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 643.5487 - mse: 643.5487 - val_loss: 647.7750 - val_mse: 647.7750\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 640.7352 - mse: 640.7352 - val_loss: 647.1312 - val_mse: 647.1312\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 640.0723 - mse: 640.0723 - val_loss: 651.3071 - val_mse: 651.3071\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 642.0936 - mse: 642.0936 - val_loss: 651.8128 - val_mse: 651.8127\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 647.8112 - mse: 647.8111 - val_loss: 665.5752 - val_mse: 665.5752\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 653.7816 - mse: 653.7816 - val_loss: 672.0302 - val_mse: 672.0302\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 651.7803 - mse: 651.7803 - val_loss: 651.6749 - val_mse: 651.6749\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 640.9348 - mse: 640.9348 - val_loss: 653.5307 - val_mse: 653.5306\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 643.7717 - mse: 643.7717 - val_loss: 655.7211 - val_mse: 655.7211\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 644.7927 - mse: 644.7927 - val_loss: 655.4963 - val_mse: 655.4963\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 648.1624 - mse: 648.1624 - val_loss: 650.3776 - val_mse: 650.3776\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 644.3715 - mse: 644.3715 - val_loss: 653.5391 - val_mse: 653.5391\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 640.9242 - mse: 640.9242 - val_loss: 648.4308 - val_mse: 648.4308\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 643.7615 - mse: 643.7615 - val_loss: 647.3175 - val_mse: 647.3175\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 644.6213 - mse: 644.6213 - val_loss: 651.8752 - val_mse: 651.8752\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 647.6665 - mse: 647.6665 - val_loss: 667.3215 - val_mse: 667.3215\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 665.3955 - mse: 665.3955 - val_loss: 661.5496 - val_mse: 661.5496\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 655.8695 - mse: 655.8695 - val_loss: 658.3598 - val_mse: 658.3598\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 647.7420 - mse: 647.7420 - val_loss: 657.5669 - val_mse: 657.5669\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 647.0471 - mse: 647.0471 - val_loss: 652.2002 - val_mse: 652.2002\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 645.5333 - mse: 645.5333 - val_loss: 658.0248 - val_mse: 658.0248\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 644.9641 - mse: 644.9641 - val_loss: 651.2070 - val_mse: 651.2070\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.5911 - mse: 643.5911 - val_loss: 645.9968 - val_mse: 645.9968\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 640.6436 - mse: 640.6436 - val_loss: 648.6781 - val_mse: 648.6781\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.4811 - mse: 643.4811 - val_loss: 656.3388 - val_mse: 656.3388\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 644.8702 - mse: 644.8702 - val_loss: 659.4554 - val_mse: 659.4554\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 645.0068 - mse: 645.0068 - val_loss: 656.8299 - val_mse: 656.8299\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 652.4901 - mse: 652.4901 - val_loss: 670.7039 - val_mse: 670.7038\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 649.2455 - mse: 649.2455 - val_loss: 651.3420 - val_mse: 651.3420\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 645.2117 - mse: 645.2117 - val_loss: 647.7489 - val_mse: 647.7489\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 646.0260 - mse: 646.0260 - val_loss: 646.7579 - val_mse: 646.7579\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 648.1736 - mse: 648.1736 - val_loss: 648.6636 - val_mse: 648.6636\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 655.0864 - mse: 655.0864 - val_loss: 663.6877 - val_mse: 663.6877\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 656.3909 - mse: 656.3909 - val_loss: 662.4910 - val_mse: 662.4910\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 654.4273 - mse: 654.4273 - val_loss: 650.2135 - val_mse: 650.2135\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 651.7698 - mse: 651.7698 - val_loss: 650.6001 - val_mse: 650.6001\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.1413 - mse: 643.1413 - val_loss: 652.7040 - val_mse: 652.7040\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 644.9250 - mse: 644.9250 - val_loss: 659.1875 - val_mse: 659.1875\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 645.0286 - mse: 645.0286 - val_loss: 653.5061 - val_mse: 653.5061\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 643.6065 - mse: 643.6065 - val_loss: 649.2858 - val_mse: 649.2858\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 642.1428 - mse: 642.1428 - val_loss: 651.2551 - val_mse: 651.2551\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 644.8622 - mse: 644.8622 - val_loss: 648.9487 - val_mse: 648.9487\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 646.0630 - mse: 646.0630 - val_loss: 647.9797 - val_mse: 647.9797\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 646.4092 - mse: 646.4092 - val_loss: 650.3184 - val_mse: 650.3184\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 649.3445 - mse: 649.3445 - val_loss: 649.8276 - val_mse: 649.8276\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 645.0048 - mse: 645.0048 - val_loss: 652.8912 - val_mse: 652.8912\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 647.7012 - mse: 647.7012 - val_loss: 652.5714 - val_mse: 652.5714\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 641.1777 - mse: 641.1777 - val_loss: 649.4492 - val_mse: 649.4492\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 641.3181 - mse: 641.3181 - val_loss: 647.6002 - val_mse: 647.6002\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 640.7996 - mse: 640.7996 - val_loss: 646.9034 - val_mse: 646.9034\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 642.8760 - mse: 642.8760 - val_loss: 653.2177 - val_mse: 653.2177\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 641.0443 - mse: 641.0443 - val_loss: 649.2618 - val_mse: 649.2618\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 638.9629 - mse: 638.9629 - val_loss: 657.7424 - val_mse: 657.7424\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 642.7903 - mse: 642.7903 - val_loss: 657.3145 - val_mse: 657.3145\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 642.0559 - mse: 642.0559 - val_loss: 649.3336 - val_mse: 649.3336\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 641.7153 - mse: 641.7153 - val_loss: 646.0034 - val_mse: 646.0034\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 639.4672 - mse: 639.4672 - val_loss: 646.4025 - val_mse: 646.4025\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 640.6917 - mse: 640.6917 - val_loss: 649.7564 - val_mse: 649.7564\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 641.0565 - mse: 641.0565 - val_loss: 651.3561 - val_mse: 651.3561\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 640.9221 - mse: 640.9221 - val_loss: 646.5767 - val_mse: 646.5767\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 641.4314 - mse: 641.4314 - val_loss: 653.9777 - val_mse: 653.9777\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 641.2750 - mse: 641.2750 - val_loss: 645.4523 - val_mse: 645.4523\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 640.7894 - mse: 640.7894 - val_loss: 654.0396 - val_mse: 654.0396\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 645.1834 - mse: 645.1834 - val_loss: 655.7987 - val_mse: 655.7987\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 646.1562 - mse: 646.1562 - val_loss: 646.2670 - val_mse: 646.2670\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 650.0305 - mse: 650.0305 - val_loss: 664.9700 - val_mse: 664.9700\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 645.7709 - mse: 645.7709 - val_loss: 647.4803 - val_mse: 647.4803\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 640.6160 - mse: 640.6160 - val_loss: 648.8286 - val_mse: 648.8286\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 640.7518 - mse: 640.7518 - val_loss: 652.3256 - val_mse: 652.3256\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 643.3011 - mse: 643.3011 - val_loss: 653.6768 - val_mse: 653.6768\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 644.4767 - mse: 644.4767 - val_loss: 653.3067 - val_mse: 653.3067\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 644.2084 - mse: 644.2084 - val_loss: 658.7930 - val_mse: 658.7930\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 642.9028 - mse: 642.9028 - val_loss: 646.0782 - val_mse: 646.0782\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 638.7137 - mse: 638.7137 - val_loss: 645.4169 - val_mse: 645.4169\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 637.2166 - mse: 637.2166 - val_loss: 646.6071 - val_mse: 646.6071\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 642.2581 - mse: 642.2581 - val_loss: 644.6879 - val_mse: 644.6879\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 641.2393 - mse: 641.2393 - val_loss: 649.3967 - val_mse: 649.3967\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 644.9626 - mse: 644.9626 - val_loss: 658.9646 - val_mse: 658.9646\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 642.4962 - mse: 642.4962 - val_loss: 658.3660 - val_mse: 658.3660\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 641.6932 - mse: 641.6932 - val_loss: 653.2475 - val_mse: 653.2475\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 638.5081 - mse: 638.5081 - val_loss: 651.9762 - val_mse: 651.9762\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 644.7213 - mse: 644.7213 - val_loss: 649.0090 - val_mse: 649.0090\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 641.5110 - mse: 641.5110 - val_loss: 650.8787 - val_mse: 650.8787\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 643.6796 - mse: 643.6796 - val_loss: 659.8465 - val_mse: 659.8465\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 640.9092 - mse: 640.9092 - val_loss: 649.9290 - val_mse: 649.9290\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 638.7083 - mse: 638.7083 - val_loss: 647.2600 - val_mse: 647.2600\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 637.4945 - mse: 637.4945 - val_loss: 647.2110 - val_mse: 647.2110\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 637.1964 - mse: 637.1964 - val_loss: 646.8014 - val_mse: 646.8014\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 637.3544 - mse: 637.3544 - val_loss: 648.4268 - val_mse: 648.4268\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 639.7587 - mse: 639.7587 - val_loss: 654.4356 - val_mse: 654.4356\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 641.9128 - mse: 641.9128 - val_loss: 650.1361 - val_mse: 650.1361\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 637.2532 - mse: 637.2532 - val_loss: 651.1327 - val_mse: 651.1327\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 641.6620 - mse: 641.6620 - val_loss: 654.0609 - val_mse: 654.0609\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 645.3240 - mse: 645.3240 - val_loss: 652.3466 - val_mse: 652.3466\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 645.2394 - mse: 645.2394 - val_loss: 655.2699 - val_mse: 655.2699\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 652.1255 - mse: 652.1255 - val_loss: 647.4162 - val_mse: 647.4162\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 657.5720 - mse: 657.5720 - val_loss: 653.7167 - val_mse: 653.7167\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 648.8091 - mse: 648.8091 - val_loss: 661.7048 - val_mse: 661.7048\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 646.3658 - mse: 646.3658 - val_loss: 657.2512 - val_mse: 657.2512\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 648.6575 - mse: 648.6575 - val_loss: 648.2823 - val_mse: 648.2823\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 652.1873 - mse: 652.1873 - val_loss: 688.5157 - val_mse: 688.5157\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 659.1882 - mse: 659.1882 - val_loss: 695.0549 - val_mse: 695.0549\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 668.3594 - mse: 668.3594 - val_loss: 692.8100 - val_mse: 692.8100\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 672.1066 - mse: 672.1066 - val_loss: 661.5800 - val_mse: 661.5800\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 662.5387 - mse: 662.5387 - val_loss: 663.6620 - val_mse: 663.6620\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 652.0521 - mse: 652.0521 - val_loss: 654.4761 - val_mse: 654.4761\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 646.0236 - mse: 646.0236 - val_loss: 655.4960 - val_mse: 655.4960\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 645.2719 - mse: 645.2719 - val_loss: 645.8096 - val_mse: 645.8096\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 639.7782 - mse: 639.7782 - val_loss: 652.9207 - val_mse: 652.9207\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 639.5557 - mse: 639.5557 - val_loss: 647.1045 - val_mse: 647.1045\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 643.7191 - mse: 643.7191 - val_loss: 645.2347 - val_mse: 645.2347\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 637.9406 - mse: 637.9406 - val_loss: 654.2437 - val_mse: 654.2437\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 641.9790 - mse: 641.9790 - val_loss: 651.0654 - val_mse: 651.0654\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 640.1509 - mse: 640.1509 - val_loss: 643.5399 - val_mse: 643.5399\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 638.5650 - mse: 638.5650 - val_loss: 645.2371 - val_mse: 645.2371\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 640.2070 - mse: 640.2070 - val_loss: 643.9982 - val_mse: 643.9982\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 634.6646 - mse: 634.6646 - val_loss: 643.5012 - val_mse: 643.5012\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 636.8469 - mse: 636.8469 - val_loss: 652.4690 - val_mse: 652.4690\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 640.8125 - mse: 640.8125 - val_loss: 642.5908 - val_mse: 642.5908\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 636.1082 - mse: 636.1082 - val_loss: 643.4963 - val_mse: 643.4963\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 635.2634 - mse: 635.2634 - val_loss: 649.3139 - val_mse: 649.3139\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 643.0175 - mse: 643.0175 - val_loss: 648.2524 - val_mse: 648.2524\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 644.0639 - mse: 644.0639 - val_loss: 651.2963 - val_mse: 651.2963\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 644.3137 - mse: 644.3137 - val_loss: 665.9911 - val_mse: 665.9911\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 654.6571 - mse: 654.6571 - val_loss: 669.6519 - val_mse: 669.6519\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 657.0864 - mse: 657.0864 - val_loss: 666.5189 - val_mse: 666.5189\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 650.9769 - mse: 650.9769 - val_loss: 650.8093 - val_mse: 650.8093\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 638.7026 - mse: 638.7026 - val_loss: 646.4631 - val_mse: 646.4631\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 638.0315 - mse: 638.0315 - val_loss: 645.0524 - val_mse: 645.0524\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 635.0376 - mse: 635.0376 - val_loss: 647.0872 - val_mse: 647.0872\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 638.5608 - mse: 638.5608 - val_loss: 641.7410 - val_mse: 641.7410\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 635.9404 - mse: 635.9404 - val_loss: 646.8545 - val_mse: 646.8545\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 642.4996 - mse: 642.4996 - val_loss: 646.4423 - val_mse: 646.4423\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 639.7237 - mse: 639.7237 - val_loss: 644.6397 - val_mse: 644.6397\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 635.9829 - mse: 635.9829 - val_loss: 637.8083 - val_mse: 637.8083\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 630.7741 - mse: 630.7741 - val_loss: 640.7858 - val_mse: 640.7858\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 629.4936 - mse: 629.4936 - val_loss: 639.0603 - val_mse: 639.0603\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 635.7212 - mse: 635.7212 - val_loss: 637.1896 - val_mse: 637.1896\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 632.2975 - mse: 632.2975 - val_loss: 649.8871 - val_mse: 649.8871\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 637.2882 - mse: 637.2882 - val_loss: 639.3118 - val_mse: 639.3118\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 626.1015 - mse: 626.1015 - val_loss: 633.7864 - val_mse: 633.7864\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 626.0567 - mse: 626.0567 - val_loss: 627.0433 - val_mse: 627.0433\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 619.5151 - mse: 619.5151 - val_loss: 638.3685 - val_mse: 638.3685\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 620.4506 - mse: 620.4506 - val_loss: 650.2120 - val_mse: 650.2120\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 644.1142 - mse: 644.1142 - val_loss: 634.9961 - val_mse: 634.9961\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 639.0309 - mse: 639.0309 - val_loss: 637.5366 - val_mse: 637.5366\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 637.8210 - mse: 637.8210 - val_loss: 810.3282 - val_mse: 810.3282\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 761.2566 - mse: 761.2566 - val_loss: 1318.7025 - val_mse: 1318.7025\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1259.0745 - mse: 1259.0745 - val_loss: 1077.7367 - val_mse: 1077.7367\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 860.8127 - mse: 860.8127 - val_loss: 813.7986 - val_mse: 813.7986\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 742.4493 - mse: 742.4493 - val_loss: 742.0385 - val_mse: 742.0385\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 716.1492 - mse: 716.1492 - val_loss: 763.1565 - val_mse: 763.1565\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 726.3054 - mse: 726.3054 - val_loss: 800.9664 - val_mse: 800.9664\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 751.8777 - mse: 751.8777 - val_loss: 746.0854 - val_mse: 746.0854\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 721.2637 - mse: 721.2637 - val_loss: 751.9377 - val_mse: 751.9377\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 714.9317 - mse: 714.9317 - val_loss: 753.2872 - val_mse: 753.2872\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 708.6821 - mse: 708.6821 - val_loss: 742.0263 - val_mse: 742.0263\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 704.4962 - mse: 704.4962 - val_loss: 737.0717 - val_mse: 737.0717\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 702.4844 - mse: 702.4844 - val_loss: 718.9485 - val_mse: 718.9485\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 697.9811 - mse: 697.9811 - val_loss: 719.0576 - val_mse: 719.0576\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 698.9982 - mse: 698.9982 - val_loss: 716.2260 - val_mse: 716.2260\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 695.0316 - mse: 695.0316 - val_loss: 713.2216 - val_mse: 713.2216\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 691.9633 - mse: 691.9633 - val_loss: 711.7845 - val_mse: 711.7845\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 690.6608 - mse: 690.6608 - val_loss: 712.0812 - val_mse: 712.0812\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 689.8241 - mse: 689.8241 - val_loss: 708.3364 - val_mse: 708.3364\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 687.6741 - mse: 687.6741 - val_loss: 705.9794 - val_mse: 705.9794\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 688.2493 - mse: 688.2493 - val_loss: 703.9816 - val_mse: 703.9816\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 685.1263 - mse: 685.1263 - val_loss: 703.4911 - val_mse: 703.4911\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 683.6114 - mse: 683.6114 - val_loss: 706.5181 - val_mse: 706.5181\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 681.8936 - mse: 681.8936 - val_loss: 695.4530 - val_mse: 695.4530\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 679.4147 - mse: 679.4147 - val_loss: 691.4140 - val_mse: 691.4140\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 675.5797 - mse: 675.5797 - val_loss: 704.0143 - val_mse: 704.0143\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 687.5383 - mse: 687.5383 - val_loss: 692.7848 - val_mse: 692.7848\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 678.0607 - mse: 678.0607 - val_loss: 697.9824 - val_mse: 697.9824\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 674.2838 - mse: 674.2838 - val_loss: 681.9879 - val_mse: 681.9879\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 672.8706 - mse: 672.8706 - val_loss: 701.5457 - val_mse: 701.5457\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 675.7864 - mse: 675.7864 - val_loss: 701.4575 - val_mse: 701.4575\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 677.4506 - mse: 677.4505 - val_loss: 694.8909 - val_mse: 694.8909\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 671.6232 - mse: 671.6232 - val_loss: 674.2894 - val_mse: 674.2894\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 662.6209 - mse: 662.6209 - val_loss: 674.1456 - val_mse: 674.1456\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 657.9897 - mse: 657.9897 - val_loss: 673.8325 - val_mse: 673.8325\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 653.5373 - mse: 653.5373 - val_loss: 659.7939 - val_mse: 659.7939\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 650.8357 - mse: 650.8357 - val_loss: 659.9429 - val_mse: 659.9429\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 646.5829 - mse: 646.5829 - val_loss: 682.7186 - val_mse: 682.7186\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 660.1099 - mse: 660.1099 - val_loss: 688.2311 - val_mse: 688.2311\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 673.9614 - mse: 673.9614 - val_loss: 698.2017 - val_mse: 698.2017\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 660.3582 - mse: 660.3582 - val_loss: 707.3654 - val_mse: 707.3654\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 664.5643 - mse: 664.5643 - val_loss: 660.9558 - val_mse: 660.9558\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 663.1953 - mse: 663.1953 - val_loss: 670.6778 - val_mse: 670.6778\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 653.1873 - mse: 653.1873 - val_loss: 654.6652 - val_mse: 654.6652\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 648.2768 - mse: 648.2768 - val_loss: 670.3898 - val_mse: 670.3898\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 673.7581 - mse: 673.7581 - val_loss: 660.7994 - val_mse: 660.7994\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 658.0386 - mse: 658.0386 - val_loss: 658.6269 - val_mse: 658.6269\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 659.3870 - mse: 659.3870 - val_loss: 665.0237 - val_mse: 665.0237\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 653.8675 - mse: 653.8675 - val_loss: 650.7325 - val_mse: 650.7325\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 652.9396 - mse: 652.9396 - val_loss: 659.6302 - val_mse: 659.6302\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 653.0966 - mse: 653.0966 - val_loss: 661.1382 - val_mse: 661.1382\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 648.0341 - mse: 648.0341 - val_loss: 652.8961 - val_mse: 652.8961\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 650.8558 - mse: 650.8558 - val_loss: 658.6089 - val_mse: 658.6089\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 647.6180 - mse: 647.6180 - val_loss: 670.8958 - val_mse: 670.8958\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 649.2881 - mse: 649.2881 - val_loss: 660.7704 - val_mse: 660.7704\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 647.1153 - mse: 647.1153 - val_loss: 670.8962 - val_mse: 670.8962\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 656.9019 - mse: 656.9019 - val_loss: 666.1272 - val_mse: 666.1272\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 678.3981 - mse: 678.3981 - val_loss: 702.3831 - val_mse: 702.3831\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 670.0368 - mse: 670.0368 - val_loss: 654.7230 - val_mse: 654.7230\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 653.6261 - mse: 653.6261 - val_loss: 656.7491 - val_mse: 656.7491\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 654.4849 - mse: 654.4849 - val_loss: 653.3840 - val_mse: 653.3840\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 650.6285 - mse: 650.6285 - val_loss: 653.0471 - val_mse: 653.0471\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 641.0245 - mse: 641.0245 - val_loss: 663.6455 - val_mse: 663.6455\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 646.0568 - mse: 646.0568 - val_loss: 654.5960 - val_mse: 654.5960\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 645.4583 - mse: 645.4583 - val_loss: 656.6688 - val_mse: 656.6688\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 641.8795 - mse: 641.8795 - val_loss: 656.2761 - val_mse: 656.2761\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 639.6458 - mse: 639.6458 - val_loss: 662.1937 - val_mse: 662.1937\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 645.0437 - mse: 645.0437 - val_loss: 659.2115 - val_mse: 659.2115\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 644.7647 - mse: 644.7647 - val_loss: 668.5490 - val_mse: 668.5490\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 643.8422 - mse: 643.8422 - val_loss: 648.9212 - val_mse: 648.9212\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 641.2598 - mse: 641.2598 - val_loss: 668.9636 - val_mse: 668.9636\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 648.8361 - mse: 648.8361 - val_loss: 654.0276 - val_mse: 654.0276\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 643.5309 - mse: 643.5309 - val_loss: 648.9470 - val_mse: 648.9470\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 636.5013 - mse: 636.5013 - val_loss: 650.3777 - val_mse: 650.3777\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 642.2410 - mse: 642.2410 - val_loss: 664.3458 - val_mse: 664.3458\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 645.8616 - mse: 645.8616 - val_loss: 648.3707 - val_mse: 648.3707\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 643.2542 - mse: 643.2542 - val_loss: 650.8400 - val_mse: 650.8400\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 637.8580 - mse: 637.8580 - val_loss: 658.5122 - val_mse: 658.5122\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 640.2518 - mse: 640.2518 - val_loss: 657.1512 - val_mse: 657.1512\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 638.4590 - mse: 638.4590 - val_loss: 664.1901 - val_mse: 664.1901\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 645.5419 - mse: 645.5419 - val_loss: 667.8234 - val_mse: 667.8234\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 640.1847 - mse: 640.1847 - val_loss: 659.0190 - val_mse: 659.0190\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 636.7994 - mse: 636.7994 - val_loss: 646.9131 - val_mse: 646.9131\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 631.5794 - mse: 631.5794 - val_loss: 645.6479 - val_mse: 645.6479\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 632.7152 - mse: 632.7152 - val_loss: 650.8611 - val_mse: 650.8611\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 632.7745 - mse: 632.7745 - val_loss: 649.6890 - val_mse: 649.6890\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 631.5081 - mse: 631.5081 - val_loss: 654.5747 - val_mse: 654.5747\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 635.6152 - mse: 635.6152 - val_loss: 687.2278 - val_mse: 687.2278\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 655.5541 - mse: 655.5541 - val_loss: 648.1123 - val_mse: 648.1123\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 650.8390 - mse: 650.8390 - val_loss: 668.7556 - val_mse: 668.7556\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 643.1558 - mse: 643.1558 - val_loss: 659.0330 - val_mse: 659.0330\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 644.4096 - mse: 644.4096 - val_loss: 656.5090 - val_mse: 656.5090\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 636.2474 - mse: 636.2474 - val_loss: 649.0058 - val_mse: 649.0058\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 637.8064 - mse: 637.8064 - val_loss: 657.3447 - val_mse: 657.3447\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 650.0773 - mse: 650.0773 - val_loss: 665.8700 - val_mse: 665.8700\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 640.6321 - mse: 640.6321 - val_loss: 656.3444 - val_mse: 656.3444\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 638.9321 - mse: 638.9321 - val_loss: 654.0103 - val_mse: 654.0103\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 634.7407 - mse: 634.7407 - val_loss: 651.7294 - val_mse: 651.7294\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 631.0237 - mse: 631.0237 - val_loss: 653.6656 - val_mse: 653.6656\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 630.4916 - mse: 630.4916 - val_loss: 647.1345 - val_mse: 647.1345\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 635.6605 - mse: 635.6605 - val_loss: 682.1038 - val_mse: 682.1038\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 644.5252 - mse: 644.5252 - val_loss: 654.3796 - val_mse: 654.3796\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 633.9651 - mse: 633.9651 - val_loss: 647.4142 - val_mse: 647.4142\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 628.4850 - mse: 628.4850 - val_loss: 638.2858 - val_mse: 638.2858\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 625.2102 - mse: 625.2102 - val_loss: 638.2236 - val_mse: 638.2236\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 624.2532 - mse: 624.2532 - val_loss: 636.9419 - val_mse: 636.9419\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 633.8311 - mse: 633.8310 - val_loss: 649.1786 - val_mse: 649.1786\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 638.5592 - mse: 638.5592 - val_loss: 646.5649 - val_mse: 646.5649\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 633.5595 - mse: 633.5595 - val_loss: 641.7530 - val_mse: 641.7530\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 637.0062 - mse: 637.0062 - val_loss: 645.6174 - val_mse: 645.6174\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 620.7039 - mse: 620.7039 - val_loss: 632.1801 - val_mse: 632.1801\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 621.7175 - mse: 621.7175 - val_loss: 650.1522 - val_mse: 650.1522\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 632.8042 - mse: 632.8042 - val_loss: 673.9863 - val_mse: 673.9863\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 638.6541 - mse: 638.6541 - val_loss: 647.9908 - val_mse: 647.9908\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 624.5044 - mse: 624.5044 - val_loss: 643.2780 - val_mse: 643.2780\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 620.7109 - mse: 620.7109 - val_loss: 633.4183 - val_mse: 633.4183\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 610.4656 - mse: 610.4656 - val_loss: 631.0712 - val_mse: 631.0712\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 605.8943 - mse: 605.8943 - val_loss: 618.4212 - val_mse: 618.4212\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 602.6945 - mse: 602.6945 - val_loss: 617.4550 - val_mse: 617.4550\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 594.7673 - mse: 594.7673 - val_loss: 614.0878 - val_mse: 614.0878\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 608.1829 - mse: 608.1829 - val_loss: 637.1549 - val_mse: 637.1549\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 617.0768 - mse: 617.0768 - val_loss: 602.3913 - val_mse: 602.3913\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 651.8694 - mse: 651.8694 - val_loss: 660.7394 - val_mse: 660.7394\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 670.2343 - mse: 670.2343 - val_loss: 683.5976 - val_mse: 683.5976\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 666.4653 - mse: 666.4653 - val_loss: 683.2647 - val_mse: 683.2647\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 659.8195 - mse: 659.8195 - val_loss: 663.4813 - val_mse: 663.4813\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 641.8479 - mse: 641.8479 - val_loss: 652.2260 - val_mse: 652.2260\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 637.9505 - mse: 637.9505 - val_loss: 659.0414 - val_mse: 659.0414\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 649.8499 - mse: 649.8499 - val_loss: 707.7991 - val_mse: 707.7991\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 661.5485 - mse: 661.5485 - val_loss: 683.9026 - val_mse: 683.9026\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 649.4915 - mse: 649.4915 - val_loss: 656.5203 - val_mse: 656.5203\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 636.5681 - mse: 636.5681 - val_loss: 654.1554 - val_mse: 654.1554\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 105ms/step - loss: 640.8157 - mse: 640.8157 - val_loss: 648.0014 - val_mse: 648.0014\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 643.5388 - mse: 643.5388 - val_loss: 644.8395 - val_mse: 644.8395\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 633.9330 - mse: 633.9330 - val_loss: 636.0157 - val_mse: 636.0157\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 626.8090 - mse: 626.8090 - val_loss: 640.6953 - val_mse: 640.6953\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 628.8952 - mse: 628.8952 - val_loss: 645.3597 - val_mse: 645.3597\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 637.1019 - mse: 637.1019 - val_loss: 656.7228 - val_mse: 656.7228\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 641.0388 - mse: 641.0388 - val_loss: 682.6929 - val_mse: 682.6929\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 653.1448 - mse: 653.1448 - val_loss: 687.5605 - val_mse: 687.5605\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 658.2981 - mse: 658.2981 - val_loss: 641.6334 - val_mse: 641.6334\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 636.3174 - mse: 636.3174 - val_loss: 646.7989 - val_mse: 646.7989\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 632.5295 - mse: 632.5295 - val_loss: 666.1321 - val_mse: 666.1321\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 636.8851 - mse: 636.8851 - val_loss: 661.6068 - val_mse: 661.6068\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 629.8107 - mse: 629.8107 - val_loss: 631.8167 - val_mse: 631.8167\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 623.2336 - mse: 623.2336 - val_loss: 632.5084 - val_mse: 632.5084\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 626.4425 - mse: 626.4425 - val_loss: 632.1432 - val_mse: 632.1432\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 627.1997 - mse: 627.1997 - val_loss: 639.3887 - val_mse: 639.3887\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 626.6667 - mse: 626.6667 - val_loss: 668.4456 - val_mse: 668.4456\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 635.8917 - mse: 635.8917 - val_loss: 635.7092 - val_mse: 635.7092\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 614.0781 - mse: 614.0781 - val_loss: 618.7303 - val_mse: 618.7303\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 609.1370 - mse: 609.1370 - val_loss: 615.6226 - val_mse: 615.6226\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 601.4830 - mse: 601.4830 - val_loss: 615.6904 - val_mse: 615.6904\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 598.8994 - mse: 598.8994 - val_loss: 597.6019 - val_mse: 597.6019\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 589.0953 - mse: 589.0953 - val_loss: 599.0499 - val_mse: 599.0499\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 580.6475 - mse: 580.6475 - val_loss: 584.6628 - val_mse: 584.6628\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 571.9968 - mse: 571.9968 - val_loss: 582.1198 - val_mse: 582.1198\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 556.7343 - mse: 556.7343 - val_loss: 710.8318 - val_mse: 710.8318\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 820.9229 - mse: 820.9229 - val_loss: 798.6525 - val_mse: 798.6525\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 765.2117 - mse: 765.2117 - val_loss: 807.7531 - val_mse: 807.7531\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 721.0709 - mse: 721.0709 - val_loss: 814.9236 - val_mse: 814.9236\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 725.4666 - mse: 725.4666 - val_loss: 702.9106 - val_mse: 702.9106\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 675.8439 - mse: 675.8439 - val_loss: 684.1739 - val_mse: 684.1739\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 670.9461 - mse: 670.9461 - val_loss: 676.7906 - val_mse: 676.7906\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 674.1961 - mse: 674.1961 - val_loss: 678.0280 - val_mse: 678.0280\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 679.1946 - mse: 679.1946 - val_loss: 674.0704 - val_mse: 674.0704\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 667.4645 - mse: 667.4645 - val_loss: 707.3714 - val_mse: 707.3714\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 685.5836 - mse: 685.5836 - val_loss: 661.6602 - val_mse: 661.6602\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 676.7737 - mse: 676.7737 - val_loss: 684.9680 - val_mse: 684.9680\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 672.3501 - mse: 672.3501 - val_loss: 672.3069 - val_mse: 672.3069\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 664.4670 - mse: 664.4670 - val_loss: 678.3738 - val_mse: 678.3738\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 657.9745 - mse: 657.9745 - val_loss: 640.3113 - val_mse: 640.3113\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 646.7449 - mse: 646.7449 - val_loss: 649.2972 - val_mse: 649.2972\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 637.6853 - mse: 637.6853 - val_loss: 629.7310 - val_mse: 629.7310\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 626.6500 - mse: 626.6500 - val_loss: 621.5806 - val_mse: 621.5806\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 619.1601 - mse: 619.1601 - val_loss: 627.0772 - val_mse: 627.0772\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 621.4948 - mse: 621.4948 - val_loss: 624.2571 - val_mse: 624.2571\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 617.1939 - mse: 617.1939 - val_loss: 601.3101 - val_mse: 601.3101\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 596.6887 - mse: 596.6887 - val_loss: 585.9288 - val_mse: 585.9288\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 599.2607 - mse: 599.2607 - val_loss: 580.9501 - val_mse: 580.9501\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 575.7320 - mse: 575.7320 - val_loss: 587.0303 - val_mse: 587.0303\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 710.9866 - mse: 710.9866 - val_loss: 934.9566 - val_mse: 934.9566\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 740.2678 - mse: 740.2678 - val_loss: 616.7061 - val_mse: 616.7061\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 645.5064 - mse: 645.5064 - val_loss: 675.5814 - val_mse: 675.5814\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 634.1233 - mse: 634.1233 - val_loss: 610.7128 - val_mse: 610.7128\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 605.9741 - mse: 605.9741 - val_loss: 592.3456 - val_mse: 592.3456\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 589.8517 - mse: 589.8517 - val_loss: 618.5712 - val_mse: 618.5712\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 592.1995 - mse: 592.1995 - val_loss: 559.9510 - val_mse: 559.9510\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 568.2792 - mse: 568.2792 - val_loss: 563.0314 - val_mse: 563.0314\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 548.0187 - mse: 548.0187 - val_loss: 528.6461 - val_mse: 528.6461\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 530.7136 - mse: 530.7136 - val_loss: 513.6817 - val_mse: 513.6817\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 529.1358 - mse: 529.1358 - val_loss: 528.4205 - val_mse: 528.4205\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 541.2781 - mse: 541.2781 - val_loss: 513.3571 - val_mse: 513.3571\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 517.8761 - mse: 517.8761 - val_loss: 478.4272 - val_mse: 478.4272\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 491.2437 - mse: 491.2437 - val_loss: 462.9189 - val_mse: 462.9189\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 516.7654 - mse: 516.7654 - val_loss: 939.7720 - val_mse: 939.7720\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 691.5320 - mse: 691.5320 - val_loss: 542.1317 - val_mse: 542.1317\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 573.5964 - mse: 573.5964 - val_loss: 593.7898 - val_mse: 593.7898\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 547.2882 - mse: 547.2882 - val_loss: 550.7853 - val_mse: 550.7853\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 516.5293 - mse: 516.5293 - val_loss: 481.9617 - val_mse: 481.9617\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 485.3260 - mse: 485.3260 - val_loss: 478.2291 - val_mse: 478.2291\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 469.1518 - mse: 469.1518 - val_loss: 479.4594 - val_mse: 479.4594\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 487.1081 - mse: 487.1081 - val_loss: 441.9443 - val_mse: 441.9443\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 629.5228 - mse: 629.5228 - val_loss: 625.1988 - val_mse: 625.1988\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 594.0668 - mse: 594.0668 - val_loss: 573.0509 - val_mse: 573.0509\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 521.9293 - mse: 521.9293 - val_loss: 504.7947 - val_mse: 504.7947\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 488.6280 - mse: 488.6280 - val_loss: 463.1062 - val_mse: 463.1062\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 460.6959 - mse: 460.6959 - val_loss: 446.3551 - val_mse: 446.3551\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 452.6010 - mse: 452.6010 - val_loss: 472.0280 - val_mse: 472.0280\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 444.9896 - mse: 444.9896 - val_loss: 432.1270 - val_mse: 432.1270\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 444.2778 - mse: 444.2778 - val_loss: 449.9123 - val_mse: 449.9123\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 458.0342 - mse: 458.0342 - val_loss: 493.4483 - val_mse: 493.4483\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 467.9372 - mse: 467.9372 - val_loss: 479.8449 - val_mse: 479.8449\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 448.1564 - mse: 448.1564 - val_loss: 436.4228 - val_mse: 436.4228\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 430.8694 - mse: 430.8694 - val_loss: 425.3583 - val_mse: 425.3583\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 425.3500 - mse: 425.3500 - val_loss: 419.8301 - val_mse: 419.8301\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 422.4247 - mse: 422.4247 - val_loss: 416.6520 - val_mse: 416.6520\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 424.0687 - mse: 424.0687 - val_loss: 420.5002 - val_mse: 420.5002\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 422.4030 - mse: 422.4030 - val_loss: 420.3569 - val_mse: 420.3569\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 428.3236 - mse: 428.3236 - val_loss: 552.2629 - val_mse: 552.2629\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 504.0927 - mse: 504.0927 - val_loss: 499.6281 - val_mse: 499.6281\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 476.1716 - mse: 476.1716 - val_loss: 474.3485 - val_mse: 474.3485\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 456.6582 - mse: 456.6582 - val_loss: 432.2530 - val_mse: 432.2530\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 438.5558 - mse: 438.5558 - val_loss: 434.4782 - val_mse: 434.4782\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 432.8474 - mse: 432.8474 - val_loss: 438.2730 - val_mse: 438.2730\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 1s 93ms/step - loss: 426.2952 - mse: 426.2952 - val_loss: 413.1775 - val_mse: 413.1775\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 423.0531 - mse: 423.0531 - val_loss: 417.4389 - val_mse: 417.4389\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 419.7944 - mse: 419.7944 - val_loss: 421.8496 - val_mse: 421.8496\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 423.4823 - mse: 423.4823 - val_loss: 415.5933 - val_mse: 415.5933\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 424.0318 - mse: 424.0318 - val_loss: 429.4370 - val_mse: 429.4370\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 435.8023 - mse: 435.8023 - val_loss: 422.1198 - val_mse: 422.1198\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 428.8178 - mse: 428.8178 - val_loss: 434.0255 - val_mse: 434.0255\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 426.9864 - mse: 426.9864 - val_loss: 425.7556 - val_mse: 425.7556\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 425.1233 - mse: 425.1233 - val_loss: 411.3939 - val_mse: 411.3939\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 421.4984 - mse: 421.4984 - val_loss: 412.5431 - val_mse: 412.5431\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 419.3751 - mse: 419.3751 - val_loss: 415.3553 - val_mse: 415.3553\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 422.2001 - mse: 422.2001 - val_loss: 411.5627 - val_mse: 411.5627\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 416.8142 - mse: 416.8142 - val_loss: 440.2793 - val_mse: 440.2793\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 423.8708 - mse: 423.8708 - val_loss: 414.0972 - val_mse: 414.0972\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 416.4804 - mse: 416.4804 - val_loss: 413.7984 - val_mse: 413.7984\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 420.2954 - mse: 420.2954 - val_loss: 410.7918 - val_mse: 410.7918\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 412.2377 - mse: 412.2377 - val_loss: 425.3356 - val_mse: 425.3356\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 421.9114 - mse: 421.9114 - val_loss: 415.2615 - val_mse: 415.2615\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 410.7921 - mse: 410.7921 - val_loss: 407.6478 - val_mse: 407.6478\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 406.1402 - mse: 406.1402 - val_loss: 409.6386 - val_mse: 409.6386\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 407.8531 - mse: 407.8531 - val_loss: 405.1570 - val_mse: 405.1570\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 407.3714 - mse: 407.3714 - val_loss: 428.3727 - val_mse: 428.3727\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 413.4503 - mse: 413.4503 - val_loss: 411.3929 - val_mse: 411.3929\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 421.3210 - mse: 421.3210 - val_loss: 405.6399 - val_mse: 405.6399\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 418.5771 - mse: 418.5771 - val_loss: 467.3247 - val_mse: 467.3247\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 441.5223 - mse: 441.5223 - val_loss: 435.6590 - val_mse: 435.6590\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 439.8798 - mse: 439.8798 - val_loss: 418.4881 - val_mse: 418.4881\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 436.4670 - mse: 436.4670 - val_loss: 423.6958 - val_mse: 423.6958\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 425.5067 - mse: 425.5067 - val_loss: 417.4872 - val_mse: 417.4872\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 408.5629 - mse: 408.5629 - val_loss: 404.0315 - val_mse: 404.0315\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 406.8968 - mse: 406.8968 - val_loss: 416.3992 - val_mse: 416.3992\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 409.5096 - mse: 409.5096 - val_loss: 410.2863 - val_mse: 410.2863\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 409.7522 - mse: 409.7522 - val_loss: 412.0917 - val_mse: 412.0917\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 407.1088 - mse: 407.1088 - val_loss: 402.0631 - val_mse: 402.0631\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 404.8363 - mse: 404.8363 - val_loss: 404.1924 - val_mse: 404.1924\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 404.4538 - mse: 404.4538 - val_loss: 412.9801 - val_mse: 412.9801\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 418.6473 - mse: 418.6473 - val_loss: 408.0109 - val_mse: 408.0109\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 417.4189 - mse: 417.4189 - val_loss: 426.7190 - val_mse: 426.7190\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 413.4388 - mse: 413.4388 - val_loss: 422.7671 - val_mse: 422.7671\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 410.5206 - mse: 410.5206 - val_loss: 415.5392 - val_mse: 415.5392\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 410.7806 - mse: 410.7806 - val_loss: 409.2228 - val_mse: 409.2228\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 405.1346 - mse: 405.1346 - val_loss: 404.2036 - val_mse: 404.2036\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 403.5079 - mse: 403.5079 - val_loss: 403.8007 - val_mse: 403.8007\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 400.6604 - mse: 400.6604 - val_loss: 425.1041 - val_mse: 425.1041\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 416.6500 - mse: 416.6500 - val_loss: 406.6216 - val_mse: 406.6216\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 408.5870 - mse: 408.5870 - val_loss: 412.3891 - val_mse: 412.3891\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 411.0211 - mse: 411.0211 - val_loss: 417.2241 - val_mse: 417.2241\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 410.7632 - mse: 410.7632 - val_loss: 408.1427 - val_mse: 408.1427\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 398.9795 - mse: 398.9795 - val_loss: 400.4106 - val_mse: 400.4106\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 397.0569 - mse: 397.0569 - val_loss: 396.3506 - val_mse: 396.3506\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 399.4017 - mse: 399.4017 - val_loss: 400.2839 - val_mse: 400.2839\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 400.4020 - mse: 400.4020 - val_loss: 396.7217 - val_mse: 396.7217\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 409.8017 - mse: 409.8017 - val_loss: 408.1640 - val_mse: 408.1640\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 423.4806 - mse: 423.4806 - val_loss: 417.4597 - val_mse: 417.4597\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 429.8227 - mse: 429.8227 - val_loss: 426.9869 - val_mse: 426.9869\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 438.6572 - mse: 438.6572 - val_loss: 435.4887 - val_mse: 435.4887\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 427.6811 - mse: 427.6811 - val_loss: 455.0263 - val_mse: 455.0263\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 426.1316 - mse: 426.1316 - val_loss: 406.6436 - val_mse: 406.6436\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 411.6813 - mse: 411.6813 - val_loss: 398.0969 - val_mse: 398.0969\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 403.5956 - mse: 403.5956 - val_loss: 404.7053 - val_mse: 404.7053\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 405.1719 - mse: 405.1719 - val_loss: 398.0964 - val_mse: 398.0964\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 399.2993 - mse: 399.2993 - val_loss: 412.8374 - val_mse: 412.8374\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 402.5092 - mse: 402.5092 - val_loss: 395.8853 - val_mse: 395.8853\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 399.8679 - mse: 399.8679 - val_loss: 393.2169 - val_mse: 393.2169\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 397.2363 - mse: 397.2363 - val_loss: 397.5847 - val_mse: 397.5847\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 415.4744 - mse: 415.4744 - val_loss: 434.1066 - val_mse: 434.1066\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 421.3380 - mse: 421.3380 - val_loss: 426.1825 - val_mse: 426.1825\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 412.8435 - mse: 412.8435 - val_loss: 396.6912 - val_mse: 396.6912\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 400.5247 - mse: 400.5247 - val_loss: 405.2681 - val_mse: 405.2681\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 401.3898 - mse: 401.3898 - val_loss: 393.2042 - val_mse: 393.2042\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 407.1131 - mse: 407.1131 - val_loss: 425.3938 - val_mse: 425.3938\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 413.7036 - mse: 413.7036 - val_loss: 417.2012 - val_mse: 417.2012\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 406.9183 - mse: 406.9183 - val_loss: 398.4283 - val_mse: 398.4283\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 398.6889 - mse: 398.6889 - val_loss: 400.2037 - val_mse: 400.2037\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 399.3526 - mse: 399.3526 - val_loss: 393.2122 - val_mse: 393.2122\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 395.7769 - mse: 395.7769 - val_loss: 393.7130 - val_mse: 393.7130\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 397.9544 - mse: 397.9544 - val_loss: 403.8423 - val_mse: 403.8423\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 396.9758 - mse: 396.9758 - val_loss: 398.3385 - val_mse: 398.3385\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 399.0916 - mse: 399.0916 - val_loss: 394.1516 - val_mse: 394.1516\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 392.7200 - mse: 392.7200 - val_loss: 389.6885 - val_mse: 389.6885\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 392.7635 - mse: 392.7635 - val_loss: 413.4066 - val_mse: 413.4066\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 405.1307 - mse: 405.1307 - val_loss: 400.7324 - val_mse: 400.7324\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 402.8238 - mse: 402.8238 - val_loss: 399.9303 - val_mse: 399.9303\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 401.4459 - mse: 401.4459 - val_loss: 404.8102 - val_mse: 404.8102\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 397.8516 - mse: 397.8516 - val_loss: 397.4144 - val_mse: 397.4144\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 398.6131 - mse: 398.6131 - val_loss: 394.9220 - val_mse: 394.9220\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 395.3424 - mse: 395.3424 - val_loss: 396.5172 - val_mse: 396.5172\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 394.4537 - mse: 394.4537 - val_loss: 388.9624 - val_mse: 388.9624\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 389.2050 - mse: 389.2050 - val_loss: 389.5834 - val_mse: 389.5834\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 390.5863 - mse: 390.5863 - val_loss: 397.6638 - val_mse: 397.6638\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 391.7843 - mse: 391.7843 - val_loss: 393.3409 - val_mse: 393.3409\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 1s 98ms/step - loss: 391.0309 - mse: 391.0309 - val_loss: 390.5713 - val_mse: 390.5713\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 392.4064 - mse: 392.4064 - val_loss: 394.6560 - val_mse: 394.6560\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 394.0227 - mse: 394.0227 - val_loss: 391.1967 - val_mse: 391.1967\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 393.7977 - mse: 393.7977 - val_loss: 396.7231 - val_mse: 396.7231\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 395.8700 - mse: 395.8700 - val_loss: 397.0604 - val_mse: 397.0604\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 395.1366 - mse: 395.1366 - val_loss: 402.0347 - val_mse: 402.0347\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 391.8762 - mse: 391.8762 - val_loss: 389.7449 - val_mse: 389.7449\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 395.5824 - mse: 395.5824 - val_loss: 403.8024 - val_mse: 403.8024\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 399.6954 - mse: 399.6954 - val_loss: 394.0411 - val_mse: 394.0411\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 392.8640 - mse: 392.8640 - val_loss: 395.2217 - val_mse: 395.2217\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 391.2267 - mse: 391.2267 - val_loss: 390.8226 - val_mse: 390.8226\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 388.5009 - mse: 388.5009 - val_loss: 389.9001 - val_mse: 389.9001\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 390.5162 - mse: 390.5162 - val_loss: 396.5921 - val_mse: 396.5921\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 395.2918 - mse: 395.2918 - val_loss: 392.7786 - val_mse: 392.7786\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 392.9192 - mse: 392.9192 - val_loss: 407.9359 - val_mse: 407.9359\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 399.1028 - mse: 399.1028 - val_loss: 400.0086 - val_mse: 400.0086\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 395.5194 - mse: 395.5194 - val_loss: 390.5100 - val_mse: 390.5100\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 1s 98ms/step - loss: 392.5903 - mse: 392.5903 - val_loss: 400.9247 - val_mse: 400.9247\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 397.2924 - mse: 397.2924 - val_loss: 407.6711 - val_mse: 407.6711\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 400.2361 - mse: 400.2361 - val_loss: 399.3101 - val_mse: 399.3101\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 391.9832 - mse: 391.9832 - val_loss: 386.7553 - val_mse: 386.7553\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 387.5486 - mse: 387.5486 - val_loss: 387.5554 - val_mse: 387.5554\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 1s 98ms/step - loss: 387.6086 - mse: 387.6086 - val_loss: 390.5962 - val_mse: 390.5962\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 389.3997 - mse: 389.3997 - val_loss: 391.3304 - val_mse: 391.3304\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 390.5598 - mse: 390.5598 - val_loss: 388.5840 - val_mse: 388.5840\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 386.6957 - mse: 386.6957 - val_loss: 393.6961 - val_mse: 393.6961\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 1s 99ms/step - loss: 394.1648 - mse: 394.1648 - val_loss: 395.5579 - val_mse: 395.5579\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 393.4823 - mse: 393.4823 - val_loss: 415.3978 - val_mse: 415.3978\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 399.4935 - mse: 399.4935 - val_loss: 407.7849 - val_mse: 407.7849\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 400.5685 - mse: 400.5685 - val_loss: 392.1336 - val_mse: 392.1336\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 392.9747 - mse: 392.9747 - val_loss: 387.3298 - val_mse: 387.3298\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 387.3536 - mse: 387.3536 - val_loss: 393.9622 - val_mse: 393.9622\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 388.9794 - mse: 388.9794 - val_loss: 393.2185 - val_mse: 393.2185\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 391.8604 - mse: 391.8604 - val_loss: 395.4601 - val_mse: 395.4601\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 395.4803 - mse: 395.4803 - val_loss: 403.7066 - val_mse: 403.7066\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the training data\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=2000, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "a519b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = model.predict(X_test).ravel()  # Flatten to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b29eb5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHFCAYAAADmGm0KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3wU1drHf7MlvSekIU2k9xaqdCRIU0FFQEAEuwiiIr7SVcpVKSKIXppUsdGLVJEa+hUDUgxISSjpPbs75/1jM8uWmd2Z2dkWzvfz4XozO+VMOec856kMIYSAQqFQKBQKhWKBytMNoFAoFAqFQvFGqJBEoVAoFAqFwgMVkigUCoVCoVB4oEIShUKhUCgUCg9USKJQKBQKhULhgQpJFAqFQqFQKDxQIYlCoVAoFAqFByokUSgUCoVCofBAhSQKhUKhUCgUHqiQRPFJFixYAIZh0LBhQ9nnuH37NqZOnYqzZ88q1zA7dO7cGZ07d3bLtaQyYsQIMAxj+ufv7486depgypQpKCkpcfn1r127BoZhsGLFCtO2qVOngmEYyedau3Yt5s2bp1zjzKhevTpGjBghat+8vDx8+umnaNmyJcLCwuDv74/q1atj5MiROH36tEva52k+++wzbNy40SXnttdf5X4rFIojqJBE8UmWLVsGAPjrr79w/PhxWee4ffs2pk2b5jYhydsJDAzE0aNHcfToUWzcuBGtW7fG9OnTMXz4cI+0Z9SoUTh69Kjk41wpJInl6tWraNasGWbNmoUuXbpg3bp1+O233zBt2jTcuXMHLVq0QG5urkfb6ApcLSQJ9Ve53wqF4giNpxtAoUjl5MmTOHfuHHr37o1t27Zh6dKlaN26taeb5fOoVCq0adPG9HevXr1w7do1bNiwAV9++SUqV67Me1xxcTECAwMVb88jjzyCRx55RPHzuhqDwYCnn34a9+/fx9GjRy20nZ06dcLw4cOxY8cOaLVaD7bS8xQXFyMgIEARDZCvfisU74dqkig+x9KlSwEAs2bNQrt27bB+/XoUFRXZ7Hfr1i288sorqFKlCvz8/JCYmIiBAwfizp07OHDgAFq1agUAeOmll0xmpqlTpwIQNo2NGDEC1atXt9g2bdo0tG7dGlFRUQgLC0Pz5s2xdOlSyKkd/dRTT6FatWpgWdbmt9atW6N58+amv3/88Ue0bt0a4eHhCAoKwqOPPoqRI0dKvqY9OKHp+vXrAIzmpj59+uCXX35Bs2bNEBAQgGnTpgEAMjIy8Oqrr+KRRx6Bn58fatSogWnTpkGv11uc8/bt23juuecQGhqK8PBwPP/888jIyLC5tpAJZe3atWjbti1CQkIQEhKCpk2bmr6Jzp07Y9u2bbh+/bqF+ZCjrKwMn3zyCerWrQt/f39UqlQJL730Eu7du2dxDZ1Ohw8++ADx8fEICgpChw4dkJKSIuqZbdy4EX/++ScmTpwoaA7u1asXgoKCTH8fOnQI3bp1Q2hoKIKCgtCuXTts27bN4pgVK1aAYRjs378fr7/+OmJiYhAdHY1nnnkGt2/flvScOPbs2YNu3bohLCwMQUFBaN++Pfbu3WuxD/ce/vrrL7zwwgsIDw9HXFwcRo4caaENYxgGhYWFWLlypem5c32Ia/tvv/2GkSNHolKlSggKCkJpaSmuXLmCl156CbVq1UJQUBAqV66Mvn374s8//zSd21F/5ftWWJbFnDlzTO86NjYWw4YNw82bNy3269y5Mxo2bIgTJ07g8ccfN/WlWbNm8fZDysMFFZIoPkVxcTHWrVuHVq1aoWHDhhg5ciTy8/Px448/Wux369YttGrVCr/++iveffdd7NixA/PmzUN4eDiys7PRvHlzLF++HADw8ccfm8xMo0aNktyma9eu4dVXX8WGDRvwyy+/4JlnnsHbb7+NGTNmSD7XyJEj8e+//2Lfvn0W2y9evIiUlBS89NJLAICjR4/i+eefx6OPPor169dj27ZtmDx5so1A4ixXrlwBAFSqVMm07fTp03j//fcxZswY7Ny5EwMGDEBGRgaSkpKwa9cuTJ48GTt27MDLL7+MmTNnYvTo0aZji4uL0b17d/z222+YOXMmfvzxR8THx+P5558X1Z7JkydjyJAhSExMxIoVK/Drr79i+PDhJiFu0aJFaN++PeLj403vlDPDsCyL/v37Y9asWRg8eDC2bduGWbNmYffu3ejcuTOKi4tN1xk9ejQ+//xzDBs2DJs2bcKAAQPwzDPPIDs722Ebf/vtNwBGgVcMv//+O7p27Yrc3FwsXboU69atQ2hoKPr27YsffvjBZv9Ro0ZBq9Vi7dq1mDNnDg4cOIChQ4dKek4AsHr1ajzxxBMICwvDypUrsWHDBkRFRaFnz542ghIADBgwALVr18bPP/+MDz/8EGvXrsW4ceNMvx89ehSBgYF48sknTc990aJFFucYOXIktFotVq1ahZ9++glarRa3b99GdHQ0Zs2ahZ07d+Lrr7+GRqNB69at8ffffwOArP76+uuvY8KECejRowc2b96MGTNmYOfOnWjXrh3u379vsW9GRgaGDBmCoUOHYvPmzejVqxcmTpyI1atXC56f8pBAKBQf4vvvvycAyDfffEMIISQ/P5+EhISQxx9/3GK/kSNHEq1WS1JTUwXPdeLECQKALF++3Oa3Tp06kU6dOtlsHz58OKlWrZrgOQ0GA9HpdGT69OkkOjqasCzr8Jzm6HQ6EhcXRwYPHmyx/YMPPiB+fn7k/v37hBBCPv/8cwKA5OTk2D2fWIYPH06Cg4OJTqcjOp2O3Lt3j8yfP58wDENatWpl2q9atWpErVaTv//+2+L4V199lYSEhJDr169bbOfa+ddffxFCCFm8eDEBQDZt2mSx3+jRo23exZQpU4j5EPXPP/8QtVpNhgwZYvdeevfuzfuO1q1bRwCQn3/+2WI79x0sWrSIEELIhQsXCAAybtw4i/3WrFlDAJDhw4fbvX5ycjIBQEpKSuzux9GmTRsSGxtL8vPzTdv0ej1p2LAheeSRR0zf0PLlywkA8sYbb1gcP2fOHAKApKenE0LEPafCwkISFRVF+vbta7HdYDCQJk2akKSkJNM27j3MmTPHYt833niDBAQEWHzjwcHBvM+Ha/uwYcMcPA3jvZeVlZFatWpZvAN7/dX6W+HeofWzOn78OAFAPvroI9O2Tp06EQDk+PHjFvvWr1+f9OzZ02F7KRUbqkmi+BRLly5FYGAgBg0aBAAICQnBs88+iz/++AOXL1827bdjxw506dIF9erVc3mb9u3bh+7duyM8PBxqtRparRaTJ09GZmYm7t69K+lcGo0GQ4cOxS+//GIyZRgMBqxatQr9+/dHdHQ0AJhMD8899xw2bNiAW7duOX0fhYWF0Gq10Gq1qFSpEsaOHYtevXrh119/tdivcePGqF27tsW2rVu3okuXLkhMTIRerzf969WrFwCjtgQA9u/fj9DQUPTr18/i+MGDBzts3+7du2EwGPDmm2/Kur+tW7ciIiICffv2tWhj06ZNER8fjwMHDpjaCABDhgyxOP65556DRqOsG2dhYSGOHz+OgQMHIiQkxLRdrVbjxRdfxM2bN03aFA7rZ9e4cWMAD0yiYp7TkSNHkJWVheHDh1s8C5ZlkZycjBMnTqCwsNDhdUtKSiR94wMGDLDZptfr8dlnn6F+/frw8/ODRqOBn58fLl++jAsXLog+tzncO7SORExKSkK9evVsNGXx8fFISkqy2Na4cWMLzRvl4YQKSRSf4cqVKzh48CB69+4NQghycnKQk5ODgQMHAngQ8QYA9+7dc4sjZ0pKCp544gkAwHfffYfDhw/jxIkT+L//+z8AsDDhiGXkyJEoKSnB+vXrAQC7du1Cenq6ydQGAB07dsTGjRuh1+sxbNgwPPLII2jYsCHWrVsn+14CAwNx4sQJnDhxAv/73/+Qk5ODbdu22ThsJyQk2Bx7584dbNmyxSRkcf8aNGgAACbzRmZmJuLi4myOj4+Pd9g+zm9I7nu9c+cOcnJy4OfnZ9POjIwMizbytUmj0ZiEVHtUrVoVAJCWluZw3+zsbBBCeJ9pYmKiRXs4rNvg7+8P4MG3JuY53blzBwAwcOBAm2cxe/ZsEEKQlZUl6bpi4LvPd999F5MmTcJTTz2FLVu24Pjx4zhx4gSaNGkiq/8AD56Z0HN19EwB4/3JvT6l4kCj2yg+w7Jly0AIwU8//YSffvrJ5veVK1fik08+gVqtRqVKlWwcNKUQEBDAG6Jt7cuwfv16aLVabN26FQEBAabtzoRB169fH0lJSVi+fDleffVVLF++HImJiSZhjKN///7o378/SktLcezYMcycORODBw9G9erV0bZtW8nXValUaNmypcP9+JypY2Ji0LhxY3z66ae8x3ATfnR0NK8DNJ/jtjWcX9TNmzdRpUoVh/vztTE6Oho7d+7k/T00NNTURq5N5gKiXq+3mVz56NmzJ7799lts3LgRH374od19IyMjoVKpkJ6ebvMb54wdExPj8JrmiHlO3Dm/+uori4hGc/iEWWfh+3ZWr16NYcOG4bPPPrPYfv/+fURERMi6DvcO09PTbYTF27dvS36mlIcXqkmi+AQGgwErV65EzZo1sX//fpt/48ePR3p6Onbs2AHAGD20f/9+G1OFOfZWwtWrV8elS5dQWlpq2paZmYkjR45Y7McwDDQaDdRqtWlbcXExVq1a5dT9vvTSSzh+/DgOHTqELVu2YPjw4RbXsL6PTp06Yfbs2QCAM2fOOHVtOfTp0wfnz59HzZo10bJlS5t/nJDUpUsX5OfnY/PmzRbHr1271uE1nnjiCajVaixevNjufkIagD59+iAzMxMGg4G3jXXq1AEAU0TWmjVrLI7fsGGDKMf4/v37o1GjRpg5cybOnz/Pu8+uXbtQVFSE4OBgtG7dGr/88otFm1mWxerVq/HII4/YmDYdIeY5tW/fHhEREUhNTeV9Fi1btoSfn5+k6wLytC9c8lJztm3bZmNClqK56tq1KwDYOF6fOHECFy5cQLdu3SS1kfLwQjVJFJ9gx44duH37NmbPns0bmt+wYUMsXLgQS5cuRZ8+fTB9+nTs2LEDHTt2xEcffYRGjRohJycHO3fuxLvvvou6deuiZs2aCAwMxJo1a1CvXj2EhIQgMTERiYmJePHFF7FkyRIMHToUo0ePRmZmJubMmYOwsDCL6/bu3RtffvklBg8ejFdeeQWZmZn4/PPPbQZ9qbzwwgt499138cILL6C0tNTGt2Ly5Mm4efMmunXrhkceeQQ5OTmYP38+tFotOnXqZNpPo9GgU6dOvNFKSjJ9+nTs3r0b7dq1w5gxY1CnTh2UlJTg2rVr2L59O7755hs88sgjGDZsGObOnYthw4bh008/Ra1atbB9+3bs2rXL4TWqV6+Ojz76CDNmzEBxcbEpHD01NRX37983pSJo1KgRfvnlFyxevBgtWrQwacgGDRqENWvW4Mknn8Q777yDpKQkaLVa3Lx5E/v370f//v3x9NNPo169ehg6dCjmzZsHrVaL7t274/z58/j8889t3j8farUav/76K5544gm0bdsWr7/+Orp06YLg4GBcv34dP/30E7Zs2WKKlJs5cyZ69OiBLl264L333oOfnx8WLVqE8+fPY926dZLzCIl5TiEhIfjqq68wfPhwZGVlYeDAgYiNjcW9e/dw7tw53Lt3z6EwykejRo1w4MABbNmyBQkJCQgNDTUJn0L06dMHK1asQN26ddG4cWOcOnUK//nPf2w0QPb6qzV16tTBK6+8gq+++goqlcqU82vSpEmoUqWKRVQehWIXz/qNUyjieOqpp4ifnx+5e/eu4D6DBg0iGo2GZGRkEEIIuXHjBhk5ciSJj48nWq2WJCYmkueee47cuXPHdMy6detI3bp1iVarJQDIlClTTL+tXLmS1KtXjwQEBJD69euTH374gTe6bdmyZaROnTrE39+fPProo2TmzJlk6dKlBABJS0sz7Scmus2cwYMHEwCkffv2Nr9t3bqV9OrVi1SuXJn4+fmR2NhY8uSTT5I//vjDYj8Aoq7JRbc5olq1aqR37968v927d4+MGTOG1KhRg2i1WhIVFUVatGhB/u///o8UFBSY9rt58yYZMGAACQkJIaGhoWTAgAHkyJEjDqPbOL7//nvSqlUrEhAQQEJCQkizZs0sjsvKyiIDBw4kERERhGEYi3PodDry+eefkyZNmpiOr1u3Lnn11VfJ5cuXTfuVlpaS8ePHk9jYWBIQEEDatGlDjh49SqpVq+Ywuo0jJyeHzJgxgzRv3pyEhIQQrVZLqlatSoYOHUoOHz5sse8ff/xBunbtSoKDg0lgYCBp06YN2bJli8U+XITYiRMnLLbv37+fACD79++X9JwIIeT3338nvXv3JlFRUUSr1ZLKlSuT3r17kx9//NG0D/ce7t27x9se82/87NmzpH379iQoKMji2xNqOyGEZGdnk5dffpnExsaSoKAg0qFDB/LHH3/w9heh/sr3rRgMBjJ79mxSu3ZtotVqSUxMDBk6dCi5ceOGxX6dOnUiDRo0sGmXo0hWysMBQ4iMjHcUCoVCoVAoFRzqk0ShUCgUCoXCAxWSKBQKhUKhUHigQhKFQqFQKBQKDx4Vkg4ePIi+ffsiMTERDMPY5JYxL1Bp/u8///mPaZ/OnTvb/M5lY6ZQKBQKhUKRi0eFpMLCQjRp0gQLFy7k/T09Pd3i37Jly8AwjE1q+9GjR1vst2TJEnc0n0KhUCgUSgXGo3mSevXqZartxId1WYBNmzahS5cuePTRRy22BwUFiSprQKFQKBQKhSIWn0kmeefOHWzbtg0rV660+W3NmjVYvXo14uLi0KtXL0yZMsVUYkAMLMvi9u3bCA0NlZy4jUKhUCgUimcghCA/Px+JiYlQqZQ3jvmMkLRy5UqEhobimWeesdg+ZMgQ1KhRA/Hx8Th//jwmTpyIc+fOYffu3YLnKi0ttSg3cevWLdSvX99lbadQKBQKheI6bty44ZKi5j4jJC1btgxDhgyxKCIKGP2ROBo2bIhatWqhZcuWOH36NJo3b857rpkzZ5pKGJhz48YNUWUHKBQKhUKheJ68vDxUqVJFkvVICj4hJP3xxx/4+++/8cMPPzjct3nz5tBqtbh8+bKgkDRx4kS8++67pr+5hxwWFkaFJAqFQqFQfAxXucr4hJC0dOlStGjRAk2aNHG4719//QWdToeEhATBffz9/Z0uQEqhUCgUCqVi41EhqaCgAFeuXDH9nZaWhrNnzyIqKgpVq1YFYNTy/Pjjj/jiiy9sjr969aqpqndMTAxSU1Mxfvx4NGvWDO3bt3fbfVAoFAqFQql4eFRIOnnyJLp06WL6mzOBDR8+HCtWrAAArF+/HoQQvPDCCzbH+/n5Ye/evZg/fz4KCgpQpUoV9O7dG1OmTIFarXbLPVAoFAqFQqmYMIQQ4ulGeJq8vDyEh4cjNzfXrk+SwWCATqdzY8soSuLn5+eSEFEKhUKheAax87dcfMInydMQQpCRkYGcnBxPN4XiBCqVCjVq1ICfn5+nm0KhUCgUH4AKSSLgBKTY2FgEBQXRhJM+CJcwND09HVWrVqXvkEKhUCgOoUKSAwwGg0lAio6O9nRzKE5QqVIl3L59G3q9Hlqt1tPNoVAoFIqXQx00HMD5IAUFBXm4JRRn4cxsBoPBwy2hUCgUii9AhSSRUPOM70PfIYVCoVCkQM1tFArFIQaWICUtC3fzSxAbGoCkGlFQq6jQSaFQKjZUSKK4HYZh8Ouvv+Kpp57ydFMoIth5Ph3TtqQiPbfEtC0hPABT+tZHckPhzPYUCoXi61BzWwXnyJEjUKvVSE5OlnRc9erVMW/ePNc0iuIz7DyfjtdXn7YQkAAgI7cEr68+jZ3n0z3UMgqFQnE9VEhyEwaW4OjVTGw6ewtHr2bCwLonh+eyZcvw9ttv49ChQ/j333/dck1KxcDAEkzbkgq+L5XbNm1Lqtu+ZQqFQnE3VEhyAzvPp6PD7H144btjeGf9Wbzw3TF0mL3P5avwwsJCbNiwAa+//jr69OljKvXCsXnzZrRs2RIBAQGIiYnBM888AwDo3Lkzrl+/jnHjxoFhGJPD89SpU9G0aVOLc8ybNw/Vq1c3/X3ixAn06NEDMTExCA8PR6dOnXD69GlX3ibFRaSkZdlokMwhANJzS5CSluW+RlEoFIoboUKSi/GkueKHH35AnTp1UKdOHQwdOhTLly8HV4Vm27ZteOaZZ9C7d2+cOXMGe/fuRcuWLQEAv/zyCx555BFMnz4d6enpSE8X38b8/HwMHz4cf/zxB44dO4ZatWrhySefRH5+vkvukeI67uYLC0hy9qNQKBRfgzpuuxBH5goGRnNFj/rxLokUWrp0KYYOHQoASE5ORkFBAfbu3Yvu3bvj008/xaBBgzBt2jTT/k2aNAEAREVFQa1WIzQ0FPHx8ZKu2bVrV4u/lyxZgsjISPz+++/o06ePk3dEcSexoQGK7kehUCi+BtUkuRBPmiv+/vtvpKSkYNCgQQAAjUaD559/HsuWLQMAnD17Ft26dVP8unfv3sVrr72G2rVrIzw8HOHh4SgoKKD+UD5IUo0oJIQHQEh8Z2CMckuqEeXOZlEoFIrboJokF+JJc8XSpUuh1+tRuXJl0zZCCLRaLbKzsxEYGCj5nCqVymSu4+AyknOMGDEC9+7dw7x581CtWjX4+/ujbdu2KCsrk3cjFI+hVjGY0rc+Xl99GgxgoRHlBKcpfevTfEkUigLQXGTeCRWSXIinzBV6vR7ff/89vvjiCzzxxBMWvw0YMABr1qxB48aNsXfvXrz00ku85/Dz87Mp31GpUiVkZGSAEGJy5j579qzFPn/88QcWLVqEJ598EgBw48YN3L9/X6E7o7ib5IYJWDy0uU2epHiaJ4nyEOIqQYbmIvNeqJDkQjhzRUZuCa9fEgPjZKO0uWLr1q3Izs7Gyy+/jPDwcIvfBg4ciKVLl2Lu3Lno1q0batasiUGDBkGv12PHjh344IMPABjzJB08eBCDBg2Cv78/YmJi0LlzZ9y7dw9z5szBwIEDsXPnTuzYsQNhYWGm8z/22GNYtWoVWrZsiby8PLz//vuytFYU7yG5YQJ61I+nq1zKQ42rBBkuuMd6juCCexYPbU4FJQ9CfZJcCGeuAGDj1+FKc8XSpUvRvXt3GwEJMGqSzp49i7CwMPz444/YvHkzmjZtiq5du+L48eOm/aZPn45r166hZs2aqFSpEgCgXr16WLRoEb7++ms0adIEKSkpeO+99yzOv2zZMmRnZ6NZs2Z48cUXMWbMGMTGxip6fxT3o1YxaFszGv2bVkbbmtFUQKI8VLgqSpnmIvN+GGLtZPIQkpeXh/DwcOTm5lpoRQCgpKQEaWlpqFGjBgIC5JnFqCrVO1DiXVIolIcLA0vQYfY+wSAcziJwaEJXyYuHo1cz8cJ3xxzut250G7StGS3p3A8L9uZvJaDmNjdAzRUUCoXim0iJUpYqyNBcZN4PFZLcBGeuoFAovgeNPHp4caUgQ3OReT9USKJQKBQ7UHP5w40rBRlPBfdQxEMdtykUCkUAT5YVongHrkyq6qngHop4qJBEoVAoPNDIIwrgekGGy0UWH26piYoPD6Dh/14ANbdRKBQKD6502KX4Fq5OqkqDe7wXKiRRKBQKDzTyiGKOqwUZGtzjnVAhiUKhUHigkUcUa6gg8/BBfZIoFAqFB1c67FIoFN+ACkkUp5k6dSqaNm1q+nvEiBF46qmn3N6Oa9eugWEYm6K7FIocaOQRhUKhQlIFZsSIEWAYBgzDQKvV4tFHH8V7772HwsJCl153/vz5WLFihah9qWBD8WZo5BGF8nBDfZLcBWsArh8BCu4AIXFAtXaASu3yyyYnJ2P58uXQ6XT4448/MGrUKBQWFmLx4sUW++l0Omi1WkWuyVdYl0LxVWjkEYXy8EI1Se4gdTMwryGwsg/w88vG/85raNzuYvz9/REfH48qVapg8ODBGDJkCDZu3GgykS1btgyPPvoo/P39QQhBbm4uXnnlFcTGxiIsLAxdu3bFuXPnLM45a9YsxMXFITQ0FC+//DJKSiyje6zNbSzLYvbs2Xjsscfg7++PqlWr4tNPPwUA1KhRAwDQrFkzMAyDzp07m45bvnw56tWrh4CAANStWxeLFi2yuE5KSgqaNWuGgIAAtGzZEmfOnFHwyVEoD+Acdvs3rYy2NaOpgEShPCRQTZKrSd0MbBgGWKeky0s3bn/ue6B+P7c1JzAwEDqdDgBw5coVbNiwAT///DPUaqNWq3fv3oiKisL27dsRHh6OJUuWoFu3brh06RKioqKwYcMGTJkyBV9//TUef/xxrFq1CgsWLMCjjz4qeM2JEyfiu+++w9y5c9GhQwekp6fj4sWLAIyCTlJSEvbs2YMGDRrAz88PAPDdd99hypQpWLhwIZo1a4YzZ85g9OjRCA4OxvDhw1FYWIg+ffqga9euWL16NdLS0vDOO++4+OlRKBQK5WGCCkmuhDUAOyfARkACyrcxwM4Pgbq93WJ6S0lJwdq1a9GtWzcAQFlZGVatWoVKlSoBAPbt24c///wTd+/ehb+/PwDg888/x8aNG/HTTz/hlVdewbx58zBy5EiMGjUKAPDJJ59gz549Ntokjvz8fMyfPx8LFy7E8OHDAQA1a9ZEhw4dAMB07ejoaMTHx5uOmzFjBr744gs888wzAIwap9TUVCxZsgTDhw/HmjVrYDAYsGzZMgQFBaFBgwa4efMmXn/9daUfG4VCoVAeUqi5zZVcPwLk3bazAwHybhn3cxFbt25FSEgIAgIC0LZtW3Ts2BFfffUVAKBatWomIQUATp06hYKCAkRHRyMkJMT0Ly0tDVevXgUAXLhwAW3btrW4hvXf5ly4cAGlpaUmwUwM9+7dw40bN/Dyyy9btOOTTz6xaEeTJk0QFBQkqh0UCoVCoUiFapJcScEdZfeTQZcuXbB48WJotVokJiZaOGcHBwdb7MuyLBISEnDgwAGb80RERMi6fmBgoORjWJYFYDS5tW7d2uI3zixICK2XRXE/BpZQB26Kz0G/W/lQIcmVhMQpu58MgoOD8dhjj4nat3nz5sjIyIBGo0H16tV596lXrx6OHTuGYcOGmbYdO3ZM8Jy1atVCYGAg9u7dazLRmcP5IBkMBtO2uLg4VK5cGf/88w+GDBnCe9769etj1apVKC4uNgli9tpBoTjLzvPpNrW7EhSq3UWhuAr63ToHNbe5kmrtgLBE2Kai42CAsMrG/byA7t27o23btnjqqaewa9cuXLt2DUeOHMHHH3+MkydPAgDeeecdLFu2DMuWLcOlS5cwZcoU/PXXX4LnDAgIwIQJE/DBBx/g+++/x9WrV3Hs2DEsXboUABAbG4vAwEDs3LkTd+7cQW5uLgBjgsqZM2di/vz5uHTpEv78808sX74cX375JQBg8ODBUKlUePnll5Gamort27fj888/d/ETojys7DyfjtdXn7YpeJuRW4LXV5/GzvPpHmoZhSIM/W6dhwpJrkSlBpJnl/8hkLM3eZZbnLbFwDAMtm/fjo4dO2LkyJGoXbs2Bg0ahGvXriEuzqjtev755zF58mRMmDABLVq0wPXr1x06S0+aNAnjx4/H5MmTUa9ePTz//PO4e/cuAECj0WDBggVYsmQJEhMT0b9/fwDAqFGj8N///hcrVqxAo0aN0KlTJ6xYscKUMiAkJARbtmxBamoqmjVrhv/7v//D7NmzBdtAofBhYAmOXs3EprO3cPRqJgysrRnXwBJM25IqGH4BANO2pPIeS6F4CvrdKgNDqHMH8vLyEB4ejtzcXISFhVn8VlJSgrS0NNSoUQMBATILWaZuNka5mTtxh1U2CkhuDP9/2FHkXVIqDGLNEEevZuKF7xybcteNbkOLn1K8hoflu7U3fysB9UlyB/X7GcP8PZBxm0Kh2MKZIaxXiJwZwrzkyN18/vQW1ojdj0JxB/S7VQaPmtsOHjyIvn37IjExEQzDYOPGjRa/m9ce4/61adPGYp/S0lK8/fbbiImJQXBwMPr164ebN2+68S5EolIDNR4HGg00/rcCC0iEEBSU6JFTVIaCEj2NRKN4FVLNELGh4rSOYvejUNwB/W6VwaNCUmFhIZo0aYKFCxcK7pOcnIz09HTTv+3bt1v8PnbsWPz6669Yv349Dh06hIKCAvTp08ciWoriPnKLy3AxIx//3C/Av1lF+Od+AS5m5CO3uMzTTaNQAAApaVk2jqzmEADpuSVIScsCACTViEJCeIC98AskhBvDqn0dMT5aFN/gYfpuXYlHzW29evVCr1697O7D1R7jIzc3F0uXLsWqVavQvXt3AMDq1atRpUoV7NmzBz179lS8zRRhcovLcD2zyGa7zsDiemYRqkUD4YF+HmgZhfIAqWYItYrBlL718frq02BgmT+fm4Cm9K3v83lnaKh4xeJh+W5djddHtx04cACxsbGoXbs2Ro8ebYqKAowZonU6HZ544gnTtsTERDRs2BBHjghnsS4tLUVeXp7FP0dQk5F9CCG4nWN/8rmdU+LR50jfIQUQb164dv+BwJ/cMAGLhzZHfLjlsfHhARb+S74KDRWvmFT079YdeLXjdq9evfDss8+iWrVqSEtLw6RJk9C1a1ecOnUK/v7+yMjIgJ+fHyIjIy2Oi4uLQ0ZGhuB5Z86ciWnTpolqA5ehuqioSFb26IeFwlIDdAbW7j46A4vCUgNCAjzz2ZWVGU1+XNZuysMJZ4bIyC3h9UvimLfnEurEh5gmkuSGCehRP77CZS525KPFwOij1aN+vM/f68NIRf1u3YVXC0nPP/+86f83bNgQLVu2RLVq1bBt2zZT4VM+CCFgGOEPYOLEiXj33XdNf+fl5aFKlSq8+6rVakRERJg0WEFBQXbP/bBSVFwGonfsd1RUXAQN3G9yY1kW9+7dQ1BQEDQar/7sKS6GM0O8tvq0w32thQO1ivHpcGk+pPhoybl3WhLD81TE79Zd+NRskZCQgGrVquHy5csAgPj4eJSVlSE7O9tCm3T37l20ayecxdrf399U5V4MnE+UuamPYkmpzoB7BY6FJJLnh0ytZzQ5KpUKVatWpUIuBckNEzCuey3M3XNZcB9nhQNfwZWh4tTPieLr+JSQlJmZiRs3biAhwdi5WrRoAa1Wi927d+O5554DAKSnp+P8+fOYM2eOYtdlGAYJCQmIjY2FTqdT7LwVCQNLMPW7Y7hXUCq4T6UQf6wZ3cZjq0g/Pz+oVF7vhkdxE9Vjgh3vhIqfR8ZVoeJSclG5C6rVokjFo0JSQUEBrly5Yvo7LS0NZ8+eRVRUFKKiojB16lQMGDAACQkJuHbtGj766CPExMTg6aefBgCEh4fj5Zdfxvjx4xEdHY2oqCi89957aNSokSnaTUnUajX1Z7HDa93q4vVyEwZfJMWk/nURHET9uijeAc0jY8SRjxYDo6OvlFBxb/Rzolotihw8uqw+efIkmjVrhmbNmgEA3n33XTRr1gyTJ0+GWq3Gn3/+if79+6N27doYPnw4ateujaNHjyI0NNR0jrlz5+Kpp57Cc889h/bt2yMoKAhbtmyhwowHoJEUFF+C5pExwvloAYIVJiWHikvNReVqaPQeRS60dhtcX/vlYYOqtCm+Ajd5Avzaz4dJuFdS07Lp7C28s/6sw/3mD2qK/k0rS22qJAwsQYfZ+wSFNk5TdmhCVzpO+SC0dhvF56CRFBRfgdN+WgsH8Q+hGcaZUHHrhVFMiLjAGHeYMl0dveer0MWsOKiQRKFQHmpoHpkHyFng8Gmg4sP8ERGkRW6RTjE/J7nQQq+2UP8s8VAhiUKhPPRQ7ac8hCLY7uSVmrZ5uiQGddC3xBujDr0ZGg9NoVAoFMmIiWCLCNIiLsyzgRzOOOhXtIK/jt4ZYIw69PX7VBKqSaJQKBSKZMT4+uQU6bDm5eZQqRiPmTLlFnqtiCYp6p8lHapJolAoFIpkxPrw3C8sRdua0ejftDLa1oz2iK+X1PQkFTVlAPXPkg7VJHkZNOKAQqH4Ar7m6yPWQd8bE2Eqha+9M2+ACkleREVU71IolIqJKzJ1uxoxDvoV2STli+/M01Bzm5dQUdW7FAqlYuKKTN3eQEU2SVXUd+ZKqJDkBdCIAwqF4otUxFJEFd0kVRHfmSuh5jYvoCKrdyneB/V7oyhJRUvG+TCYpCraO3MlVEjyAiqyehegk7K7EPOcqd8bxRVUpGScclMG+BoV6Z25EiokeQEVWb1LJ2X3IOY500y7FIo4aE0/CgdDCHnoHV1cXUXYEVyVakfqXV+rUi00KT+MFdZdiZjn3KN+vNdVQqcaRvoMAO9+Bt7cNooRV8/fVJPkBVRE9W5FzjXiTYh9zqEBWq/ye6MaRvoMAO9/BtQkRaHRbV5CRYs4kOKMTpGP2Od89GqmqPO5w++NprugzwBw/TOoaHXXKJ6BapK8iIoUcVDRndG9BfHPT9wE4Wq/N6phpM8AcP0z8HYNFcV3oJokL4NT73qyzpESVGRndG9C7PNr+2iM7EroSkI1jPQZAK59BlRLR1ESKiRRXAKXa8TTk3JFR+xzblMz2isy7VINI30GgOueAU3MS1EaKiRRXAJNf+8epDxnb/B7e5g0jEI+MQ/TMxDCVc+AaukoSkN9kigug+YacQ9SnrOn/d4ehmzGgH2fmB714x+KZ2APV30HVEtHURqaJwmez5Pkq4jNIfIw5Rrx5L36ynPmfEYA/nQX1lotX7kvDjF5qwBIegYVEanfgRiOXs3EC98dc7jfutFtXBra72vfrC/j6vmbCkmgQpIcaPSILfSZiEfss/K1Z8olhhWTtHN3aoZP3ZsrUPr9ekNiXl/7Zn0dKiS5ASokSYNm0raFPhPpOFpte/KZytUESNVkUI2D8loXV2iopF6bjgPug2bcpngVrs5v4ouTBs17Iw972Yw9+Uyd0QRI9YmhGZ2Vfwae8oWk40DFhApJFElIiR6ROvD5qpralc/kYcVTz9TZIsA0cs078ESAAh0HKiZUSKJIQsnoEXOt0bX7RZi355JPVqinETXK44lnqoQmwBuj93xNO6tUe+VqqORen44DFRMqJFEkodRKmU9rxIcvqKmp9kB5PPFMldAEeFuxal/Tznq6vc5cn44DFROaTJIiCSUyaQuVDRDC2xPA0eziyuOJZ6qUJsAbknYCvleew9Ptdfb6dByomFAhiSIJZzNp2zNpOMJb1dQ0u7jyeOKZKqkJSG6YgEMTumLd6DaYP6gp1o1ug0MTurpNQPK18hyebq8S16fjQMWECkkUyTizUnZk0rCHN6upvUV7UJFw9zNVWhPgyWLVri7PIVRyRS6eLiei1PXpOFDxoD5JFFnIjR6Row3ylTINni75URFx5zP1Nn8iZ3ClE7Er/IY87fSs5PUf9nHA1wIFHEGFJIps5ESPSNUG+drkRPPeKI87n2lFqTfoKidiZ1MkONsOV2mTlb7+wzoOeNrx3hVQIYliF6VXBY5CpK3xtcmJ4hzesAqtCJoAV6QicGWyRE+nTvD09T2JUn3OVQK0p6FCEgUAf0dxpraUUMdzZNIgAMZ1r4XqMcE+OTlR5ONNq1Bf1wS4wnToymSJnjZ1evr6nkKpPleRs43T2m2gtdv4OkpEkBY5RTqbfcXUIBLT8bxpQjTHGzQZDyO05pVrULKfbTp7C++sP+twv/mDmqJ/08pSmwrA8+OCp6/vTpTsc1JrFioJrd1GcSlCHYVPQAIcrwrEqlyTGyaga904rDp6DdezilAtKggvtq0OP43nAi49MUBSoaxir0I9jZKmQ3f4DYlpryv7TEUwtYpB6T7nacd7V0KFpIcYuTmLhNTqUjoenynvv4fSPLZi84Q9/WFatdqD1rxyLUqZDt3lt2Ovve7oM75uahWD0n3O0473roTmSXITSucVUQJnchYBtqsCsR1v4b4rXpUJ2BOJ7DydXdibqMir0IqEp5Ml0j6jHEr3uYqcbZwKSW5g5/l0dJi9Dy98dwzvrD+LF747hg6z9wl2ancJVM5OOtarArHnW344zasyAbs7kZ2nswt7GxV5FVrR8FSyRNpnlMUVKQ8qarZxjwpJBw8eRN++fZGYmAiGYbBx40bTbzqdDhMmTECjRo0QHByMxMREDBs2DLdv37Y4R+fOncEwjMW/QYMGuflOhJG6+pEqUDmD3ElHaFUg9nw5xfz+ToBn6rS5W5Ph6ezC3kZFXoVWRDxRcsWVfcYbtfyuxhV9rqJmG/eoT1JhYSGaNGmCl156CQMGDLD4raioCKdPn8akSZPQpEkTZGdnY+zYsejXrx9Onjxpse/o0aMxffp009+BgYFuab8jpDrHudsvRmrOIuDBqmBS73o2zo1ifBbCA7V2hSQOd5pWYkL8Fd3PEdS8ZMnDGn7ty7jbb8cVfcbAEizcdwXLD6dZjElSfZx8MfjCVX2uIjq+e1RI6tWrF3r16sX7W3h4OHbv3m2x7auvvkJSUhL+/fdfVK1a1bQ9KCgI8fHxLm2rHKSsfpJqRLk9wkdMziLrVADx4QHo1yQBM7Zd4HWedNTxXmpfHXP3XHbYtvv5pdh09pZ7OplYCVGhBSY1L9lSUTJdU1yD0n1m5/l0fPjLn7xRvFIWpb4cfOGqPlfRHN99KrotNzcXDMMgIiLCYvuaNWuwevVqxMXFoVevXpgyZQpCQ0MFz1NaWorS0lLT33l5eS5pr5TVj6cifBx1FOtVQXZhGd5ca1/b5eh860/csKu9UjHAjG0XTH+7etC5X1jqeCcJ+zniYc7ua4+KuAr1VbxNO6Jkn9l5Ph2vrT4t+LvYRWlFyDBN+5xjfEZIKikpwYcffojBgwdbJIwaMmQIatSogfj4eJw/fx4TJ07EuXPnbLRQ5sycORPTpk1zeZulrH48aYJx1FE4oczAEnSYvc+htuvQhK52zyekbeKwdglw9aDjbs0ONS8JU9FWob6IN2pHlOoznAuEIxwtSitSbi/a5+zjE9FtOp0OgwYNAsuyWLRokcVvo0ePRvfu3dGwYUMMGjQIP/30E/bs2YPTp4VXChMnTkRubq7p340bN1zSbinOcZ42wXAdpX/TymhbM5q3Y0vRdtk7n5CDn9BY4uroFU84DldUJ0eKb+PNYfZK9BmpaU+EFqWeCL54GB3MvQGv1yTpdDo899xzSEtLw759+xymHW/evDm0Wi0uX76M5s2b8+7j7+8Pf39lnHDtIWX14wsmGCW1Xdbaq/v5pRYmNmtcmVDQU5odquqmeBO+oB1xts9I1cQLLUrdrfn3Ru3ew4JXa5I4Aeny5cvYs2cPoqMdT45//fUXdDodEhK848MRu/rxhTwTrsitwWmbYkLFCa2uivhSWrMjdtUnRoNHobgDX0lN4UyfkaKJt6c9dqfm35u1ew8DHtUkFRQU4MqVK6a/09LScPbsWURFRSExMREDBw7E6dOnsXXrVhgMBmRkZAAAoqKi4Ofnh6tXr2LNmjV48sknERMTg9TUVIwfPx7NmjVD+/btPXVbNohd/Xh7hI8rtV2eNjcCyml2tv8vHR9vOo+swjLTNrrqo3g7D0NqCrFpTxjYX5RKGQudcYL3Be1eRYchhHjMsHngwAF06dLFZvvw4cMxdepU1KhRg/e4/fv3o3Pnzrhx4waGDh2K8+fPo6CgAFWqVEHv3r0xZcoUREWJn6hdXUVYKt4WWWIOt6oB+M1Scv1pOKdwR4POoQldveZZ8DFzeyqWHEzj/Y0BrWZP8V48WcndnQiNYRyRQVrMfKaRqPB/R2MhAKfMZA/LO3EGV8/fHhWSvAVvE5K8HVfZx10lgLmL7f+7jTfWnrG7T4KCgp43C9MU36OiLFTEwDeGRQRq8VL76niray3R92dvLATAmyJAyni26ewtvLP+rMN2zB/UFP2bVhbV5oqGq+dvr3fcpngfrnI49nZzoz0MLMHHm8473E8p53NXO3JSAcy3UOJ9PUypKZQaw4TOA0BUuhRHZjJPuyHQcYAKSRSZuCq3hq9GfKWkZSGr0HG5FcB5nw5XJ7GjkTS+hZLvy5cXKlJRagzjO8/Rq5mKJAf2ZNQzHQeMUCHJy6CSu28mN5Mi+Diz6nO1I2dFyCL8MOGK9+WrCxVvQikneE9p9+g48AAqJHkRVHL3XcQKPtHBfk6t+lxZvoZG0vgWrnxfvrhQ8SaUNJO5W7tHxwFLqJDkJVDJ3b0orbHj1OKOsvnO6N/Qqeu4MkzbU/UDKfKg78t7ccZMxjc2JTdMQNe6cVh19BquZxWhWlQQXmxbHX4a5VMd0u/KEiokeQG+Krn7qmnQFRo7c7W4ULjoqx1r4MnGzgm6rnTkfBjy5FQk6PvyXuSayYTGpn5NErD5XLrF9v8eSnOJJol+V5Z4dcbthwVfyXRrzs7z6egwex9e+O4Y3ll/Fi98dwwdZu/z+uyvrsxey6nFE6yydkcFa7FocDNMfLK+7HNzuLLOnKcjaSjSeNjelxK1y9xZ/0xqFn+hsSk9twRLDqa5LeP2w/ZdOYJqkrwAX5PcfdU06A6NnaudXl3pyCkmG7HShX4p8hFj0okL8wdLCDadveVT2l5rlND+esLnU+x4YG9sEsJVVgZfqCPqTqgmyQvwJcndkaABGDutN1aodpfGztX12OytUL8e3AzhgX6yVsrm9QOF6NckwScn2YqIo3qPBECJnsWQ/x73KW2vNUpofz1Z/0zMeOBobBLCFVYGX6gj6k6oJskL8CXJ3Zed+nxNY2cPvhVqdmEZZmxzbqWc3DABr3SsIVha5duDaWhWNdIrNYW+hFL+fEKRT+FBWuQU6ZBTZJm7y9u1vdYoof0Vc46pm/9CaIAW9wtKPaJxc3bMUXrMepjyZTmCCklegC9luvVlQcObNXZyJk3zMO2d59Px5lrnTaAGlmDzOfuram8MIvAllDb7WAvMMcH+GP/jOQC2yU29ORCEDyUWZWLOkZFXiiH/PW7a5u7UK86OOa4Ys2i+LCPU3OYlSHXy8xSuEDTc5UzpSqdnZ3DWCV5JE6gvBhH4Eq4y+5ibdFQqBhl5FeMdKrEok7Ngc4cZzhxHY5MQrh6zXO064AtQTZIX4QuSu9KmQXc6U3qjxk4JJ3glTaC+rCn0dtyV6kPJd+jpNB9KLMrkaFncrXGzNzYJ4W1WhooK1SR5Gd4uuSvp1OcJZ0pv0tgppQFSclL0ZpOkr+MuLZ1S79Ab0nwoof2Vq6Vxt8ZNaGxKCA/Aqx1r2KQW8TYrQ0WFapIoklHCqc+TCTQ9qbEzX5nfzy9VRAOkpGDjS0EESuEubYm7tHRKvENvSfOhhPZXjpbGHHdq3OyNTR8k1/NqK0NFhQpJFFk4K2h4OkrOFbWpHA2UfKZFMTgapJNqRCGiPJqJDymCjTeaJF2JO8297tLSOfsOva0CgBKLMqFziEGMxk3Jb0hobKL19DwDFZJciKft+UrDdz9yO21F831xNFAKrczF4GiQ3p2aISggAcaJTYpgIzShRAZr8XTTyggP9IOBJR77lpXqV+7WlrhTS+eMYOHpBQwfSmh/haIA7+T5vsaN4jqokOQiPJHd1ZUofT8VyffF0UD59eBmmLHtgmQBScwgza367RERpEWP+vGSrm0+oexOzcDGs7eRVViGpYevYenhax77lpX6Dj2hLXG3lk6uYOGtCxglNCnW55jaT9gMRwAMalVF8FzepnGjuAbquO0CPJnd1RVs/186XlP4frw1HF8qYpyvP950XrKKX+ykKSZTb06RTpbzqVrFILe4DMsPX0NWYZnFb574lpXsV55KdeDuwAE5gSAVaQHjCKH3wTF3z2VBZ3WaLuPhgApJCuPLZTv42P6/23hr3Wne35y5n4qS+l7MQJlVKGwKE0LspOnKVb83fctKt8WT2pLkhgk4NKEr1o1ug/mDmmLd6DY4NKGr12iYfW0B42yeNe59jOtem/d3ISHcWzVuFGWh5jaFcYc9312+TjvPp+ONtWfs7uPM/VSE1PdKDoCTetdDTKi/pHfqylW/N/mmKN0WT2tLvNkJ15ec95V0A1h/4l/e7UKmM09/QxT3QIUkhXH16sJdvk5ifF3MkXs/3hKOL/e6SgyAnO/RiPY1JF/fkTMwAEQFa9GiWqTkdol9pxm5xZLPLRWl+9XDmOpACr6wgFHSaVqsEH7saiba14oBQL8hcypakJI5VEhSGFeuLsQ4CEcG+yvyoUqtSm1+P1I7jCdW1UoJm2KEFHs4uzIXkwMmq1CHTv/ZL/nexH6jM7ZdQKCfGskNE1w2WIpty/38UlGRd46eG4FRs1dRBno5iF3AeGKCVNppWqxw/eba05g1oBGSGyb4lMbNlVS0ICVrGEKIbzjHuJC8vDyEh4cjNzcXYWFhTp3LwBJ0mL3P4eri0ISukjoPd157gouKAczN8c58qJvO3sI768+K2jfB7H58ocM4Csd/uX11dK8fL3qw584HSE9Up9SzcZSDibsLKatrR9+y9blf6VgDm8+lu+Tdi22L1Gvae27e9t16I57q70evZuKF74453G/d6DaiFmBizwcYv3fzfuQLY56rEBpL5Yw3clFy/uaDCklQ/iELTZrOfDhSOrG7r/dN+fm9ocM4QoywyWFvoLNePWcXlmHGNmmJ6t7qUhPjetRRbKVZpmfRZuZem0g0DjkCujP5nbhrAsq8e7HCqNRrbv9fOt5YaxucwJ1HSQ1tRcKT/V3sIm7+oKbo37Syw/2kCOF8/agim5uEcDSWylUISMXVQhKNbnMBQmGlcWH+GNu9Fkr1rOQoDDk+P85EIImpd6RigEWDm5vMLN4SCWUPKWZEoagWvppWM7alYlLvelg3ug3e6lJT1PnbP1ZJ0cHj1PVsQQEJkBeSzH3LUcFaWW1S8t07CteWc00DSzBjG7/vHSn/99a6Mx6tX+aNeLq/K+3WYB5t6wi+fuTtNTddwcOSAoEKSS7COszXGF7KYO6ey7IGW7kOwnI/VHsh+hwLX2iGJxsbV4q+0GEMLMHhK/dF78832Avl6knPLcEba88gu7AU43rUcShgRgRpFXfodFXQQHLDBEzq00BOkwAo++65fjWpdz1R11xxOM3uRC1GaLY+3FfznSmJp/u7K9IUcEJ4RKC4BcHDHtr/sKRAoEKSC+FWF/4aFebtuYSMPPlJ8ORWsuaQ86Haq0r9zdDmeLJxouTze6rDcNqfhfuvSDrOfLC3t3rmeGvdGew6n4Epfevb3S+nSIfdqRmS2uIIVwYNxIc5H8Wn1LtXqxjEhPqL2nfGtgt2FyN7ZLwDb9KMegpP93dX5VlLbpiAEe2qi9rXVaH9zuZ9chcPSwoEGt3mYpSKwnC2krXcD1VshIs3dxhn/WoA42AvVuvwxtrTWDS4mcOis0qULDD3hYgJ9kd8WIBTtaiEcDaKD3Du3Vv7fEQF+Yk+VigkfOf5dCw9fE1WezxRv8yb8Ib+7oo0BQaWCOZLMsdVyTR9yQn8YUmBIFtIYlkWV65cwd27d8GyrMVvHTt2dLphFQUlk+DJqWStxIcqJkTfWzuMGO2PGGJDAyStij/edN5h0VlnJ1m+ATXEXy34/AHXphoQwtl3z3efUu6AbzEiNQ+YEL5uSpBLi2qRNtG01qgYyMrPJQWl86ylpGUhI6/U4X6DWlVV3O/IE8VynXE4f1hSIMgSko4dO4bBgwfj+vXrsA6OYxgGBoNBkcZVBJRWS3ODwrGrmXhz7WnkFDsueeGOD9VbO4zUfE98cKvGY1czRR8jthSJM0lF+QbUglL+vqdEEkBOSJ+6OdXCdJwQHoB+TRLw7cE0AMq+e6H7lCr0WgulSnwXgHeaEtwRaXXqerZdAQkwClCnrme7XNOmZJ41sf2xekyQItfj8ESxXCW0Vr6QdNRZZAlJr732Glq2bIlt27YhISEBDOPbkqIrcYVaWq1ioFIxogSksd1ru+1D9cYOo8RKv18TY+I42Q5hdpAzyUrVjo3rXgtvda2l4ERpeWVCCJpVjcTioZGKmz6U0AKaw30Pzn4X7tCMyhF23GWu8bRPklJYP+OYEHG+bkoLx+4uAaSk1sqTVRPcgSwh6fLly/jpp5/w2GOPKd2eCoerzFCeWvE4wts6jBKD2eZz6fgguR7uFzhWw5sTFeyH7MIyUe/derBuUS0Sp65nIyO3GFmFZYgKMfobJdWIkqQFYQCsP3EDb3WtJantfAgNrHfySk0D66EJXRU1fSih7TGH+x6kfBee0IzKEXbcaa7xBp8kZ+F7xnGhfmAYwF72QFeYEd0pdLpCa+XNtQidRZaQ1Lp1a1y5coUKSSJwlRnKmwcpb+owSjgccys4Kc8yKliLaf0aYMy6Mw7fO99gLeTvkRAegCcbxotuh1IrUCkDq7tNH2KwFkrFLl4m9a5vkyRUjHZMSOgVIzzKEXbcba4R069ckeZCKQQF/nzhPGMcLAEW7L2M9o/FuL3szrX7RU5fy5sKV/sCsoSkt99+G+PHj0dGRgYaNWoErdYyr0Tjxo0VaVxFwRVmKG91lPY2nI0K5LibX4I+jRNFC1xZhTp8tv0Cb6kO8/cuNFgL+Xuk55bIishyVuDwxMCqlIDPtxgRu3hJbpiAng2laUbFCL1CWiG5wo673w/3/F5bbZupnINLcyGlDI47NNBKmHEX7r+ChfuvKGbKFLuYm7fnEurEhzh1vYpiKnUXsoSkAQMGAABGjhxp2sYwDAgh1HFbAKXNUN7qKO2NyIkKtCY2NECywJWRW4JvD6YJlrVwZrCWKvA5K3B4YmDNLpRm3mQAhAdpEaBRWziWCy1GxC5epGhGxQq9QlohucKOJ95Pj/rxiqW5cGfou5JmXKVMmWKETg5nNYLebIXwRmQJSWlpaUq346FAaTOUNzpKeyvmQuqO8+n4/uh1UcdZa+SkCFzcyn/Gtgu89YucGaylCEhK5HRx98BqLBdyQfT+3JOd9Uwjm8UIZ+radPYWr+nr9/e7iDaFOWqzWKFXSCskV9jxxMSXkpalSJoLd4e+KykoKmnKTG6YgHHda2Hunst2r+esRpBaIaQhS0iqVq2a0u2okLhDfextjtKuQMxzdLSP+e/VoqQ5s1tr5Myf+eEr97Bw/1XBY+0Nau5SZyuhUXT3wHrsn0xJAqT1woB71jvPp6PTf/aLMn05KoTq6BuTKvTyfRtyhR1PTHxKaK88EfqutIZESVNm9ZhgUfs5M3ZQK4Q0ZCeTvHr1KubNm4cLFy6AYRjUq1cP77zzDmrWFFfcs6LjTvWxuYaqolWj5nuOEYFavNS+uims3dGzluIYbY6998U9c2cmCmcHa3vRc4DxHhe+oMwq3B0DK/ft7k7NwA8nb4g6ZljbaujVMIH3O3fW9GV9Lkf9We7EZX6cXGHHExOfEtorT/i6iXnGfGZbRyix6HGXRpBaIcQjq3bbrl27UL9+faSkpKBx48Zo2LAhjh8/jgYNGmD37t2iz3Pw4EH07dsXiYmJYBgGGzdutPidEIKpU6ciMTERgYGB6Ny5M/766y+LfUpLS/H2228jJiYGwcHB6NevH27evCnnthRDqAiqqwtj8lWn9+WK5ULPMadYh7l7LqPFJ7sxc3uq3Wct9LsjAWlc91o4NKGrw8HCmUFNbj0+BsYJ+pP+DU1/82FegFgJhGr5xYcHOG0SMf92lx2+hkKBpJjW9GqYwFt1XarpCxCuxSa2P8uduMyPE1uTDIBNfS9Xvh8+nC0yK6XgtJJaVzHPeNYzjXD4Q2OB8re6iFv4xwT7O11zTcyYEB/mL1sjaF4XLjzQD7+/38VUhH3d6DaixryHDYZYp8wWQbNmzdCzZ0/MmjXLYvuHH36I3377DadPO3Y+A4AdO3bg8OHDaN68OQYMGIBff/0VTz31lOn32bNn49NPP8WKFStQu3ZtfPLJJzh48CD+/vtvhIaGAgBef/11bNmyBStWrEB0dDTGjx+PrKwsnDp1Cmq1WlQ78vLyEB4ejtzcXISFhYl7CAIYWIIOs/cJro64lSCfj4ozCK2auSu4YpB0JY6eo1jElE4QE3XkqJ2OVv5C75t7b4B4PyMGD96nJ2o9Ka2tlFNbz9FzPXo1Ey98d0xyW9aNbmOhsZDSnwHY/Rak3IO99wrA7jt3pzZ55/l0u87G3wiMO3z3Zw/r96IEYvuOmD7Op3mS2w8djQkRQVrMeqaRrPP6Sl04KSg5f/MhS0gKCAjAn3/+iVq1LBPUXbp0CY0bN0ZJifSJjWEYCyGJEILExESMHTsWEyZMAGDUGsXFxWH27Nl49dVXkZubi0qVKmHVqlV4/vnnAQC3b99GlSpVsH37dvTs2VPUtZV8yGIHZyU7vacEM1cid5KTw6Te9RAT6i97Qtn+v3S8sdZ2ohAroErNk8Q3iIuZFL3RFCtXGDYXFPnYdPYW3ll/VnJ75g9qauGbJLU/ixV6xXwbfO9rd2qGVy2G5AhJUoRiV49dYvuE0Hu1F2Uq9Z2Yt+Xa/SIsP5zGW1VBzruuaItoc1wtJMnySapUqRLOnj1rIySdPXsWsbGxijQsLS0NGRkZeOKJJ0zb/P390alTJxw5cgSvvvoqTp06BZ1OZ7FPYmIiGjZsiCNHjogWkpTEE6G4FTE5mDtzdMSE+jt02hVi5/l0zNjGXyhVrH2fz/neXsZt60GcL2rSevDPLiyzSYroyVUk177DV+5JFpDErKSVMH0B0vuzkK+HtdAr5tuwfq+ecHK2h6MiwXztkWIGdYcTsdiIY6H3GhfmjxI9yxvlJ+WdCC2U+JD6rr3tu/E1ZAlJo0ePxiuvvIJ//vkH7dq1A8MwOHToEGbPno3x48cr0rCMjAwAQFxcnMX2uLg4XL9+3bSPn58fIiMjbfbhjuejtLQUpaUPcrDk5eUp0mbANY539lY7rrTre1Lz4M4cHXKv5WhFPKl3PdECiJDzfXx4IPo1rSzpuYs1Zbiyurg9pJparBnetrrD9krNtC7kEC2nP9sTesVEXwr1NW9bDMlpj5QIQG9zIjZ/r9ziJauoDF/LjG7lkJpQVux5OaS+J6Fv0Rs10e5AlpA0adIkhIaG4osvvsDEiRMBGDU4U6dOxZgxYxRtoHXxXC5hpT0c7TNz5kxMmzZNkfZZo3QorlTfBHtIEQYc2a9d3WG456iETxIh/CpxZ8KiHa2IufxIPRsmOC3gSNH4SDFleGIVKcf/yJoFey+jXkKoQy2M2MSf9jQWzkSbWU9e9iZJMe/c2zIly2mP2GPe6lIT43rU8bpJWK1ikFtchjm7/pY0Ngndt7PZv8U8TynvSehb7NckwaZyQEXwZxKDrOg2hmEwbtw43Lx5E7m5ucjNzcXNmzfxzjvvOBRgxBIfHw8ANhqhu3fvmrRL8fHxKCsrQ3Z2tuA+fEycONHU7tzcXNy4IS7cWAxio1PEdH6hqJr03BK8tvo0XuP5jQ9HUSZir2seMaZ0FJ151MXRq5kAHkTxOMPox2vwbndWlS9ldSYWZ6Mi5Qy4jtpp/V7kROw40z4hhCLRzBGK9rJ+3faiv5Tsz3xIeefelilZTnvEHtP+sUpeJyABwu/LEUL37Wz2bzHPU0pdOKH5ZsnBNMnjkpJjhyeRnSeJg4syU5oaNWogPj4eu3fvRrNmzQAAZWVl+P333zF79mwAQIsWLaDVarF7924899xzAID09HScP38ec+bMETy3v78//P39XdJuQJkcFM5OKCqwSFJdRCxycBcRGNHnBVGDjiP7NQAsOWibcd0Z04316kUFFsmh/+DVZkHY8EQlvPaHP7KKWUnnBIBx3WujTnwIwoNu2vgMRARpMVNGhAiHo9UZ9/y1F24BqnpAtXaASjjaUgm/AWcGXL77UToaRkz7rL/bFLYuWKu1nBRTgxzTF985XJFTRuo7d0fCSCkaYjntEWMGjQrWIiOvBEevZsrSULtKyy1nTHb0TuRq/YTOy3fvYt5TXJg/1qX8K3mBJTQuVaRIOtFCUvPmzbF3715ERkaiWbNmdjVGYlMAFBQU4MqVK6a/09LScPbsWURFRaFq1aoYO3YsPvvsM9SqVQu1atXCZ599hqCgIAwePBgAEB4ejpdffhnjx49HdHQ0oqKi8N5776FRo0bo3r272FtzCc5mwnZmwuupSsEU7fdIZMy0A7uXAerZQP1+LrmuXNONtfnF1HZdFpBi3HYqLBHb6ozFx3/X4I324CM+zB+1YkMETTvZdsopiMHe6szi+Z+E8V9YIpAs/PyV8DdxxsxifT+uKBXhqH183+1tEoVpumHYxSZJPh+HFNOXEK7IbC/1nTuTMFKM4CB1YpPTHjFm0KxCHcb9cNbh9flw5eQsdWwUo2mUo/UTOq+9e3f0nl5Iqmq3HIoQfOOSu8vMuBrRQlL//v1N2pf+/fsrYlY7efIkunTpYvr73XffBQAMHz4cK1aswAcffIDi4mK88cYbyM7ORuvWrfHbb79ZaK/mzp0LjUaD5557DsXFxejWrRtWrFghOkeSK3GmVpvcCa+nKgWLtfNsf8hLBzYMA577nn+iZg3A9SPQXriANqpc3hW8I6Q6jlqvzOy1vU/eBPR6diVSAjqYQmTn7blkui4H91VO7lMfM7bZ9xlyxhdHaHUm9/kr4W8id8C1XpG6KhrGkWDJ99zikYXF2nl4QzcGOQiz0DC5zKxU3hdQcAcIiTNpAeX0Z3vCiZx3LkertfN8OqZu/gsZeQ+CVeLD/DG1XwOTf+HCfVcwt7w/meNoYpPTHin1D6VMrK6enKWOyWI0jUk1ohAf5m/xbqSc1zxL/bLD12z2Nb93e++pVC9dU28O92wqYiSdrDxJFQ1X51mQg5w8QSqwOOQ/BvHIEggfZYwajbF/Wpp+UjcDOycAebdNm+yt4B1hnWtGCPN7lNN2eyun8EA/h89PBRZb+qrQIKzYYjIUi3XuFFnPv3xCvnT1Cibvu+9QOLWXX8tR0jue1gCwzZHiqlxfQu1z9NxYAhCooGYeDOR3EI2YZ+dC3aC/6OvztcdGgLm4xaYvONICCuFIq+HMc5aS38deHqNXO9bAprO37U7SYnIVGfR6XDy+C8XZtxAYWRl1W/eEWmN/Dc4JZ8sO/YPcEr3d6yeGaXFwUADUhXd5+6o7csWJfV9vdXkM7R+LEa1pnL/nkqAWx9z83L5pA1Rt1h1JNSsJlmPiw/zeAfB+N87mpeO+UU/kCfTKPEmPPvooTpw4gehoy5vMyclB8+bN8c8//yjSuIcZqSHMAJCkumhpYrOBAHm3jKvkGo8bN6VuNmo4rK7CreBf142VLCiJXeFb1KwS2/YdHwBVWgOhCUiu307QBLLp7C271zaZdnY/uGZpUDw0veeInnitV8SSn7+ZcFobwHo/YeFUjL+JlIguQHil66ooKqH2OXpuxnnGcqUbiywwPw4HGAHNqAO4CeZObpFpEvoz8D5GG34AY/3k+LSAAtom8/M70mr0qB8v28dIjFbLwBJ8+MufAIR9vfj8C61xqCFO3Qz1zgloYC5YHo4GGj8P1HlScPGxOzUD8/ZccvidPqFKwZTS76H+3uwbsRJc3ZEeQawP1rgetSUJYlxRW+t3FIl8TNKuetA3UgHcNN73TraVpChW83vnu3858w1HRJDW9I3ezStEG1WqXZ9CwL158JxFlpB07do1GAy2tZVKS0s9XjfNm3DGgVDqhAcAscgR17CCO8b/sgbjJM1zdi753RTtKuwubSnK9CbVcdQi6kVs20/81/gPAMISoU6ejbY8k6Qc0462MAPMj8Nw5uYCNOs5XFRzzH1VtKk3gFMiDiq441A4tTYvnWDrioqiEjJlJIQHYFLveogM9nf4PboyioqvfaLfvRkMp7zf+SFQt7csDeATqhRM8TfzgTIY00XYFs4yu1btZODQXOD4YqDYLKrWbNIWE/zAmRxcWZT22NVM5BTpJPt6CXE3v8R2TCs5BPWPw2EzhhRlAscWGf9Za+JYAwzXDuPIxn1orQq2qz0Va752R3oEVxURjg0N4H1HvDaevHSQDcNwQPM+CJpKuo69eze/N6m81K6G8Z5TNyN59/vo7/cgIl3oO3NnHjxnkSQkbd682fT/d+3ahfDwcNPfBoMBe/fuRY0a/CHXDxtKOBBKsd0DwF1EiGtcSHl6hOtHLM0KVqgYIBGZSFJdxDG2vilfxrflq0/GauUjdiLnMF+9iG67OXm3Bf18hFZGKrCYov3edH/W98sSIO7INOxM7IbkRo84bgNrgPr6EbS9vB04v1pcu4NigE2vQ1A4BfC1dqGFeak4MB6Bqv8A4NeaWE9ev7/fRVIElzmuiKKy177HCgHsXij6XA/g0YyKaMe0Lal4QmDyFXa1LL/WnEeBsnzbn80m7RT/9g77K7ey5/q4tc9QnJnPkFyO/nPfoa+XFE3xtftFFiYtFVgcDRiHWBD7RZrNBRoA2DkB6rzbmA4AdrSn9voqrIRkpQR7RwtbV0Q6JpUcQhu/ebxCke33aLzvMbql2ID5kvxGxTyj8CAtb/ZwISKCtHir62OmRZ+fA4uEEhGY7kaSkMTVVWMYBsOHW660tVotqlevji+++EKxxvkqSjoQmmsqhJzzOGIbdAK5swxMXjoE0yeGJRrV38ADjZID3msXDl29NqYBo1nVSBzYuAxjdP+1WPk4msitMV+9nGDr4jaJsuPPYwcebYIzpp1EZOKTzT+jR4Mx9gULHl8u+zAgYYlITc+3NE1YtwEAGEvzUmDxHUGB0J5ALqfciqMVMwEwqFUVbP3fbVECmMP2sfHA8UTjZCon6YXI7xgwmmXu5BZhir/Q5OsAPgEJgPmkndF5p6hTmRdDFc7CJB+GOF4QiNEUMzBOnuamMRVYjFDvRBwyRbSk/Nlseadc+ybOtC/FfJ1Uo4PTgr3Yha2ikY6sAepdHxp9Gq0OFxLYGRAkMplorUrFUbahw0uIvXc5SV5nPdMIarAmi4R1k82/sz3l35kry8y4AknhSyzLgmVZVK1aFXfv3jX9zbIsSktL8ffff6NPnz6uaqtPIFbVLiWxFud/MLlvA7zaUVhTt/nPe9iW+A4I+D7X8r+TZz0QJkKEE26a07JebbRVpUL918/A1QNIvrcCM/VzkGA1gJkm8tTNAmcqhzUAaX8Af/6E5OArWDykCWLDgzBNN8z4s6SeaqZNsIIvmaBY007zoqP2E0Fy5jLRAhJAQDCxaAiWbJfjIFn+UHZ+aHx+5Vgnt1OBRRtVKlrl78OKtaux80955m+hRIzhQVpEBGkxd89lUYlERSVLVKmN5hgAsoSDTOGyENbczX/gO6b8OG38Fv1uinu/98szHL+++rSVwATcyROXQNSEWZ9C2h8Aa8ATIf/YvU8VAyQyRk2xPYjVf3uqUnDIfwwma0VqTrmji7MgpD0FjBOpysz3TIr7gLNJP6UmcuXG5P5NK5vSM8iiXJsv5+hvtV8iWWX/WxNz72LyP1kfmhAe8KB4sRiLBJOJnqH/+Fz4PyDTJyktzbGz38OKWAfCY1cz0b5WjPgTl9vxi0/vQxs7dvy3zlbBFtU7tnmSwhKNApK5FqJaO+N2e5qnwEijaciqE/B3t/IV444JgF8I8O8R46YajwPVOxgnQx7tS3JYInr0m4WUgDE4+XcNNDk/E/5FGbxXEERAm8Ct+ubuvoSF+6/gHsRFPzylOYyVlzP4V4p2fLmEIACySQg2FDR2OCnZPYuZeYkvhYL1e7/z82IYVPKiwCxWzHmF0F09jIOnzxsdMvHg+xPSkEoKB67fz6gls/o2DEQFFVg7ZjAAB2YCsfVEOXDHhgbI8oGSQp3sg1Chp8OkmF/tuwKVysZNHIDEcGk+jWZYIhrUE/fO7T2PhPAADGpVxRR9Jegj5CScBneEeidWGJLBQiXZfUCuKUzoOzV3pN686Qp61H3TYcSeZCRoQa0JZUqwWLsAS/T/YJZhMO8+kcFaPN20MsID/WBgCe93JCb/E0uA/3uyHmLD/G3HQ5H3sLBvIlQ+JiABTmTcLiwsxO+//45///0XZWVlFr8pXb/NlzB3jrOXPfjNtacxa4BAxmfryJmiTGDXRFF2fADYxSZhd2lL07WL/GMwsMezSK7/iK3NveescsdLAcNKcRZQLOUJECD/NrD66Qeb/vgPEBgFNBsKHPkKNsJFXjrUPw5H2+e+B54cASS/CBz/Btj1kfjL8mjFzO81Mkgr5SYQw+ThxMHt+Io1rk4t1O4OVk58MACimAIkqS4ixRnTIgBc3ArUeBzHrtxFtfzTaKXKQTUmA+M0P9nsWolkOhUFplYxaFt6GGT/BDB5tzHQz7jd/PsTmtAlRxzV7wfU7Y2UA1uwes8JU4TP19r5ALHnLwT7Dtxm/SkpOBZrgmIA4Yhzp6mZtgon/X9FFFNg2sbXX/PshL0DIiOyBAIAkJcO1fHFotorJIyM614Lb3Wtha3/M37r9n2ElGGydjXe1vyKZfpkLDb0t9tPCBgw5u4DkGcK4/tObRYcOqD0y0VQ9/mPpH7kMHhHpDbfHq9qtuIcqYkdbGvTtm51K+HMjVxkFZZh6eFrWHr4mqBPrFhn9q/3X8GsAY1sv0WR96AKjRe1n7chS0g6c+YMnnzySRQVFaGwsBBRUVG4f/8+goKCEBsb+1ALSZxznKOIkpxiHb9/kkg/F0eOlyxUOFY+waMY2LvmHF7pmMdTpDAEi9rOR7O/ZlleMzQB0JeUq8gVoDgLOLJA4EczDVRAOFB4D4htUK7lciSMWPlZlcPnX6BigErIE91k8xW2hbaEyF/9xSIHLFSYphuGxdp5YImMCef4N8j49zJqpp/Fer8HPiGER5BQMeXTp4woMACiU0QQAHdyi3Dx6HZT3qm7edVEXcJ8kDZAhXeOhyKdffA+5+oHYLz2ZztnsOPAbdWf1AC+0IbDQAC1C90iIs0EJMC5lBqCk5hdjWb5NkZlLPjNsw8Bg5LAONzwawLkGZ11zUsCNakZBqCmaUxz7COkDJFMIcZrf8ZLml3YoO+MVzRbbfoJy33r5u4D5UhN+mn9fIW0ZX5Fwn6BfIjycXKozbcP199naJdjV2krxIUHmYJrxPrEinV6F5yzxFgkeMZoX0FWgdtx48ahb9++yMrKQmBgII4dO4br16+jRYsW+Pzzz5Vuo0+RVCMKg0LOYrF2HuJhOaBwA2VPlbHeBoGVf5IEPxduwPhUuwwaEctiAggWKXx6fwwWNPoFh9qvwKUO82AYtgV4+hvlBCRRlGugvu8H/PwysKo/oBOpwrIaKIX8C1giIQIQlvta+JMFx4o+h9A5d7FJeF03FhmwcqZkHHdJAiDu9l7EEUunWXuOnkJ+W3Yxm4T5HDKBB34knJ9Kg92Dje9vZR8k7+5h+tY5X6l+qiNoo0q19D0xG6Q5x2rzff8lIlfbFzab/HEACPYnf12uyzQhgFGr5uh5SUFwEhOj0SQs+CYuTvsX2Pc/OPhhD6wb3QYbOt7Dhaj3sEg3GU1S3gNW9gHmNURSySEkhDtjpiy/+cAoSPE5i0QBXtFsxbf6Pjb9JAPRuNTpa1naUWvMn689bZlJ0LTyC+RDtI+Ts/545cQwedjSV4Xf3++CzefSxfvEsgYkMX9hWMgJm34phI1Prd174PGF9TFkaZLOnj2LJUuWQK1WQ61Wo7S0FI8++ijmzJmD4cOH45lnnlG6nT6DmutkOnERJSZ1eo0IyX4uKgaIQR6O+7+Jj3Qvy8qOzV3ty73/APADEIuEcB2+afIPmkg+m8IU5xj/GxjFL7CFVbbxs3LkhJjC1kU6iUQ8sgWFCkKAdEQhha1ruR3l5g9DI7SVuPpjiXFgNz+ntVn01d7t0CBCB/w43M6ZyocdOeOpVP+Ha4dEpYh4U72R19TnV3QH3/jNwxJdH/TTHLHRqk7XDcO50I4WUTfqv7fgkP80i33vE5FFtFO+Nf4LSwSemAn8NhFC78cTsTXWKTXEkGAnKonNzxC3yuUkIqtt/9QZiUfr94MaQNvSw0DKWAiZwhe1nY/Zv0eIajP8w4BSM40t5w8JlGslrU37/DCMsS/20xxFx9J5aKm6ZHJduBHSBAc79RDXHgdkF5aaxmZZCXmt4BuDrF0vZmzWPjBNC/jjgVGVC7niaBBaiKPXs8WbuEsPi07HwHu8ubZO6B6CooEnv1BEmPUUsoQkrVZrqt0WFxeHf//9F/Xq1UN4eDj+/fdfRRvoc1w/gsDiDMFRmG+g3J2agbaqVMl+LhxRyBesbyW1/hpgXO3MPJSD9X6ymqMg5aO7JgAYttk4yRfeA4IrGc2BPJl8HfnBsFBhqm44vvGbxz93lI9s03TDBJ/d3UKdceUkcsBnTed80eacnFk0IkiLuW17AGABbTCgK7R7TllI8X9I3QxseVvUriM1xpB3vpU3gdFnwvoJxSMLi7TzcK75ow98NFI3o1XK2PKjHhCFfNN7EVUyMi8d+Mm+oOlJpGhkBrWqKlhuZPOW21gk4hx8z4wACLq0EQb9HOP57ZrtGDT7azZGDNqBO78sRiWSab/szpizwI3j/NnI+SZSO3DjZUvVJRxj6z8opdOvkfNh5KwBKQe2YOeeE0hiIpBC6kpLyMv5uuWnG/8uzgHA4KJ/E9zJBThDDa/rRWkULu3/BPW6DTFuKPfHw/UjwN/bjUk4JQhIAICdE6FuOAlAJYe7qv/ewisUxzPizMK8JuD6/Yxt3jYeKLpv3FZ0H8VbP8C/9wrxWKfBPhX6zyFLSGrWrBlOnjyJ2rVro0uXLpg8eTLu37+PVatWoVGjRkq30bcQuVo374ybzt7Gx5q98myfeLDisk5AKLf+GoFR45KBaMQhi9efwX2Um+EYFdD4OYd7i3Gc3822xMW6b6HeP8uBMkthJBshmKgbhd1sS8H0+rGhAUBN/pVTHgmECixCmAeJATMQjWm6F+2+h5Ftq0J9/RCQ9rsLBCSJPgFCzsACWPvfWF0ZYPjNT6R88kWPocaN5RO1kAaWAUT6cLn4ew2MBsBaZtyWgBSTb/WYIJttnCmHwaO47S8vAEDFAPHIxF/Hd6FBYpgDocWoPUkO/ReGZ+eC+XE4iI0J1jhKXGr2f7h4/h5iQ+sjqUEH20mREwYkBmZw46UzSRvNnajrZu5D7VNTkFSUiSRTMEIk/jCInL8yrwLzGvI+twYATvobxxEAgsk84/94A2f0esvs/qwBOLdO4p2VU5SJVilj0VP1jt2xRgUWTc7PBG86BhiT2TrKn8VrAk7dDPw4wua8/sV3UOvAG/jo8DV0fmrkw5EC4LPPPkN+vjGp2owZMzB8+HC8/vrreOyxx7B8+XJFG+hziFytmw+U2YUl0J9dD2cUN3z1rZxxFmWhwpSyF40dnGeSs6HjB0ZTR0mO4C6k/H8IxEx0VogVPh04zm/WtzOafi6aqdT9goGa3WFoMRJ9N5Shke4wDvmPcWweMlv9nbtwETMP5ZjMaY7Cv815JvA03v7zPeCwPE2ifST6BEhIb8ASIBchdoUk+y2z8pWyky/GFG1MAhEqLdxSQcob0XceAIBsGAYCYvFmieWeFvCZXB1hPRmZm3KInQAAsQEBxdm3gDCRz7PgDnYz7XFA875NItlcv0qYyY7A+l0RAM4CsFNhQKUGWr8GHF0oWqP0XJeWeOHRNvKSNpZrjLYeOYtLRcHowpxBP802Gw1bArLxvOagg5OVp0U5wC9kcESiAN9o5yEbIQBEZPdXn5aYmJYPo9Zvmt8q7ClpCYPAmNMl4LLdFCv2zMIMBBJTiihxNUG3CG+u1QAvDBFXzcBLkCwkEUJQqVIlNGjQAABQqVIlbN++XfGG+SzV2qE4MB7+RRmCg5SBqBCJB5l7k1QX4Vcqb1VqDzn118zZxSaJiCwqp1p74MR3gj9zAtK3+t7oqzmKRNiz+9vyw4UyPBJ4H20etZ+4jXOc/0w3z+a3eGThVc1W2xmsrAi4sBnqRgOxsEU2mhzhP9bGPAQAKjUMVdpiydrTiEWOKcSfz+eEzzDXU5WCL8h8MHnStB98kWy82/nyY9lDZHoDAmPm/fwmoxB5bp64cwshwVcqhCkGGjwDBMcYhXIFIQAMmmAwz68GSnOh3/6hxWRCwhKNmpKyFrh2vwgXyt7BZCtBPJuEIBIFIAxjoYElYMAwBNPKHphcuf7Jh9BkZG1O5gIApmi/t+hTWQhDjIhIzsDIykCIuNxhKfc0eP230yBoip8wD8PUv6Eqcxf/klh8X/IE9NBYam/zI/Dm6iJ8PbQlv6CUPBvY8KLdaxIAxQFxUFdvL15AKjeDsfkZuHnlPMIvrEGS7h6SAMBPoCYabPuTbR8z78H2+yun3Y+ys4DghJGtG2eA8BVWlgEDgnhkopXqIo6z9Xn9oh7Xp4ia+dsx5y3yoXGPgjcxpYiEkpEowFq/z3Dn5yWyc7d5AllCUq1atfDXX3+hVq1armiTT2OACpNKh2IOPhdczanA4mvtfJOGx5XJ7biOOKNpLj4+GwlAmjHiOhGpGr1+yK75gTO77CfNcFb3GBZp5xu3OxjzuNX3xNOhYE8fR0SQFrOeEcgvBceO84TwrfIfpCBoxgBErHmo3H+APbMei3RZgEltz2/mjAz2Q1bhg5xilcO0mKdeD6ZYfuivOdyEe6X+26hVt/ED/63ASOPEIUaT9Le4BY/eLwKq/gtQtV4fIG2D/JIigCRfKQYA/voF6DhB3rXsQYA3i0bjxNpStCD/oLGuNRJV98CAQaY6Fil5DbF3VxjYck0JkITfzBzvuUSl3ZgzGKA9jEgzIaU4MA7XW07GsGo98WRBKWJDA5BdWIY3157mLm15jyifjMACaQ9ypvGlVbAOALiLCJxka+Og/1hBUxxLgLtMNOq27mn8uB2EcJOwRIw7FgQC/oK5ozTbH2hprTSwCzaOQo/6H/Gb3p5bBWwZIzh2MABKiguxYvnXeDe0o8OkkFd+X4uqx6chsOQOVACqAjZFi0X5tfHsx4KBqsHTxu9PxvFCPKvfCjDKmogndojA8JMP6rDxvTNHjNFuxEDNQdNYxmvq5PyyLjiosmCGs7nb3A1DiJBcLUyDBg2wdOlStGnTxhVtcjt5eXkIDw9Hbm4uwsLEraqEOHo1Ey98dwzJqmP4WvsV1AIfPzf5P146Hz1D/8Ei3WTHJ7eOGpHCgKXYybQXXSyXo40qFev9PnG84+PvG5NGOmClvgf6qI8hEvkOzQHcpM9nLvxGKL192h/G0GVX0vkj4PQKwZWTULvnPtcE8eGBDxLLMX9B/X1fxZqVgWikt52CZlUieTMwW1RiNzXWLHHp/cvA77NEXeuFso9wLbSlcdBUneA1PXEIab1MvlJj/zT+KeDjwY8jh3njuQ1PfAqy8U1o9I79vM4YauIyqYwe6tOCJkQhAZhvEirSRGAT2wGbSpqaTK7WJii7uXRUJ2zeY2lQPMbkDBJlPjfP92NtigOAc+0WPPCH+W2SnTxmDP7u9DV67oqwe07uT4bnWpc7L0KdLkP4T88agIOfA0fm2/gImp/jjfL+xFfaYuf5dBzYuAyf6ebYtE0puNxMvuB6bBi2Be3X65CRVyL4zoT7pdk+5Xd7qdPXto7XkmtXWp6X4fq+k6kBlJy/+ZDlKzxnzhy8//77OH/+vNLt8Xk4x+EchAkKSMCDejatVBfRr98A42Rhr/uFVQb6zpffsJA4JDdMwKEJXbFudBvMH9QU47rX5s3pYg6XHdpuPbXASCAwQlQzhmt2I5pxLCABxklfyJ9KsP6dE2n+xUIOfOZQtQzY5sSJDw+0rPdUeFeR9hSpw/Bvk7Go9PElo4DEl2uLq8RuXlcvdbNRMFnZx5jbSISARIjxXwQKH+R8YVvhUof5IIT/pXKmB6utxv9wvlIWuVbE4EBAAnCmwQT838ZUqHSFgiYW4EHbmqmv4jnNQURA2ESSYJXrDHggjFjnRQvQ5eB5w1a0Yi6Ytpme2Z83gbQ/kEwO49CzKmzrw+KnDrewrQ+LQ8+qkXxzgdEUZfUeubQKyWbXF0IoF1cGonGmzQI07jEMR69mImX7CpAjXwk/0XZv42JkZ7s5hLi/+ZKZAkD1IxOBf37nzy+kUgMd3wPU1jXkLc8xWfs92qrO48jGJTD8c9B0rp3n0/Hm6pMYo/svb9uUQsX7HTtG6BiWAAXE37lGWV8LAMIqI8VQFxl5JfbzPom4H6ZcTKpz5lOjVpNDIAeZ2McjO3ebB5DluD106FAUFRWhSZMm8PPzQ2BgoMXvWVnuTELoXXCOlmJNaBM7RKBJo0eA9IF2V3JInmUURuQQVtkU2WSdjbZOfAg+/OVPk1rWGlHZoYuzgd/+DyxUYAh/nS0xqxZzvtL1x1zDs4J+VILlGhRI868E5s6Px9n6/M6OCrU1QJ+HKufmg3msCbDjfdgL5TZl3r64TVIEGwc3sE7Srsau0lYgUOHAxmXozHxnd1Fg8+4DI4DWrxvbwlG/n1FLd+AzSW2yISwRZxpMwMD9UfjDfyr/9cvhmyTsfafc/U/RrsLe0uZopbqIWdr/GhcbAgLCeO3PGKzZj6nlGqhkVQqa/fw2AGMyUDWMEVFiYMrjyiaX+xkKOecCRrN+LkIwWzcI0UweMkkY7iAKw54fBJVagw6z9+FObhEO+U8zagGF7vv8z4jt+7bDHEJCz03FGBN44vt+whrNg58Dxdl2HfcTkYW1fp8ZS8p8P9eoKew5C9O2hKCVm7KBm8o3inSMBwAwtuMft74LRin/MTIwmRWTZxnTlMBx3idxYzKxzA1lx0mb0++KHurdsKh1FllC0ty5c015kiiWJNWIQkJ4AO7mR4jaP18bg7/3r0HtI18Jf1ht3zQKSBLsvhY0HGBXpZkrICBx7GKT8IZuLKb5rUIcMgX3Y8pXGtYDglQBCQBGaHahDBp8bXhaOF+ReTkLLrw3rxqSg+LhV3RHoBSD/Q7MOZjbnShF3YGRWOSAAJjUu56tT0a1dsZka0XCz1QMKgZgQYCfRzpw/iwf7PZ9Cpz4FnJ9iBgzATAcBfhMN0/0+zVogqDWFxkF6wOfGc2W5pNmx/eAlCVOPRNDv6/xxo8sWqlOO5w45QxjnAB83P9NRDP5jg8AEFeugfpW3wevaLZKnEksYUCQyGTireC9SCsONkVQglGZJl8+8186icLtNlNxT63B66tPgwBoI0a4yLuFJPVF1A4qdL7mHafRNC/twRqAwzK05HnpUP04HI3L3oG/K4vx8cBAvKDEZxjOQBQCUIYIFChuvjMQInmxLgpOoHHgpC3pfrxkUWsPWULSiBEjFG5GxUGtYjClb328ubrIbnFGzidpxF4VDvp/DMLYln4AjJ2LHF0E1dGF8ht1/meg+1QbQclRdmoOBkZB6akBo5EcdAX4aQSvoyUDgGUAQlQWqlk5E1EoU2Kq3zRRN4rX5MYNBNZ+HT1Vg8qTRTI2QoOjpjBidpLAPYRBBRZbt/yIyjeD0KReXaBaOxigQkpaDtQNPkarE+NEtc0eRjFSpNBz6AsnrvSAHsxJ9NIYzT5i267SF1lusJ40VWrgyS+dSgZ59do1pOfGopUqR/Y5xBAFcQIS8CCSbbRmu+lvZxlnWG4KFigNisf5Rh9h4O8x6KlKwSK+3DxMFuKPj8F3JwaBQR8wANqpxLlMqAvvok+7poCjCHmHlH+j5rUED34uMzeYUdKcol2F8bpXnW2YJAoQgFBGvG8nNwYu0D+FI2xDMGCxzs9JjSnPNVgC3PtxHLKf/l3SYl0UnEAjUvtThAAEkBL7iUd9oJ6bLJ8ktVqNu3dt/SkyMzOhVvtmfRYlSW6YgK+HtsQCrTGZmLXrjHkG5paqS0hksgRfBANIrvVkg7ntlzUYnZv//AkXj27Hndwi+8cCiAr2MzpLNnrEOKjZiWJTAVAzLGboBuOMoaZz7YYxbNTaBwQA4sP8kVQjirdG0i42Ca+XjUU6kWmeVJAk5gIO+Y+xqIdVNrMGln7yGoZ8dwTP/RGH3/QtPN1MWYzU7DR+uyImfEKElCdmkybnr6JSARr5vhp3SYTxvxKSNspBqvCvYox9wxU+M/5FGWhxfAx+6XwX0/xWma5nDud/+Aq7Hqf8X8NJ/9cwRrNR3AVC4pDUuS+KA+OdHY2McGMSawCOi8kbzg+nVQPg2HdSATifvGDY1oUUw9NNK+O9duH4oLYy/ojWcElCv/9hPfo1ScAJBz6lYnysWGJMKWGoXL5QFan98e80DgzDeTWZY+WP6OXI0iQJBcSVlpbCz8/jtSy8guSGCehR/yP8vb86Iv+YhHgzM5V5BuZ+Kjc5rhXcsYlGaADglH8wlumTbcxa5vlOnm3dAo/Xj31wHhGM0W5COJzPHM35gMzS/hd5uiAcZ+uDhQoleha7zqdjxrYLvPqT39iWyNMF4Fu/+QhGscciUsZqfrXZ5qfLxStYj4H+W7FB3xk91KecMr94CilNti9QmPk8FGc7zJ1j5ypAWCLUVdugjWo14pCFTBIqKpKyotDs9CQA+Q5fjD3ndHMIgLKgBOzMqYZYNgdJfeYIZNyWAZdugqvR6ASVkCfoOynH3C8Edx7r04n9vqqc/xpVlGmKXWKRg83n0jF/UAt88uOL+Fozn9cvSkyzVQwQhTyUzmsMdZ//GDWADlJGICwR6sffNV7w+GLLhbXU3G0eRpKQtGCB0bGYYRj897//RUhIiOk3g8GAgwcPom5d8dlkKzpqFYOc6snovTtMMAOzq1e7JjKv8maJjWQKbcxaNv4MRwCcL3e4FLmKCFNAQOLgEpGt8/vMFIL9W1ES3lh7hnd/OTlBrLGXrFFUBnIzhAboSBQYk1va2cebUVrwYPNuQ7VnisP9uC/Y8vLlfzUcgDbbuqKt3wOfCW71LzRBSHn2Sk64LqFMnAlQzD1wz3l5bgvM+sGYpiEhPARrao/Eo5eWymygGf/bACQ0cf48AGKYHNwnEdhiaIs+6mMwH+dYACqBfuvJtYmkeoQSuYsIpOeWIODqNnyiWcp7DamX9SvKMC5gBq50kAiUGP1gFzSx9F0KjABav2H0O/QBDRKHpDxJNWrUAABcv34djzzyiIVpzc/PD9WrV8f06dPRunVr5VvqQlyZZ2HT2Vt4Z/1Zwd9VYHHIf4ys+ksAgFajgL82ghRlCjgqM2BCE4w9wo6zHWcOMTmWwnoSLP9j4AqQ3yaC5N0WzIkDuG4isZc7CRDODSMVocHT6ydJH2aeajjGsitF7WvzfoJigCYvGEtdWPUDTiAyf2+3SRRusjFopboEWP1m7x3fJ2GIYWTmKvNBON/JDqXzwcLoa/iH/xgkMFnKCBetRgEn/uvcORgVzIvB2gSOmO/q3JVEIWWMUHq8NH9fPVQn8Y3fPMFAFLsLQXttYlRAmzeBo19JbF35Cc2d9hXA1XmSZCWT7NKlC3755RdERnre50MJXPmQueSS9uAmduuBXAx/9ViLkrz7aHZsDAD+pHFXG7yNWqmOP2iWGOtBMeD3myBgUBwYh6M130XXPz8AIH5yURLrgZvDaYHTy5E9qPkAeSQQBqgQyTihgWRUIIQVrJuWhTDM0A1FVeYuBmv2IUFA06gnDLYbknCNJIBhCLJJCDJJOO4gSlQmay6ayZPfoNIakkFlH+MYW198clmx1OwGXN2r3Pm8AE8tpMwXkLvZljjk/zYSGOG0Cp6BeZBAViFtkquFJFk+Sfv371e6HRUWU0qA3CK0Ul1EHLJMOUs4U1sAylCIQIRIKNzJCQp9t7AAE4MejG39pgxEY7ruRcReYjBdxDn5iuSaw4AgqDgDZ8+koIvGc2pqoQKMjnKCWCMp14mXYG+V7O7BWUnhLBTFzleuEhCQAON7jkEeqjJ3MU7zk83v3ATzo6Ej/k8/Cno7Q+M03TDjCt0quJvrOUv0ffC8Zj8iFTQ5y0FJQSmufFxRvITSv/J9Mj1hKhNzTU8tVsx9XduoUpHICAfYeA6rnEs+gCwhyWAwYMWKFdi7dy/u3r0LlrWcWPft26dI4yoCahWDRc1vIu7IVMWSnZlHx7FQAQTYRR7UbzIXxHIQgtwi1hQqrAQjNTsB2A4GUlTMSgwk5gM2A+kDuK8JSEJ+BcTO7+YoKUS5QnvljvfBfbu8VdkBJKtPogT+uE7i8L3hCV5h6VzI42D7N4d614cWJmwmrDIuNfs/JER2xu2C04jcM1SRNsvygzM7Tgkma1ehROenoA8lA/iFiPahEjiD2/G2ISOXBGGybgTuIMrC17W76qSHW+YAH0giySFLSHrnnXewYsUK9O7dGw0bNqSJJXngkhuq/96CViljoWQBQ/MVgzksVAhHASZo11sVmYxEqV8E/MtyFLm+UF0rsSj1uZgP2JHBfrhbHCG4r1K4yuTljAAj5jhHkSw6TTA0+kKFotXEw2nz3DWE2Pt2VQDCmSIM1+wGAPyfZg2+0/fGLMNgAA+e39R+DaBukADU6/Og7l1IHJhq7VBHpUYdADh/AoBz2g5uMbSPbYpu6rPgT0soDPdMlRCOI5GPxdp5eEM3xm7+N4GWwNYziFj4EVHk8aO+EzaxHSy29VSlYKR6p4daJBIfSCLJIUtIWr9+PTZs2IAnn3xS6fZUCLjkhqJS/kuAS0RmvmIwx9xp2Zx4ZIMps9lsg6OJnhAgB8Gi/Eb4oonEPgNi+h9hgSQbIcYsw+UYDCyqNOmK26mLFPNJEoqIEioxwE0Fci6dw4RZVI1XmlyEYKJuJGoxt/Gu5icbzYRaVwgwQLE6DIEG4XbwR5bJw9U5bcyRI8SqQEzRh7MMgx9UQa8fa8w1Vi4cocHTlv4VrAH4baLxes60GQzUDEF39dkHjTdzIRX7rS3TJ2OEZpfdsjGO4JJhTtauwQzdi/haO1/cgW3eAFI32hZbbvoicFBcMWVX4oOZNyzYQyxzrJnXavNazMpk+QKykkn6+fnhscceU7otFQLz5Iacj4yzEzYBgzy/OMzTD8Sx8jxB5qjAop3qf/hc+40x+SSPKcG4iQH8gnmvYapwbaetDAP8ZhCX+DALodZHizoOMOZlWaLvY8w2LjCuR6IAPcxUyrklevx4JgPTdMMAuGYCzkA0luj7IJ2nYOjrurF4TTcWer9wSeckAEqDEhD2QSqgDXG4v1wW6vvhNzYJL2j2gfCYbrjinYV6grm6Z0CI7TMkxNhgsW8yrfoLwDPfAcO3As+uRHFgvMXvGYjGXP0AubckCTmaFO6YUZrteL5JNA49rzUWnv289oOiwCv7GIsEmxcOdlC2QQyEGIU0y43lmpc2bwCdP0KZVlzgzB7SHG/pxpgiWOXCFeXORqj491arJzD2vPEbGLDU+N+enwEnvnGiJRSWALdJtMVCEYBic44juLQatt+TiAs7KJPlbcgSksaPH4/58+cLJpV8WLEu8xEHZXyQGBDk1HuB97eeqhSc9H8Na/1mIZQpcZy0r6wQaPCMTbHcXIiboO+SSKTbyeDKdd7WpV9jUNnHGFP2FqbrhkIldhXb8zNo3j2PVcHDkSPQJoYxds4p2lU22ci5yue2Qpp0uDT/2SQEL5R9hA6l8zHLMBgdSheY7m1Q2cfoUDofu9gk7GKTcLzVXNHn57qPf9NnoV7YBNA5Z8a0R1XmHkaod9rN7q5igBgmH8M0u7FE38emerwjIdqaGtfWIW/LR0BxNgz1+qO74Sub5/a14WncJpF2M/8SAtwnoXin7A28UPaR3e/PHibzk8RjNAyL//v7aai/7wscWwQU3bfciSutwglKCvhbCD9rBkjdBHR8D6cHHkUmCXWYNXmRdgFYMHhNp0wW+ljk4GvD06Leg+6H4UjZuQpH2fowNBgAFGeD/DgCRIEEkhUZbpHCt1ix8Uk1Q3HHegEe9CWrjzQ0AQiMsj3AnPM/P8iu7wPIMrcdOnQI+/fvx44dO9CgQQNotVqL33/55RdFGudrpKRlmdUPS8Ek7SrFzl313DwcDYjGlLIXsbPcF8k8dYAkbhwHxl9CysHt2HrkLC4VBYuuJfS2dhMKiD9vgUfzzquHxhR5JjqreGAU0Po1qFVqzG1ThKiDdvxHBCLcuMrnn+iGYJr2e4ShyCl/DC6RJYHKNCCxUFlc05zTaIAOYYkgeekOis3iwaLryAL5DRQJ52cjhijk4xXNVryhG4MchCEWOXhMdVNUCQtrU2Ro2T2QDS/iSqdFuJUXgVuwfW7r9F0xXvuz4DkZBohBPu4gCsfY+pgqkFlZSsFRqYSSIjsHlhttuHpkLvW3eBAdlFSrA/5P+zo+080xap4E2heBAnyjnYfXdGPRofQrbGt6DHUvLrR7jD3uIgIsVKb3YM/nSVOag1bH38Frh9LwXkh77MB4hIA4XJ1zJndX+6p5q6mNYYAf9R2xl22OqdrvkWC24M6FsUrCbralzXHVmHS3tpEBwZ1HByCu2ZNASBwMBgPUq/vbP9DHottkaZIiIiLw9NNPo1OnToiJiUF4eLjFv4cVrio9J7xIKYDJwQIgfvxakFhkYVF5HTOj7XmlrNxKyLuFlIPb8fxvWnxf0ArH2Po4ztYXXfsohCkt1+ZYXvguE403zJI8qsCijSoVjzE3xbWr9WsmNWxSJXFVvc1XTj1VKTjkPwbr/T7BPL9vEM4Y69IpofAUu0Jbd/IWDA0GOBaQAFMtLW+D+54ma9fgJFvb6CAv8hkKRTxWP/qRhdaP+zb6qY5Ay4hbVXLvYDfbEnP1A5HPWGoaXWlicNzHzEKbq7UDwhKVKNwhTMEdqFUMOj81Em/qxth9PVzbOV+V32JG4HTr+YLaY7taPQBn2MegBovazE3R4fBTtN+jasEZhJXdFScgweh36P3ImkJFUQRjAW8iUCUhxf91JKse5ODrqUrBOM3Piox3Uoi4sRdo8DR2Fj6GqetEpgeq6NFty5cvV7odFYLY0AALxzmpgza3ImPUWt7fmXKHkCnaVcjTBTmVB2PrkbNg0AKtzcqlcA6ZYqNhVIyx+zJt3gDqPInTeTWwc905APylQew6SQZGGdPVcwTFiLqPewgzXY/PaV0px0yxoc+N8w9CdXShAle0g18o0OdLoPAesOsjl1yC09Qd938T0cwDYV9OpBQDwL8sB61VqTjKNpRdNuYuItBTlWJcWds5VqiNLACdXyT8y1yYPybtd6DgDi4/MgA1//rKdUkly7VVyQ0TENW9BdQH7e/OMEAispCkuojlR/yxoCgah/z9eJ+VXb9EAHvrbILm+u+IF+lOwF27rSpV1P56vwi8VTACu9mWpnJO1Zl0jNP8LNg+zyVUdV2EXhBKeMc0jhgmH4u1C7BE/w/mGAZhpva/8hbNTuKvy0HKgS147Tct2qhCRKWbMQTHwle8kmQJSQCg1+tx4MABXL16FYMHD0ZoaChu376NsLAwi5puDxNJNaKQHPoPEnXyfJGymDBk1R9uNzs2A6PzZDvVXzJbaSS8+AYO+a+0SRVwhK2HDuoLos5h6oupm7Cz8puYsf1vAMICi92+23c+oFKbUicY/slEB3v7m2FPMOWicjJJKIJRgkBGJ/KsRrikndYOkvbb4eKlnFprdH4EgCNfAfmuU7HzaUOtBU+xglOPgEsILynCIj5h1k4uIO4dRCIfi0REVXFBYHwRiGMLXsSXYT8goOSOa/Q8B/8DAKgFIKtcExIlspisOBhjdJhZdJBYrSsAdGdO4VhRfbRRXbQraNqj8vVf5a0+RHaL4y2/xK59AeUGbj06qU6jj/o4APsCUg5CEKnos1YeMX2FEKPo9bj6PADHQvarmq1IZO4jysnULM7wyx+nAbRGClvXYYoIA1HhStp11HnUrU2UjSxd4fXr19GoUSP0798fb775Ju7duwcAmDNnDt577z0HR1dc1CoGrzYLknwc55japmQhvjorbiQZod4l+TpAeXkGEoJxmp9sVoIJyBYtIFmQdwsr161Bem6JdE1aWGUYBq7AX9lq/LxyLl77ZB6GfHcEG/afFnXpbswZhxEdnEOyVAGJlEdybda35U25YA3XDpcv5IqzjGYdlRpo8ZJLLyU3YSgfteOCMVng27CXdgIApuuG4FPtUtFtsN6Hi0DcybbBspJObjFzRqAAESjAD/qOso63NZuUtzp5lmV0kAQfqKc0h6EC65SDr1xtxVFi36TPEqBUG47IID/0Uh3HOf9RWOs3CwM0R+DPGASvyTm5bzG0xpCyiXin7A1s0HdEAfGX3kgZlAd9ikIX4MCpuRwVgAQRUWrcvRuL+nqOa6VGFxEWKocRxiqwqP3H25YRoV6M7GSSLVu2xLlz5xAdHW3a/vTTT2PUqFGKNc4XaVKvLpAi/bgjhgbopUpBDJMjav8QlEi+hvVHK3aiEsMi7QJ8qBuFXISIM6M8/j7waCec+fsKEn8ajwbIRAMAAwDc9o/COn0XUdd9WbMDMLhGc8NpJJ7THMAcwyCHgpK7IksA4NLVK6hZrQPUJe67Jof1ZyL2uzl1B+hg59sQOg0DoDZzU9ZKeYX+Cexkk0y5xVRgYdCXOaFDFw+nxXxCLU7gt8b6uRYHxiGw739si4NWaweExAMFGQ7PGcPkIUl10WSmloJc0zUhQDqicJytj2kCTvecE7m/LhcN9gzFIj9IVsgO0+zFELIPewzN0UN9SnTbAAVMVA4eDqcNvf7MYbT1u2LU/m4eA+htS1ExjFGTJKVJnqwekEnCbDTtOQhGlEA+PS462RTo4OXpAGRpkg4dOoSPP/4Yfn6Wxsdq1arh1q1bijTMZ5HptNlPcwwL/BZisnY1DIQRdL7j8lPI6dRcXpoopkDxThWOAizWzhOfDj+2Ls5c+gdNjo5FJZJp8VM8sjBO8zOySIhDR3IC4Cm1/PpPjmAYIIopQGsR/hTKlWxwzOR99zHps09Aji1y2zXlQgiQRwKQViJdy8oNqKM0O2RdeyebZMotxjn2i4nSUwoV43yGegDIJYGYXjYEh/3aYdPZWzh6NRMGrnOo1DBI0CjKEeaJ6X8kHmeKeB0GFipTig7r9BJ8yBnjVAzBE5pTvPnizNvDkY0Qpx3EHTWTe03r9J1xt0hnjOoKTeAVkDhc5w6uPL/q25sWkJyrRYSDuoWMeaCDlyNrPcWyLAwG24iUmzdvIjTU+fw0Po1KDSTPBrNhmM1PQqsW67+5JHLOZK3myCVB+NHQEXvYlkhh66KPyjVqWW7VLFZg0WffxKNH/8OruufOJfa6MchDJglFJPIFK7NnIAr+0Fk4IUuhbbnTsc31wSJJdRFVNHl4pYEBuKhSpNyCoPNx+Yo0CrmYoVvosWKaQgg5AoehBNO18gI+VAwQJqH4M9eOdDNfMiE/OXeRTUIQDvmLkzAU41P9F3h9mcEUPZpQngEcAI4cLhFVxBoAivxjUKn0vuMdzWBM/yONAgTgPd1rFiWUdrHGOpOtValYpF2ACBTYfjPSL2V5nB3THGBZvQAwmsp7MCcF61I6vK6d/bl3Pl77M0p3Hwb8/wMYRJRAgPuLVsuBy/otK2jJB6LcZAmsPXr0wLx580x/MwyDgoICTJkyhZYqAYzq8HZvA4zl4xWbjI/bx7qmudiEj4Bx0XefhKFF6Tf4RD/MtJp2pbbD6PtjFFgcCTmafVMQzjM4mp8riinAOVJT1LV/1RvdvK3FE+7vabph+NXQXtS5eOG5H/OUA/9RLUCtC187LSDp1EH4UvcMCISTyG3Wt8ZC7VdOlZlwFQXlYct8hKJEkv+GXLjFyAzdUJOJTergfdmQqGiblumTAQi/U0c8CKV/kEA1I7cEr60+jddWn8alIv5M+taU+kdh4DPPukXrSQiQjyBTPp+E8AC82rEGEsIDwEIFAhUiGeExwJVcYR8xjYlc3rMzTD0UIMCl7fErumNMPJp5VfQx7izfwyHmktZZv2Vl+/aBGm6yhKS5c+fi999/R/369VFSUoLBgwejevXquHXrFmbPnq1oA6tXrw6GYWz+vfnmmwCAESNG2PzWpk0bRdsgmdTNxqgjJyZMhgHUDME+Q2O8U/YGBpV9jDd0Y0Qda/zAGXyufQ0GaCxy0jBgkUlcq+07Y3hMMcfYZipxg8le0gxz9QORSywFyQxidNjdzbbEbSIurQAfR4llEkROMyE2DFpsV0tv8Ar+JlWRgxDeSD0VA4zW7PBYfiUhM7BxwIxCAQIF92EYmLxc5Qz8xcRP1ODNLUayy7Ouyxm8d7KtxO1Y7yljtJnAG+Emkq8NT/GamTIQJcqsDDwoC5KkugjAciLjooqEzsMJp+caT0J4UCAat0tGFglxaU4dhgESGWPagUm96+HQhK6Y+GR9HJrQFeO610Z1P3laXSWwFhJ7qlLwlWYegmX4ekrBlD/t1Aqbqge8+zM8Wa3dgYM+yv223dAKSaqLkoMBCADiIzXcZJnbEhMTcfbsWaxfvx6nTp0Cy7J4+eWXMWTIEAQGBirawBMnTliY9s6fP48ePXrg2WefNW1LTk62yN1k7SvlVlgDsHMClFovd1X/D01UafjV0B572eZIJ1GIc1DA9S6icbvtFHSu/ARy1n6DyVY5aVwd9dFNfUbxwpH2zE85CMGX2m8sQpp1fuE4GDUQo691QQ/VSRzyHyM5Lw933WyE4LhVVm/pubBYlPpFQluaLegrUeYfgcq1m+Kb/42wO3lJ0SD9bmiITuWhxEohFF6/Tt/FbuZs4MFxBSQQoWYmNHtmBQKgTBuOAF2upHZyg7YcH5wjpAGGkL2ItKPtJABwYSOuPDYSj+UtB8BYJBEl5SWPufIRnJkpySw3WSTy8Zl2qSQBju9+uKgiPqdojiW6Ppj1RxzwxzH0UqcgQuOekPFY5CAm1B/q8kbtTs3AvD2X0FoVKiqnjpLwpfRQgcV0v1WAQCFyrrA1oJTpiwD5t435zkSgAgEhgA5qaCEc5ack29kkNFNdQaLAIpBABTXDYpRmJ0ZhJ24T8cE23Nh2qclE1PFyp23AiRiPwMBAvPTSS3jpJdeGIFeqVMni71mzZqFmzZro1KmTaZu/vz/i4+OtD/UMChS3tCaayTd9jFkkxG5JkLn6AVhkeBqG/SosbLoJi/3m2YhrQSgVdV3OWVNspzTm9zBOFEo7htvLfWMsG2KJujQXXdKX4gP1HbxSXsnduq1i8pUQABN1o0xmmyTVRbRjzssSuP4uq4RGyBa8zlTDKHz2mzE5pNNFkct9cpYY+igmJN0nofhJ/zj6aY5ZDJ4ZiMY03Yvwh/h8PSEoRjHxQyBj9M1wlMDQX5cnub2ctkCKaYmbRNt26Yc0fTwij48R/Fa4fhh8eRPe0I3BFL/ViMeDIITigFgszu8Af+jRRpVqirDjStr0VKXgaxF5n6yJYXLQT3UEdxFhOifwoG7hFO33Fu/H6Jf4OA6QpiZT3SSNUch3x4R7FxGIDTWaYc3rW6awdZFHAhDGuFZ7w8Gl9OCEVvP+HIdMweMc9UXZfkNl4jRp3Ln9IK/emZz2/UMSsEbXFXWZG6jK3MMNEoOLpBq6MGfxsmYHGCvHBvNgmwgHvndcW+6xIagj8V48gSwhaebMmYiLi8PIkSMtti9btgz37t3DhAkTFGmcNWVlZVi9ejXeffddMGZv/cCBA4iNjUVERAQ6deqETz/9FLGxsYLnKS0tRWnpA0EhL0/6ACyIix3RIsoFghyEWCSp4yYq85IgzS/M5s34y1V8BxxPTuARTux1Olf6yVhfMxfB0IBFMIoFk0iO1mw3/W3vXHywYPCdvjd2sUmys0Sb0xiXBPWL3+r7IE0XAMagnIA9TfcijrENkUVC7GtERA6ixppu2y1quplP1G1EZlTmCIA459XyVorfs1z7x2kLTrK1YSAMVCB275MTuv8X1gndgv5B3dZDYPBPh+bgTMFjuMzk2QhFu5L5SFJdxCOaPDxTrRQtMjdZaNZukyhM0w3DLjZJljaSJcYV/GTtat5zAkZBaW9pcwxT/4YOqj/RQnUZ4UwRRml2YRR2mVb8znzHUrhPwnDFvyGSahjNjOb1LXuoTkpOZeLoW7WXlBR48BUp0Z85vN2xWkr7uOf7tmYT3sYmi9/ukxCoAME5RaoJPVZkuhtPI0tIWrJkCdauXWuzvUGDBhg0aJDLhKSNGzciJycHI0aMMG3r1asXnn32WVSrVg1paWmYNGkSunbtilOnTsHfn9+sNHPmTEybNs0lbXS1Ixr3MZbADy+UfYRKyLNZUQIP/DCEMFVx5hGAzH+3d6zY7UpTSPwRzJQiUiAPB4exIzv2CyskfghmbCdsBgSvaLYigbmPfgola+PNGAygn+YoLuiqKnINAqOQsJttCRYqzNG+gZn6OaKFISGBgvv2JmvXoEPpfIvVeCxycA9hSCeRiEe2w+u4c2JpqbokWnhXMUBy/i/A7l+QtTsM58K7Q4wRIRY5Ji1RT30K2vy7xGamjkcWFmvn4XXdWPH5xMrhTD58K3junGKEeW7FrwS5JAihKLIbaj9J9xL0AWrsTs1AcsMEU31LcyFRSVgAJQhAEEp483kRAszU/pc3os59MEBQNFAkLcLQ1TjqITEOUlmoGGN2+f2Gxuii/p/D69V8VFxQjqeR5bidkZGBhIQEm+2VKlVCerrrSiQsXboUvXr1QmLig8iT559/Hr1790bDhg3Rt29f7NixA5cuXcK2bdsEzzNx4kTk5uaa/t24cUO5RlZrBwRGKHc+HlTlDpEEKmxm25miNMwR64fBa0bg0bpw+ZlcBUuAfCIcGWWOWHOhWMqg5b03VfmKtL/mmOjIRDlwDrnRjDIaTQbGyMAR6p2ICVKhY7+XwDy3CnqNcJ4iQoA9+maYrhsKNSOsceHa2jP4CgYGnTZF9y3wW4h1fp/BHzrT+TwFl9uKc3AW3Res/o5CHjrn/CLqWM6kZ6EhstqHEyamaL9He9Wfos7LwTnv8gmuxnOuQi/VcSzWzrOoGG8N5/zvDIQAeqLCD3r7mcuX6PtgB9saOUU6vLb6NHaeTzeZ3cQ607PEqI1aqOsLwHEfLEAAgnkEJA4uapaxo21yLeVXffILFAfGu7Dymy0O+6RC6Qa6qP9nN9cfS4DiwHioqzsRbexGZAlJVapUweHDh222Hz582EKAUZLr169jz549DjN6JyQkoFq1arh8+bLgPv7+/ggLC7P4pxgqNdD6DeXOZwd7g7/cEF9Hqf/FIHWCJGDAMMB01RuiInSUFlYimUKPa8cAY+Zae/cvlcna1dhseAOb1i/Bp5erQMOW8K4WuXvsrD6HLJGRj+9XT8N/2C9sovs4c3Ax+Is0uxOuf4jtC/bMkfYG/PskDCfZ2gAcT/7cAudtzSb+HQQQI7jO0X4rqWSIXEGWYQANw2K0Zgfv90QI8K2+N2YZBlts//CXP9GiWiQSwgNEJ51lAPyk74ghmn2i9g8X6d/kjm7NEsBgPcWGJQLPfY+daI1xuYNkR3rKwZ3aXS6AwfobY2FMGRTY9z9en2mbQ5aQNGrUKIwdOxbLly/H9evXcf36dSxbtgzjxo3D6NGjlW4jAGD58uWIjY1F79697e6XmZmJGzdu8Gq63EbH94xV7V2MvcFfTEiwy2BsO4e9ATmdROG1srH4sbglvlSPNKXlN4dL0y+lH7PEWExR+BkwyCbeU4z5DqIc1j2SCmeOeezEZDDEOvPWA7iJr7nqkqjzRl79FXzRQNzfRfBHPgnwqEYphsmBCixS2Lq4LzPthfnigO+dcLnBDvqPRU9ViltL01gTyhRLnuicfT+8pjYAfTVHTU7iHDlFOiw+cBVT+tTBU2rbRTYfmw1t8YpmK8IdZHD2Nkz+bW2+BF7cBHR831iK6anFMNR+EtO2pGKnKft4pFPX8mQfE0LF8C+sSwLiwTz3vW1pHS+GIUT6IyaE4MMPP8SCBQtQVmb05QgICMCECRMwefJkxRvJsixq1KiBF154AbNmzTJtLygowNSpUzFgwAAkJCTg2rVr+Oijj/Dvv//iwoULorN/5+XlITw8HLm5ucpplVI3AxteVOZcVnBv7A3dO9jBthbczzzLsLtr+1j7v3AOo9dJAjo2rYu6qn9x8uxZ/Eti8b3hCejN3OP4/CqySYik8g7cIPWtvo8pus3yGRjXOt+pnscr7HoZd6gcXEQV5+djvP+VSGRsI+E4pNScYolRaAlhHJspdxqaI1lmrTEhPJk1mHNsbqW6iFHl2ZTlkklCBTO2m0eXOkqDIAUp787b+EHfEYfZxhY+kxFBWpwaGgD1930dHn+fhEAHP4cpT6yxl33fXWQgCvn1h6BmqB6Gsz9AW/pgLCsNjMPCvA64ThJwD2FgwGKIah+eVBuLfjrqKywBshCKcFUptERK8IPn4PrH5U4LUaersvOiS+ZvM2QJSRwFBQW4cOECAgMDUatWLUFHaWf57bff0LNnT/z999+oXbu2aXtxcTGeeuopnDlzBjk5OUhISECXLl0wY8YMVKlSRfT5XfaQD8wGDnym3PnM4CJ4WpZ+Y/JHMnei5QamHqqTikVxyME8/X9ceBAWNb+Jumc/Q2Dxg2Kct0kUpuuGWkRMnWRro6XqkulvBizW+Yl/lrfJg2g/XmfWsMo4Vfd9fH08E/PxH4S6KQzZGm7w4BxvOVRg8aZ6I97V/GQTTcIdw4A/0sQZSogaAYy8UGMhPCkkKSm8jC17DZO0axCFfDslY6LAAJIn9oqOeRTe8hbX0OWvjxwes02fhN4a8dXCubQXM3RDTakVrIvouuM7vPPoQMTeOwImnz9StTwAjxcDYSyCDITSnmw1tEE/jbRgEnu55ghUYMC69JtlATBhlcGM/VNRU5tXC0kVBZc95D9/An5+WdIh3ED7X30vTNaucbj/F7qB+MrwDK8gwA1Mu9kHCeximByLEGIxOFMp+1KHebgQ8wRiQwOQVHIIqh+HgxBiM+lb+1JYhzarwOKQ/xjEC0w+XBuXGZKxu7xOnbkzOydATuwQgSb16uKXQ+fQ5soXHhMezSkgxvpWO82EJA7+92oUAAFIEoBZYsxh5SiE2hUTCUuAPCYIDCEIg3SzkLPXzkAUglCKCAcRkfaYrhsqqu9s0rdFP/VRAN4fHu4uzBcDuQjBer9PHB6zQP+U6GLEXK4xsVF+9jhsqIt25U7/vNGogn2EMWbRLs4GkZknmzUbx3JJCAZr9lkkyb1NojFdNwQztUsdRvfyISR0CWvcHZ9DMsO3Gov8KoRXCkmFhYWYNWsW9u7di7t374JlLW3P//zzj2INdAcue8hpfwAr+4je3Xwg8YceC/wWOjwmm4TgI93LvCsnPi2FI2GDW1WomQfvtJhoEQCdvI7BdQjWADKvIUjebV5HOKHOu8yQbCrO+4QqBYu1CwAID17W2jVrIgK1mF77H/S5aExT4Q2rfS63y+nW8/HW2SrIyLV0sObTEJprD0eod7p18r5fnndJ7eJnp7TAJjY0ma8d6YjGbN3zmO+3yOH+2SQYERAOBhBzPSmTsy8UQQUemJU7ls7FQf+xdsegDERjvO5V0dpjc80xh7k2VszzIQQogD+CUCr52yZctvXASJDibKccw83N7wBs+n6S6qIoIZMPa7cFhxp3K/gWzJK/vwFLgUYDJbZcGFcLSbLyJI0aNQq///47XnzxRSQkJFgkdqSYUaU1EBgNUpwpqtOYJ4QUm5gvkinAJ9plAIQTfM3S/hd5uiAcL08VIFS+gBNM3tS9hVrMbbyq2YoQpgSBjE5UW8zhOlPa0Z/xaI3HgetHwOTdtus4bN12AKZM49kkGLsNzR3mb4pCAVqrUnGUbcgrXOQVl6LlxdkW1/A0xvpMQIsLczClz294fc05i9/NszRbw0KFFYZkjNJsdzjpjNO/iXQSjdGarXBG2X3cUF+SGUQuQgKBvd/tIVdAIjAm5hRbYFrOCt8cOZGWzmh73QWXeLOl6pLDMWia7kUcZ+vjNolyqD2eqx+AhYaneRdGL2j2SSqRFIJSec/QPxSIrg3cPul05Bz3nJJUF3GMrW/T950JDnhDNwYEKt4Fl3XZnOrMbQzX7LbxwxNKESP6uflAUVtzZAlJO3bswLZt29C+vW/kOfAIqZuNNdxECkjTdUOxwpBs+mBT2LrIJsGiBlwhZ1LA2OEiUYB1fp9ZmLD4yhdwQhoAjNP85FRn5zpOtUsrcfjiB4g7sQGPOXG+SKYQz2n+ELVvW1UqwlDEa350Z7ZhKTAAkHcLySFpeKVjDXx7MM0mAlFIoyRG8OVKMcwyDIYfo8NIzS7ZbY2z41DuasyToArVKBOD2EE9E2H4P91IU5Zse5M2n9nYHTDMg2v7glYpFjnYzLazOwZxGqHpuqFYrF3Ae1/cGDNIcwALDU/bXMdRQl1rChCIYBSLHvfM28SU5gG3xaU1EIuQMCQnvYtRGxplWihzcMXPzccUTlsFArylexsA0JZJxRjtRidTpTDGFAg+UNTWHFlCUmRkJKKiXB/i7rOkbgY2DIOUQPv7JMLi42WhwjJ9sqKRMtbZea2LbXJlHA75v63IYM8wgBosbq1+FW3VB92Wva0mbuMt7Uab7UpmG3YVO46dxbfnHrX5cuz5nO1ik8wE35VINKsPlwFL366eqhSMUMsXkAgBWqiEc5A5i1jBZ6m+F57UHLeYYKUICGL322ZojVyEQAXWoTDqSdlEZSY8ejvcJC80BpmPgzkIc6g9TkQmWqtSbTQkUjQuuSQQ4Uyx4x2tru1KrIUhbpEUhyxJEXzcN7FO3wV9VMdwD0aTVDfmDJ7WHLJYZGeVp0SJsjDJRSHVUM25m+F6R/Isn8mPxCFLSJoxYwYmT56MlStXIihIOIvvQwlrMGqQJGYi4lsdfG14Gi9pdgnW3WIJkA/xnZszv03RrsLu0pa8Zpw2qlS7oedy6K0+ruj5HNFGfQEAv/nR21n5p23CR/NUDuZYC70AwFhN1QwIajM34K/S4x7CMNXJUhCunhjyEYRwFDnc7zaiMVs3CNFMHjJJGKoyd53WfvIxXLMbw7HboRY2C2GIUShjujO4yune3qJJrKmPM/tyizHAuBjkNBexyEGS6qKFoCRW0Fmm/Y+FW8B9EorjZtdxxClDbXTVnHO8oxswhviHIQ5ZpsLIfFHKnCnY/LHzLRQKEAAdNKIW3JGwTbMSjywkqJ3UvgdGAK1fB+raz3Pojchy3G7WrBmuXr0KQgiqV68OrdYyu+7p08rmWXE1ijp+yXDWNs+RY42rch0NKvsYx9j6NiacOGSJck71RggB8uG+quJKwxJguVV0nhhH+yyEYbJuOBZqvwLgmbBnpRhX9gre1/4kKbBAyVxIHEKBBJxA6u5+463vkZs9Cq1yOTl6fhyONKRtVKmynZSlMEP3AiZp17n8Oo7gE0i5AtVi0n3cJlFYr+8MDViAMZaPGasxltbxxCLRRogLSwSTPFvRZJJeGd3mqDjslClTZDfIEyj6kCWE/XMrAaGq6hxKVqzmeKfsDZTAz+a890koYuz4OEnFGb8RKRAYn+cOg7TcKt4KN1HkIUhUhI+YKveeROwk/7O+Pa6RBIzT/ARA2KTFNwErlcjRXj6ZDETh8dIFiAkNgI4FsgqNyfzcNZl7I0bB1TK/j3W+H77oM6EFoLlAtZttaXeRIAYxmi4DgcujNcUgFD1mvc0aFgCIMegmGxGmgtNfar/xqpxdxsoJjKJZt71SSKpoeFKTtEnfFq3UfwuupDieVB3FV9qFoquZOyKfBCAEJbyJCvkmIrmcMjyGFuorzp/IAQXEHwQqhEr0K3AFSqz6uYnCE9mW5fhnKA2fb4SBqKBi+EuryEnkKDci7Ad9R4Q1eAIr/ywRrfFzJd6oZeK+3wNsYxxiG9tk1RejIeU07D1UJ7FYO88jTvFKwBIgF+KCcJx5l3xaVm+EJUBpUDwC309VxD/J1UKSrNptHKdOncLq1auxZs0anDlzRqk2+TbV2iFXW0l07a1+6qM2RUI5X5OeKqNGpKcqBQu1XykmIAFACIwmKSG/HaUGo88NzylatFWIEKbUKwQkpVAxRmE1GO4TkFhiXPH/oO/icQfgCBQgAgX4QjcAY8rewiwyDGoBAQl4UDh2rb4rAMcOzM6EzD+vOYhef3+M9X6f4JD/GPRUpZicugH3FSw1x0AYSdd19ftVMcZ/XdX/w2TtalNtOw5xhYCNYfC72CTM1Q/wWQEJAJbpk0Xt78w9qhh4vYAEGNsZWJwBwzVx9fs8jSwh6e7du+jatStatWqFMWPG4K233kKLFi3QrVs33Lt3T+k2+hYqNU7UnSDtEAFBZYp2FTTQY4pMZ1t7AyFf8UHz35yFm3BPsHWxTt8VDDwzebgbA1Fhi6GNIuey946Uhns3m/VtMUqz3bUFkEXA9YHBmgN4rMtQ9ExqLOq4COSjBFpRFc+VeLYJZguaXWwSvtX3cXuUG8MAasa22LCjY6whxHXCk/XCT6xDNrffdeLBguVOkIFovK4bi68NT9svOO7pDucAV3wbd1J+UfaELkKWkPT2228jLy8Pf/31F7KyspCdnY3z588jLy8PY8aMUbqNPkfH/i/jLf0YGIjjUUtooOZWUsPUv9ldcdlDeN3tWswn3IP+YzFea8x4q7QZwhvHFRVY9FEfQxYJ8SmhMANReEM3Bv00RwB4RySgigESmEy8GbwPZ06Jq1M1UrMLQTKSn8qFKdf4zdT+Fxro0U9zxCu/SzFkIwTZIhNmSsV84acCKzrXTwyTI2l/b4AQYI++GQaVfYwOpfOxi00CCxWm64aacllZ401aMuv2sU5oXe0RfuVXYzS4lyMrBcDOnTuxZ88e1KtXz7Stfv36+Prrr/HEE08o1jhfxU+jQpX2L+C/h6/iFc02pz6uvqqjso5boHsK/5AEzPNbLP/iMslANDbr25pqAZnDdTglJmFPjitCvgMMA4AAGhg7v5Djurf5kYzXvQYClVcm2lT/9hFGlv9/e07VnnqcXKb3b7Wfe+Xzs8f3+m7IIaEAAxxl6+MEWxctVZcQhyxM1q4SnYtHDOaZpFPYunYTc3JM1q7GKM12TNcNFbW/N0AA1Ff/ixS9tJxPds/pIkFFDK66ZLA+B4Zrh6F+tKOLrqAMsoQklmVtwv4BQKvV2tRxe1j5oNplMMe3SUqJz0cz9VVZx+mgQQainbiyNKbrhiCThCOayUMWCcGk8uK8QqVSfBlHAg7DAGEoRj7xRxDKwKfzkpzK38VUgudz/IiFL7xcilMvN+EIhVTLfS9dZZQ98RSEGDXNPdRnTAVUx2CjKWhkE9sBJTo/3sSZ5hiI0WldyvOKRY7dxJzWzz8eWVikXWAqwuquiFm5cMLgWM1POMI2NDn3yy0n4u775TK45yIYLFSKCsrWXP3nKmp7uZAky9zWtWtXvPPOO7h9+7Zp261btzBu3Dh069ZNscb5LKwB+m0fAFDm45ZqDybEWLPoJFsb+X6xLlX/E2KMREonMZigXY/J2tWY5/cNohnhjsVtd4ewpMQlrJ+92AkhBKV2ne29RUACjMlMXWnSUMqfge+ZZUlcoXP+SELfp6vfi6f9T7jrq0AQJxA0kqw6ZkqcmQH+6gr3SSi+0yeDQFpfNs+4zXd+oTqO/TRHME//jOgaekoj9b2N0Wy0cO6X278KEChqPyW/KxVjLAVlbxxXog13SYS0AzyALCFp4cKFyM/PR/Xq1VGzZk089thjqFGjBvLz8/HVV18p3Ubf4/oR+BdlKCZ9m9erErt/IpOFlqpLuN12KgBpkS9SiUQBFmnn20TpOYJBeX4PNyK1Ezuj7RF7XClxKsjUae6TMFPNJndEIjoL91wX6J/CoLKPMUM31LMNEon5YseTz9gAoBABvJo0Lirta+1C9FIdxy42CVv0bXn7TTTy8YpmO77V9xEUpMzhgjnMM27vYpPQoXQBpjt4h1z04rvaX0xV7LNJEDboH8dXuv5YoH8KX+n7O2yDM8gdBzjBswtzRpYD9Eq9eBcWTwvgYp8R9y2oq3t//VdZo3OVKlVw+vRpbNu2DWPHjsWYMWOwfft2nDp1Co888ojSbfQ9Cu4ofko50Th1AvPxWLUqIK1fQy4TqnibuHZxSBUK5+oHgIhwbncGLqoum4TgS90zyECktOPdoO3Rul1UtGSjvr1FoVzAdhJnifFfmQSBjiUPBAOhaCpnuMI+gmNsfdwRMUF7A1wfZhhj8kU5fK3rjQW6p7BA/xQGl32IdDtCLUuAPBKIbBJssT0XoQhhSuz2VzXDYpF2PuZr5uMVzTbh+wHQT3MUn+kGOxQAGBiDOawrC7BQIZG5L3ygAOEowkD1HzhPauBL/XM4zDaSfA5z8og4jY1UuOc8SrMdgPQx5QhpIGrxQiD/u3In3H0s0L6MpJqVPNsYEUgSkvbt24f69esjL8/ov9CjRw+8/fbbGDNmDFq1aoUGDRrgjz/EVWqv0ITEuezUUiaWj9TfQ/19X6iOL0Yk8lFIbP3IlECOAHefhOEEqaNo7ichjKrjAqSQ+mhf+hW+0A00VZH3BjztX1HE+KONKhUqsIImEAIVVAzgJyEPC2cGk5pqQux74cwXKWxd3CeuWQS4ChWIUeiEn6Q+PUhzEH+R6vhS/xyOsP/f3nnHR1GtDfiZ2d30QkJLQEWUZogNMFSxUSIiYhcV9LNcC4io99oVsIF6VVAp99quWLCLKAjitSAlREQFBKyAXkmIkJAE0nZ3zvfHZjZbZnZnW7KBeX4/S3ZnZ86cOXPOe956HNMCCLUA6dTSBu8khlkYy6gvSXCOdV3QZ9hJ2sts2xxD88DfrB9xk+Vdxshr3GNupFzMVZbQy8n4RsytV3rgFFJYwvcyRz9mOc4L/YcGkRvTNIQzT65T8tybl2DXkJthPo0UNS3CqWOvwtLSk58BQsq4PWbMGE477TRuueUWze+ffvppPv/8c95///2oNbA5iHrGTsUJj3dD1Ja3iFzvSv3u7zAeqRN5NHnefiabRNeI6l2Fagqb3DCJxcogIDalXgIRifNlrBy8fc/rmeldrU02TPqGq60fG6ob5cnT9rGkSnVcbaCWWoOcTILSlAh0l8iiIxXIBMjnA4y338VapTcKMoVyEfNsT8eVn1cwwnmuWjXQtMZyuUglk5pm2YSEgv+YyyIJO23YH9Fm4QH75bRhP5Nti6LavpZCXZVvtN/Mx0p/AJ63Ps4w67ct2KrwEcJV3+9a+218LfJ4elw/Rh0XndxXcZVx+/vvv6ewUD9z6IgRI/jmm28iblSrZ9sS0BGQYpmwDZoEIa1rx8G77+ZT0Ze2EVRND0cL5Ok4qfpCjGu4m4oAOY0ifVZKo2N7JanBDw7AfpEU1TZq/cYz4Z9anX2UdV3IAhLAWpHHORZjGXWvqLuFSxruZXLDJC5puJe/26/DEkR7IUvwWsIMt1PsMmUAnzj7tLhPRiiEsxj7ak8Avk4ezJD6p919+IT9AtpwIO4EJPC/5xwqyJYiE5DAlSogUgEpEt51Rt+35l+O0W4BSUbhhAjLO7X0u6Eg8bXSi6fH9Y2agNQchCQk7d69WzP0X8VqtZoZtxUnLAuecTtWph67LT2uhCEthHCp/PeK8KV+WTIeuablMAouX4i1Sj532q9xtUuj50JZyHzbI5CQJLjLfg032m82fiIPKkUKN9gnc5v9elebw0xEZySBne8CHKx0hN51dglX6gkjhZJVP5BipReLlUEUKXkMkLYZvl6O1BSNdaxlh/GGtmLURLPTjtvHwmsHUHTXMDpmprBOyeMjZQDjrJ+1dBMNE2/WlnA0e7tEW+6wXxe1oIc9IoMb7JOZ6bzU/VmBvC3iwuMtqSGTJMiQ6vg+bTKjrOtbriFhEJKQ1LlzZzZt2qT7/caNG8nNbT0SYkzYuQaqdul+rdrtK/D2oYiWlF9rb34n4HDafp/tVbpIkTm4qxNsoOur3y10nKp7jOqH05ASXV8yKaMT0kWvcO6l19M5oTasflrgGM4nSkHQcOyQ2xYgPYNaMyvcvC7T7eMN513KkGpZmPCIWyPkapzxa6kT2EO2/9BJKo8oWV9L7bTDXVh/+e1XCrpmk2CVmXp2HhC8JppJ9FDHy3T7eBxYI6rdJwQ87yjkkoZ7KaifyzLFu7RRuO9ivJHi2Id4awJsWdzSTTFMSELSqFGjuP/++6mrq/P7rra2lqlTpzJ69OioNa5VYjCy7QH7eMY13M3T9rEscbp8C6IxSWeI4JWmWxrV2fMW67tRW5j0JibVNHOb7V3vhdiH5UoBy4Ytg5R2YbdBjaRrsGXChMUwZRPkjaEwrwMPJL0eVs6mm2wfuNutmghVs0qwsGmVcPq4A/tCzuviEDI32m9muVIQ8m89TX1rlbyQfitL0C4C063KAZJ0vwvWheE6DNeIhNB/1MhPNakUb3f5IRXm5zLv8j70SIn/9/9gQZLgKccFbt+wSDYyTzou4BGH630eLRe5ndpVWlNZlkC4Zfdld7aKkiQQYsbte++9l/fee48ePXowadIkevbsiSRJbN26lTlz5uB0Ornnnnti1dbWgcHItiOkMu6wvuHlbBkNgaElMjkvdRZwllVb+AhGNNr5pOMCxlk/oxP+fembuXeebZaX06sn3Wq3QE3oocieyBIk2CuxKxI22eL6cOcaUup2h+0U5tvuokYhQkbhGutS3VINimg0+RFa8VNwTcpGS0eAq79fcJzp9qFQI86MmgjUTOxTba/wkP1SnEJqVp8aAVSRwrUNt9KeKv7CZQpuTxVdpFJutb0TMPAhnLYKAck08F/niSE55CrCFSFUrPSiZF+Tw3thfi7DU06HBU+F3JaDHacASwzmxJ0ix+vv5UoBK+r7uTWxf5HBk7b5dAzwjpaSzS+iM6sSJ3utB56BFKG8i9Em2gE/EgKq/nRZXbqeHMUzx4aQNEkdO3ZkzZo15Ofnc9ddd3HuuecyduxY7r77bvLz81m9ejUdO8Yu/L1V0GUQZHTSzVchcDny3mJ9xy/5YrQEm+a2Pb+qDGOXyA5ZyIu0nao/wBznWB60j2evRxi4VjiyltOrSm5mEsek10TWIA+mvrqCZZtLXH9EmDdLr93B8hpB6NXhPf23Ap1fi2utS9yaOgWZRSE6s6qmvjm2Z1wTaYhUi+SwNxpqskKBzEfKAAQy7amijDbMcY7lhoYplIjQcmwFQ2r0qzshhNJD6nOYbh+Pgsy3f1Q0fuGE7V9h2V8KKe2aPV+O1vjzfRYtYc182jGWJ+wXxKw3tDQ8CjJFSh6LlUGsVfKDpmlY7BjEHI1kvL6BFHrvoiC0vg0r0CP0nwQnBvkEY0HIySS7dOnC0qVL2bNnD+vWraOoqIg9e/awdOlSjjzyyBg0sZUhW/i2950IIYJOHC3tNxCNyK1doi3rlDwWOwZF5ZyhXBtci8VweT1zbLMN5X/x9LnxZOrZecjpOTq/Cp2eji1MfHW9S1CKQt4std1TrO94qeKXKwX82zHab1FUMyeHgu8CrJ7/BvsU9gUpBSFpCHKfKv1Ca4AHoba9QqSGJVj5Mkz6hlWJk3kj4SGeTnjWXVZCAH+33xDx+X1RTYV7RbohQVTNMaNqQgW4/Dtm5cPLo+G9axu1oSLkUkbhvLtq9KZvQk9XOye7TcNzuSj0k0eAK4Agm6cd54XkyG60D/SCQbTQM8OV0paJ9klcaP0SCe3s59D0Tumdp0KkhSTFqLXZgrFfJPKE/XxubLg56hsEIKb5BKNJWAVuAbKysjjppJOi2ZaDAqciuHHDYRxnn+LKXeKxOyilLQsdp3Kb7d1maUuw3DyRaHI8F1Rw1VUKJ1Q8XMrJ4B77VaxQ+rEqcTKEeG3VETIrxcaM846lMD8XlA7UJ3ckoWa3bt8YNWVeYf2U4ZYNPL3oGobfeQeWjE5QVUKke7LJ1kVehUjBlaAvGpTSlun28ZqmyDbsD3rvnlXeixoryu8S2eRKoeULC2dc/qB0YYhlS+g/9EHNCeWJuqN/0amf/iRS3ncM4Srrx37vrPqefaccxXaRy3vKUNYqvd3fn+osgrf+ge+4ktz/Co6ad0oiNFO9EK7fvOU4lcecl3iZmKCpaPJHygA+rJOptTibbe6TJFhoP51+8k8h5UIzcu+qLtdzMxGMT5QCPq3vx2vDnWQp5XxXkUjl3lIe3j2L7ACbO993ytecp5rF77a+yjUGcpKpVJJGFvsDHpNCPbdY3+UG+xSG1D/DJMt73GJ9D4hs7RBISBmdXFaXVkDYQpKJNsXbyymprKME/cEcLsL9r+CD1Ckk5CgpSV2+LTIWj2zLngvqAHlLSBNRNHymHrJfSiVpTLG8E1ZCyIu61nHxaf0ZcFTbpqyvsoXfulzIMdue1f1dKO3OoZxH7I/x81dH0rPwUXhrQtTs++rCrWp4AgmIwfq7QqTyoqOQOc5zUZDd4f/qgjfNtgAwfu+qANohM4XdfabRae1kYz8MAyGgglR6yzujcj611IYnqr/UhZaVUbmGFp+Kvnxt7+m3sRK4fLP6WH6jD79xPqspF2ncZb+G/4p+nLHjSSIVvAUSE+2TOV76lWutS7AYPJ/q/zjGupbHnJdQpOQxUi7mCdt8Td+aOc5zudT6ua5/TrSx4aBQJ1DDl1DmpFKhv5nwxPM9cqR24IgTTuf61SXsq7ExUi5mnm2W60AD1/WMblPNeZ58qvTjGowLSTfaJyOQ6Ug599teIZtqTfcERcDDthcpcGxlrHVNVFwkJEngHDkDi+qzGeeYQlKUKatuivzzHczhpt9XCWV3KCOisiCrO9mJ9knsI8NL4FN3UaGGp6qTq/r/4XCf7TXaRpA3ZMiuF6H+ZJDHen1uadfN0O+NTKrqJHPkmrtg3Cs4L3iJPe/c6ld5PdTzep47Wwq8G4Tg58vkALdY3+UncThAxJnIy2hDepKV+846hhOPOwMSS+GLR8I+nx7qGFrlPJYx1qKIzmPkWWZS49p8SNHz+PF0wgaosqcwUNrC0fIuRsnFmhudLPYz3zaLlZ2vRdqln27EKLIkqCCdmc5L+afzIh61/ovzrcYSgUoemo5M9jct/B54Bh5Ms09gnm1WRBnojRKL5JKb8u/gnPXHBtUg+WVBt8Oe4sfZYf8/PqGAqY0bD6N9oPo+eQpenvPweqUHlSKZTKk28IloKnWiIDNA3hJwHpUlaEcVV9uW+30XzjMspS3TG8aTV5LHzb2DHx8PmEJSlOmQrh1GLKMww/Z8s7lTegoikVBKU4SFHuGEp4ZrzlIaVfxG60/pIhR4+wqQXsHZ62yKt5dTVl3HCZU7DP1ctesHmyRkCRLtlbBgDLWJHZnacDndpV3can3Hzzyp3ptRorXIqALXDNvztAmigg+E54Iv6hxMfP1b5skShUP/Tn3xi9gOlEZ1YVTH+MmWzRGfxygyHrapCFHfz6XOk5hkeY8rrCu8Fiy9d0F1+B5a8U7kjWhE3eg4sPK2chrnY0xIUhksbeICq6tup5ZvjRq5OKR+NjfYp/Cw7QXaRfoO66C1AQv2yIKPAQkyOrH/+GtQ1n8d8EgvLZEH7aRq5tme5kPnAMObEM93Sqv8zC6RzWLHIMZY1wQVkNR+uc/+f2FvcD2RQ4ikftoxljVKvluoW/7pT/TMSXO5OcQ5ITtumwSmoGs2uZlJfi/kRMv7ZEv7mzXyLJRki1qfV4kkhtbPCqpWVsNTo5VFPFCb1O6LxmIrgNoP/8HQmSsY91wRS9/6N4dvnGXYeFFLYkjXS6nbzVzb0/wkDuN6DQfMlvTjlyWXVkrLgdQI6rNXk3aqfTj9wy04kVnUcbLXcdFCklzFi5uLaL+/sgTXWJdxq+09vx19oGtJgFRbEbV2/EUGA+QtjJHXIKFQEuL7fJPtA3IDJLH0DJhYrhTwYKMvY6zw7TvV3yrMs7n+UziTgqPba87vKjJKUC3R2RZjWk/PZJXD5fXMs83SjIC7zvoRuQG00554ljqByPMvSUHWGCFcjuVrlTwv6wM0zg3xUmU8AKaQFGUssuTOfute0FG4KgSnumgTcLLV+U5NI99P/ino+UMNFdc8h2j6rW51+MYyH1FLlQAk15Zy+P7vvSY3o6dPlepDup5ntMoKpZ87MeTNDTeyV6S7drth3FuwyT+UxSHcvlWj6TyTdgqgpLKOy58r4o6tR3KDfYpfFFS0CFR/L9rEQwFUlUjvWwioFkk8aZvvjuhbmPAIiTS4k6NGE1VzEatxAIHntLDI6AQXLYC8MV7zuy8yCldalgXMeB7K/FVNMk85zue/Sh9dwUv9O9g5tUqdQPQ2uHqFqNVNzMKER1jtk8y3pLLOnQw1njGFpBigZr/NyXSZ3grkbWRJrTMTbiD/GU+WKwVMtN/MgRC1KyrqIhvoZY9VcsEO7AupnINf/pcQwqfVHfWVlmWMll07yjLa0FaqDlmDo143UJ+1RFVz1QflUet8zpFXIXaucqcFEDHKlrPC2SdCbUHzE43n8qnzhIjvO406Pw1FG/YjgHrCzwiuhaq5KFZ6USEiK/rcbJwzF/LGuP9U5/fs1KY6piPlYlYlTuZ+W/iBOb5kSLXcZnuXosSJQQWvQDxgv1yz1AlEZ4Orh38x43LmN+Z9UvH04Y1XTJ+kGFGYn8vwvByKt5dj2/ontK6afm7ut71CnT0hqMltpFzMw7YXSA9RuxIPlNEmJNu8nyo/DP8vz8k0nMXCqPATUjh3FH2cAC62ruRiXBFh5cIVchwLGcYpJC6yxi7yLJ650Loqot/rZehXn2EyDQDUCisCmRSpIazrqFGIqoO6gsyLjsJmSwkQERpZ+Avzc6m1K9zy5ne6PkjRIlCKACP0lX5ij9zGL+BGRc2/NNX2Mp2IngnXF3WszbA9z4r6fijIuj688YSpSYohFlli4NFt6Ze6t6WbokuwxT2LanfWVz3USSJY3o1oUC2So7bj8UwIFy3bfDi0IXQtY22Ud/ix1japYyMWEU16qS4i0a60ZMHb5sbIs0/CEbaApF4jiwPcbnnD/dk85zkRZUkPlbCfqUfSQ6ciWPvrXj747k/K99cb8kGKlEjPe5a12CsxqtZcvlwp4LYYJEv1RWr0fRwgbyE3M4mCrrEzu0YLU5MUaxQnFP+7pVuhiRpNFUiL4BmZokr/Xt97+vLEeKEVAiw4ouLg7OkUqYbQ7hXpmvlCYk0414tkwWoJYtmngXxQwtWQuR1SaVmH+nghWs/vOutHbBRdOVoq4SrrUtINhKxHA8+EmSGFriemQ5dBOBXBs5/9wkurt7Ov1u7+emCjmT7Utihh1lSMFM/EqJ8q/dhs7c3+BtdkqCb/bA4GyFuYcPaEphx1cYwpJMWanWugNj6d00ppy2LHQC6wfhkwHNc366tnro520r6IcuqEgiRBCvbgBxo812LHQJYrBe7Q2kjyLqnE0gco6udOSIdT74RPDt6i1JH2V0tP4QeTkKY+i2dtzzS7cLC3MUM/uMw92Ua13gMmsmxLGXe+t4l9Nf5zT/swQuglCRqEhSQcIeca8p0DQv29euw11mVcwzL2Wdtzh+MylisFdJFKwmpDOIzKz6FbKwj/B1NIij1xWsRvrbMn65VeCEliofM0brIuDvqbDuzTzNXRUkT6so6xrKVEtI1aWQ9oGY1J2PQZDwNugKI5USmZ0tppCSf3QKjaToWWr/MYTVriXuw0ZXc2UmJHCHDYUvhvu/Fc/+oGrDi4yvIJR0hl/C46sMA5AgfWsM30yZIDAEVIhPLe+ba5nAzaRaAByrT/xXzbLG60T2Kc9bOA/RJpAmBPuvUdEflJmglTSIo1cVrEb6DlRwZafgzpN12kUm6xRi+BXaRomVNCqj0FXGtdChxci5BhehSCbIHCRxGNJVM8janRnBRbA9G+z0i0QELAvx1nIZC4LopCvNZ1DoXn25EKrzI+Ru75DWU4cz78kTstr7vKtXhE195jfY3nHGfxmPMSdolscnRKrQR7h2RchdD/4xzB+ZZVZFATtG2qT+ZTjvOZ5zyHlYlTdK8fjCbt3rNYgvw+quPE0npED9NxO9Z0GcT+xI7NlsMlXAI5NLocnLO5tLGadjwJFL4vrhLCsiRLYJGUmNzPMmef6J80yuz89lNXMre8MSzpNZNS4VNdvHFBifexG4iWbHu4w0rNafOoc5y7cHSsOBQEJGias7Kl/Ybf98ucHzC95mGus37kFxwgI7jO+hG3W97QDaFXBVAjeequsKwgUwouIHneyzjrFwAsdJwecU6rYAJS1DnwVzNfMHziWkiaNm0akiR5/ZOTk+P+XgjBtGnT6NSpE8nJyZx66qn88MMPLdhif5ZtKePumsuA+F5sApYJAdY7ewTMqNvSLHP24xnHOewjrcWjkipEGrtE+5ZthAGO2Pg0tz/wADOWbmHSd4e7k1tObpjEJQ330q9+Pv9yjCZ6lcqiT7Bs8vHbcm9cmYlTGddwtzunTSi5u0yCE0o/qvPhCMs3Xn/7fn+NdSmfKyfwlOMCakjSPMZIu0LNAafmW1uXOJHbbO8gSf7319LzYCCcqR1augmGiWshCaB3796UlJS4/9m0aZP7u8cee4wnn3ySZ599lq+//pqcnByGDx9OdXVsagKFyrLNJdzw6gYW2/txg0YZimggRGyFL/VFP93ybci/PSCiG6YeiELLem6yfkBbKXbRaUb7eaXzWK60+BeENEpzTW6SBI+JWfy+yhWWrRZkXqwMokjJY7i8nr9ZP0Jqpb5KRrIbx8NCorbhRUch7amiQN6GjBJRXS2TyFGT2waKnrRKCl8n3shttndIk5o/MaJvDiW1csEHjgEI4m9jLoQrZ9qzv8T/JlIl7oUkq9VKTk6O+5/27V2dK4Rg1qxZ3HPPPZx33nnk5+fz8ssvU1NTw+uvv97CrXbl05j+4Rb38rJcKXDv1F92DI/adbR2ENFGkiAtjCSR99ivimpNt+bGdwEtJZvyAGUgXBNAKgUh+nq1JBZJYa5tNiPlYmQUd/2ugfJmpsU4/0s0iDh6LU523wdI4jbbu+58Nt8kXsdgeWPLNCYOiOVziPZ8lEFNdE8YAnpJQE+y/MxE+81uH6x4Iov9bF/9Vquo2watQEj6+eef6dSpE127duWSSy7ht99+A2D79u2UlpYyYkSTl3xiYiKnnHIKa9asaanmuineXk5JpffOQt2pexYYDEY87HTDpZR2MUt5D9HtG99zKY15VZ6wn+82Pw2pf5q77Ne4v9c6/iVHYcRmyVpswQ8KQDj9MsP2PKsTJ3vV74r0PlrJHOhFS/nopOI9V2RJB7jYuhKnkFr1HBAusXgOqhYDojs2482vSzXFdZP+dEfyRYNoJFiVJNc8eTsvU/xr6/BLimshqX///ixYsIDly5fz3HPPUVpayqBBg9i7dy+lpaUAdOzoHT3WsWNH93d61NfXU1VV5fVPtAlUkyZYUUFFQJVIolpEP2V7c0y4wiOT9QqlH085LqAyBjuaaE5O5aR7/V1KW26wT+EZ5/lu85OC7E7h72s6VY/fKSLP/ZGMPewJKZzJX82C61u/KxS06tlJQK1IOCQX+VAIZNJRHYZbUx/GY1vVNt1jv5ob7FOopJXUjYuAq6zLkIhiQXAD5msjqEKcc8fqyE/WDMR1HN6ZZ57p/v9jjz2WgQMHcvTRR/Pyyy8zYICrWJ/k89SEEH6f+TJjxgymT58e/QZ7EKgmjVpUcJ5tll8yMHWR+8J5PGOs62LStuYI+13oOJWR8tfcZ3vFK6eSmuU7nnZfe0QGA+qfpZ/8Ex3Yp1vjSGW5UsCK+n7uhJqexw+UN0fcHs9acKEmiyslmwfsl5Mn/85k66KQrxsOWuNJ/Vut/WUSHvH0ngQjnlNGqG06Rt7JGiWfSfbJvJYwI+zztYbUCVlS7MtERUIHaV9LN8EQcS0k+ZKamsqxxx7Lzz//zNixYwEoLS0lN7dp915WVuanXfLlrrvu4tZbb3X/XVVVxeGHHx7VthZ0zSY71Ub5Af0M0ftII9tnIO8jja+dPTnbEhsBSY9ovvSSBLfZ3tXcUcbTvKK27z77/+HASpGSp3usZ5ZxVSjyPd6VaPPlqLRNfRblIp22BgpcqvfygP1yPlEK6CQ1X73AeF8sTEInnPkg6nmmYiCITLYuYjKL2CWyqBJJZITpbB3PYz6ehVVPjj7q6JZugiFalZBUX1/P1q1bOfnkk+natSs5OTmsWLGCE088EYCGhga+/PJLHn300YDnSUxMJDExMaZttcgS5x2fw+ai5X7aBr2q0YpwZYNVw05jRXO+PHoahlhjdKJ4zjGKCtIZI6/R1SCpwk8nqcL92S6RxXT7FSxXCtzHGK0EHsrkv87ZizMtXwe9F0lyjZ9HbC8ygxfjfhcZLVrDjj4eCLWf4qVPY/V8cxqr3ceLQBHtTWpLmzwD3Y8ioD4lh+QjBzdvo8IkroWkv//975x99tkcccQRlJWV8dBDD1FVVcUVV1yBJElMmTKFRx55hO7du9O9e3ceeeQRUlJSuPTSS1u66bBlMf/Y9g8SE5r8o3YJlynkfturgL8ZRdbIIB1tAoWzNte1mgMj15YkON/6FX+Tlro/2yWyWOg4nd9FR9pKVXTmL66y+ofz5zZm8L3RPplPlIKQKoGH0i+jrF8bPlaWIDuKjpom3nj2azhjuzkFOr8aX8hYUFqkLeGitdiHan7WQy3cXYeNpCjVg4yEaD+Lln62unn3cLnIJJ/9uCvbfysgroWk//3vf4wbN449e/bQvn17BgwYQFFREV26dAHg9ttvp7a2lhtvvJGKigr69+/PJ598Qnp6epAzx5gti+GtCST45JfJoZy5tqcDvuStpjjqQYJvnpFcKrjN9m7Q30mSy3Q4x/YMsx3nxaSWXaQV7A8FmlsrqvrUhbNYN7cW9U3HUNYo+ewmm/VKD7fPnVpeSERJ4Iglap+96xjM28pp5LCXWQnzonJuWWoKkmgJaoWNz5QTOMtifCPU6pEsSBe8CHljWrolhpGEMPedVVVVZGZmUllZSUZGRmQnU5wwKx+qdml/HcOJqVZYScLhqsHl4wwe75NhayYWAuihINS60iZISIhWNz73ijTahmnSbM5nWyFSedFRyBznuV5m5JFyMQ/bXqCdFB+Jd4OxzNmXSfabedj6PBdbV7Z0c6LCA/bLOEL6iyutn7R0U5qXKz6CridH7XRRXb81MIUkotzJ27+Cl0dHp2EhckvD36ghhRm25/0cwk1ix6Eg0EQbNYrzM+UEzpC/AyLrw+Z+BjXCRooUvpmmudtbLtK4y36N24cO4Bx5FbMT5jZfIyLEKVqgxlgMEMJVYzLUUiQHDee/AMdeELXTxVpIius8Sa2S/bsNHRYL0fRe20JOlH6JagIxk+CYAlLoCCRkCYZZvotK/pVIfx/q+xKJgATNP2ay2M882yxGysWAK1qzrRT9/HC+RHMeivZi1ZJzpG/B3EOKtMDR5/FGXPsktUoMDoBYTJJZVHOd9aOYnd+kdRNPGq94WyS0ypPES19FA9UJeqrtFWS78MtfpkU0+iCafXiwODcfTOMqZDI6Q5dBLd2KkDCFpGjTZRD1KTnYDpRG3c8i2KTV2vw6TJqXeJqc46ktWsR7+8JBlqATe5lrm+0novpFw4n4ymlmcpDQ54qWbkHImOa2aCNb+D7/LiB69YHiJZeHiYlpxj048N1Q+eUz0/jMxCRivnjEFdi0ZXFLt8QwppAUA5w9z+YG+xTDhUoDLTxCYG7pTOIGc+Fs/ZjP0KRFqSqBtya0GkHJFJJiQEHXbLJSbKREKUmZOae1PNGogH2oYfZX66W5BalDYazE8h5bV/81NnbZna6UOXGOKSTFAAsKU/m34eODlZswaXnUXMWtazJqWSIZu4qAapHEM45zuKzhdrafeCd1JJr9b9JqaYlKCvGLgKo/Yeealm5IUEzH7ViwYxXJjkpTBXQQcTDkZ2ktqILQ3+3Xs1wpoG1qArvTDtCV+qi8U6YFO/6I9jNRHc/jQXg42CIlo4rBlDktialJigXbv2rpFpjEEMU0vcUczzVl+tm9Wbr2u6ic1xSQ4pNoR+bKUci9pUW0gnFMGmkFOZNMISkWxMksbL7PsUGWXH1bJZJNX6UYIDX271TbK1x/8hG0TU/kp5rU6Jw7Kmc5NDHHOZSShVNIIfXFoahFUgQoQgogVEqtJmeSKSTFgGKR19JNcBHhpGbOifrIEmRItUDrnATjfcGTJegk7eXOvH2UVR1AQqFaJLV0s6KKVoX7eKY1jvNo8q5jMEPqn+E5x1lA8Hco3t+xWKEWTpYlV01G334Q6lalcCbIluZvYIiYQlKUcSqCW9alURUHE3o4k5qqGam2to1+g3Su15qJl4WjtfejLtuWULhiOAsTHiFdqovaaeOhv3zHTjnpLdOQKBFpn8bDnBmId5RTUJD5VnRjP0kB3/14GF/xSkNKDly0APLGtHRTDGEKSVGmeHs5f1bZudN+bat9USQJ0h17m8U0ES9CRmsn1H5sLf0u1s0joaY06ueNp/svdnZnmbMf8xyjqRBprXreiIQSJTs6DYkB+0UiAPdaXmG+bRapBBbY1b5orc8yXLSc1CXJpSWtEGmMa7ibZcM/aTUCEpjRbVGnrLqOkXIx99pei6uJuDVzqEeHHNL3fwjce4HlZwAKLetxHmKLqic9LbvidqwLZBYmPOL+20gT4/E+Yo3ePcuSq8iyQKZDRnT8C5sLU0iKMr0qvuBs26yWbkbYRPJix2KCU/00FCFhkVr/ChJOHx2Kk61KPN97LMb7waDaj6Rf4u15i8Z/pVLb0k05KOiRcoCCrvGrMdTiYHgn4wfFSY9vHwIpspDWZY5+0WtTK6dGSuIpx/ncZJ90UESSqYtAvDvptjZaYlzEYkGXYhS63lyoz6G1v6cqUuO/zOLh0XmmowedgKWVdaapSYomO9cgVe2K2JfngJQYleY0F8EK8AbbWQb6Po06brO9yy7RhjoSSKIhssbGCa1pmohXE4gn8d6+Q4XmeA7NPR4P9aHlFnwJvy8UoD45h4JTz45Sq5oPU5MUTSLMHqoOxvMtq73+jie0wpaD7X6jEQWSyz6SpQZzMWxGhIAPHAMopXWpxw9F4nGuiBXmHNAyhKsAEkhISCSf/XirCPn3xRSSokmUs4e2hsnAaBPfdQymzJmhOZkbuc/W0BdGUE2GsbyfaC6YJ1l+5pT6J3nAfjkvO4az0tk7eic/BGgO4eVQEpBCIdJuMbvVRaQmYCk5C6kVhfz7YprbokmXQZDRCap2hfXz1iAIvOgoZIXoR0fKud+2gGz2G/rdCdKvtJerNMNDDyWa437VjNWRXkqSoBN7WZt4E22l6mg0La4JJLyGK9juJxGETLoUO8ffapJJp7ZVmEWbk0i6Qpj1a6KCABpIYL21P3u++5MO6UkUdM1uVX5JppAUTWQLFD4Kb42P+qnjZQJcIfpRrPTiSssy2krGBCSAoy3Rz3Vjok80h0o23gJSMB+01oZaDFUPT2fkUO75LcfJ3Om4DoACeRvDpG+42voxgug4AivCJSApjQaBg+V5xANmX0YHCUisLeXZ//yHtUo+ALmZSUw9O4/C/NyWbZxBTHNbtMkbAxe9AgnRzQXR0i+taib6h2UhXyfewP22V1u2QSbNhp72ryXMPNG+pvAQkAK9Y3XYDL+DQkCdsFBLEldaliGjUKTk8Y3owX6SoiYgSUCmVEuWdKDF5weT1oHe+xPryOF/256kUC4CoLSyjhte3cCyzSWxu2AUkYQwLdpVVVVkZmZSWVlJRkZG5CdUnDArHxGFSLdYEi/aKRMTX7TGZizG6wGRQKoUPGIylGv7HusUEhuVrpwg/xa19h9s2jyT5kFr3HhKALH2lfzQOYApjkkIZHIyk1h1x+kRm96ivn77YGqSYsHONRCigHSw5HkxOTho6TxOWmMzFuPVgmLouFCu7XusjOAE+bcQWhUYU0AyCQe9caP+HevxJEkwxlrEN4nXM0IupqSyjuLt5bG9aBQwhaRYEGYqAFOn14TZF4GJdf/UY4vtBeKEJMkR82uo0UHRWoRae8JJk5Yh0LhpzvHUhv3Ms81ipFxMWXX0ilbHClNIigHO1A6GjnvLMZQKkQaYE58WB0TzLdStRShThKtaeqzHSrJkD/h9sP6Kh/6MhzaYhI753A5u1Llrqu0VOqTG/2bMFJJiQLGzF7tEtq7JQhFQLtK4wLKSTJ8IMYGZnwNcL1JqkIU62tdTiddJWm3XW85TWrwdwYS0eBD446EN4RCv46+5aE3PLVrPqlbY+Mx5XHRO1gqQJegk7aWftK2lmxIUU0iKAWUH7Ey3TwD8fTt8//Z9AFLjP/stmVSI1Bb3DTGJHypI4wb7FHaJ9jE5v9EJvzUtYq2NQ11AioQqkUi5SGt1c6YQkISd75TuLd0UP2I9Hrfv+DW2F4gCppAUAzqkJ7FcKeAG+xS/kg6ltOUpx/lkS/sDhgKnOSt50XFmjFsa/1SL5Gaf9CTJNTnUNqO5LxhvOobSr34+y5UC9oroR3CAKfyES7QXEmOu5PFHLBbUYKdUhOuftxwnc5/9al5yFLo/bw6i8c6orhYTrJ9QEsAC0RLEek4oE21ie4EoYCaTjAEFXbPJyUhkeVUBK+r7USBvowP7KKMNxUovxsirDZ0nkwPcaJ/MHNszWKTmfXM8E+y11OIpBKRSi9TYnuZM0ipJkIydvSKdLKpbrAq4EFBCFnc5/uZOGrjbrKUWN1SJZBxYDGeeD4YkQeurbuUiVvNEIPPuPlw+nRdZv+IivgJcrgxA1J5Jc9FOquYJ+wXcYn3H8G9qhZUkHK1ugyOESzNuOXJwSzclKKYmKQZYZIlpY1w1rhRkipQ8FiuDKFLyuN3yBk/Y5hk6jys7r8zzjlEtooZv6Qgn9cWvJplKopuc0yhFzmOAljODSBIsdJyBgoyMwkB5M4OlTVSLpBbbcR7qJqF3HYO5ueFGLmm4lxPqn6Nf/XwesF/e0s06KNFa+/eIDF5wjOQtx1Cy2E+WjzDUhv20YT/fOI+mWiTGpF2xegd+Fx2oDWHeTSL20ZmxQpYkCrrG/4bP1CTFiML8XOZf3oc739vEvhqXA/Jdltf4m3VJSOeZYXueNuyPSi2uUElqRsdpPWQJMmiqe1UhUtiidGGQvBWIvZZrOznNcp1A7BQ5jJSLmWF7nmxfR/8oJVgMNffOoZyI9G3lNIqVXhTI2xgtF1FGGxY4R3CNdSk5lGtqHQUSUnouzq6nYNm4sPkbHYB4z7uktutpx1jWKPlkUc19tgV0kio0j1f7v68ldv4useqrtlJVSAEr8frMgiFJ0IZq+GMtdD25pZsTEFNIiiGF+bkMz8uh6Ne97Fm3kDG/LAlJ0JEkl8q4JRakeK0/mEkNg+SthvojGv02WNrU4n1xpLSLKdb3NMdONHPvGOVt51CGWzb47eBVE21rnbiDoQiXT2EW1axKnEwnqSkR3i6RzWLHIP5m/cjPNKwqHX488W56FN/XIhse0fgv37pxzW3GjoRflMPIZD9zbLNbuikB0Zt3AgmjLrN625j5G0ZKzATpMHMKNiemkBRjLLLEYPsa+OXesM/RWhcd38kiGhOyLDVvFNaJlu2RnyRCbm4UkOJlHFxkXckukcVL9vOwonC0vIsB8lbaStXBf9xKUU2bXzu7ay7SOZTzN+tHfKacwInyr7T1KApcItoy3T6eqk93sTBBW/sRKe86BrNPpHGVdTmgkVUZ+K3n1aT+tIiO7HV/XiWl0aaV+O78RQZP2OYD8S/Y+c59geYs0Si8LnScShltYt20gOgJeDGbe9I6xujE0cMUkmKN4oRld7R0K1qEctK9FgvXVB25MT9ehIXmwhIH9+s7eeZQwRTre/zbMZoz5eKWa1gzoS7K51iLNBcS9fthlu8A2CPSWKccw6+iM2uVPNYpeUwJwSE3VN5WTiOLai7iS9IlnyzGtjToO4Gjeo7Ced5DbF8xB1H+G1L2URzRqy+8dm7M2mWUQJoKRUA5GQySfvDS3kV8TWKj0dO6B2ejb+n34mgesr3otaGQJFc7brO9yy6RRblwCa4tIQg219yqCKhJ6khal0HNc8EIMAvcEuMCedu/gpdHR/eczUyok4k6oibab6KcTIZJ3zQ6ocf/DtDEOIoAgYyE0izPtVokk0ptqxhDvoLUHpHO70p7+liiV8MNmkyAHzoG8DfrEv+iwPi8u5IMwiPJQHouOOqhtoJ4SGOrp4GJyeKd0g5q9sTgxC7edQymmlR+Fx1Y4ByBo1EnIaMw0bKIWxuFZl9tOzRtJ1vDWA8V9Zm+cdTDjLtiUsTnMwvctnZagc1VD6GWwAjxd+pLf6/tddYrPRhlXXfQvvCHMrIEFil8ASnU6DwHFnc6iHjHd1FvJ1VHXUASjT5gqoCk2Q6/33hnYRLVpYjacgQiaiLS046xcR7tJ0FGZ7h1K1zxETu6XYEQ0R9XP4iubFB6sEUc6U7foTLO+plLgNXRSFaQ5pfqQ4jQouq0jo8XlUgFadR2HdnSzTCEaW6LNXFocw3FN+ht56lcbV0W8jUkCTqxlwmWT8JTkfvueE0OOipJJYsDho9v0xjZt0+khZUDJ16iuKIZiCGA8dYVhs/ne5iEQBFQKaWRlJRKcl1km7o9IoNZjgsAAkb76bbP15cq6s+q8YSFM8GaAF1P5siuJ/Pt8r50Wjvdy1+rFhvJhB7hq2pY77e96v5sl8hmun0Cy5UCCuRtAedEuTFgZ1zD3Qhkd449V1TfK3TC+Hyq1Z/hjj9PASuS56IGJI3vVALEX5ZxX0xNUqzpMggyOtH88Sz6GJ20JAn+FO0iutYRUll4PzQFpLBQnUADfh/ijjTaKMK1mE6yTw7pd+7kpghedgwL+boVjYkHW3ozrS5UnoTzPFRflhSpIaL2yBJksZ+rqq7mlZ7P8rz9TPaK9LDOtcgxGAUZBVm3NFMsMHyNlLZw0QLIG+P18Ykjr6DdvT/xw/DXWd/3UX7rcw9/9b42rLZIuExqnuRQzjzbLArlIgbJmw2dpz1VXjn2Plb6M7R+FntFuqHxoifIhCvgqJnBg/3e6Fi21Ya5NjQzcS0kzZgxg5NOOon09HQ6dOjA2LFj+fHHH72OufLKK5EkyeufAQMGtFCLNZAtUPho4x/xIygZZa/IYJfIRoTZ9t9Fhyi3yEQPdYcY6ElJEnzo7O8WGKJ13VCQJWgnVaEgUS7SQvq9BGRJB7jC+ilOIen+1mUqTuSyhruY3DCJNYdfR3Jyqmb/7BcJLVL6xpMSssKqOxZNTUt7qpi7oxO7B93PSfXzuKThXiY3TOIZxzmGz/Gp6Au4hIRK0njRcSYVeAtcLWkC+r737dDrLJev6KZ3XP91NMD2r7BsXUSvhk303PQER214mCN+mBte+zQECXVjOsf2LJOtiwydRivSrZ/8E22l6hbXhgbCcNvi0MqiRVyb27788ksmTpzISSedhMPh4J577mHEiBFs2bKF1NSmDMyFhYW89NJL7r8TEhJaorn65I1x7V6W3QFVu8I+jVFzQTTV+btxqYnnJ8xGKzpNz6lbjUjZLTJxCinysiqWRHDWR3aOIHzuPI7TLBtjeo1Y0oCFRJxBj9shcvnYPoDHbPNJlyLv03DH2t8tb/nlWgrpuo1jUSvVBMDt9uvITE3m1i67OPKXl3XPYyeBfzuGcZ11qeu8zbgA/ccxgmVKgatcUdK3PCmeaLHcRWW0oaSyjtN7deTEw7O494Mkig40MIAt3MQHQX8vEtJpZ7VyZs06l1nIw6S0R6SRhJ1U6qNqUqsVNpIlu+H++nRNMT02P0lybalHA5pM+xYgLcKwN72futoYXEOuOuMXK738vuvAvvAb5kPLJYSVXNaVVhDZBq0suu2vv/6iQ4cOfPnllwwdOhRwaZL27dvHokWLwj5vrL3j3ShOWDcflt8d+k89oh5Af3CrT7OaJDJ8Q4FDQE1uNqR+Ngoyl6R9x4yUV5E8hbzkbKgtd2UT1jFiRM0PJCEdGmKbh+fmhhuZaltAFvsNtfdlxzCusH4a0zapqH4OFsl/knUKiSXO/uykIzdZgy9m3zqP4gT5t4PCmV6rXyqsHfiry2i6lCwlsaY0wK9dqGN0sXMABZYfydXJ5BwLHrBfzn+chW7H3pFyMVNtC6Ia6h4MdUMzoP5ZHFiZfckJnHNCZ5yKoHh7OWVVByhcMZyEmlJDsoPWOx9twU94/I/RxLIVNOaEkuLXhKLO87Mc5/G16EV7qtw1PzNSEuknfuB5MS0q11JN87GcA/wFscY/NEye4RLr9TuuNUm+VFZWApCd7e31/8UXX9ChQwfatGnDKaecwsMPP0yHDvpmnvr6eurrm3bQVVVVsWmwL7IF+l8Pa59FVJXoChZalNKWTc4jGWH5JuCkUEEad9mv4SR5G9eE4XANTS/PdPt4d82wHTUJ/Nz/7/RIq4PU9q7Q4S6DYNsSpCAasqjsVhqqcVqSkR21Mdv97Cabu+zXMM82K+Dkq+70Nig9uILmEZIkYJZjLFYUZEkhnRpAYqfo6A4vHihvNrTjP7ExyqqVy0dA0+78Afvl7BFtXA6uDdXM/XW24XOoz/kcaxElIosPHP0ZY1nn9V2suN/2KtdYl7qdepcrrqLY/eUtzLU9TWYz5MuRJWhHFSsTpzDdPoF2qf0BVyLcgUe3BdpC4uPw1gSMeHRp9Vkk96Cl8VB12kYFJPU3EL8CEjT1062297w+r0/JwTpqJiSdgP2tNlgb9kX8/j7puIBx1s9CcgQPFb9ceRmdXE7zURKQmoNWo0kSQnDOOedQUVHBV1995f78zTffJC0tjS5durB9+3buu+8+HA4H33zzDYmJ2sUNp02bxvTp0/0+j7kmqRHnDx8gvT0BfHZXfjlCGj97ynE+v4pOzLE9A+intd9LOgPq5+DAygB5C28kPBRW+ypFCnfYr2GZMkB7Z5vRyeVnpQ50RwPiyV5QszfmC28sIpQUAZWkcaN9MuuUPIbL6zXrpKnHAtxgn0IlaWH3cajsF0mkeWgGPaNlVGQU1ideb1gTdjAxuWESi5VByCisSpwcclSVivp8m3N3rTSad56yn89OkevWHAyX17sE9hi3x6sdwN222zl17FUU5ud6H7BlccQuA+HgO/Zjnd8oHlEXacnnM71h4RSuzW2g5JwP2i+njDakJ0g8JmaTGcV5Q91IXpwwh8cH1JMtKigTbbAcOZiCo9tjieKAjrUmqdUISRMnTmTJkiWsWrWKww47TPe4kpISunTpwhtvvMF5552neYyWJunwww9vNiFp9qc/seWz1wyp1V2DLZtE7IbKPlzScC9FSl7Ei4VnLSrwrUXl+kNSVaYRJMz8zHk8p8nfG345teqDBZoQQkUVPmQEj9n+5Ze9uEokcYf9GipoQ0fKud/2CllUx3wR0/O7ecpxPnOc57rNNWfK65jbWDbjUBKU1HEfyeZApSV8gnwXPHUcAjExv+n5o6iL28n1s5lzeT9/QUlxws41UPwcbA2utYwGlzbciYKVDuzjurMG0Tv9ALwXXuRZa0ZrE+35CPeIDBY5B/Gp0o8sqt3lc3xr9fnOn3tEOu3CLCmkLby5/vrplDn82vZ0HlyyhZLKpnk0NzOJqWfn+Y+tMDGFJOCmm25i0aJFrFy5kq5duwY9vnv37lxzzTXccYexciDN5pMENDgUTnzwEw7UO5FRuNKyzCufRqSoO2pw+TeEuxNVXybQmUyB+qSOJF/0HDtXv0mXX18Lq72XNNxLG6qYY3vGsHO3505oN9nuCcH35Q8HIxlvfR3RY5l/x8i5S0Q202K4oLY0wUpWlHr4zo2R1/B0wrPN28AY4KmxlBERCb7hCH0P2C/HkdyeqZeejuXIwS5XgUacDgfKY0dha6gMvTEaBHMgVsf3cqWAiacdza3dy7AsODsq144FzSlkKwJqSeAlZyGrlXzWKXkB/du0hJqotzejMxTOZJlyEje8usHPQKteat7lfaIiKB3SQpIQgptuuon333+fL774gu7dgyee2rt3L507d+bf//43EyZMMHSdmHayuvPav5viv6zcuCqRPTVNTqbRntS1E5AtoFMzOqMapUKk0bd+PgpyWBoQT62ZETOTaNx6BTt9MMGk5aJCtDnYShn49m+5SCOL/ZoV7MElSKxQ+lEgb2OQtJnJtkXN2dyYoWqRJaBjBObD3WSTG4ng7GFeX7a5hMUfvMVc+/0hn0bvvQn2vnk+5+VKAZ0zbHxquck7Qs0AFSKVTA7E/P2oEpEFzUSCrxleRuGZQbV0lMo5fvOjWOvLY+cScfI/4KhToMsgnMgMefQzLw2SJxKQk5nEqjtOj9j0dkg7bk+cOJHXX3+dDz74gPT0dEpLXS9FZmYmycnJ7N+/n2nTpnH++eeTm5vLjh07uPvuu2nXrh3nnntuC7cePxt+AbBYZDNdbhrE0az6XCWSedI232tC3CWyecA+nh7Sn9xifReI3QIfqvCw0plPgbzNLdDdaL85pIyyajhsgbxN03/IF8NZiYMcF2/Ckyw1LTTRWACEAIUopG2IgMWOAXyq9PPyz5lqW+A1Nkppy3T7eABWJU723jHHmSAbDrJExE61sgS3NlwPwFzb07QJx++kqgTemsC3A2dzw+ftOFsugzCyrISb3FCWXILSVNsrrKjvx64qO7fIlzAvYVZIC/6LjjO5xfqOn+bE12ylVT8uFHeAdFpGQALIbUxaqQqUbVITaTi8D8k132Grj7GGuUMv6HoyAMW/7tUVkMDV5yWVdRRvL28MDohf4lpImjdvHgCnnnqq1+cvvfQSV155JRaLhU2bNrFgwQL27dtHbm4up512Gm+++Sbp6eFljI0aWxZrRoPk+AziYqUXu0R22L5D0LRAplNLGrV+15tre5ob7FP4l2M01zX6GMWCUFLeC2C0ZR3nWIvcn7kEusvpJJUbMkGW0QYZxXAG21gT8uKTnIXSZQjytg+b/9o6qJGNE+03sY8MOlJOW6mKzvzFVdblzaKpEkA/y89McUxymw7UqC9PodrXuVnrXsLrF8mlPel9Hqx9Jtzb8CYtF5QGqNkb/Ngoo4aRZxnYSGj3mUAgkbt2OhKzo7qxM4pLYNxLgbyNIiWP5UoBd1v+ziPKk0hBsvOrJtlfRGf2kaaxoVJ1sC5KyGah/TR2ily6SKVcav2MXA9hdY9II5V6krBrJo0MZpvREsogOu+wOgerAmX5ATu3vPkd58irmB3r9IEeySHLqo0JikaPa0niWkgKZglMTk5m+fLlzdSaEFCcLg2SRris765ITd+vN9Eb5QBJpFDnt4B5Xm9I/Ww2iq48Y3s2ZlqCUGpI+bZBFehmOc6jRGTrmhjUSS+Laj8NQtyT0g4KZ7hTKMg710AUhKRw0JqcS/CPmlP5WvRsjLCMrYbJd0FUUZC9/pZRmGpb4P6NJ1qlP4zReCI1TPmwfrD4JqiPME2Isx5qW2acltHGcBJCXW0PgpzGZxLqxm730efT8dd3jTc4AOp9CGDhgT5cOfxpenw1STdlhzsHlmOg25HZE4XGpKSn3g1tj6Zot8yLq34jSVRQRhs+cg5gjnOsl3BuwclrCTN02xhUE934X4ecyBwu4ce6DJ61PRMw7UgoAr/6/kyxvsMaJd9d8y1WqPPxgi1tuLPRZbhDepKh3xo9riWJ55QRrZedawKGycoSdJJcEw64dskvOgvDvtzbzqGkSf4Cktb1yslsFjPK90pwB3tfZKnRPGB7jyQaNCu+Kz6TXo4Bc4RAopRsSkR2y1eQH/0UHHeRSy0tW9y1/fTKvqhpIGJBBWlUkOrzqf7F9pHRrCa4YAu7WihUb9yri8oSZ4FulXffj0RGJ+9Ed73HwllPhNJsb5Ibc7oFEJD0nq8iXNrVQOM2UB0+1+9dmZujpf1Rn8lCx+ma76cXGZ3holcoyp/GrgD3oNbyM4LvfbxZ04frG6YELLMjARdZvwD8hWkZkJBgw8t8+2c1R3x1G//mQZ5OeJY3Eh5iVeJkhsvr3TXUMtnPs7anDbU1GFalnkmXX8D4q2/hx2MmBRSCwtEyTbYu4o2Eh5hrm+2dqyhMtN4h9e/p9vHM/+p3ZizdAkBB12xyM5N0zaESrii3gq7ZOkfED6aQFAv2G6uk7bkIfKr0C/tyNRiU2tkX1bT2gThe3h7R7zMbHXX3+Ux+pbTlRvtkxljXAEZMP64DpjZMcEeAtYigJFngwpf9k6g11vbzVviHjpGitUrjJPe8YyRP2C+gDftpwwGvY3KoYJ5tFiPlYr/fhzN21HZVhFGXrJv8PwbIW1zpHTS+N9qe5c4CrrdPoRTvCbk2OYe7LX931yi7pOFehtTNYplykvcJ0kOMwDn2YpcT6+Xvg03/3VQE1IgE9//7fgcw3a4/boVHFEKgxUtBpg1VOKMw7rtIpaxKnMxttneQJP/3r5x0SjuPdN3/2HnQ6yw6ZKTqFrtV/77XfiX1KTm6mwVPgc+TRd/tYoXSj3oSNMe/JLneq2wpUFJOAVV/ckLRFL9Nl+oeMVIudkcLZ/q8M5FgOVDGwKPb0pBxZNTOqUXAgBYCb8bUvr/RfrPfO1RKW7frCMBzX22nwaFgkSWmnu3S+vpeWv176tl5Uc2XFCvi2tzWajFYuM9zV/RzYj6loi0dxN6QfT6MFpEdLG9kt4hcct8r0nVzA0XLvq6aCetIYFzD3V7p+VUNgiEyOvF1r9tZvrI94IqQ8XUAjiZaanEB/HTybLbZT6LDr3sp6JqNRZbcZR9K6/pw1BETOO73lzXPGawvPaPbAoXzqn06yvJ1U/bhAOZZ1RyscvRRR8H/ArdFiw+dAygTWVxt/dhQuLHqszHZuojJLGKXyOZp29UsUwrYV2N3H2dUO1JGG4qUPC+fpqF98rljfRpOn32iVGXnhlc3eIUnOw8fyB7a0j7Iu+n2Ndn0puuDb9oG9EGSJUihAQBFeIvJqlO6uvhojVupMXuxXRHUf/gP0up3a/5+pFzM3Ai1H4pwbVhusb6j+R24nnOB5Sdy/1wOfy6Hrx5HZHSiYORMbk0fyo3VcL+G8/0D9vF8nz4U61n9kN6+wq/Mka/AB65+zkq1UX6ggQHytoDRe4bnU42x2fQ+vEwijqikGfEirSPLNpfwn1X7eMOAz1ClSCFDqgnJYT1oe1Pa8WrdEC5zLkL49IFn3y9XClhef5KfX6DnHKEIeGXtDq4++SgK83OZd3kfpn/onScpJ8p5kmKNKSTFgkYTClUlaOkH1DpCxUov92B/+PwTWL/5dkZtvcNw3gq3Ldg5gmusSwP6CAgBF1tXhn1LnrzvGMJVGgtetPMFqdE9Atmd+wlC02g4x8zBKR0HK10O4p4OwLEIF/e999rkHKbbJ/DGJ9nAd4BLzTzm+FwWf19CSWVdY+LPDzXLLBjpyn2NpWgAHra9QLsAqnUjEVO+PkGyBNee3JWbCwthxn1gN7aTriYZOxbGeDjn+woDeiUnPMmVKpjh+CcVDTezgiZB5y8yDPmuqdoHT5+mlT/YcGL3Ol5GcZ978Qe/MLzXRCxWK8U7K/lPw3jm2WbpvpvCLSF5EIKTtoRAEfCis5BPlX7uNg+Qt7gXpKH1s+gn/9SUVHGgy0Rv27kGy6gHefz91fyvIZXdZLsXr0B+W3r43qOv9kdPkBhjKfI3X1btQn77CuYOnM15n7vevZM8FtmvG9s57+w8LL1zQVrgV+bIV2BUL3/uCZ15YfWOqGnH9eYt1/tQEZVreJHRGefhA5n++JfsDuLnJZCoTe5Iab97yfjqJqLpF/jziXdz339zWCUfqRtBqva9r1+gFjvLa9z/X5ify/C8HFcNwOo6OqQnuTeJrQVTSIoFjSYU3hqve0gW+xkur2dj+lC3VO3Mu46/P/gXf1deDLqQeUr4Dqxu5289Bz+jEWdGhu4u2jJRI1w/ViHXvpNgKP4Vv+7YQcHpp5KbmeTezagvejG9uMC6MqzIwrccQxllKfYul9CIyxkUfsm7icIN/f20FSWVdfxrZZM5sr+8JWzncyGgDhsrFJfWJ8newOyEuWGdy5fzu1sZ3u0YLu3fhe/+2McH3//JWcLYpPFt21Ecv2ep3+eewkClSONy2+d0JLAwITVGV82wPc80FnhpDcpFmqYGTUv74Mm+Wm8ByS/xnh3qn5yLZfTjlDX0ZblSEFQLGcnw99TyPeK4vCnlgV86jwl8nX46Tw083eXw3yhQyMA/gF02l+O9es8haV0bET7G31LastBxKrfZ9J2v1b737QMZUISg2/qHWDjsUZYWbeSnmlQ+UgagIPtnX84bA73O8sotd0tRCn/WNz0vVRORmZzAC6t3GJ4PWiKTuj4SFM6keGdl47zUFMCjNZYlCVLOfpyeeWMgNzOq5WHKGk1oehGkWu9PILpkp3g03gk7VtN2+684RRtIHRyVNjcncZ1MsrmISTIqxQmPd9N12BRINKTkYL11MxZr07KzbHMJE19dz5PWOZxtKULWcZTdJbwlfICbLO8GnMiMYFhQEtk8Kiaw25FGB/bRTf4fk62LIrq2Hpc03MuA08Yw67+/AK4df3HiDYZS6a8a/B+GDD+XZZtL/LK/yihMtCziVus7fqHtwco2DK1/iq8SXT4MmlE1SOwmm0F1swNOMiPlYmbaniNLiszPQU2s+c9+lVyw+YaIzqXyw/DXeWdvF97Z8CfVdQ7DJT/2iHTs2AJqeHZLbfnt0rUMOLINlll5hmtx6ZVn8Q3t1no/wDW2M5NtXkKSXmZ6l9kHfjxlDiOXt3F936htUlMjZFHNTbYPDLXdKE/YL3CbtbQEv+8HPc2Jh2dpphjxTbwYTrJa9RyeWq3RclFUk97WJnXk9/5T6XbKpUG1CqpZ2lcT4VQEfR9aQVVNPasSJ5Or9y42au7b4Bof3pdTRfBmJKMzzpEzKE4awsebS1iwdqf7K60s2btEW/7X/34KRl3ZdA41SXF1CRz4C2rK4at/htgQCTI6sfbsLxj3wteR3VMjsgTbHjyTBKsMWxZT++E/vJJ+ukzn12jXBgyTQzqZZKtm55qAES0SgsSaEvhjrTsBF7jUkyuO+5yuP63106iq4uyHzgFeOWTclxRhDjo1U2rNXqSPpkCtv2rZd3HKoZyn5FncwBQWK4MYwBYmsyi86+ugCCiT2nLluHEM792ZN9f/j9LKOhRk7rX/H/Ma/Sz0JsYS2rpKKoCffdx3MtKaJPUW5On28fSTfwroB+EZMq2nnlYX52hM0Kq27ZEfsjg/oxOSjqnXSBZnVcA7+0MFhaYJ3KhZY53zGM6y+jt+q8gS5LKX8r/WY7FlhFSsVCsvjZ7vmu/7of70/wYfyVOf/uz6faA0Ao1bhh7fPkx28hOU1yp+5oYx8hpD7Ta6+QC4yrpMsz1yoxNyzw0Ps3+DIFVjcff1KQsnqs1Xq6UgRz03UnJdGT2+nMhPwLasUwOaYSyyFDDhoILMYscgrrN+pJkIEuAtx6l8K7r5aQJrkztya+VF3Gd7NaJcdXoIQErLhfP+5RJm0jqybH9Xpi/+kZLKIr/j9bQ5r/Uc5H2gbPFaN1Cc8P3rAV08JB/hEIDCmRQc3Z7czCRKK+tcm0UPs3Oo2qRrT+5KglXG+cMHyG9PINFn4OdQziP2x7jx9Qa49PpW4ZdkCkmxwmCEm99xjga6/vwSoOGrIbkG+yhLMbc6FL+BG/ZE5pEplWPOhpX/hHXzvIQlvcVJnYwjSYqpJjD028VL0P7Cpyjs7SpoPPXsPG54dQMSsEwZwL8cv2kmx1TP97Ttah4+2uWw7VQEmckJ3D6yJ+nbP+aMTbMCRoPVWjNocCru3Sd42+eNLo56goWMwgzb81FzBFWffXmtwrYh93LMVxMDOMC6Io3m2Wb5J7bDlZ9smv2ysMfXr3QydFxtxZ+QURv8wCDo+a75kp2awMPn5jM8L4c3vv6D0so6A+YogVT1Jz0aNlOEv7BrtE/KRbqhAtVAwKSPEpBSH3hu8fQpC/e99PVLi0bSW28EAkj/4j5uaay7Z6TwqadWaU91Pftq7MgojLGu0Ux0Kqn+Uta1PFZ/CZsTB/PUgBoK2jtwpnZg2Bt1/KnYUexyQJ+zcFDNZIx6zLUJxWUpuOE1/3pmXr/zEcTbpNiCh8q7XTwm4JscU4C/hJ7RCUY8AslZWH54l9n9rYz7xMIwHTOvXu409+Ub/RbvGpXHsk3/48R3b6F9AEf4+22vcOHiwQzPy4l7/yRTSIoVBiPcfI/buvgJjgmQQVaSwIrCBMsnvOgc5fVd2BOZZxtkC5x6Bwz9O6ybD8vv1v2Z70SqZ1PX20WrpqsH7Zf7+zc1Ru5YPELmfbVBM52X8r04modsL3otQCWNETNjL7wKiyyxbHOJ+zcuJ+lHgmaOTnJWkQw8YT+fnSLXb0cVSmSVFv3lLYZKqRipI1fS6KirssTRlx4Xvsyet2/x8vfRiph6IOEVr2NUoe1+26sIu+w1MRYrvdx11AKZNdYqeYa0islZnSEteurxYJque886xr0Ajzk+l3+t3G5YO6Z3XLB3TtXKDal/ipPkbcy1PU0m2uHoClAp0gxlxjbaZs9ktb5Cs9FzuNoWxGem8f9DEfhlmvK3FSl5lFbW+UUWeuL5HnsSTNBV56kPz5bpNXC4e1Eu/nUvf1Y1BXREGvnqq62RJahPaENi499ORTD9wy0hu1wb7tK8Ma4cXz7+SlJGZ5dAlNrWtSlP6+gKKlh+l1fJrE1pGSTbq/za51slQmX8gCOQJIku2SmMH3gkCVbZFam3cCGFCXt1G64+j8P3f0/x9r5mWZJDlmARbo3RCt87elKgCPdiXrphA8cYeCpHSGV+nwWayLRx2aTporH7li2GBT11Ig000QQyXamhpackbOOevD10a5/u0mwdOcTvWr7REtv/6s7ItYPoVrfJrR7+I+147rvwWArzc/18kYw6ssq4nto46xfuCvOeGF0cv/bJ66IyUNoStA3gMiMl0aApaAp3H07waZ9EcdIQLqubHVBtvlwpQG4QzE2Y7XduvYnRCF8H6RvVjNqr/0jXIA3wnoRCMME1JzMZcC22/250nI9U2A0mPIBgamNwxVolnzvt1+huJBDwomNkxH6Fvm3emD6U7/scxYk/zAzZ2dfzvvXe71LastgxkL81mrtCVQx4ZtGWgOkfbvHTMGj5FPr+Phi9M2q9GudbEsPX1PUXGTxpm69vltbwW/T9LKGhEvHWBL4umMWm9KEB65npUVFj96txpuen5ev4TlpH1/wuW5pOuGUxvH0lvu9bssOVVd5oWpB+R2Zzzgmdvdo0/cMtnBTCxsMsS3IoE0D9qQAIwS2Vl7D8ha/JzUzivrOO4cElWznTYM4jvdxIehNZIJu01wvkSRj5njwnmh4pB5h66en8sn0n6SvvDxhaOlxez9Npb5C4rRS2AV897lV93BPVR2HZ5hLeXP8He2qc7Gk0hWSn2nhodL4rWlBj5xZKuLCE907XE6/FEd+srC6H35KBU1E+l7UTRRpcSJ53nslmpSvPpv0HW4N32ysaQ/99hZiBR7elrLouaLiujKJbrkBrYgxWSFiSIJv99JN/cvuI+KIKdqu7/Z3z1YAFnffETVKW6+S1FZrfBxNIJVwRUQVds/3GhBFht0Rk+yUx9CSQ8ODrPB7o2Gn28axQ+jHO+nlEZi3f1Af3nXUMJx53Bgy/vGnxTGkHH9ygK5z6nsOz/f3PuJwrDivBcqAMZ2oHdjp7Ubq1jBuK/H1+jOA5fwj8C58G08AYdjPwmc+0SmL4vjPTAgrA8KT9fH4XHbnf9opm7jg1mvOwdQ9wSf1sws3f7ClMaGnUvEyVHv5KfsJUl0wsOiWzJPe//NEqFeTbf8XbyymprKNMbmPsnmjTKsqSmEJSLNFRf5b6RN6UVtZx4+vfArCAEdxjfQ0ZoWvScCKzwDlC97K+OyKtIo0ioxOSWp9KjyDaML2JVJ1oBg7ogeWo7nQ7UjB0XUcO3/+9plajUC5mXsIsqPG5QGP1ca8yEY3o7SwrDtiZ+Pq3zJMlMpMT/HZu4fht6QlWXguep3aq0VR4Yt4Y5nUu4c73NnklQQQMm6TWKr3Znt4P+R/34dzxFS+8+gp1DidrlTzWKXnuXDjqs65JbMeAI0dSvLMy6LmNminUidGogDlM+oarrB/rmln/7RjNy3/0ZGyjBlXvPSE5C/rf4DL9blui42/husL6XnegfOcvkKrXV7P//mf1dq8xEUgTpJ5bL42AJ6GETwc7NjRtsDe+qQ8k4MElWxmZn4vFx9nXOXIm8ttXgIHkjdAkbF4xpBsWuTsAFmAggGxh3JrQNDF68wd4CwXq4quHEUFX0tCYF3TNJicjkdKqet1zGxGAB8hbAvqb6dUiDIUO6Uk4FcGzn/3CU5/+5Pe9lqlSS5galf4Lc+3hpw5Q54AsDT8p9ZkFex7qc/8j7fhWUZbEFJJiTaP607ljNdNf/4yfalL9Jk/PSd2BleccZwWM1HjeMQpHkEfnuyPyLdL4R93x3KccS8CKcR7aMCNZcH2xO504GxfC+8Ycyw2v2v3u14LC/Y3RRf7vU+Myu+xOlwq5UePV4FC4+/3NmjtLT5X97YX+k284fluBBCvPBe/IxGoeHj8MjhhE8c5Kyr77k3apiSRZLeCTuHCdkmfIv6dIyePZs45xpYnodhpHXNCL61/d4D7OL2RYAE//m4KRM2mTZKNXww+6i3ao/jhGBcxzrasAnaSLNDrRVl7ibUIIZibQEaRKRLZrsfruMNqk2AC8BFI1pw7AkEc/01xs9RbC3WTzv4L7+fqbznCgIeh9G0m053ushCslgeKRkiAS/xhf7ZWWZgbUBTSN4xpu9hPy1SzYnhowT2FTy9FWXSBD1cTozR+eGoZgJpmAJk+17Roac4ssMa7gCHekox7BhNph8vqAv3ffUxhJL1XBtOJAA4Nn/ldXoPM1Va7YUqq5ibQeKAMDmb31UOcATbNn4zMLboKGB+zjue/CY+PeaRtMIal5kC0Ui94s2G8sumWm81IArrUuweIxHJ3IPO8Y5f4+FHwnL63yC+7reKloB1Nw4cs4ltxOYk1TvgstU4Ivz37+K+9u+NOtBtZKUT8y/Tc62QNHF1H1J2z/Co4+lWWbS7j7/U2UH7AH+gUllXVs2Ol/3tD8tlz+MlcOH8eP7/9ARY1D8yi1b4tqIefXHN5888ugvgcKMnfZr2G+RgJQVRi+y34NCjIPLtmKLEsU5udSmJ/L/Mv78MAHmzi/5k1u1SgTQVUJlrcnsNqSQWpCU/V6NUplheKa8LtJxmqMqBOjkR17Bem0lar8v2zEc1ddVt1Hw7diiP7E2ShIvfbWQtZt3Oq3WKnC0S3DunNku1S3r4beguGJ7kK4UgaaBKRIwqN9Ue/SMyWBVnuMZoZ/wH45/3EWarbH11yj9kcJ/vd9wuBCvt9YBiGUktAzm4RiilTJTrXRt0tW0HMbuU59cg7JZz+uqzE/sp1vgWdt9ARgGYWxltWGzhGqFlsdH2OOz2Xi64HHLzTNe0W/7tU1T4YbAe2r9dun4SelFrUtrawL+Nyftl3N2Aujlycp1pjJJIl9MiqAD777k5vf+C6k31hxMMHyCUdIZfwh2rFNdKEt1RFPzioS0DEjkScuOoE9++vpkO7asTy4pCkSTPUt6t61K0t/KA2YhybQdVRhzHdR7H/gM+T3rgl+kuQsvjluOud/2S6ke1R9a3zRStrm32rcpr5/LvuB9SuXRmVx9G3HNJt3FmnfkFt1snQLtFsWIz6+Ham6JOC5fc1deokXg0UfejquX5CygceVJxrb5W32koDfjp7AUb++HPS+JzdMQsk/n292Vuj7VmiwdOMut2laj9zMJFbdcbo74eDQmSt0Tb2hoDVmqhM6MLVhAu/V9Qn5fG2Sbfzf4CO54dRunPL45+48Nb64IjInBzVfaAUYqNwyrAc3D+uOUxG6GjVomhMev+B41m3fC7j8/wYc1dZLePV9j/t2yQp6D6EIl57jQG1zoDw+SLJr0+MxZ40edAIFp56t73MJrP11L+Oe889XZBTjCVYzKKifq3vPWlpQT19Vveel1Rc3ntadZz//VfPY/vKWgBGWWtG0vglKVWZfcoKX4zY0CeCA5rMadNpoJp7RK6oapFiv36aQRPMISaG8jL5+FdpZWL0X0jY+WYQjxcg1Q8Fz4fJi+1fw8uigvxe4XmC9aCt1AhgobQEJL58dLaTG37w23MkRf31B298WkdhQ0XRASjs47iLoOQpq9lL9wT9Ib2iKKNwj0lnkHOzOSKxeJxxNg4zCB6Ml3v5ivaY5Vm1vTmYSq8bsx/L2FYQbCaY1CWpGzjV+UtzvKTZnnkJ2WiId0hJBgj/XvMnQ354gxye9wJ/97+eFDZXMtd8ftB1qhnA95l/ex6/mU98uWQyY8WlALaLa/5f3TqTrkUcj1+2lzcqpXkJoichmWojjOFBWbhBc32AsCvDM/I6s/bWcfbV2rwW9Z7du3Pddpu5Y0bu+uoDdaJ/MMmWA7nXV9694e3nIQoGv4KrnOHzOcR34bvWyqGnZZBQWjnBS0N5B8V+B8/is7nYbhw0ap1kfzFOga5fqGsPqprBvlywKHvnUz2fQKEYzmn/qOJFrHP/w+3zSad0Y3K2d2zfHN2It0PPSm6O/7nkHN288POixvu+9aMw+vk8Yy16/8NoBmuH7QR3Lo4wpJDUDzSEkNTgUet33saZWQ0WWYPYlJ/LI0qadQ7DJURUaXru6P7IssfqXvzR3EWB8ATd6zVDPr/lSKU6YlW8oBFxvxzxSLmaG7Xm/yKty0RT95atR8ntp1TT/Py6FjW/5ZYHW07ZAk8BUKdJcDvIhCJbqzv3qIUfx8NKtAe9fRmFr9t+9zJ7Rwu/+PJ2mZYvfxOf7rL9WeuFsdCIPV+vhec5KazY/Jx7Lruqmxatdiky3us2640tvIUDHnHm9wfQG0dDk+KLV1lKRzdQAYyWQ9tPIBmbhtQMoq64LWaPtqckENE2XhXIx90dxU6V1rzXWpjw+WvPS+91ncP7lN3p84aT4iw/5aM13upuPnIxEquoc1DQ4A7ZHJ+4yIk2SjMKCMxwMyXFqh+qjb4HQnaNxueFf33Czu9/1BXyfdz6jM9/2voPzP88OOI+7N2xam95GdFMUxABTSGoG4kmTtPDaAe4dxKc//Mk135yjWx9MnZwvTJzPyjtdSdICvVRGNEPhLghGzq+lngVceTs06lDp4amF8CztoZWzBJoWw/vOOoZ26Yn6L22I7dBCLx+UlmCpTrxtUmyGdrJGJ+RI2E8yaXhkwc7oxLe97+S8z9sZ7pVwhOxg48fI95oLgV/qi6bPK0ijX/38oIKN0X4P5BOktksRwfvnKYd2AlOAM+V1zLXNBoyPM5XZl5xAh/SksMxLqjAPEqVV3qafSLVcvgRa1H0FXs9rldKW785byajjD9OtGxau0JadmkC5h/N+TkYi4wqO4Mi2SQxfcjIpjn1Bz+E7b/kJvClt4biLXdrrRoFJa90INkerKTEG181GQMBjAdeG6MKXXXnpGjdEWhG5oGH6jwNivX5H7lRhYgijSbNW//IX4Mp1c1/Gx+RK2gISNDrBSnt5akCNe8HXcnJUJ50cn0gZNWHgTZZ3kV3Zm9xh4XovlHrNAnmb4fOPlIt12wa4I5dEchvt731Qo0Rcdbde1i3toX421bYAGYV26Ymcc0JnBh7d1k9Acjoc1H/0j8ZiCeGjVb7F1YZX3H2skqnhhxCIcKJjQiVVeJcJEVUlnLB2MiNk/VpsvqhOm6V4h/eW0pYb7ZOpJI0x8hoGyFuQUYKOnzstrzLfNssrhYXn94VykX79NZ1xLEmQLe2nv7wFWQqctspov99ve5VViZPd4919rcb/qj4zem1V23Gb7V2eTniWNxIe8jqfmtdKaNxXoHHmvo/0JCoO+EdHySgMkLd4PRNfaXwKLQAAMlJJREFUBFBaVe8nIAW7H1mCObZnOVNe53fOFJu/r1DgWnr6z1OdlxZ98DbOHz5AvDWBxFpvjavvfBQKTqd/n/TMSeecE48gpZ+xQBp1HLnHu69GsGYvFM11uR/Myocti93O0J63HWyOVutGniRvC3os4Mo/JsluLVZhfi7f3DucW4b1oE2yzevQnMykwAKS4nS5UGx6x/VfJbCGrjVgRrc1E0aTZqkRYXP7/I8T1z5i6DcF7ZuirtSXytMsEmgSA9ekfKn1c6bZJ5CIdgSXL9edmELRN8HPLwTMsD3PBsvAwDkx8sawpVyi96eXB722GqHhmgAqAh4rSa66XgXyNjqka9f1Wra5hMUfvMVce/TNWKCfJ6UqBB8yCXCkdvDNJKBJsFImAa/jtzAJzWy7wdCKFsuimvttr/hog7JIarwpvUy/11mXat6L+v1Dtv/QLkBEXSAGylv4Xj6emganrkkllIggrUzlOZlJjMrP4YXVO4LmpvK9T8/zVZIWUl4r9zkb26A6V3sSqe+hkQz2Fklhrm22n3nzulOO8ovqM5oRX4/kujIcS+aTgPAbqXqZo41QWec9L+6uqm+KDu45yiXcBKGMNt7zZaCDG3PEWS5awNSzT3LXrBQYF9of7fUr/91pByNyik8NUYsscfOw7kw6vZtxs9mWxRq5ztpA/xvdZvvWiKlJaia0dgR6lFXW0HHNNOM6DY9MshZZ4r6zjmm6rpGdBK6K8PNss+giBY6YUrFldDB0fnXH/mrPVUFt0r+kHs8uka3rt6UIlxOhGoYaimblqMT9mkKaGo1hPeBf5iXa+LY3kH+aJ2qvjRlzvitRZRAqSNM8vxAELOqrh5b20Ahq2PRiZRCZ7GeObbaGtqiCbEk70ka9diBhT5YIW0ACQEBtoz+KqtnzRU19YOR5+Wp0Jp56NKvuOJ2MZBsyCuPlT0Jqnuf5OhrMmaT1Xkw9O88vktCoBjjUa+mh9okswdxL+zDp9O5+c2Kk2tK2UhWJNaW682y4Y9kXdShM/3ALzsMHNr6X2lf1nLeMzsfuKyy7k8K8Dsy7vA85ma6NtlGhvctvC7nKqZEiRAud6gpqdQM9Dbwb1VXBt+xN7T744hF4vJvrmFaIKSQ1Ey7hJc+Q4HNS44tkSBGQ0dkvk2xWaqL7/41OOurYH2f9nBIDC8Lgor9xp+V1w+fvueO1oKrXDhmp7gr1vtfXSj4Xyg6/Z/du/iY2j3IH4eYPCYVwr6GquIfL32Cv801L7kLg6qMn7OfTr34+12uYu/SEJ6PCWrBnLQGpiaGZUFo6l9xaked2YE2yyrxyVYGfiUHNrQXG+spzIV749R88tmwrWz57jfWJ13OWNXRTj3q+QPmnPPEdZ1OG9aAwP9fL5G/kmahmaqAx6aXV71ijY1ry6JNnx53IqONysciSO9GnetpI8vjsEm3ZK4z5pAySNgc0LxrBnahzZ6Ur6S5NUaGe7YKmeSs0IbAxR9zONRTm57LqjtNZeO0Axl14MfUpOX7XCg9Jcw0JCcXp0iAFWt1qy11CVCsUlEwhqZlYtrmEB5cYK2pq9EUSoJlJ1nMyDGXScU3G5aRRE3zxEgrX2T4ynG2W2nJX9FgACrpmszF9KDfq+LP4OqW6dvhZAbUjQrjMBz1OGun3nWe5g1C0BaHiqwELhfvOOoZVd5xOxz8/QX57Apb6fZrHORKzuME+hWec56Mgs1wpYEj901zScC+TGyZxScO9usJTOcYWlr/I0PVdUU0BVo2BY3z3HD4VZIT07IRwRT+uazRLqT43VovMzPOP9Vt+9PysAtGBfZQfaGDHqjeZZ5tFFvp174ywV2SEpGlVObJdiqs9HiZ/Y76H5Uy0LHI/28pah9+1Q31v7hrShlHHNWlD1SSzqpbEfT6d32tpQz0FkQOJxmpfTrYt8vL7Oi95g59wbJSy6jq3X2Vdkvf1feetsITARlOYW6tz4hEkjn48YhFJqJnOAtXvNIBzx2qDhZOFq3pCK/NTMoWkZmDpxhKuf3WD4QrQRl+k5yyX4Ox1ttdnTkWwp7rJOTOcxT+N4O1UX9BRlnVUCGNZa33t3r6oO8vlSgEn+yzwQ+pn+/lIuHb4V7hzKPmifvZP6SoUScbp0wmewmQgbUEkcpOR8i1aSLjSFFw5uCsrfvjTZX4V+qU+rAnJbE4b7J080sPcVdSYM0pLeBpQ/2zAMSKA/SKJZ23P8EbCQ5pOxTmZSdwyrDuVtf4+bbF2OK9NzuFhXAlJjZgYhXDdk5rR3JOy6jr3wp2b6e1HqPbdA/bLDLXrLzK8NDbh+Ih5spvskDStKqpw5GnyN/pMbrW+w8Vp37qTHfri+d4Y4fhj/DcKnlqSpy7pQ/WpDzWmJvXXygiaNKIqnoLIcYPOhIxOuloWrfGQQzlPiH8yoN5Y5mxfft69n7W/7qWhx2gWDloScN4KazOmZQpTy/Sk+OcpMkqJyOYu6z9YppwU9jmWbS5h+uufGf9Bo2asNWE6bseYpRt3MWnhtyH9pljpZaCuVyozD4zmWI/U8FpJvEIrw+HC6GQuAVZJsJVuDOL74D/QsXt74lm+pKiyyflUzT6blZpIWXUde6rreXDJVvcOf4btebJ9duoVqHmS+vDe8+v8ciP5OtPrpdJvSMklcdRMSG2rm0dJxTfk3Ej5Fl/Un6umiHfee5vCQM6+ANW7eGpoDRd/YtN1QFbRKrHwoH08c22zNUPmJSBNqvMTnnOkcuYnzOKnU+bS7ZRL+Wij925SzXtktPxJOAVdBXBL5SUsU/pRLfs/u/1SMomSIEE0tb0EfcdkdUwU5ue6k1mu2FLK68W/U2dXUJDZKroYbl+kjsjgXRJCQeYG+xQeTXmNNo6/3MdojTPVYVv1xVM3ITe8usG4RkOC6Qmv8lb58ejtqZcrBdxon8wc2zNYJL2RJ7n8dnTMOqqWxMVl0DHdvzB44z2qZXV88/ikJVqZeEZPnJ1mIr89wb9gsU5Agyy58gvdb3uFT0J06AZ49vNfePbzXzxyseknSQ2nLJKuKSxvDDjq4L1rDbf1aftYfhGHNfVbvcwbr27g6sFHMiwvJ6R8Rqo/Z385NaR6cN9v3cbxHoWW4x1TSIohyzaXBC2hED6ugVxa6QrZXrqxhBtf36B5ZNPi/zKdCBwNFg4DrT8TOCguyMvug+cCpRdV4VQEz3z2C/tq7e5IqmAZt30rZXvWGlKndt+oLEdqB565dSJYG1+VrifDiIdw7ljNW6/+ixHOL70qgJeQzUL7aV55bjJSEpFq7LqCi2+iS886WbM//YmU+j2GJqGC9g7mXd7fT1AOhCTBCKmY+2yvaAvk6IfHu3pWoue3D8Mpl3gJnZqJHfVyFiFRY0mnymH1CvN3CldySj2h3YnMvZZbWaa4khx6Prth0jeca13lejaNfVshUnnRUcgc57maC2Gbxsrmvonw7jkrjzvPPIY+D65gf72D9hjzDTJ6nCe+/a2lIVquFLBZHszKCUls3vYjM1btcyfzVPEUtD3fG3UT8uBiG7vqgxd6loDEmpKgFeyXKQOYZJc0czi5jbF9roAf3tdNnOiFR8Hj9T9s5Z9rKr1yRmm15aJ+h2GRJdYmDeE/Df4Cc8AAAJp8powWKfbFqHbISAFjtcxPUFNYemi5itaIfM37e2H1Dl5YvcNwZmxPf85Qi4bPWLWPK48oiZs8S8EwhaQYoQ6icCiQt/llj/ZEkiCb/RTI23hwSRJbSip5YdWOgOdUF5A7Uz/iWucbfgtfOLt4d3sc2s7Ejd+6/hOi3dt7Z6n9vWdhUAWZtUo+a8nX/Y26AKmVsj131p7aFwXZ7asy75w+WKw+r4lswXLUULLO607Bq+s5SSc7bVaKjbnnHQvgdw1oWsieHXeiW0PmKRA6FcFLq3fQy+iuP60jhV1dAmbRr3uZ+PqGoKVqRkiNyTh9nr3xNAJNzqUFXYeQm5nE8dUrmduYDNDvaD9ByfXHg9J1vFV/vJeG4DTpW/5mXaJbAPh5x5ks9KmZpiCTyX6usn7sd+1MDnCL9V1+EodrapH+b1BXVmwp1S2p8M8LjwtJCxOK/4kiXDX16knwytiup4n8s8pOsejLwFFDufKIEnb6tDlQQVp1E/LLlw+R++WNft9rYcQ897HSn+s1Fn+RnOV6yl94pDTJ6ORydtYoPOstpObh6NGLolXBHd7P6OXSVJdV17FC6UeVPcW9aZIQ3GT9IOg5miMXGQQQ6BuRMjq55sy8MYGzV3cZ5OrLID5BvgVq9fDdSOrh6c/pqR3T2wh5tuFrpRc7PebgeMcUkmKE5yAKFaMvagf2UXSggee+2uH+LFBpkHvO6s2Vg0cjbTvLT5VdTgbtQtz5qgt+oGFem9wxYBXuSJh0enf+/dVvHKg37gjojkhpNFN6mveMLjIqhfm5zLm8H9M/TKHI47dq4dJJp3d3TwLhXKN4u6vGVzGBd2qKAHtqLomNmjqLLDG4eztmnn+sZgkJFS9/GZ/vQvaf2b/bJXSO7slx77j8g7QSO/q2pTa5o8tcVnci0KQhkFF4MnGuZlskySUonW0t4lHnOL9SD4GitvTy5LRJsdG9Q5pmf5V4LBxGtDC+C1KwXbYq9N1lv4ZPlX6clvQLKQ17ApYOklFw/rYSapwUpnVk+D9OoXhnpeEyEBZZYnv701liP59bbe/qHqfSNfkAY2rXBK3J5quJ7SKVcivv4vfkG/MAqQWkVbRcBrJ0/KH8aLzdHnu/YFXivV5azD0i3dApmiPKVUU1exeRxyPOyxiW8gsT+6W5/LYaNW1B66DJFpew+dYEhI4nltDQRuqhtZHUwjc58nKlgH87RnOd9SPt84rG89rH40T2moPjHVNIihFGM2yrZKXYOO/EziQnWFn/pTEN1JFSCQPkLV7J+u7zS9bX5H/RLj3RNegbVdk/rF3Gv5a4Jr71Sg9WJk7RT3WvsZs3spBeVXkVVygnUWjojkLDIktc0u9wXli9I+Tfej4fo+Y9re+N/NboNfTaGMiPQWmc1axnPeqnqVMFwLvf36RZFDYa/jJuGv3NCtO2QzD/KYCT/4Gz61CGvVHHn0robXMlCfU3jwT7nV7CxUfG5vPgki26AqXAtXCsuuN0hufl8PFbdzJq6+3az4OmBUkCHrBPYF6Cvg9Kk++cS1v0aV0PoIfuPbhNmaub7lPO6ET2ifdSlnWq7u88UTXdu53nMs76OR11S1yAJMnc4nzJbfINlmxSXfzV8hnaHnKNA3fZnS6zWqNAoCWkVhjMSL/21z0MqF9Nr68m+mXOz6Y6oHZUAUrDjECNBgoyZ46+kOP7HOb+TK8//LQ9eWNwXvgye96+hY4eRadVSkL0i/TdSGrRziPNDLiE9jHWNQHN8xWksULp5/471DWypTCFpBhhNMO2yr4aOy+u3sGUYd1pQxVOIQVwgnQJKbdY39U0Q3jimbG3Q7pH/STZQq+Bo/h6ZZNPTqCF2M88h4TFQNxXe6q4671NnN6rIwnWwLuYcIoiDsvLCUtI8n0+gcx7wXZzwUyDQa+hFtfdv9vLX8OzjXp+DKW05ZPDpjD+GG1NXWF+LrV2hVve/M7vu+iYFnz8zYJEMKp8X9+RGtGbP6u064gZbVv35AOsO9C0DIeihYWm55iZnBBU86suHAVds3l4ezc+1HkengtSTmYSY8++nq9/78ph66Z7HVsh0njRMVLXR0oLz7pmnoiqXXT/4kaebIzyCuZb0qTplpkW6L2XAOEdkK+VVVyL4EJ4k6nW2WWI28clXOZ+/jPjk26hA0I3+z9ouRZIjcLseI083c1HTmay+/89fX580dL2FCcN4bK62RTI2+hIOW2lKvaKDHaTHVDzF4hAQszXO7yFMSObGtVFRN2chLpGthSmkBQjCrpmGy5cCk0Df9faN5lrezro8ZKkLRRpRm4ImJ7wCu273Of1na9PTqCF+EH7OHKlfRwhlfG76MCP4nBeS5gRtJ1ltKGixk6fB1fwzwuP0520g6qVVXwEioIuA/2cr4OhOugawfBuLly0Uvk3+msU9Drb6960Sn0UK71QfpH516Of6S6Kv+89oHnpyE0LrsHmHDmD4u37KKuuo9uBZHob+OW/vq1heK7+JGy0bWcPPoFXP2nK02T0d/3yezGu/wC3IP7+BmMReLsqavjPrkpKKusoQed5NC5I9511DFcO7upyJk4+myEr2wasrh6MgKZEXNoQ1ZQYbHx+uqWpBI/eey+QkTQyFsmNZtOptlf4b30f+sk/ad6TYSF8/+6I3BPA1TdXWpZpalJU1Llxv0gm3aeIs1Q4k7HKSRTpFHaNhEAuEOAfhQjB3TV8tT2lVXWaUauRoAoxvpvXigMNzPrvL97HhrA50brfeMYUkmLEii2lIb9sEgo3O14EwgvVD1T8MYe98MdaV3SWB74+OepCXJj2KxnOcnbUp2tO5hYUdtOWDpSrKcm88PXL2F/v4PpXNzBfY9I2Kog4f/gAx5LbSaxpmuAtGZ2Y2+dOzv28XYCe8ub/BnU15DBodDd3eq+OfLOzgrLqOpcaWoI9++sDasOciuCXL1+nx5cT8cvTG6Buk95EqLcoOhXBwuLfNe8vWFRKUOftjE582/sOblycRkmlSyMko7AmqS0dxN4A/jrZLKs+ir77/YutGm4bElJGJwpOPZt5Hcrc4zfY79Rx+a8dHVl5SdOz8azwHohpH22h2qOOV6CFyW3exrVp6piZ4pXWIlRCNSX6ahvUxW7FllJe9NG++grg7aR93G97VfdaEq5osHWJE70cjj1NcUYF1nd+tLPRZqwckhZakZSBcCAzruFu2lNFGW0YdOxoujRk0C7VRpLVgqECiRG0zbOP9KIQjZqiyqrrWLqxhPs/2By1NnsKMVqbV633KtRgBt/7jWdMISkGhBvZFlUfES10TCHa/jKjWbGllBte9U8rIOFaHHYNnEqHtTcH9cvw3Ekt/uAXhvea6I4YCyaIgGuib//HJ/RZNxmbj9HbVaX+ZkbKNxuyubdJsTHp9G5BjwPju7kBM/6ru8hqacOWbS7hwcWbeLv+XoSGacDTX6NwyiZNp2+tX4C/w2Xx9nJKq7SFkaC+TrgirrzyT6W0g+Mugp6jWLa/Kze89j3CI3+SgszUhvG6eWBkCZJEA8Pl9WSnnkh2qk3TXypQ2zzDo53IZCYncPvInpQfaKBNSgKPffh/PCmeCDgu/6y3e/lcZKd5+1joUV1nrAA0eJsTPLW24ZqUQjUlemobKmsbmLb4B92xAN4C3xjZWMK/bKq9/vY0xfU+bRxi04uIql2a+jJVYL19fRoKO41dLzXB613TMz8GIks6gEBmseIyERf997eQfm8UvbZ59tHG9KGaGmCjpqgVW3bz0cbQBcyUBItmUWdPoU2d/33Hq1aqA6Obkz/SjmfemGNbTfg/mBm3Y0K4qmOjBSzDJkAyR61Chr4lA1TUWmInjrwC5cKX+Uvy9rPxzIA7Ui5mVeJkd6bmufb7qX08j+Kl/2H1z3t4cdX2oH21u7KG3CLtjNMSAoFwF88MxiNj8w3vYIzu5gJpIVQNz7LNrolMzb5++P7vg5TqEH51mzwLF+uhLopG70Gv3Ib6DPvVz/fKILzszC+hcIbLh+SjHzUXfPWc+3wyI6u0YT/zbLNI3/4xx3bODLltUkYnuGgBy5STGPLoZ4x7rohb3vqeB5ds5eGlW1hU1zfgPblLRHj0TU5G9P0jHvjwB+5btMldQFcvk7dKdqqNKWfoC/Dhph5YsaWU61/dEFBACvdaWuZ9cJniurRL4acT7wURWoZwPdok25h98QlMPO1o17UCmB+DEc1Q/6sHH8no47wX/WBRlpIk8XSbN1n1j1M0BYZgBdElXLX0whGQAGoanNwyrIfu3D48LyckH7FAFQvUvx/jCj6/fVirEpDA1CTFhHC99o0WsAwVgURtcke+d/SkQBEhqTmDRWVZep/Dt0pf/rNwoZ/NXW8nlVK3m37rbuaGVdsNaX+CmhkwngjugY+2IjcKgMGIhmOhp1nO4RBMftOVXDQUfw1wCbG79tUGOdjFgrXbKa2spfxAA+U1wc1Iur5OGon7dn70I8N7dw66EVih9GMaCzSjIFU/ubyNM/iqfjaB9mpq205N+pn55xzGzzWp/JJyLDv/rGHN569yEvsok5vaq2qlgt0T+NQya1yUIvGL8WVraTVbS6t5peh3hud14LkJJ3m9T5/8UMI7G/50a6fKD9h54+s/dH0Zje7WfSO03lpvzN8qlGsFQjX7davZxLasU3nSgIO7EfbV2hn/YrE7JUAkmvdohPr7aolH5Zdw7webKT/QENyRGUFiTQk/rFvOL6kn+M+rOjncXL91/e2IsNDknv11/POC4zXdA9b+ujfkdyGQT6vrWffj4p0VrSLs3xNTSIoB4S6uRitYQ4DsxT6fK40f3lJ5Cctf+Fozh48WToeDbeuWU1vxJ8lZnTmh73BeLd7Hko0lvPX175zX5zAGdWvn0jgdexg/7j7HndgRws9Xo0WoZoZAlFbVcf2rG7j5jG44FYEiICslgezUBPbVNJCdlkiHNJdfUVlVnZ96PxxUs8ekN751f2Z0knamdsCCSwNlNIrv4827+XizsSgzFaNOnyWVdfxn9XZ2lgdKIOpawHLDCMXXa9tndT3p+aarL0fKLzDVtoDJCdp+HkbuqW1qgpfjqLooXa9hXo4GK7aUMfqZr7hnVB4FXbOpONDAS2v8TUy7q+p1d+9GzKNampn99cZNhEavZURw+m3HL3xp7WRIYA0FNSVAONogo0kV9chOtXHf6N7kZPj7G446LpeR+S4B2PrD/8DAUPrXkjUsblSAewpdTkWQmZzAlYO6eAnS4NL2XHLS4V7zbTi8UvQ7rxT9TnaqjXNP6MywvBy339rHm5s0VMEczz0J9qxbS9i/J6aQFAO0yl344luKAlwFLEPBTyDSCNUvFd47tn21dp769GdeWrODmedp24a/Xf4yndZOp7dHpMiuT7JZb5/AJ43nef+7XaQmWHjiouMpzM9l0undeX3d7+xuLK4bbr4aLWKR4Xi2T3RGc2NUK3DhG3WMOv4HnvdIGNrSPLhka9BjoinYqrgEpOB+Hka0E+f16ey3Sfj29wrDbQmHzX9WMe65IjKTrVTp+DapmsfMFJcTcWmVf9K+wLt145qZYOhdy2ji2dd+aKBIcUVtRjvyCkLXBoVbbFpFAh45N7A/jUWWqKxtYPGmOoyUjfW8B9U0/7ehXVn8fYmmJic71cZ9Zx3DNzujN1bLD9jdZUl816VgjudaBHrWrSXs3xNJCK1A8kOLqqoqMjMzqaysJCPDuDYnEGrEFmg7xl1zclee+2q712/U5Gu5lOtqifaRxo32ybThgEbiyLY8YL+MfWQY3rHdMqw7R7ZLdataN65YwPFrJrvao7FT1VqE1Ii1ZZtL3DvxMfIank54NkAPuZjcMMntQKmH2i/BBIoh9bPD3p22BJ4LvtG+bi0MkLfwRsJDQY+7pOFew4tnNMeBBF6RgEs37ophncXweO3q/siy5GU6nfP5r0Bou/tI8b1WsMSzzfU+uiIpb9aNpNTStpcL78Sdhq8lwbPj+jDquMBmenXelw6COSva81NWio319w6PelRbLNZvT+Lz6RwEBHJ6nnPpiZoOd6qKW6Dt/CaAO+3XsFbJ52OlP0Pqn/Zyqh0jz6Eo6WSKlDwWK4Mo8inwqsVTn/7MzW98x7jnijh5xifkrp0OaJvIAE0H6ekfbsGpCArzc5l/eR/apNiiqv0x4hQY7u6wJQnmNN1aBSRo0pTpuU0owiXUh2L2ULWTenOsLDX5phlBHbdORXBvFEOoo8WeA/UMPLot5/Y5jKtPPopuHZpKa6i7daPveST4XsuBNS7eRwWZtT3+jiRJfgU51Hb4qgDUoIGRcvBacL7ny0oNXGXaM1K3tc9ZwdwlwLUW3HhKFzKTjBmkWqs2Jj6f0EGCGpW08NoBzL7kBBZeO4BVd5xOVmqirlNcKAun5+T1U/LxPDWuX0SJ0I44sJEctHdloL8IeUZUFebn8s29wxk2cmxUF8mDVaBYrhT4CbtD6me32vtRicUiEU0Tnmd4fPH2cs00BFo0Z2YXX9NEeYC8UpEQzj3Fy/v4a9szkC5agJThreFRM2cHir4zEg3rSTB/Gt9ghnjpo3AwuiHpbd/CVUO6Gjrnvhq7V+Rta+Gg8UmaO3cujz/+OCUlJfTu3ZtZs2Zx8sknB/9hjNEqRWEkLDsUR0fVVm4kkikQkSxCnvdkkSXaZ6aE5WTqi2dkR7QdQJuLm8/ozlvr/9D1UYuFv0Y8EG3/mVj4poXqSHrzGd2Z9d/IHGaNkKuRkTg7iCYjXP42tCv/Xuky/Yey24+H93Hg0W2hm6sW5Yuvv8Z3W34MmggzFH9IT4L502iNpXjoo3AwvhZU4GiXavi8puN2C/Hmm28yZcoU5s6dy+DBg/nXv/7FmWeeyZYtWzjiiCNaunl+GHFeM7pwZqXYmNHogL32V/2U/EaIZBHyvacO6UlRWSR9Izlam0CRk5HI5DO6c0xuumY478HOcqWAbywD6Va3KeJFItwQ+ECE4kjaNjWBm87ojiQRcWRRMLQyEnvW9ooGntFUJx6RpZlZOViUuYLMT8nHU2RQExdNslJsDDiqcQMqWxBdhrB4c1vDiTCNCgJGy2jojaXWNmeB8bUgpe1hIb1DrdFx+6AQkp588kmuvvpqrrnmGgBmzZrF8uXLmTdvHjNmBK8v1twYiX4LRmqChb8NPcorlD/S84a7CGntegu6ZpOTkcjyqtB3Ur7O5AALi38PKRlePCAB08b09krMGc5CZIREq0y9IzTzQaxRF5cv/3Ea3+w8yav204NLvPshJyOROodCZY09rBB4d8ZxgyY834XPSI6kB89xJSKddHp3Fhb/4Rd5Fg1UB+FACQbDyeUkAR0zEnniohM0S+Zo5UOrONDAxNf9g09U/m9QF0b0zqVvlyyGPvZZRO+nWoA2lFdhxnnHegmS4wceycNLt0ZV46hXNkSLaMzr8YKRtaBMakuv/iNBtpCTkRj0+WutE62B+Nb5GaChoYFvvvmGESNGeH0+YsQI1qzR3lHU19dTVVXl9U9zouZkgdD9AVITLNwyrDsbp43k5mE9vF7cSM4L4fuRaE0gFlli2pje7vMacTLNzUxi/uV9uHlYD6/M357nijf0+jkrxeZXR03LR+3ZcX2i4ucy+5ITuGVY95B+0ybFRkqCJQpX98dzcUmwyl7Z3Ecd598Pq+88g5nnHev1Wy30s3B3Zukxj4ZkwlPHrfreBLrudUO7uiObXOMxNpqBZ8edqBtBZaSdgZg2pjeDu7Xzerd8z+/7nLSCT9T3dOqYfAYe3ZYEqxz2+yk1/nPtyV3dfwdDvb6vIJlglbn25K5hBw2MPi7XL/O6moHaSPJZo/Ov+l2bxqSYnvd13dCuzer3poeRtaBk4FQsVqvh+bk11WvzpNWnANi1axedO3dm9erVDBrUFEr+yCOP8PLLL/Pjjz/6/WbatGlMnz7d7/NYhRDqoVU8MDcziTHH5/rlyTCaBFLvvEbNPBJwbvIG7hAveVXU3iX8TWSpiRaeuPD4gBPI0o27mLjwW78oE0/aJNuYc1kfBhzlP3H73tedIVTp9tXSqH375vr/heTg7nue7FQbD52TjyxLfv0cynNS0Xpevm3Wy5vim4Bu8MzPAmo4UhMtPDT2WHcyPIBnP/uFF1dvp7LWv088E83paYD6HZnNqp/3sM/j91o168LtC9+x2ybZxlWDDmfi0X9hOVDmKrfTZRBO5KD3H6htWtdWn/Wo4zr5nWfpxl1MWvit7mKsl+9IXRw9x2Ao/RVovGgR7rNQ8a0Cr1e02cj7qfVOqm3Tmw/vO+sYslITg15fZcbSLfy++k3mWGe5r6kiGkfT9Q1NjtM5GYlMG9Pb/Q4ZuddABHs+6j3rVTIINh+ogliwvtYaZ9mpNs45vhOHZaXwv321fPDdLq9kub7P57zkDdwuXnIVSG+klLaUDJzKiSOv8LtvrTZ5uoTEglinADhohKQ1a9YwcOBA9+cPP/wwr7zyCtu2+YcD19fXU1/fpBqsqqri8MMPb3YhCfQnoEhfVt/f9+2S5a5Uv2NPDbM+/QnQzuE07/I+DO/V3ivj9lF9h/Nq8R98vaOC1ASLV8btYCzdWMKNr2sXylWvZ/QFciqCol/3sva3PYBE/67ZyLLEnv31tEtN9Eqx73nPvn2rniNQxu1g59Hq53AmVc/zqDlxstMSvbL6BvteRS8/l4rWDtzI9X2Pi/Z41WqL1tgNdu5g93/LsO4BBdhQ78PI2NZaDIGovN/q82qTkkD5gXr21doRjWO6Xbr2M4wlgd5PI88yWuOowaGw8oMXOGnbo2Ta/2r6IqMzzpEzKE4aEpWxqofnffjOS0auZ+R9DNbXRsaZkXcNxem1FvTqP9JdoFyr3Z5tGnh026Cb30gxhaQgNDQ0kJKSwttvv825557r/vzmm2/mu+++48svvwx6jlh3cjyit2uLZMcZT9c7lDnU+9oc2yZuFCfsXOOqgdiocUSOjYnZpGUwhSQD9O/fn759+zJ37lz3Z3l5eZxzzjmGHLcPRSEJordri9frHcoc6n1tjm0Tk0MDU0gywJtvvsn48eOZP38+AwcO5N///jfPPfccP/zwA126dAn6+0NVSDIxMTExMWnNxHr9PihSAFx88cXs3buXBx54gJKSEvLz81m6dKkhAcnExMTExMTERIuDQpMUKaYmycTExMTEpPVhFrg1MTExMTExMWkBTCHJxMTExMTExEQDU0gyMTExMTExMdHAFJJMTExMTExMTDQwhSQTExMTExMTEw1MIcnExMTExMTERANTSDIxMTExMTEx0eCgSCYZKWqqqKqqqhZuiYmJiYmJiYlR1HU7VikfTSEJqK6uBuDwww9v4ZaYmJiYmJiYhEp1dTWZmZlRP6+ZcRtQFIVdu3aRnp6OJEWvKGVVVRWHH344f/zxh5nJO0TMvgsPs9/Cw+y38DH7LjzMfgsP334TQlBdXU2nTp2Q5eh7EJmaJECWZQ477LCYnT8jI8N8CcLE7LvwMPstPMx+Cx+z78LD7Lfw8Oy3WGiQVEzHbRMTExMTExMTDUwhycTExMTExMREA1NIiiGJiYlMnTqVxMTElm5Kq8Psu/Aw+y08zH4LH7PvwsPst/Bo7n4zHbdNTExMTExMTDQwNUkmJiYmJiYmJhqYQpKJiYmJiYmJiQamkGRiYmJiYmJiooEpJJmYmJiYmJiYaGAKSTFk7ty5dO3alaSkJPr27ctXX33V0k1qMaZNm4YkSV7/5OTkuL8XQjBt2jQ6depEcnIyp556Kj/88IPXOerr67npppto164dqampjBkzhv/973/NfSsxZ+XKlZx99tl06tQJSZJYtGiR1/fR6quKigrGjx9PZmYmmZmZjB8/nn379sX47mJHsH678sor/cbggAEDvI45FPttxowZnHTSSaSnp9OhQwfGjh3Ljz/+6HWMOeb8MdJv5pjzZ968eRx33HHuZJADBw7k448/dn8fd2NNmMSEN954Q9hsNvHcc8+JLVu2iJtvvlmkpqaKnTt3tnTTWoSpU6eK3r17i5KSEvc/ZWVl7u9nzpwp0tPTxbvvvis2bdokLr74YpGbmyuqqqrcx1x//fWic+fOYsWKFWLDhg3itNNOE8cff7xwOBwtcUsxY+nSpeKee+4R7777rgDE+++/7/V9tPqqsLBQ5OfnizVr1og1a9aI/Px8MXr06Oa6zagTrN+uuOIKUVhY6DUG9+7d63XModhvI0eOFC+99JLYvHmz+O6778RZZ50ljjjiCLF//373MeaY88dIv5ljzp/FixeLJUuWiB9//FH8+OOP4u677xY2m01s3rxZCBF/Y80UkmJEQUGBuP76670+69Wrl7jzzjtbqEUty9SpU8Xxxx+v+Z2iKCInJ0fMnDnT/VldXZ3IzMwU8+fPF0IIsW/fPmGz2cQbb7zhPubPP/8UsiyLZcuWxbTtLYnvYh+tvtqyZYsARFFRkfuYtWvXCkBs27YtxncVe/SEpHPOOUf3N2a/uSgrKxOA+PLLL4UQ5pgzim+/CWGOOaNkZWWJ559/Pi7HmmluiwENDQ188803jBgxwuvzESNGsGbNmhZqVcvz888/06lTJ7p27coll1zCb7/9BsD27dspLS316q/ExEROOeUUd39988032O12r2M6depEfn7+IdWn0eqrtWvXkpmZSf/+/d3HDBgwgMzMzIO6P7/44gs6dOhAjx49uPbaaykrK3N/Z/abi8rKSgCys7MBc8wZxbffVMwxp4/T6eSNN97gwIEDDBw4MC7HmikkxYA9e/bgdDrp2LGj1+cdO3aktLS0hVrVsvTv358FCxawfPlynnvuOUpLSxk0aBB79+5190mg/iotLSUhIYGsrCzdYw4FotVXpaWldOjQwe/8HTp0OGj788wzz+S1117js88+44knnuDrr7/m9NNPp76+HjD7DVz+ILfeeitDhgwhPz8fMMecEbT6Dcwxp8emTZtIS0sjMTGR66+/nvfff5+8vLy4HGvWkI42CQlJkrz+FkL4fXaocOaZZ7r//9hjj2XgwIEcffTRvPzyy25HxnD661Dt02j0ldbxB3N/Xnzxxe7/z8/Pp1+/fnTp0oUlS5Zw3nnn6f7uUOq3SZMmsXHjRlatWuX3nTnm9NHrN3PMadOzZ0++++479u3bx7vvvssVV1zBl19+6f4+nsaaqUmKAe3atcNisfhJrGVlZX4S8qFKamoqxx57LD///LM7yi1Qf+Xk5NDQ0EBFRYXuMYcC0eqrnJwcdu/e7Xf+v/7665Dpz9zcXLp06cLPP/8MmP120003sXjxYj7//HMOO+ww9+fmmAuMXr9pYY45FwkJCXTr1o1+/foxY8YMjj/+eGbPnh2XY80UkmJAQkICffv2ZcWKFV6fr1ixgkGDBrVQq+KL+vp6tm7dSm5uLl27diUnJ8ervxoaGvjyyy/d/dW3b19sNpvXMSUlJWzevPmQ6tNo9dXAgQOprKykuLjYfcy6deuorKw8ZPpz7969/PHHH+Tm5gKHbr8JIZg0aRLvvfcen332GV27dvX63hxz2gTrNy3MMaeNEIL6+vr4HGshuXmbGEZNAfDCCy+ILVu2iClTpojU1FSxY8eOlm5ai3DbbbeJL774Qvz222+iqKhIjB49WqSnp7v7Y+bMmSIzM1O89957YtOmTWLcuHGaYZ+HHXaY+PTTT8WGDRvE6aefflCmAKiurhbffvut+PbbbwUgnnzySfHtt9+600dEq68KCwvFcccdJ9auXSvWrl0rjj322FYbVixE4H6rrq4Wt912m1izZo3Yvn27+Pzzz8XAgQNF586dD/l+u+GGG0RmZqb44osvvELVa2pq3MeYY86fYP1mjjlt7rrrLrFy5Uqxfft2sXHjRnH33XcLWZbFJ598IoSIv7FmCkkxZM6cOaJLly4iISFB9OnTxys09FBDzXVhs9lEp06dxHnnnSd++OEH9/eKooipU6eKnJwckZiYKIYOHSo2bdrkdY7a2loxadIkkZ2dLZKTk8Xo0aPF77//3ty3EnM+//xzAfj9c8UVVwghotdXe/fuFZdddplIT08X6enp4rLLLhMVFRXNdJfRJ1C/1dTUiBEjRoj27dsLm80mjjjiCHHFFVf49cmh2G9afQaIl156yX2MOeb8CdZv5pjT5qqrrnKvi+3btxdnnHGGW0ASIv7GmiSEEKHpnkxMTExMTExMDn5MnyQTExMTExMTEw1MIcnExMTExMTERANTSDIxMTExMTEx0cAUkkxMTExMTExMNDCFJBMTExMTExMTDUwhycTExMTExMREA1NIMjExMTExMTHRwBSSTExMDmokSWLRokUt3QwTE5NWiCkkmZiYxC1XXnklY8eObelmmJiYHKKYQpKJiYmJiYmJiQamkGRiYtIqOPXUU5k8eTK333472dnZ5OTkMG3aNK9jfv75Z4YOHUpSUhJ5eXlelcJV/vzzTy6++GKysrJo27Yt55xzDjt27ABg27ZtpKSk8Prrr7uPf++990hKSmLTpk2xvD0TE5M4xBSSTExMWg0vv/wyqamprFu3jscee4wHHnjALQgpisJ5552HxWKhqKiI+fPnc8cdd3j9vqamhtNOO420tDRWrlzJqlWrSEtLo7CwkIaGBnr16sU///lPbrzxRnbu3MmuXbu49tprmTlzJscee2xL3LKJiUkLYha4NTExiVuuvPJK9u3bx6JFizj11FNxOp189dVX7u8LCgo4/fTTmTlzJp988gmjRo1ix44dHHbYYQAsW7aMM888k/fff5+xY8fy4osv8thjj7F161YkSQKgoaGBNm3asGjRIkaMGAHA6NGjqaqqIiEhAVmWWb58uft4ExOTQwdrSzfAxMTExCjHHXec19+5ubmUlZUBsHXrVo444gi3gAQwcOBAr+O/+eYbfvnlF9LT070+r6ur49dff3X//eKLL9KjRw9kWWbz5s2mgGRicohiCkkmJiatBpvN5vW3JEkoigKAllLcV7hRFIW+ffvy2muv+R3bvn179/9///33HDhwAFmWKS0tpVOnTtFovomJSSvDFJJMTEwOCvLy8vj999/ZtWuXW6hZu3at1zF9+vThzTffpEOHDmRkZGiep7y8nCuvvJJ77rmH0tJSLrvsMjZs2EBycnLM78HExCS+MB23TUxMDgqGDRtGz549mTBhAt9//z1fffUV99xzj9cxl112Ge3ateOcc87hq6++Yvv27Xz55ZfcfPPN/O9//wPg+uuv5/DDD+fee+/lySefRAjB3//+95a4JRMTkxbGFJJMTEwOCmRZ5v3336e+vp6CggKuueYaHn74Ya9jUlJSWLlyJUcccQTnnXcexxxzDFdddRW1tbVkZGSwYMECli5dyiuvvILVaiUlJYXXXnuN559/nqVLl7bQnZmYmLQUZnSbiYmJiYmJiYkGpibJxMTExMTExEQDU0gyMTExMTExMdHAFJJMTExMTExMTDQwhSQTExMTExMTEw1MIcnExMTExMTERANTSDIxMTExMTEx0cAUkkxMTExMTExMNDCFJBMTExMTExMTDUwhycTExMTExMREA1NIMjExMTExMTHRwBSSTExMTExMTEw0MIUkExMTExMTExMN/h+60qhXJJafyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot actual vs. predicted\n",
    "# Create scatter plot\n",
    "plt.scatter(range(len(y_test)), y_test, label='Actual')\n",
    "plt.scatter(range(len(y_pred)), y_pred, label='Predicted')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Concentration')\n",
    "plt.title('Actual vs. Predicted Concentration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f739b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 1s 6ms/step - loss: 416.9805 - mse: 413.3126\n",
      "Test MSE: [416.98046875, 413.3125915527344]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30692d87",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1b815a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = nona_data[['Year_Begin', 'Month_Begin', 'Day_Begin', 'Hour_Begin']].values\n",
    "y = nona_data['Concentration'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2279b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "100078bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data to fit the LSTM model (samples, time steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a8ee4bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bro_1\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 7s 69ms/step - loss: 2967.5491 - val_loss: 4609.5674\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2781.1631 - val_loss: 4277.3276\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2506.6523 - val_loss: 3850.7944\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2207.3279 - val_loss: 3437.1274\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1952.5164 - val_loss: 3101.5562\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1755.2401 - val_loss: 2835.3877\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1601.5383 - val_loss: 2616.6001\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1477.9763 - val_loss: 2430.2844\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1374.5339 - val_loss: 2270.7878\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1287.9294 - val_loss: 2129.4607\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1213.2625 - val_loss: 2005.1134\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1149.4313 - val_loss: 1893.1771\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1094.3196 - val_loss: 1792.0157\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1046.2756 - val_loss: 1701.8149\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1004.9413 - val_loss: 1619.9385\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 969.0947 - val_loss: 1545.9762\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 938.2422 - val_loss: 1478.5022\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 911.2390 - val_loss: 1418.6461\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 888.4666 - val_loss: 1363.5751\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 868.8129 - val_loss: 1313.3800\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 851.7869 - val_loss: 1269.0431\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 837.6345 - val_loss: 1227.8851\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 825.3838 - val_loss: 1191.6042\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 815.2319 - val_loss: 1158.3074\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 806.5518 - val_loss: 1129.0238\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 799.4618 - val_loss: 1101.7710\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 793.4399 - val_loss: 1077.8215\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 788.4387 - val_loss: 1056.8156\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 784.4650 - val_loss: 1036.7501\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 781.0328 - val_loss: 1019.5887\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 778.3898 - val_loss: 1003.4924\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 776.1641 - val_loss: 989.6919\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 774.3687 - val_loss: 977.8298\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 773.0134 - val_loss: 966.3298\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 771.8309 - val_loss: 956.9083\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 770.9286 - val_loss: 948.5898\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 770.2349 - val_loss: 940.9687\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 769.6992 - val_loss: 933.4390\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 769.2306 - val_loss: 927.7507\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.9013 - val_loss: 922.4283\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.6423 - val_loss: 917.6415\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.4316 - val_loss: 913.7662\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.2805 - val_loss: 910.3010\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.1913 - val_loss: 906.6093\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0727 - val_loss: 904.9693\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0245 - val_loss: 902.0834\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9650 - val_loss: 900.3505\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9411 - val_loss: 899.0449\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9172 - val_loss: 896.4183\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8795 - val_loss: 895.4653\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8687 - val_loss: 894.3091\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8608 - val_loss: 894.0302\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8535 - val_loss: 892.7457\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8470 - val_loss: 891.8246\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8450 - val_loss: 891.5035\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8425 - val_loss: 890.8727\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8428 - val_loss: 890.1999\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8365 - val_loss: 889.9513\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8552 - val_loss: 890.9294\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8423 - val_loss: 889.6181\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8431 - val_loss: 888.6119\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8510 - val_loss: 889.5496\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8353 - val_loss: 889.6979\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8349 - val_loss: 889.2385\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8356 - val_loss: 889.2522\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8352 - val_loss: 889.0489\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8396 - val_loss: 887.9963\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8415 - val_loss: 888.8574\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8418 - val_loss: 888.0067\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8363 - val_loss: 888.2582\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8356 - val_loss: 888.4245\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8365 - val_loss: 888.6838\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8332 - val_loss: 889.0393\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8345 - val_loss: 888.5226\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8342 - val_loss: 888.6684\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8371 - val_loss: 888.1243\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8403 - val_loss: 887.6752\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8410 - val_loss: 889.2413\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8447 - val_loss: 888.2971\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8393 - val_loss: 888.2678\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8436 - val_loss: 888.4689\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8347 - val_loss: 888.0825\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8342 - val_loss: 888.2638\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8848 - val_loss: 890.1848\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8316 - val_loss: 888.5135\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8313 - val_loss: 887.9825\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8340 - val_loss: 888.1168\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8394 - val_loss: 887.2276\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8366 - val_loss: 888.0223\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8459 - val_loss: 887.4142\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8572 - val_loss: 887.3104\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8381 - val_loss: 887.9461\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8414 - val_loss: 889.1935\n",
      "Epoch 94/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8344 - val_loss: 889.1915\n",
      "Epoch 95/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8315 - val_loss: 888.6577\n",
      "Epoch 96/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8343 - val_loss: 888.1475\n",
      "Epoch 97/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8358 - val_loss: 888.6696\n",
      "Epoch 98/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8339 - val_loss: 888.3428\n",
      "Epoch 99/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8348 - val_loss: 888.2596\n",
      "Epoch 100/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8478 - val_loss: 888.7299\n",
      "Epoch 101/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8489 - val_loss: 888.5461\n",
      "Epoch 102/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8650 - val_loss: 887.3323\n",
      "Epoch 103/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8480 - val_loss: 889.0203\n",
      "Epoch 104/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8563 - val_loss: 887.1604\n",
      "Epoch 105/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8332 - val_loss: 887.9513\n",
      "Epoch 106/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8368 - val_loss: 888.7447\n",
      "Epoch 107/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8467 - val_loss: 889.4322\n",
      "Epoch 108/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8323 - val_loss: 889.0324\n",
      "Epoch 109/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8454 - val_loss: 887.2372\n",
      "Epoch 110/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8460 - val_loss: 888.8752\n",
      "Epoch 111/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8482 - val_loss: 886.9843\n",
      "Epoch 112/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8556 - val_loss: 888.9445\n",
      "Epoch 113/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8637 - val_loss: 887.2976\n",
      "Epoch 114/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8504 - val_loss: 887.0773\n",
      "Epoch 115/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8550 - val_loss: 889.6689\n",
      "Epoch 116/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8423 - val_loss: 889.4567\n",
      "Epoch 117/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8450 - val_loss: 888.5810\n",
      "Epoch 118/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8373 - val_loss: 888.1737\n",
      "Epoch 119/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8448 - val_loss: 888.4710\n",
      "Epoch 120/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8447 - val_loss: 888.8771\n",
      "Epoch 121/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8351 - val_loss: 887.4269\n",
      "Epoch 122/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8354 - val_loss: 887.7427\n",
      "Epoch 123/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8464 - val_loss: 887.7505\n",
      "Epoch 124/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8360 - val_loss: 889.1848\n",
      "Epoch 125/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8367 - val_loss: 889.4828\n",
      "Epoch 126/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8383 - val_loss: 887.6675\n",
      "Epoch 127/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8384 - val_loss: 887.9672\n",
      "Epoch 128/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8412 - val_loss: 888.0430\n",
      "Epoch 129/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8480 - val_loss: 889.3787\n",
      "Epoch 130/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8369 - val_loss: 888.4115\n",
      "Epoch 131/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8348 - val_loss: 887.4236\n",
      "Epoch 132/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8349 - val_loss: 887.6850\n",
      "Epoch 133/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8551 - val_loss: 889.0895\n",
      "Epoch 134/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8331 - val_loss: 888.7269\n",
      "Epoch 135/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8622 - val_loss: 886.8075\n",
      "Epoch 136/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8299 - val_loss: 889.0125\n",
      "Epoch 137/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8546 - val_loss: 888.2229\n",
      "Epoch 138/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8434 - val_loss: 889.6553\n",
      "Epoch 139/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8567 - val_loss: 887.3926\n",
      "Epoch 140/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8456 - val_loss: 887.2110\n",
      "Epoch 141/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8464 - val_loss: 889.6245\n",
      "Epoch 142/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8649 - val_loss: 887.2338\n",
      "Epoch 143/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8388 - val_loss: 888.5286\n",
      "Epoch 144/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9034 - val_loss: 891.5270\n",
      "Epoch 145/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8267 - val_loss: 888.8815\n",
      "Epoch 146/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8380 - val_loss: 887.5364\n",
      "Epoch 147/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8497 - val_loss: 886.5151\n",
      "Epoch 148/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8358 - val_loss: 887.0878\n",
      "Epoch 149/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8436 - val_loss: 888.6171\n",
      "Epoch 150/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8572 - val_loss: 887.4133\n",
      "Epoch 151/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8357 - val_loss: 888.4461\n",
      "Epoch 152/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8409 - val_loss: 887.6686\n",
      "Epoch 153/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8439 - val_loss: 887.3357\n",
      "Epoch 154/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8512 - val_loss: 888.9289\n",
      "Epoch 155/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8464 - val_loss: 889.5135\n",
      "Epoch 156/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8560 - val_loss: 887.9110\n",
      "Epoch 157/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8572 - val_loss: 887.4125\n",
      "Epoch 158/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8508 - val_loss: 887.8411\n",
      "Epoch 159/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8340 - val_loss: 888.1204\n",
      "Epoch 160/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8372 - val_loss: 888.5802\n",
      "Epoch 161/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8500 - val_loss: 889.5880\n",
      "Epoch 162/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8818 - val_loss: 891.1179\n",
      "Epoch 163/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8206 - val_loss: 887.8384\n",
      "Epoch 164/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8464 - val_loss: 885.8127\n",
      "Epoch 165/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8476 - val_loss: 887.2762\n",
      "Epoch 166/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8452 - val_loss: 888.9523\n",
      "Epoch 167/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8497 - val_loss: 886.9761\n",
      "Epoch 168/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8484 - val_loss: 888.5283\n",
      "Epoch 169/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8416 - val_loss: 888.8358\n",
      "Epoch 170/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8558 - val_loss: 887.2574\n",
      "Epoch 171/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8469 - val_loss: 888.5838\n",
      "Epoch 172/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8406 - val_loss: 888.4091\n",
      "Epoch 173/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8431 - val_loss: 889.6516\n",
      "Epoch 174/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8411 - val_loss: 889.8937\n",
      "Epoch 175/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8417 - val_loss: 889.0696\n",
      "Epoch 176/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8443 - val_loss: 888.3229\n",
      "Epoch 177/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8560 - val_loss: 889.1335\n",
      "Epoch 178/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8403 - val_loss: 887.2728\n",
      "Epoch 179/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8431 - val_loss: 887.2347\n",
      "Epoch 180/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8474 - val_loss: 888.9150\n",
      "Epoch 181/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8459 - val_loss: 887.6475\n",
      "Epoch 182/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8409 - val_loss: 889.9894\n",
      "Epoch 183/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8403 - val_loss: 888.4603\n",
      "Epoch 184/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8400 - val_loss: 888.1390\n",
      "Epoch 185/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8529 - val_loss: 890.6909\n",
      "Epoch 186/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8384 - val_loss: 889.4348\n",
      "Epoch 187/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8575 - val_loss: 885.5723\n",
      "Epoch 188/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8847 - val_loss: 890.0736\n",
      "Epoch 189/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8420 - val_loss: 887.4813\n",
      "Epoch 190/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8478 - val_loss: 887.5969\n",
      "Epoch 191/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8448 - val_loss: 888.1797\n",
      "Epoch 192/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8508 - val_loss: 886.3168\n",
      "Epoch 193/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8754 - val_loss: 889.1442\n",
      "Epoch 194/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8575 - val_loss: 886.4955\n",
      "Epoch 195/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8319 - val_loss: 888.4152\n",
      "Epoch 196/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8557 - val_loss: 887.8408\n",
      "Epoch 197/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8660 - val_loss: 889.5457\n",
      "Epoch 198/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8472 - val_loss: 888.6467\n",
      "Epoch 199/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8846 - val_loss: 887.9925\n",
      "Epoch 200/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8628 - val_loss: 888.2687\n",
      "Epoch 201/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8526 - val_loss: 888.6104\n",
      "Epoch 202/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8417 - val_loss: 888.6157\n",
      "Epoch 203/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8466 - val_loss: 890.0870\n",
      "Epoch 204/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8788 - val_loss: 890.8788\n",
      "Epoch 205/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8695 - val_loss: 886.5560\n",
      "Epoch 206/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8557 - val_loss: 887.2040\n",
      "Epoch 207/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8442 - val_loss: 888.8647\n",
      "Epoch 208/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8652 - val_loss: 890.9169\n",
      "Epoch 209/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8679 - val_loss: 888.7989\n",
      "Epoch 210/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9163 - val_loss: 882.8079\n",
      "Epoch 211/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8741 - val_loss: 888.8444\n",
      "Epoch 212/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8423 - val_loss: 889.9421\n",
      "Epoch 213/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8638 - val_loss: 885.5992\n",
      "Epoch 214/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8411 - val_loss: 887.1795\n",
      "Epoch 215/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8341 - val_loss: 889.1032\n",
      "Epoch 216/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8698 - val_loss: 888.1986\n",
      "Epoch 217/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8505 - val_loss: 888.1309\n",
      "Epoch 218/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8815 - val_loss: 892.3807\n",
      "Epoch 219/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8500 - val_loss: 886.5953\n",
      "Epoch 220/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8339 - val_loss: 887.9238\n",
      "Epoch 221/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8480 - val_loss: 888.5245\n",
      "Epoch 222/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8724 - val_loss: 890.5637\n",
      "Epoch 223/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8597 - val_loss: 887.0441\n",
      "Epoch 224/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8417 - val_loss: 888.4365\n",
      "Epoch 225/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8719 - val_loss: 889.5123\n",
      "Epoch 226/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8757 - val_loss: 890.2928\n",
      "Epoch 227/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8611 - val_loss: 883.7768\n",
      "Epoch 228/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8898 - val_loss: 888.1157\n",
      "Epoch 229/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8459 - val_loss: 888.6647\n",
      "Epoch 230/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8518 - val_loss: 885.8132\n",
      "Epoch 231/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8517 - val_loss: 889.5781\n",
      "Epoch 232/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8519 - val_loss: 888.1402\n",
      "Epoch 233/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8506 - val_loss: 886.9697\n",
      "Epoch 234/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8516 - val_loss: 890.3067\n",
      "Epoch 235/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8764 - val_loss: 890.1539\n",
      "Epoch 236/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8824 - val_loss: 887.5110\n",
      "Epoch 237/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8643 - val_loss: 885.6199\n",
      "Epoch 238/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8468 - val_loss: 886.9305\n",
      "Epoch 239/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8404 - val_loss: 891.5734\n",
      "Epoch 240/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8466 - val_loss: 889.7518\n",
      "Epoch 241/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9098 - val_loss: 884.3401\n",
      "Epoch 242/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8892 - val_loss: 891.9472\n",
      "Epoch 243/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8724 - val_loss: 887.6916\n",
      "Epoch 244/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8469 - val_loss: 889.4110\n",
      "Epoch 245/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8473 - val_loss: 888.5517\n",
      "Epoch 246/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8829 - val_loss: 891.0092\n",
      "Epoch 247/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8400 - val_loss: 889.0951\n",
      "Epoch 248/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8612 - val_loss: 885.2496\n",
      "Epoch 249/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8560 - val_loss: 886.6819\n",
      "Epoch 250/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8354 - val_loss: 890.3982\n",
      "Epoch 251/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8484 - val_loss: 889.6459\n",
      "Epoch 252/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8425 - val_loss: 888.9123\n",
      "Epoch 253/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8632 - val_loss: 889.6451\n",
      "Epoch 254/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8423 - val_loss: 887.5129\n",
      "Epoch 255/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0126 - val_loss: 882.6275\n",
      "Epoch 256/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8367 - val_loss: 891.5262\n",
      "Epoch 257/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8905 - val_loss: 892.7839\n",
      "Epoch 258/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8856 - val_loss: 885.9595\n",
      "Epoch 259/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9099 - val_loss: 889.8138\n",
      "Epoch 260/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9291 - val_loss: 884.1271\n",
      "Epoch 261/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8312 - val_loss: 889.2191\n",
      "Epoch 262/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9149 - val_loss: 889.5987\n",
      "Epoch 263/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8715 - val_loss: 890.7791\n",
      "Epoch 264/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9084 - val_loss: 888.5759\n",
      "Epoch 265/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8732 - val_loss: 893.6160\n",
      "Epoch 266/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8715 - val_loss: 888.6946\n",
      "Epoch 267/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8777 - val_loss: 889.2241\n",
      "Epoch 268/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8497 - val_loss: 887.3247\n",
      "Epoch 269/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8558 - val_loss: 887.6675\n",
      "Epoch 270/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8577 - val_loss: 887.8477\n",
      "Epoch 271/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8936 - val_loss: 887.4899\n",
      "Epoch 272/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8442 - val_loss: 887.7583\n",
      "Epoch 273/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8646 - val_loss: 890.4940\n",
      "Epoch 274/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8510 - val_loss: 888.6774\n",
      "Epoch 275/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9208 - val_loss: 892.0984\n",
      "Epoch 276/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8919 - val_loss: 884.3228\n",
      "Epoch 277/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8715 - val_loss: 887.8117\n",
      "Epoch 278/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8605 - val_loss: 890.9836\n",
      "Epoch 279/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8843 - val_loss: 884.0304\n",
      "Epoch 280/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8751 - val_loss: 890.0269\n",
      "Epoch 281/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8494 - val_loss: 886.8649\n",
      "Epoch 282/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8578 - val_loss: 887.6471\n",
      "Epoch 283/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8557 - val_loss: 890.5710\n",
      "Epoch 284/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9080 - val_loss: 888.7890\n",
      "Epoch 285/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8581 - val_loss: 884.7690\n",
      "Epoch 286/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8474 - val_loss: 888.2642\n",
      "Epoch 287/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8577 - val_loss: 888.3341\n",
      "Epoch 288/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8492 - val_loss: 888.7648\n",
      "Epoch 289/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8443 - val_loss: 891.2584\n",
      "Epoch 290/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9333 - val_loss: 886.2071\n",
      "Epoch 291/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8414 - val_loss: 889.0581\n",
      "Epoch 292/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8737 - val_loss: 891.1642\n",
      "Epoch 293/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8656 - val_loss: 888.9161\n",
      "Epoch 294/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8432 - val_loss: 886.7397\n",
      "Epoch 295/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8682 - val_loss: 887.6578\n",
      "Epoch 296/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8730 - val_loss: 891.8801\n",
      "Epoch 297/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8917 - val_loss: 888.5662\n",
      "Epoch 298/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8647 - val_loss: 883.6279\n",
      "Epoch 299/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8338 - val_loss: 888.4517\n",
      "Epoch 300/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8386 - val_loss: 890.6094\n",
      "Epoch 301/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8712 - val_loss: 889.1386\n",
      "Epoch 302/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8725 - val_loss: 888.8055\n",
      "Epoch 303/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8824 - val_loss: 888.9804\n",
      "Epoch 304/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8455 - val_loss: 885.0138\n",
      "Epoch 305/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8807 - val_loss: 884.8421\n",
      "Epoch 306/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8337 - val_loss: 890.4297\n",
      "Epoch 307/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8532 - val_loss: 888.1490\n",
      "Epoch 308/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8650 - val_loss: 886.9634\n",
      "Epoch 309/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9050 - val_loss: 892.6422\n",
      "Epoch 310/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8336 - val_loss: 886.4338\n",
      "Epoch 311/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8755 - val_loss: 888.9705\n",
      "Epoch 312/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9307 - val_loss: 886.4590\n",
      "Epoch 313/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9557 - val_loss: 889.2266\n",
      "Epoch 314/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8773 - val_loss: 889.9692\n",
      "Epoch 315/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8436 - val_loss: 887.8539\n",
      "Epoch 316/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8567 - val_loss: 884.8963\n",
      "Epoch 317/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8670 - val_loss: 887.7329\n",
      "Epoch 318/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8633 - val_loss: 888.9650\n",
      "Epoch 319/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8499 - val_loss: 887.8536\n",
      "Epoch 320/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9061 - val_loss: 887.3065\n",
      "Epoch 321/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8931 - val_loss: 883.3166\n",
      "Epoch 322/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9176 - val_loss: 891.9731\n",
      "Epoch 323/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8448 - val_loss: 888.4741\n",
      "Epoch 324/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8698 - val_loss: 886.3985\n",
      "Epoch 325/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8665 - val_loss: 886.4087\n",
      "Epoch 326/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8550 - val_loss: 888.9630\n",
      "Epoch 327/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8513 - val_loss: 887.0560\n",
      "Epoch 328/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8916 - val_loss: 887.6577\n",
      "Epoch 329/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8303 - val_loss: 890.5305\n",
      "Epoch 330/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8913 - val_loss: 891.3248\n",
      "Epoch 331/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8779 - val_loss: 890.4718\n",
      "Epoch 332/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8252 - val_loss: 885.9823\n",
      "Epoch 333/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8821 - val_loss: 884.5487\n",
      "Epoch 334/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 768.0098 - val_loss: 891.0070\n",
      "Epoch 335/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8488 - val_loss: 886.8582\n",
      "Epoch 336/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8505 - val_loss: 888.6419\n",
      "Epoch 337/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8419 - val_loss: 887.5480\n",
      "Epoch 338/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8671 - val_loss: 886.0015\n",
      "Epoch 339/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8706 - val_loss: 890.7828\n",
      "Epoch 340/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8780 - val_loss: 885.0233\n",
      "Epoch 341/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8951 - val_loss: 887.3696\n",
      "Epoch 342/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8797 - val_loss: 889.8361\n",
      "Epoch 343/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8586 - val_loss: 888.5874\n",
      "Epoch 344/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8735 - val_loss: 889.1084\n",
      "Epoch 345/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9338 - val_loss: 888.2830\n",
      "Epoch 346/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8864 - val_loss: 886.4684\n",
      "Epoch 347/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8533 - val_loss: 891.0873\n",
      "Epoch 348/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8952 - val_loss: 886.5724\n",
      "Epoch 349/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9299 - val_loss: 886.2421\n",
      "Epoch 350/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8417 - val_loss: 888.7523\n",
      "Epoch 351/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8624 - val_loss: 887.6628\n",
      "Epoch 352/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8890 - val_loss: 889.5132\n",
      "Epoch 353/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8477 - val_loss: 886.5739\n",
      "Epoch 354/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8712 - val_loss: 887.6135\n",
      "Epoch 355/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8813 - val_loss: 892.1542\n",
      "Epoch 356/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8680 - val_loss: 888.9786\n",
      "Epoch 357/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8479 - val_loss: 888.6270\n",
      "Epoch 358/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8759 - val_loss: 885.8578\n",
      "Epoch 359/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8622 - val_loss: 890.4026\n",
      "Epoch 360/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8742 - val_loss: 886.2964\n",
      "Epoch 361/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9073 - val_loss: 891.4830\n",
      "Epoch 362/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8698 - val_loss: 884.6124\n",
      "Epoch 363/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8472 - val_loss: 890.0604\n",
      "Epoch 364/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8815 - val_loss: 885.7687\n",
      "Epoch 365/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8802 - val_loss: 891.9551\n",
      "Epoch 366/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8785 - val_loss: 889.4785\n",
      "Epoch 367/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8764 - val_loss: 885.8972\n",
      "Epoch 368/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8705 - val_loss: 888.5566\n",
      "Epoch 369/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8429 - val_loss: 888.3595\n",
      "Epoch 370/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8534 - val_loss: 887.6090\n",
      "Epoch 371/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8716 - val_loss: 887.4496\n",
      "Epoch 372/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8525 - val_loss: 889.1451\n",
      "Epoch 373/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8870 - val_loss: 893.7929\n",
      "Epoch 374/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9190 - val_loss: 887.0010\n",
      "Epoch 375/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8802 - val_loss: 887.5177\n",
      "Epoch 376/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8907 - val_loss: 890.5197\n",
      "Epoch 377/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8475 - val_loss: 887.2581\n",
      "Epoch 378/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8642 - val_loss: 884.4038\n",
      "Epoch 379/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8386 - val_loss: 888.2047\n",
      "Epoch 380/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8975 - val_loss: 892.5197\n",
      "Epoch 381/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8280 - val_loss: 887.1005\n",
      "Epoch 382/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8625 - val_loss: 884.2601\n",
      "Epoch 383/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8787 - val_loss: 887.0028\n",
      "Epoch 384/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8768 - val_loss: 886.2110\n",
      "Epoch 385/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9534 - val_loss: 891.0295\n",
      "Epoch 386/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8746 - val_loss: 885.9913\n",
      "Epoch 387/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8942 - val_loss: 891.1976\n",
      "Epoch 388/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8687 - val_loss: 890.0838\n",
      "Epoch 389/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9016 - val_loss: 886.7438\n",
      "Epoch 390/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 768.1227 - val_loss: 880.7197\n",
      "Epoch 391/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8349 - val_loss: 893.5447\n",
      "Epoch 392/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9468 - val_loss: 892.3008\n",
      "Epoch 393/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8385 - val_loss: 887.2295\n",
      "Epoch 394/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8900 - val_loss: 888.3772\n",
      "Epoch 395/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9024 - val_loss: 889.5558\n",
      "Epoch 396/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8901 - val_loss: 887.2526\n",
      "Epoch 397/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8880 - val_loss: 891.2735\n",
      "Epoch 398/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8884 - val_loss: 887.1035\n",
      "Epoch 399/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8694 - val_loss: 886.3350\n",
      "Epoch 400/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8653 - val_loss: 891.5717\n",
      "Epoch 401/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8439 - val_loss: 886.3168\n",
      "Epoch 402/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8853 - val_loss: 885.6274\n",
      "Epoch 403/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8527 - val_loss: 890.7750\n",
      "Epoch 404/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8563 - val_loss: 886.1210\n",
      "Epoch 405/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8911 - val_loss: 892.0574\n",
      "Epoch 406/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8514 - val_loss: 888.9313\n",
      "Epoch 407/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8331 - val_loss: 884.6145\n",
      "Epoch 408/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8605 - val_loss: 887.7521\n",
      "Epoch 409/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8629 - val_loss: 890.4545\n",
      "Epoch 410/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8818 - val_loss: 888.7209\n",
      "Epoch 411/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8625 - val_loss: 886.3616\n",
      "Epoch 412/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8878 - val_loss: 887.4312\n",
      "Epoch 413/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8525 - val_loss: 889.5464\n",
      "Epoch 414/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8782 - val_loss: 890.3704\n",
      "Epoch 415/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9121 - val_loss: 884.9556\n",
      "Epoch 416/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8517 - val_loss: 886.8011\n",
      "Epoch 417/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9380 - val_loss: 888.2761\n",
      "Epoch 418/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8454 - val_loss: 886.0281\n",
      "Epoch 419/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8966 - val_loss: 892.5468\n",
      "Epoch 420/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8501 - val_loss: 887.3328\n",
      "Epoch 421/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8818 - val_loss: 887.5342\n",
      "Epoch 422/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8647 - val_loss: 885.3754\n",
      "Epoch 423/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9067 - val_loss: 887.9944\n",
      "Epoch 424/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8655 - val_loss: 884.4100\n",
      "Epoch 425/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8962 - val_loss: 891.3986\n",
      "Epoch 426/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8953 - val_loss: 887.6708\n",
      "Epoch 427/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9340 - val_loss: 891.8042\n",
      "Epoch 428/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9143 - val_loss: 886.9734\n",
      "Epoch 429/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8535 - val_loss: 887.7864\n",
      "Epoch 430/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8942 - val_loss: 892.1933\n",
      "Epoch 431/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8439 - val_loss: 887.5861\n",
      "Epoch 432/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8837 - val_loss: 885.8641\n",
      "Epoch 433/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8453 - val_loss: 889.5266\n",
      "Epoch 434/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8685 - val_loss: 890.8802\n",
      "Epoch 435/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9167 - val_loss: 884.4179\n",
      "Epoch 436/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9500 - val_loss: 891.5427\n",
      "Epoch 437/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8325 - val_loss: 887.3309\n",
      "Epoch 438/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8458 - val_loss: 884.8434\n",
      "Epoch 439/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8547 - val_loss: 887.4543\n",
      "Epoch 440/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8566 - val_loss: 888.7591\n",
      "Epoch 441/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8923 - val_loss: 890.0701\n",
      "Epoch 442/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9294 - val_loss: 883.1439\n",
      "Epoch 443/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8550 - val_loss: 887.9058\n",
      "Epoch 444/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8549 - val_loss: 890.8229\n",
      "Epoch 445/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8732 - val_loss: 888.7632\n",
      "Epoch 446/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.1474 - val_loss: 882.0816\n",
      "Epoch 447/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8132 - val_loss: 894.5870\n",
      "Epoch 448/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9059 - val_loss: 894.4595\n",
      "Epoch 449/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9733 - val_loss: 884.8908\n",
      "Epoch 450/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8866 - val_loss: 893.9811\n",
      "Epoch 451/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8652 - val_loss: 886.8862\n",
      "Epoch 452/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8623 - val_loss: 888.6081\n",
      "Epoch 453/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8536 - val_loss: 885.4940\n",
      "Epoch 454/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8457 - val_loss: 887.9445\n",
      "Epoch 455/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8882 - val_loss: 888.0859\n",
      "Epoch 456/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8696 - val_loss: 890.0521\n",
      "Epoch 457/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8788 - val_loss: 887.7962\n",
      "Epoch 458/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8542 - val_loss: 889.4714\n",
      "Epoch 459/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8703 - val_loss: 886.4729\n",
      "Epoch 460/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8396 - val_loss: 888.8370\n",
      "Epoch 461/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8746 - val_loss: 891.1253\n",
      "Epoch 462/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9647 - val_loss: 884.2761\n",
      "Epoch 463/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8481 - val_loss: 889.4796\n",
      "Epoch 464/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8801 - val_loss: 889.0584\n",
      "Epoch 465/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8749 - val_loss: 891.5035\n",
      "Epoch 466/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9009 - val_loss: 892.1201\n",
      "Epoch 467/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8655 - val_loss: 890.7986\n",
      "Epoch 468/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8678 - val_loss: 887.8527\n",
      "Epoch 469/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8571 - val_loss: 886.2073\n",
      "Epoch 470/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8462 - val_loss: 887.6053\n",
      "Epoch 471/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9028 - val_loss: 890.5140\n",
      "Epoch 472/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9178 - val_loss: 887.6468\n",
      "Epoch 473/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8818 - val_loss: 890.6997\n",
      "Epoch 474/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8777 - val_loss: 891.5494\n",
      "Epoch 475/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8245 - val_loss: 886.4266\n",
      "Epoch 476/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9365 - val_loss: 884.7946\n",
      "Epoch 477/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8611 - val_loss: 891.5565\n",
      "Epoch 478/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9183 - val_loss: 883.4506\n",
      "Epoch 479/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9370 - val_loss: 894.3726\n",
      "Epoch 480/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8344 - val_loss: 886.9645\n",
      "Epoch 481/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8729 - val_loss: 889.9919\n",
      "Epoch 482/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8643 - val_loss: 888.5993\n",
      "Epoch 483/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8597 - val_loss: 887.1135\n",
      "Epoch 484/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8505 - val_loss: 885.2339\n",
      "Epoch 485/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9169 - val_loss: 886.0828\n",
      "Epoch 486/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9072 - val_loss: 888.5375\n",
      "Epoch 487/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8538 - val_loss: 885.9307\n",
      "Epoch 488/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8585 - val_loss: 889.0533\n",
      "Epoch 489/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8521 - val_loss: 889.5868\n",
      "Epoch 490/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8538 - val_loss: 888.2415\n",
      "Epoch 491/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8648 - val_loss: 889.5457\n",
      "Epoch 492/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8893 - val_loss: 884.6473\n",
      "Epoch 493/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8391 - val_loss: 889.2063\n",
      "Epoch 494/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8628 - val_loss: 886.6650\n",
      "Epoch 495/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8962 - val_loss: 885.8712\n",
      "Epoch 496/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9373 - val_loss: 893.1891\n",
      "Epoch 497/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0112 - val_loss: 884.2059\n",
      "Epoch 498/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8624 - val_loss: 891.2574\n",
      "Epoch 499/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8696 - val_loss: 892.1862\n",
      "Epoch 500/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8447 - val_loss: 888.5860\n",
      "Epoch 501/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8926 - val_loss: 887.8445\n",
      "Epoch 502/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8473 - val_loss: 888.2712\n",
      "Epoch 503/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8586 - val_loss: 886.3151\n",
      "Epoch 504/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9055 - val_loss: 891.7537\n",
      "Epoch 505/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9218 - val_loss: 882.8583\n",
      "Epoch 506/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9045 - val_loss: 889.7548\n",
      "Epoch 507/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8657 - val_loss: 884.9018\n",
      "Epoch 508/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9005 - val_loss: 886.2698\n",
      "Epoch 509/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9052 - val_loss: 891.8871\n",
      "Epoch 510/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9352 - val_loss: 884.0959\n",
      "Epoch 511/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8372 - val_loss: 889.7585\n",
      "Epoch 512/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9038 - val_loss: 893.2675\n",
      "Epoch 513/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8513 - val_loss: 885.4225\n",
      "Epoch 514/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8889 - val_loss: 883.6791\n",
      "Epoch 515/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9318 - val_loss: 893.5687\n",
      "Epoch 516/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8326 - val_loss: 888.7155\n",
      "Epoch 517/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9271 - val_loss: 883.1807\n",
      "Epoch 518/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8430 - val_loss: 887.8486\n",
      "Epoch 519/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8741 - val_loss: 892.4874\n",
      "Epoch 520/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8792 - val_loss: 888.3762\n",
      "Epoch 521/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8600 - val_loss: 890.9716\n",
      "Epoch 522/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8745 - val_loss: 887.4520\n",
      "Epoch 523/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8834 - val_loss: 886.7659\n",
      "Epoch 524/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8682 - val_loss: 891.5710\n",
      "Epoch 525/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9038 - val_loss: 889.5571\n",
      "Epoch 526/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9326 - val_loss: 891.1863\n",
      "Epoch 527/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8473 - val_loss: 887.5967\n",
      "Epoch 528/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8615 - val_loss: 884.2808\n",
      "Epoch 529/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9013 - val_loss: 890.5071\n",
      "Epoch 530/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8757 - val_loss: 886.4305\n",
      "Epoch 531/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8995 - val_loss: 892.1596\n",
      "Epoch 532/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8745 - val_loss: 886.0085\n",
      "Epoch 533/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8646 - val_loss: 888.0647\n",
      "Epoch 534/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9107 - val_loss: 886.6738\n",
      "Epoch 535/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8527 - val_loss: 888.8583\n",
      "Epoch 536/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8900 - val_loss: 888.2140\n",
      "Epoch 537/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9066 - val_loss: 892.3431\n",
      "Epoch 538/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8482 - val_loss: 889.4935\n",
      "Epoch 539/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9350 - val_loss: 884.2583\n",
      "Epoch 540/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8643 - val_loss: 890.6582\n",
      "Epoch 541/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8600 - val_loss: 885.5292\n",
      "Epoch 542/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8638 - val_loss: 885.8613\n",
      "Epoch 543/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8517 - val_loss: 888.1345\n",
      "Epoch 544/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8646 - val_loss: 891.3694\n",
      "Epoch 545/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8837 - val_loss: 889.1506\n",
      "Epoch 546/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8616 - val_loss: 891.6088\n",
      "Epoch 547/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9606 - val_loss: 887.7397\n",
      "Epoch 548/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8433 - val_loss: 883.8673\n",
      "Epoch 549/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8488 - val_loss: 887.5028\n",
      "Epoch 550/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8705 - val_loss: 885.3099\n",
      "Epoch 551/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9744 - val_loss: 895.1057\n",
      "Epoch 552/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8329 - val_loss: 888.5991\n",
      "Epoch 553/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8547 - val_loss: 885.8215\n",
      "Epoch 554/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0062 - val_loss: 884.2403\n",
      "Epoch 555/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8969 - val_loss: 891.5986\n",
      "Epoch 556/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8505 - val_loss: 887.9257\n",
      "Epoch 557/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8666 - val_loss: 888.9254\n",
      "Epoch 558/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8494 - val_loss: 890.8704\n",
      "Epoch 559/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8614 - val_loss: 890.3939\n",
      "Epoch 560/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8884 - val_loss: 886.3786\n",
      "Epoch 561/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8935 - val_loss: 887.6613\n",
      "Epoch 562/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8510 - val_loss: 889.1371\n",
      "Epoch 563/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8555 - val_loss: 890.1999\n",
      "Epoch 564/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8546 - val_loss: 889.5884\n",
      "Epoch 565/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8503 - val_loss: 889.9224\n",
      "Epoch 566/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8445 - val_loss: 886.4582\n",
      "Epoch 567/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8745 - val_loss: 884.6481\n",
      "Epoch 568/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8558 - val_loss: 888.4993\n",
      "Epoch 569/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8693 - val_loss: 888.1962\n",
      "Epoch 570/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9410 - val_loss: 884.1547\n",
      "Epoch 571/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8559 - val_loss: 890.4033\n",
      "Epoch 572/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8954 - val_loss: 888.5632\n",
      "Epoch 573/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8850 - val_loss: 886.6539\n",
      "Epoch 574/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9485 - val_loss: 892.9413\n",
      "Epoch 575/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8797 - val_loss: 884.8803\n",
      "Epoch 576/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8668 - val_loss: 887.7488\n",
      "Epoch 577/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8515 - val_loss: 886.5429\n",
      "Epoch 578/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9268 - val_loss: 886.4083\n",
      "Epoch 579/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8460 - val_loss: 890.1763\n",
      "Epoch 580/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8559 - val_loss: 891.0707\n",
      "Epoch 581/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8720 - val_loss: 891.0621\n",
      "Epoch 582/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8866 - val_loss: 888.3864\n",
      "Epoch 583/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8910 - val_loss: 890.1967\n",
      "Epoch 584/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9392 - val_loss: 883.3956\n",
      "Epoch 585/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8940 - val_loss: 890.6880\n",
      "Epoch 586/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8522 - val_loss: 886.8843\n",
      "Epoch 587/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9560 - val_loss: 889.0352\n",
      "Epoch 588/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8420 - val_loss: 885.6630\n",
      "Epoch 589/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8555 - val_loss: 886.8044\n",
      "Epoch 590/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9104 - val_loss: 889.0433\n",
      "Epoch 591/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8792 - val_loss: 889.6645\n",
      "Epoch 592/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8484 - val_loss: 886.8226\n",
      "Epoch 593/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8775 - val_loss: 891.3599\n",
      "Epoch 594/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9557 - val_loss: 885.2279\n",
      "Epoch 595/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9031 - val_loss: 888.3035\n",
      "Epoch 596/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8593 - val_loss: 891.0472\n",
      "Epoch 597/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8475 - val_loss: 886.8787\n",
      "Epoch 598/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8518 - val_loss: 886.9413\n",
      "Epoch 599/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8418 - val_loss: 887.0456\n",
      "Epoch 600/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8503 - val_loss: 890.1747\n",
      "Epoch 601/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8444 - val_loss: 888.3101\n",
      "Epoch 602/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8508 - val_loss: 887.5542\n",
      "Epoch 603/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8820 - val_loss: 888.8628\n",
      "Epoch 604/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9429 - val_loss: 890.6434\n",
      "Epoch 605/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8582 - val_loss: 885.4014\n",
      "Epoch 606/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9017 - val_loss: 886.7826\n",
      "Epoch 607/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8477 - val_loss: 887.3799\n",
      "Epoch 608/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8582 - val_loss: 888.6496\n",
      "Epoch 609/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8807 - val_loss: 890.8069\n",
      "Epoch 610/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8948 - val_loss: 889.1956\n",
      "Epoch 611/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8788 - val_loss: 882.8176\n",
      "Epoch 612/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8478 - val_loss: 888.6108\n",
      "Epoch 613/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8978 - val_loss: 891.9930\n",
      "Epoch 614/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8988 - val_loss: 886.2538\n",
      "Epoch 615/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9112 - val_loss: 887.8760\n",
      "Epoch 616/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8528 - val_loss: 887.2033\n",
      "Epoch 617/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8510 - val_loss: 889.5321\n",
      "Epoch 618/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8746 - val_loss: 889.9579\n",
      "Epoch 619/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8626 - val_loss: 888.3951\n",
      "Epoch 620/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8705 - val_loss: 887.0122\n",
      "Epoch 621/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8901 - val_loss: 886.2432\n",
      "Epoch 622/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8661 - val_loss: 888.8129\n",
      "Epoch 623/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8392 - val_loss: 889.6519\n",
      "Epoch 624/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8715 - val_loss: 887.3007\n",
      "Epoch 625/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8574 - val_loss: 888.1940\n",
      "Epoch 626/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8692 - val_loss: 886.7888\n",
      "Epoch 627/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8567 - val_loss: 887.2829\n",
      "Epoch 628/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8456 - val_loss: 887.6260\n",
      "Epoch 629/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8457 - val_loss: 890.0731\n",
      "Epoch 630/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8553 - val_loss: 887.7473\n",
      "Epoch 631/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8618 - val_loss: 890.2845\n",
      "Epoch 632/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8729 - val_loss: 889.5297\n",
      "Epoch 633/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8817 - val_loss: 886.7120\n",
      "Epoch 634/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8564 - val_loss: 889.3915\n",
      "Epoch 635/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8659 - val_loss: 888.9551\n",
      "Epoch 636/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8850 - val_loss: 885.7686\n",
      "Epoch 637/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8777 - val_loss: 894.0605\n",
      "Epoch 638/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8871 - val_loss: 886.4489\n",
      "Epoch 639/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8416 - val_loss: 889.8400\n",
      "Epoch 640/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9258 - val_loss: 884.8132\n",
      "Epoch 641/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8363 - val_loss: 893.0758\n",
      "Epoch 642/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8759 - val_loss: 890.3757\n",
      "Epoch 643/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8501 - val_loss: 887.4775\n",
      "Epoch 644/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8634 - val_loss: 886.7592\n",
      "Epoch 645/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9290 - val_loss: 893.5334\n",
      "Epoch 646/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8676 - val_loss: 883.4943\n",
      "Epoch 647/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8585 - val_loss: 887.0852\n",
      "Epoch 648/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9152 - val_loss: 892.0808\n",
      "Epoch 649/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8497 - val_loss: 887.1047\n",
      "Epoch 650/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8740 - val_loss: 884.4246\n",
      "Epoch 651/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8655 - val_loss: 889.2277\n",
      "Epoch 652/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8547 - val_loss: 887.4547\n",
      "Epoch 653/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9194 - val_loss: 889.5619\n",
      "Epoch 654/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9546 - val_loss: 884.0511\n",
      "Epoch 655/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8572 - val_loss: 891.6449\n",
      "Epoch 656/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8627 - val_loss: 887.3203\n",
      "Epoch 657/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9206 - val_loss: 887.1510\n",
      "Epoch 658/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8464 - val_loss: 889.0075\n",
      "Epoch 659/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8496 - val_loss: 892.7905\n",
      "Epoch 660/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8765 - val_loss: 888.9444\n",
      "Epoch 661/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8878 - val_loss: 889.6498\n",
      "Epoch 662/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8483 - val_loss: 886.9760\n",
      "Epoch 663/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8586 - val_loss: 886.1306\n",
      "Epoch 664/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8439 - val_loss: 887.4242\n",
      "Epoch 665/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8387 - val_loss: 888.2224\n",
      "Epoch 666/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8521 - val_loss: 889.8754\n",
      "Epoch 667/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8745 - val_loss: 887.3863\n",
      "Epoch 668/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8937 - val_loss: 892.5663\n",
      "Epoch 669/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8466 - val_loss: 886.7751\n",
      "Epoch 670/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8727 - val_loss: 886.2075\n",
      "Epoch 671/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9592 - val_loss: 887.5892\n",
      "Epoch 672/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8843 - val_loss: 890.4098\n",
      "Epoch 673/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8762 - val_loss: 889.6263\n",
      "Epoch 674/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8682 - val_loss: 886.9681\n",
      "Epoch 675/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8701 - val_loss: 891.7669\n",
      "Epoch 676/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8940 - val_loss: 885.4967\n",
      "Epoch 677/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8504 - val_loss: 889.2477\n",
      "Epoch 678/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9498 - val_loss: 884.8801\n",
      "Epoch 679/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8174 - val_loss: 894.7101\n",
      "Epoch 680/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8755 - val_loss: 891.5690\n",
      "Epoch 681/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8545 - val_loss: 887.5076\n",
      "Epoch 682/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0016 - val_loss: 884.3011\n",
      "Epoch 683/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8459 - val_loss: 890.5486\n",
      "Epoch 684/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8942 - val_loss: 894.2833\n",
      "Epoch 685/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8800 - val_loss: 890.4958\n",
      "Epoch 686/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9328 - val_loss: 885.5819\n",
      "Epoch 687/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9553 - val_loss: 892.3610\n",
      "Epoch 688/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8788 - val_loss: 886.2939\n",
      "Epoch 689/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8632 - val_loss: 889.0322\n",
      "Epoch 690/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9195 - val_loss: 884.1805\n",
      "Epoch 691/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8772 - val_loss: 893.1817\n",
      "Epoch 692/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9365 - val_loss: 883.4329\n",
      "Epoch 693/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9124 - val_loss: 893.7688\n",
      "Epoch 694/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8641 - val_loss: 889.8491\n",
      "Epoch 695/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8301 - val_loss: 887.2408\n",
      "Epoch 696/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8784 - val_loss: 888.8393\n",
      "Epoch 697/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8636 - val_loss: 884.1801\n",
      "Epoch 698/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9293 - val_loss: 887.2853\n",
      "Epoch 699/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9366 - val_loss: 890.1289\n",
      "Epoch 700/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8497 - val_loss: 886.1011\n",
      "Epoch 701/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8761 - val_loss: 885.3638\n",
      "Epoch 702/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8693 - val_loss: 885.3068\n",
      "Epoch 703/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8820 - val_loss: 887.0953\n",
      "Epoch 704/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8390 - val_loss: 890.0183\n",
      "Epoch 705/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9431 - val_loss: 892.7850\n",
      "Epoch 706/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8498 - val_loss: 884.6345\n",
      "Epoch 707/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8783 - val_loss: 887.9135\n",
      "Epoch 708/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8723 - val_loss: 888.9401\n",
      "Epoch 709/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8657 - val_loss: 889.1442\n",
      "Epoch 710/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8485 - val_loss: 882.9697\n",
      "Epoch 711/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9365 - val_loss: 891.8033\n",
      "Epoch 712/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8489 - val_loss: 884.3154\n",
      "Epoch 713/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8925 - val_loss: 888.8672\n",
      "Epoch 714/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8553 - val_loss: 887.5932\n",
      "Epoch 715/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8572 - val_loss: 887.7590\n",
      "Epoch 716/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9509 - val_loss: 883.6627\n",
      "Epoch 717/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9385 - val_loss: 895.3197\n",
      "Epoch 718/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8547 - val_loss: 887.9445\n",
      "Epoch 719/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8810 - val_loss: 888.9725\n",
      "Epoch 720/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8353 - val_loss: 885.9655\n",
      "Epoch 721/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8641 - val_loss: 885.6300\n",
      "Epoch 722/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8848 - val_loss: 885.9875\n",
      "Epoch 723/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8445 - val_loss: 891.1160\n",
      "Epoch 724/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8469 - val_loss: 890.0055\n",
      "Epoch 725/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8573 - val_loss: 890.7660\n",
      "Epoch 726/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8394 - val_loss: 886.6262\n",
      "Epoch 727/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8972 - val_loss: 889.0795\n",
      "Epoch 728/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8597 - val_loss: 885.4988\n",
      "Epoch 729/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8542 - val_loss: 889.8574\n",
      "Epoch 730/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8847 - val_loss: 886.4252\n",
      "Epoch 731/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8532 - val_loss: 891.0250\n",
      "Epoch 732/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9285 - val_loss: 890.8900\n",
      "Epoch 733/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0195 - val_loss: 881.7215\n",
      "Epoch 734/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8859 - val_loss: 892.2944\n",
      "Epoch 735/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8676 - val_loss: 887.8145\n",
      "Epoch 736/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8430 - val_loss: 887.5811\n",
      "Epoch 737/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8541 - val_loss: 887.3445\n",
      "Epoch 738/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8633 - val_loss: 888.2426\n",
      "Epoch 739/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8568 - val_loss: 889.9405\n",
      "Epoch 740/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8964 - val_loss: 890.0967\n",
      "Epoch 741/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8726 - val_loss: 889.6199\n",
      "Epoch 742/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9339 - val_loss: 893.8411\n",
      "Epoch 743/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9133 - val_loss: 887.5548\n",
      "Epoch 744/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8882 - val_loss: 889.5225\n",
      "Epoch 745/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9084 - val_loss: 886.2512\n",
      "Epoch 746/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8390 - val_loss: 887.7705\n",
      "Epoch 747/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8694 - val_loss: 891.9863\n",
      "Epoch 748/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8964 - val_loss: 887.2762\n",
      "Epoch 749/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8665 - val_loss: 890.8831\n",
      "Epoch 750/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8903 - val_loss: 884.9626\n",
      "Epoch 751/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9288 - val_loss: 889.6191\n",
      "Epoch 752/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8815 - val_loss: 886.6902\n",
      "Epoch 753/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8720 - val_loss: 889.7074\n",
      "Epoch 754/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8729 - val_loss: 891.5257\n",
      "Epoch 755/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8972 - val_loss: 884.3784\n",
      "Epoch 756/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8495 - val_loss: 891.5614\n",
      "Epoch 757/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8484 - val_loss: 890.3537\n",
      "Epoch 758/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9229 - val_loss: 886.5357\n",
      "Epoch 759/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8861 - val_loss: 889.6464\n",
      "Epoch 760/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8471 - val_loss: 890.8334\n",
      "Epoch 761/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8568 - val_loss: 888.7237\n",
      "Epoch 762/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8607 - val_loss: 888.7867\n",
      "Epoch 763/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8976 - val_loss: 888.6402\n",
      "Epoch 764/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8568 - val_loss: 887.9669\n",
      "Epoch 765/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8461 - val_loss: 888.7213\n",
      "Epoch 766/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9008 - val_loss: 894.1039\n",
      "Epoch 767/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8956 - val_loss: 885.1680\n",
      "Epoch 768/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8381 - val_loss: 887.2628\n",
      "Epoch 769/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.8920 - val_loss: 892.2704\n",
      "Epoch 770/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8685 - val_loss: 886.2051\n",
      "Epoch 771/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8563 - val_loss: 887.2125\n",
      "Epoch 772/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9857 - val_loss: 891.9684\n",
      "Epoch 773/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8854 - val_loss: 883.0121\n",
      "Epoch 774/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8597 - val_loss: 885.7097\n",
      "Epoch 775/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8862 - val_loss: 893.1295\n",
      "Epoch 776/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8567 - val_loss: 886.8829\n",
      "Epoch 777/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8466 - val_loss: 889.7153\n",
      "Epoch 778/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8959 - val_loss: 889.2461\n",
      "Epoch 779/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8697 - val_loss: 887.0104\n",
      "Epoch 780/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8674 - val_loss: 890.1176\n",
      "Epoch 781/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8777 - val_loss: 887.5338\n",
      "Epoch 782/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8571 - val_loss: 888.0126\n",
      "Epoch 783/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8757 - val_loss: 885.4392\n",
      "Epoch 784/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8656 - val_loss: 888.1588\n",
      "Epoch 785/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9140 - val_loss: 890.4517\n",
      "Epoch 786/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8566 - val_loss: 888.2335\n",
      "Epoch 787/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8402 - val_loss: 888.4621\n",
      "Epoch 788/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8779 - val_loss: 890.2227\n",
      "Epoch 789/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8556 - val_loss: 886.9528\n",
      "Epoch 790/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8687 - val_loss: 886.5657\n",
      "Epoch 791/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8365 - val_loss: 888.2158\n",
      "Epoch 792/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8727 - val_loss: 891.8384\n",
      "Epoch 793/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8999 - val_loss: 887.9122\n",
      "Epoch 794/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8801 - val_loss: 888.4990\n",
      "Epoch 795/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8664 - val_loss: 885.1314\n",
      "Epoch 796/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9642 - val_loss: 892.5588\n",
      "Epoch 797/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9862 - val_loss: 882.6597\n",
      "Epoch 798/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8432 - val_loss: 892.7331\n",
      "Epoch 799/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0344 - val_loss: 885.6818\n",
      "Epoch 800/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8357 - val_loss: 890.7704\n",
      "Epoch 801/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8893 - val_loss: 889.9652\n",
      "Epoch 802/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9068 - val_loss: 892.1306\n",
      "Epoch 803/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8655 - val_loss: 885.8716\n",
      "Epoch 804/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9212 - val_loss: 892.2128\n",
      "Epoch 805/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8626 - val_loss: 887.3516\n",
      "Epoch 806/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8792 - val_loss: 888.8302\n",
      "Epoch 807/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8850 - val_loss: 886.7122\n",
      "Epoch 808/1000\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 767.8477 - val_loss: 887.6711\n",
      "Epoch 809/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8713 - val_loss: 890.5518\n",
      "Epoch 810/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8272 - val_loss: 886.6254\n",
      "Epoch 811/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8770 - val_loss: 885.5454\n",
      "Epoch 812/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8589 - val_loss: 887.2803\n",
      "Epoch 813/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8563 - val_loss: 891.1923\n",
      "Epoch 814/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8646 - val_loss: 887.8753\n",
      "Epoch 815/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8459 - val_loss: 887.5599\n",
      "Epoch 816/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8698 - val_loss: 886.4153\n",
      "Epoch 817/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8990 - val_loss: 893.5400\n",
      "Epoch 818/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8546 - val_loss: 890.0435\n",
      "Epoch 819/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8424 - val_loss: 886.7639\n",
      "Epoch 820/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8484 - val_loss: 886.0543\n",
      "Epoch 821/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9109 - val_loss: 888.5624\n",
      "Epoch 822/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8942 - val_loss: 887.1315\n",
      "Epoch 823/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8894 - val_loss: 887.7104\n",
      "Epoch 824/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8845 - val_loss: 888.8061\n",
      "Epoch 825/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8805 - val_loss: 884.8943\n",
      "Epoch 826/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9869 - val_loss: 893.0714\n",
      "Epoch 827/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9553 - val_loss: 885.4421\n",
      "Epoch 828/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9574 - val_loss: 890.9910\n",
      "Epoch 829/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8555 - val_loss: 884.6538\n",
      "Epoch 830/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8859 - val_loss: 883.7373\n",
      "Epoch 831/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8698 - val_loss: 890.9493\n",
      "Epoch 832/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8660 - val_loss: 887.3989\n",
      "Epoch 833/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8713 - val_loss: 890.8258\n",
      "Epoch 834/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9258 - val_loss: 883.4398\n",
      "Epoch 835/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8696 - val_loss: 889.0057\n",
      "Epoch 836/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8726 - val_loss: 895.0163\n",
      "Epoch 837/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8489 - val_loss: 889.5668\n",
      "Epoch 838/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8616 - val_loss: 884.4407\n",
      "Epoch 839/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8393 - val_loss: 889.3655\n",
      "Epoch 840/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8492 - val_loss: 888.9972\n",
      "Epoch 841/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8613 - val_loss: 886.5991\n",
      "Epoch 842/1000\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 767.8391 - val_loss: 889.6625\n",
      "Epoch 843/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8746 - val_loss: 893.1080\n",
      "Epoch 844/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8752 - val_loss: 883.5715\n",
      "Epoch 845/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8599 - val_loss: 890.0315\n",
      "Epoch 846/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9266 - val_loss: 888.1275\n",
      "Epoch 847/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8513 - val_loss: 885.7183\n",
      "Epoch 848/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9286 - val_loss: 888.3130\n",
      "Epoch 849/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8835 - val_loss: 883.9732\n",
      "Epoch 850/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8908 - val_loss: 889.6495\n",
      "Epoch 851/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8578 - val_loss: 890.9594\n",
      "Epoch 852/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8648 - val_loss: 889.7730\n",
      "Epoch 853/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8584 - val_loss: 887.5983\n",
      "Epoch 854/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8519 - val_loss: 888.0874\n",
      "Epoch 855/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8923 - val_loss: 890.5697\n",
      "Epoch 856/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8994 - val_loss: 885.3394\n",
      "Epoch 857/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8786 - val_loss: 888.7568\n",
      "Epoch 858/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9344 - val_loss: 893.4995\n",
      "Epoch 859/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8545 - val_loss: 890.5768\n",
      "Epoch 860/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9147 - val_loss: 883.4904\n",
      "Epoch 861/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8787 - val_loss: 890.4851\n",
      "Epoch 862/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8582 - val_loss: 887.5565\n",
      "Epoch 863/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9306 - val_loss: 893.2543\n",
      "Epoch 864/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8768 - val_loss: 884.2371\n",
      "Epoch 865/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8813 - val_loss: 886.9465\n",
      "Epoch 866/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8445 - val_loss: 888.1147\n",
      "Epoch 867/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8585 - val_loss: 889.1587\n",
      "Epoch 868/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9337 - val_loss: 885.6588\n",
      "Epoch 869/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9376 - val_loss: 892.2042\n",
      "Epoch 870/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8877 - val_loss: 887.2309\n",
      "Epoch 871/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8386 - val_loss: 889.3007\n",
      "Epoch 872/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8576 - val_loss: 888.9925\n",
      "Epoch 873/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8831 - val_loss: 888.4990\n",
      "Epoch 874/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8687 - val_loss: 884.9909\n",
      "Epoch 875/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9201 - val_loss: 886.4818\n",
      "Epoch 876/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8829 - val_loss: 893.8140\n",
      "Epoch 877/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9864 - val_loss: 885.0281\n",
      "Epoch 878/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9923 - val_loss: 893.3492\n",
      "Epoch 879/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9116 - val_loss: 886.1664\n",
      "Epoch 880/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9031 - val_loss: 890.9713\n",
      "Epoch 881/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8653 - val_loss: 885.0331\n",
      "Epoch 882/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8528 - val_loss: 887.0468\n",
      "Epoch 883/1000\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 767.8609 - val_loss: 891.2318\n",
      "Epoch 884/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8469 - val_loss: 889.4454\n",
      "Epoch 885/1000\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 767.8898 - val_loss: 887.3521\n",
      "Epoch 886/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8515 - val_loss: 888.0176\n",
      "Epoch 887/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8665 - val_loss: 889.5476\n",
      "Epoch 888/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8531 - val_loss: 889.5070\n",
      "Epoch 889/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9822 - val_loss: 883.6340\n",
      "Epoch 890/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8504 - val_loss: 891.8514\n",
      "Epoch 891/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8734 - val_loss: 888.8995\n",
      "Epoch 892/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9331 - val_loss: 886.2019\n",
      "Epoch 893/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9466 - val_loss: 894.2126\n",
      "Epoch 894/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8956 - val_loss: 885.7783\n",
      "Epoch 895/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9177 - val_loss: 890.7056\n",
      "Epoch 896/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8619 - val_loss: 885.0431\n",
      "Epoch 897/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8664 - val_loss: 888.9801\n",
      "Epoch 898/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8486 - val_loss: 886.6881\n",
      "Epoch 899/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8854 - val_loss: 888.5378\n",
      "Epoch 900/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8585 - val_loss: 887.4450\n",
      "Epoch 901/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8522 - val_loss: 887.1205\n",
      "Epoch 902/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8544 - val_loss: 890.2853\n",
      "Epoch 903/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8644 - val_loss: 890.6904\n",
      "Epoch 904/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8990 - val_loss: 886.9338\n",
      "Epoch 905/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8572 - val_loss: 887.8398\n",
      "Epoch 906/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8324 - val_loss: 890.9014\n",
      "Epoch 907/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8977 - val_loss: 887.8592\n",
      "Epoch 908/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8602 - val_loss: 890.9929\n",
      "Epoch 909/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9711 - val_loss: 889.5728\n",
      "Epoch 910/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8873 - val_loss: 885.2031\n",
      "Epoch 911/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8941 - val_loss: 882.2426\n",
      "Epoch 912/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8547 - val_loss: 889.3570\n",
      "Epoch 913/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8797 - val_loss: 890.4597\n",
      "Epoch 914/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8776 - val_loss: 888.2150\n",
      "Epoch 915/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8698 - val_loss: 889.4843\n",
      "Epoch 916/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 767.9854 - val_loss: 884.1660\n",
      "Epoch 917/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8692 - val_loss: 892.3481\n",
      "Epoch 918/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8731 - val_loss: 888.2935\n",
      "Epoch 919/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8654 - val_loss: 887.0070\n",
      "Epoch 920/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8454 - val_loss: 888.9387\n",
      "Epoch 921/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8692 - val_loss: 890.0196\n",
      "Epoch 922/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8660 - val_loss: 887.4346\n",
      "Epoch 923/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8498 - val_loss: 888.5821\n",
      "Epoch 924/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8582 - val_loss: 887.5166\n",
      "Epoch 925/1000\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 767.8644 - val_loss: 886.2100\n",
      "Epoch 926/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8696 - val_loss: 889.7150\n",
      "Epoch 927/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8914 - val_loss: 885.6860\n",
      "Epoch 928/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9417 - val_loss: 892.6618\n",
      "Epoch 929/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.9901 - val_loss: 884.1935\n",
      "Epoch 930/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8370 - val_loss: 889.5001\n",
      "Epoch 931/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8574 - val_loss: 888.6062\n",
      "Epoch 932/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8478 - val_loss: 890.6794\n",
      "Epoch 933/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8452 - val_loss: 888.3046\n",
      "Epoch 934/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9438 - val_loss: 889.6796\n",
      "Epoch 935/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8534 - val_loss: 884.8818\n",
      "Epoch 936/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8715 - val_loss: 885.6187\n",
      "Epoch 937/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8455 - val_loss: 890.0410\n",
      "Epoch 938/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8646 - val_loss: 891.2751\n",
      "Epoch 939/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9030 - val_loss: 883.2032\n",
      "Epoch 940/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8553 - val_loss: 890.5635\n",
      "Epoch 941/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9341 - val_loss: 888.4676\n",
      "Epoch 942/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9026 - val_loss: 891.7526\n",
      "Epoch 943/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8749 - val_loss: 885.5690\n",
      "Epoch 944/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8588 - val_loss: 885.5991\n",
      "Epoch 945/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8463 - val_loss: 887.8796\n",
      "Epoch 946/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8960 - val_loss: 889.3830\n",
      "Epoch 947/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9073 - val_loss: 886.3074\n",
      "Epoch 948/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8673 - val_loss: 891.8140\n",
      "Epoch 949/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8595 - val_loss: 888.8502\n",
      "Epoch 950/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8358 - val_loss: 888.3380\n",
      "Epoch 951/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8773 - val_loss: 889.6276\n",
      "Epoch 952/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8663 - val_loss: 885.3132\n",
      "Epoch 953/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8801 - val_loss: 887.8358\n",
      "Epoch 954/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8661 - val_loss: 886.0963\n",
      "Epoch 955/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8988 - val_loss: 884.7097\n",
      "Epoch 956/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8488 - val_loss: 891.8489\n",
      "Epoch 957/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9730 - val_loss: 893.4017\n",
      "Epoch 958/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8744 - val_loss: 885.3599\n",
      "Epoch 959/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8702 - val_loss: 886.8137\n",
      "Epoch 960/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8844 - val_loss: 891.6500\n",
      "Epoch 961/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 768.0109 - val_loss: 888.1031\n",
      "Epoch 962/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8614 - val_loss: 887.4916\n",
      "Epoch 963/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8384 - val_loss: 889.5458\n",
      "Epoch 964/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8667 - val_loss: 891.2311\n",
      "Epoch 965/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8952 - val_loss: 890.0709\n",
      "Epoch 966/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8956 - val_loss: 885.0582\n",
      "Epoch 967/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9370 - val_loss: 888.9033\n",
      "Epoch 968/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8574 - val_loss: 885.8895\n",
      "Epoch 969/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8663 - val_loss: 889.7239\n",
      "Epoch 970/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8933 - val_loss: 887.3261\n",
      "Epoch 971/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8569 - val_loss: 890.3574\n",
      "Epoch 972/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9179 - val_loss: 886.9890\n",
      "Epoch 973/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8541 - val_loss: 886.6573\n",
      "Epoch 974/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9000 - val_loss: 886.5026\n",
      "Epoch 975/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8564 - val_loss: 891.7643\n",
      "Epoch 976/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9655 - val_loss: 886.2459\n",
      "Epoch 977/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8776 - val_loss: 892.4517\n",
      "Epoch 978/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8574 - val_loss: 890.5026\n",
      "Epoch 979/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8750 - val_loss: 886.1671\n",
      "Epoch 980/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8766 - val_loss: 891.6380\n",
      "Epoch 981/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9291 - val_loss: 886.3196\n",
      "Epoch 982/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8419 - val_loss: 891.1987\n",
      "Epoch 983/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8865 - val_loss: 887.9346\n",
      "Epoch 984/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8577 - val_loss: 891.6265\n",
      "Epoch 985/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8726 - val_loss: 886.3333\n",
      "Epoch 986/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.9149 - val_loss: 891.7343\n",
      "Epoch 987/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9742 - val_loss: 883.7067\n",
      "Epoch 988/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8182 - val_loss: 888.3826\n",
      "Epoch 989/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8661 - val_loss: 891.8021\n",
      "Epoch 990/1000\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 767.8464 - val_loss: 890.5154\n",
      "Epoch 991/1000\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 767.8875 - val_loss: 888.2486\n",
      "Epoch 992/1000\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 767.9360 - val_loss: 894.8241\n",
      "Epoch 993/1000\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 767.8190 - val_loss: 887.7883\n",
      "Epoch 994/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9180 - val_loss: 885.8691\n",
      "Epoch 995/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8953 - val_loss: 888.7220\n",
      "Epoch 996/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.9041 - val_loss: 885.6422\n",
      "Epoch 997/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8479 - val_loss: 890.0978\n",
      "Epoch 998/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8854 - val_loss: 890.3391\n",
      "Epoch 999/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8664 - val_loss: 884.5755\n",
      "Epoch 1000/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 767.8699 - val_loss: 889.9692\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=500, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d70ad84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 3ms/step - loss: 961.1740\n",
      "Test MSE: 961.1740112304688\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test MSE:\", mse)\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca86346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
